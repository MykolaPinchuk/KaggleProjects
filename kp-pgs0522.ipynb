{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Outline:\n1. Load evth.\n2. Preclean data.\n3. Train-test split.\n4. Missing values.\n5. FE.\n6. Modeling.\n7. FI.\n8. predictions.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os, time, warnings, gzip, gc, random, math, shap, pickle, optuna\nfrom IPython.display import display\nfrom matplotlib_venn import venn2, venn2_circles, venn2_unweighted\nfrom matplotlib_venn import venn3, venn3_circles\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split, KFold\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, precision_recall_curve, auc\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score\nfrom sklearn.inspection import permutation_importance\nfrom category_encoders import MEstimateEncoder\nfrom xgboost import XGBClassifier\n\npd.set_option('display.max_columns', 5000)\npd.set_option('display.max_rows',200)\n\nwarnings.filterwarnings(\"ignore\")\n\n# target encoding code:\n\n### target encoding ###\n# source: https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices/notebook\n\nclass CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=4)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n","metadata":{"execution":{"iopub.status.busy":"2022-07-21T20:06:26.006282Z","iopub.execute_input":"2022-07-21T20:06:26.006667Z","iopub.status.idle":"2022-07-21T20:06:26.030496Z","shell.execute_reply.started":"2022-07-21T20:06:26.006633Z","shell.execute_reply":"2022-07-21T20:06:26.029574Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def TargetEncoderMP(train_set, test_set, feature_cols, target_col, M=5):\n    \n    \"\"\" This function implements terget encoding on train-test split with 2-fold CV\n    It relies on previously defined CrossFoldEncoder, stolen from somehwere on SO.\n    m parameter controls smoothing and is defaulted at 5 \"\"\"\n    \n    encoder = CrossFoldEncoder(MEstimateEncoder, m=M)\n    train_encoded = encoder.fit_transform(train_set, train_set[target_col], cols=feature_cols)\n    test_encoded = encoder.transform(test_set)\n\n    train_set.drop(columns=feature_cols, inplace=True)\n    test_set.drop(columns=feature_cols, inplace=True)\n    train_set = pd.concat([train_set, train_encoded], axis = 1)\n    test_set = pd.concat([test_set, test_encoded], axis = 1)\n    \n    return ([train_set, test_set])\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-21T20:06:26.256642Z","iopub.execute_input":"2022-07-21T20:06:26.256960Z","iopub.status.idle":"2022-07-21T20:06:26.269049Z","shell.execute_reply.started":"2022-07-21T20:06:26.256932Z","shell.execute_reply":"2022-07-21T20:06:26.267905Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# 1. Load data #\n\ntrain = pd.read_csv('../input/tabular-playground-series-may-2022/train.csv',\n                   skiprows=lambda i: i>0 and random.random() > 0.1)\npred = pd.read_csv('../input/tabular-playground-series-may-2022/test.csv')\ndisplay(train.shape, train.head())\n\ndisplay(train.target.value_counts())\nnum_cols = [col for col in train.columns if train[col].nunique()>10]\nnum_cols.remove('f_27')\ncat_cols = list(set(train.columns) - set(num_cols) - set(['target']))\nprint('num_cols: ', num_cols, '\\n', 'cat_cols: ', cat_cols)\ndisplay(train[num_cols].describe())\ncat_cols = list(set(train.columns) - set(num_cols) - set(['target']))\ndisplay([train[col].value_counts() for col in cat_cols])\n\n#[train[col].value_counts() for col in train.columns if train[col].nunique()<10]\n#display(train.count())","metadata":{"execution":{"iopub.status.busy":"2022-07-21T20:06:26.527941Z","iopub.execute_input":"2022-07-21T20:06:26.528524Z","iopub.status.idle":"2022-07-21T20:06:29.430446Z","shell.execute_reply.started":"2022-07-21T20:06:26.528482Z","shell.execute_reply":"2022-07-21T20:06:29.429382Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"(90540, 33)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   id      f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n0   8  0.866221  0.842351 -1.367634  1.237506  0.682962  0.845666  0.173852   \n1  18  0.922494 -0.828627  0.953987  0.835863  0.112589  2.432248  0.236815   \n2  21 -0.645481  1.060355 -1.213576 -1.319743 -0.032761  0.868289  0.082763   \n3  27 -1.814636 -1.578055 -0.164912  1.024490  0.810403  1.949860  1.704441   \n4  39  0.916766 -0.468947 -0.255398 -0.569036  0.193245  0.775350 -0.274236   \n\n   f_07  f_08  f_09  f_10  f_11  f_12  f_13  f_14  f_15  f_16  f_17  f_18  \\\n0     3     2     1     7     4     3     5     2     3     0     0     4   \n1     0     3     3     1     2     1     2     5     1     1     3     2   \n2     2     3     4     1     2     3     2     0     9     1     2     3   \n3     1     1     3     4     1     3     5     1     0     1     3     4   \n4     2     2     6     0     1     7     3     1     1     7     3     5   \n\n       f_19      f_20      f_21      f_22      f_23      f_24      f_25  \\\n0 -2.568930 -0.796303 -0.786741 -1.241121 -1.245038  1.696402  0.354545   \n1  0.594356 -0.983587 -0.789391  4.188384 -2.615815 -2.015672  7.466349   \n2 -3.408796  3.370601  0.445238 -0.305235 -4.579724 -0.982572  1.438014   \n3  1.247929 -3.367163  0.974690 -0.255284  0.086702 -2.260849  0.981560   \n4  0.593269 -1.350143 -4.503929 -0.129318 -1.132656  0.588172 -3.338356   \n\n       f_26        f_27        f_28  f_29  f_30  target  \n0 -0.541267  ACAEBADDAA  -52.223857     0     0       0  \n1  6.045183  AGBCBACCBA  448.896335     0     2       0  \n2 -1.008720  BBADDAECDC  143.101347     1     1       1  \n3 -3.270380  ACABCBCRCC   36.856304     1     1       0  \n4  0.478027  BCBDAABGCF -262.819456     1     1       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>f_00</th>\n      <th>f_01</th>\n      <th>f_02</th>\n      <th>f_03</th>\n      <th>f_04</th>\n      <th>f_05</th>\n      <th>f_06</th>\n      <th>f_07</th>\n      <th>f_08</th>\n      <th>f_09</th>\n      <th>f_10</th>\n      <th>f_11</th>\n      <th>f_12</th>\n      <th>f_13</th>\n      <th>f_14</th>\n      <th>f_15</th>\n      <th>f_16</th>\n      <th>f_17</th>\n      <th>f_18</th>\n      <th>f_19</th>\n      <th>f_20</th>\n      <th>f_21</th>\n      <th>f_22</th>\n      <th>f_23</th>\n      <th>f_24</th>\n      <th>f_25</th>\n      <th>f_26</th>\n      <th>f_27</th>\n      <th>f_28</th>\n      <th>f_29</th>\n      <th>f_30</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>0.866221</td>\n      <td>0.842351</td>\n      <td>-1.367634</td>\n      <td>1.237506</td>\n      <td>0.682962</td>\n      <td>0.845666</td>\n      <td>0.173852</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>4</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-2.568930</td>\n      <td>-0.796303</td>\n      <td>-0.786741</td>\n      <td>-1.241121</td>\n      <td>-1.245038</td>\n      <td>1.696402</td>\n      <td>0.354545</td>\n      <td>-0.541267</td>\n      <td>ACAEBADDAA</td>\n      <td>-52.223857</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>0.922494</td>\n      <td>-0.828627</td>\n      <td>0.953987</td>\n      <td>0.835863</td>\n      <td>0.112589</td>\n      <td>2.432248</td>\n      <td>0.236815</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.594356</td>\n      <td>-0.983587</td>\n      <td>-0.789391</td>\n      <td>4.188384</td>\n      <td>-2.615815</td>\n      <td>-2.015672</td>\n      <td>7.466349</td>\n      <td>6.045183</td>\n      <td>AGBCBACCBA</td>\n      <td>448.896335</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>-0.645481</td>\n      <td>1.060355</td>\n      <td>-1.213576</td>\n      <td>-1.319743</td>\n      <td>-0.032761</td>\n      <td>0.868289</td>\n      <td>0.082763</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>9</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>-3.408796</td>\n      <td>3.370601</td>\n      <td>0.445238</td>\n      <td>-0.305235</td>\n      <td>-4.579724</td>\n      <td>-0.982572</td>\n      <td>1.438014</td>\n      <td>-1.008720</td>\n      <td>BBADDAECDC</td>\n      <td>143.101347</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27</td>\n      <td>-1.814636</td>\n      <td>-1.578055</td>\n      <td>-0.164912</td>\n      <td>1.024490</td>\n      <td>0.810403</td>\n      <td>1.949860</td>\n      <td>1.704441</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1.247929</td>\n      <td>-3.367163</td>\n      <td>0.974690</td>\n      <td>-0.255284</td>\n      <td>0.086702</td>\n      <td>-2.260849</td>\n      <td>0.981560</td>\n      <td>-3.270380</td>\n      <td>ACABCBCRCC</td>\n      <td>36.856304</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>39</td>\n      <td>0.916766</td>\n      <td>-0.468947</td>\n      <td>-0.255398</td>\n      <td>-0.569036</td>\n      <td>0.193245</td>\n      <td>0.775350</td>\n      <td>-0.274236</td>\n      <td>2</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>5</td>\n      <td>0.593269</td>\n      <td>-1.350143</td>\n      <td>-4.503929</td>\n      <td>-0.129318</td>\n      <td>-1.132656</td>\n      <td>0.588172</td>\n      <td>-3.338356</td>\n      <td>0.478027</td>\n      <td>BCBDAABGCF</td>\n      <td>-262.819456</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0    46675\n1    43865\nName: target, dtype: int64"},"metadata":{}},{"name":"stdout","text":"num_cols:  ['id', 'f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_07', 'f_08', 'f_09', 'f_10', 'f_11', 'f_12', 'f_13', 'f_14', 'f_15', 'f_16', 'f_17', 'f_18', 'f_19', 'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25', 'f_26', 'f_28'] \n cat_cols:  ['f_30', 'f_29', 'f_27']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                  id          f_00          f_01          f_02          f_03  \\\ncount   90540.000000  90540.000000  90540.000000  90540.000000  90540.000000   \nmean   449008.769903     -0.001078      0.004748      0.001573     -0.001465   \nstd    259707.689482      1.000146      0.998448      1.002224      1.001003   \nmin         8.000000     -4.286109     -4.167642     -3.937882     -4.628484   \n25%    225154.000000     -0.676722     -0.677484     -0.676710     -0.675423   \n50%    447951.000000      0.001841      0.006407      0.007071     -0.001586   \n75%    673742.000000      0.675066      0.680002      0.678414      0.668399   \nmax    899989.000000      4.249785      4.013197      4.200609      4.230063   \n\n               f_04          f_05          f_06          f_07          f_08  \\\ncount  90540.000000  90540.000000  90540.000000  90540.000000  90540.000000   \nmean      -0.004293      0.001890     -0.004092      2.031047      2.063044   \nstd        1.002941      1.000911      1.004206      1.655558      1.594261   \nmin       -4.070449     -4.576952     -4.060522      0.000000      0.000000   \n25%       -0.684657     -0.669395     -0.680961      1.000000      1.000000   \n50%       -0.008212     -0.003147     -0.005699      2.000000      2.000000   \n75%        0.674137      0.673176      0.671435      3.000000      3.000000   \nmax        4.104314      4.060916      4.211428     13.000000     13.000000   \n\n               f_09          f_10          f_11          f_12          f_13  \\\ncount  90540.000000  90540.000000  90540.000000  90540.000000  90540.000000   \nmean       2.362889      2.176463      1.801469      2.848918      2.232483   \nstd        1.635472      1.648631      1.536410      1.765622      1.535558   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        1.000000      1.000000      1.000000      2.000000      1.000000   \n50%        2.000000      2.000000      2.000000      3.000000      2.000000   \n75%        3.000000      3.000000      3.000000      4.000000      3.000000   \nmax       13.000000     14.000000     13.000000     14.000000     12.000000   \n\n               f_14          f_15          f_16          f_17          f_18  \\\ncount  90540.000000  90540.000000  90540.000000  90540.000000  90540.000000   \nmean       1.506174      2.093749      2.099790      1.863773      2.070886   \nstd        1.358467      1.566340      1.562913      1.467218      1.573027   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      1.000000      1.000000      1.000000      1.000000   \n50%        1.000000      2.000000      2.000000      2.000000      2.000000   \n75%        2.000000      3.000000      3.000000      3.000000      3.000000   \nmax       14.000000     12.000000     12.000000     12.000000     13.000000   \n\n               f_19          f_20          f_21          f_22          f_23  \\\ncount  90540.000000  90540.000000  90540.000000  90540.000000  90540.000000   \nmean       0.305905     -0.181463     -0.159229     -0.029894     -0.361611   \nstd        2.316888      2.395452      2.469125      2.452356      2.448831   \nmin      -10.481084     -9.878739    -12.183785    -10.820862    -11.629187   \n25%       -1.236377     -1.806292     -1.817116     -1.662761     -2.010249   \n50%        0.333198     -0.185209     -0.157871      0.017744     -0.392200   \n75%        1.866994      1.428255      1.510876      1.631938      1.258636   \nmax       12.079667      9.914480     11.527211      9.850519     10.860577   \n\n               f_24          f_25          f_26          f_28  \ncount  90540.000000  90540.000000  90540.000000  90540.000000  \nmean      -0.341586      0.175730      0.357280     -1.195224  \nstd        2.393193      2.421398      2.464871    239.146084  \nmin      -10.798768    -10.173820    -11.169623  -1157.166666  \n25%       -1.966418     -1.430129     -1.255450   -160.271535  \n50%       -0.341565      0.162599      0.417487     -1.798168  \n75%        1.263288      1.794457      2.025530    158.890966  \nmax       12.389844     10.273561     12.775398   1018.321466  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>f_00</th>\n      <th>f_01</th>\n      <th>f_02</th>\n      <th>f_03</th>\n      <th>f_04</th>\n      <th>f_05</th>\n      <th>f_06</th>\n      <th>f_07</th>\n      <th>f_08</th>\n      <th>f_09</th>\n      <th>f_10</th>\n      <th>f_11</th>\n      <th>f_12</th>\n      <th>f_13</th>\n      <th>f_14</th>\n      <th>f_15</th>\n      <th>f_16</th>\n      <th>f_17</th>\n      <th>f_18</th>\n      <th>f_19</th>\n      <th>f_20</th>\n      <th>f_21</th>\n      <th>f_22</th>\n      <th>f_23</th>\n      <th>f_24</th>\n      <th>f_25</th>\n      <th>f_26</th>\n      <th>f_28</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n      <td>90540.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>449008.769903</td>\n      <td>-0.001078</td>\n      <td>0.004748</td>\n      <td>0.001573</td>\n      <td>-0.001465</td>\n      <td>-0.004293</td>\n      <td>0.001890</td>\n      <td>-0.004092</td>\n      <td>2.031047</td>\n      <td>2.063044</td>\n      <td>2.362889</td>\n      <td>2.176463</td>\n      <td>1.801469</td>\n      <td>2.848918</td>\n      <td>2.232483</td>\n      <td>1.506174</td>\n      <td>2.093749</td>\n      <td>2.099790</td>\n      <td>1.863773</td>\n      <td>2.070886</td>\n      <td>0.305905</td>\n      <td>-0.181463</td>\n      <td>-0.159229</td>\n      <td>-0.029894</td>\n      <td>-0.361611</td>\n      <td>-0.341586</td>\n      <td>0.175730</td>\n      <td>0.357280</td>\n      <td>-1.195224</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>259707.689482</td>\n      <td>1.000146</td>\n      <td>0.998448</td>\n      <td>1.002224</td>\n      <td>1.001003</td>\n      <td>1.002941</td>\n      <td>1.000911</td>\n      <td>1.004206</td>\n      <td>1.655558</td>\n      <td>1.594261</td>\n      <td>1.635472</td>\n      <td>1.648631</td>\n      <td>1.536410</td>\n      <td>1.765622</td>\n      <td>1.535558</td>\n      <td>1.358467</td>\n      <td>1.566340</td>\n      <td>1.562913</td>\n      <td>1.467218</td>\n      <td>1.573027</td>\n      <td>2.316888</td>\n      <td>2.395452</td>\n      <td>2.469125</td>\n      <td>2.452356</td>\n      <td>2.448831</td>\n      <td>2.393193</td>\n      <td>2.421398</td>\n      <td>2.464871</td>\n      <td>239.146084</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>8.000000</td>\n      <td>-4.286109</td>\n      <td>-4.167642</td>\n      <td>-3.937882</td>\n      <td>-4.628484</td>\n      <td>-4.070449</td>\n      <td>-4.576952</td>\n      <td>-4.060522</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-10.481084</td>\n      <td>-9.878739</td>\n      <td>-12.183785</td>\n      <td>-10.820862</td>\n      <td>-11.629187</td>\n      <td>-10.798768</td>\n      <td>-10.173820</td>\n      <td>-11.169623</td>\n      <td>-1157.166666</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>225154.000000</td>\n      <td>-0.676722</td>\n      <td>-0.677484</td>\n      <td>-0.676710</td>\n      <td>-0.675423</td>\n      <td>-0.684657</td>\n      <td>-0.669395</td>\n      <td>-0.680961</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>-1.236377</td>\n      <td>-1.806292</td>\n      <td>-1.817116</td>\n      <td>-1.662761</td>\n      <td>-2.010249</td>\n      <td>-1.966418</td>\n      <td>-1.430129</td>\n      <td>-1.255450</td>\n      <td>-160.271535</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>447951.000000</td>\n      <td>0.001841</td>\n      <td>0.006407</td>\n      <td>0.007071</td>\n      <td>-0.001586</td>\n      <td>-0.008212</td>\n      <td>-0.003147</td>\n      <td>-0.005699</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.333198</td>\n      <td>-0.185209</td>\n      <td>-0.157871</td>\n      <td>0.017744</td>\n      <td>-0.392200</td>\n      <td>-0.341565</td>\n      <td>0.162599</td>\n      <td>0.417487</td>\n      <td>-1.798168</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>673742.000000</td>\n      <td>0.675066</td>\n      <td>0.680002</td>\n      <td>0.678414</td>\n      <td>0.668399</td>\n      <td>0.674137</td>\n      <td>0.673176</td>\n      <td>0.671435</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>1.866994</td>\n      <td>1.428255</td>\n      <td>1.510876</td>\n      <td>1.631938</td>\n      <td>1.258636</td>\n      <td>1.263288</td>\n      <td>1.794457</td>\n      <td>2.025530</td>\n      <td>158.890966</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>899989.000000</td>\n      <td>4.249785</td>\n      <td>4.013197</td>\n      <td>4.200609</td>\n      <td>4.230063</td>\n      <td>4.104314</td>\n      <td>4.060916</td>\n      <td>4.211428</td>\n      <td>13.000000</td>\n      <td>13.000000</td>\n      <td>13.000000</td>\n      <td>14.000000</td>\n      <td>13.000000</td>\n      <td>14.000000</td>\n      <td>12.000000</td>\n      <td>14.000000</td>\n      <td>12.000000</td>\n      <td>12.000000</td>\n      <td>12.000000</td>\n      <td>13.000000</td>\n      <td>12.079667</td>\n      <td>9.914480</td>\n      <td>11.527211</td>\n      <td>9.850519</td>\n      <td>10.860577</td>\n      <td>12.389844</td>\n      <td>10.273561</td>\n      <td>12.775398</td>\n      <td>1018.321466</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"[0    30514\n 2    30278\n 1    29748\n Name: f_30, dtype: int64,\n 0    59138\n 1    31402\n Name: f_29, dtype: int64,\n BCBBBBELCC    4\n BABBABCEBD    4\n BCBCCACIBD    4\n ACBCAACPBB    4\n BCBBBACPBD    4\n              ..\n BDBEBABSDE    1\n BAAAAABFCC    1\n BBBBDABCCF    1\n ABBCABETCF    1\n BABACADRAC    1\n Name: f_27, Length: 88447, dtype: int64]"},"metadata":{}}]},{"cell_type":"code","source":"# 3. split data #\n\n#train_test_split approach does not work when I use TE.\n\ntest_size = 0.1\ntrain.reset_index(inplace=True, drop=True)\ntest_index = random.sample(list(train.index), int(test_size*train.shape[0]))\ntrain_ = train.iloc[list(set(train.index)-set(test_index))]\ntest = train.iloc[test_index]\ndisplay(train.shape, test.shape, train.head(3), test.head(3))\n\ntrain0, test0 = train.copy(), test.copy()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T20:06:29.432399Z","iopub.execute_input":"2022-07-21T20:06:29.432748Z","iopub.status.idle":"2022-07-21T20:06:29.531838Z","shell.execute_reply.started":"2022-07-21T20:06:29.432710Z","shell.execute_reply":"2022-07-21T20:06:29.530994Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"(90540, 33)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(9054, 33)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   id      f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n0   8  0.866221  0.842351 -1.367634  1.237506  0.682962  0.845666  0.173852   \n1  18  0.922494 -0.828627  0.953987  0.835863  0.112589  2.432248  0.236815   \n2  21 -0.645481  1.060355 -1.213576 -1.319743 -0.032761  0.868289  0.082763   \n\n   f_07  f_08  f_09  f_10  f_11  f_12  f_13  f_14  f_15  f_16  f_17  f_18  \\\n0     3     2     1     7     4     3     5     2     3     0     0     4   \n1     0     3     3     1     2     1     2     5     1     1     3     2   \n2     2     3     4     1     2     3     2     0     9     1     2     3   \n\n       f_19      f_20      f_21      f_22      f_23      f_24      f_25  \\\n0 -2.568930 -0.796303 -0.786741 -1.241121 -1.245038  1.696402  0.354545   \n1  0.594356 -0.983587 -0.789391  4.188384 -2.615815 -2.015672  7.466349   \n2 -3.408796  3.370601  0.445238 -0.305235 -4.579724 -0.982572  1.438014   \n\n       f_26        f_27        f_28  f_29  f_30  target  \n0 -0.541267  ACAEBADDAA  -52.223857     0     0       0  \n1  6.045183  AGBCBACCBA  448.896335     0     2       0  \n2 -1.008720  BBADDAECDC  143.101347     1     1       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>f_00</th>\n      <th>f_01</th>\n      <th>f_02</th>\n      <th>f_03</th>\n      <th>f_04</th>\n      <th>f_05</th>\n      <th>f_06</th>\n      <th>f_07</th>\n      <th>f_08</th>\n      <th>f_09</th>\n      <th>f_10</th>\n      <th>f_11</th>\n      <th>f_12</th>\n      <th>f_13</th>\n      <th>f_14</th>\n      <th>f_15</th>\n      <th>f_16</th>\n      <th>f_17</th>\n      <th>f_18</th>\n      <th>f_19</th>\n      <th>f_20</th>\n      <th>f_21</th>\n      <th>f_22</th>\n      <th>f_23</th>\n      <th>f_24</th>\n      <th>f_25</th>\n      <th>f_26</th>\n      <th>f_27</th>\n      <th>f_28</th>\n      <th>f_29</th>\n      <th>f_30</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>0.866221</td>\n      <td>0.842351</td>\n      <td>-1.367634</td>\n      <td>1.237506</td>\n      <td>0.682962</td>\n      <td>0.845666</td>\n      <td>0.173852</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>4</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-2.568930</td>\n      <td>-0.796303</td>\n      <td>-0.786741</td>\n      <td>-1.241121</td>\n      <td>-1.245038</td>\n      <td>1.696402</td>\n      <td>0.354545</td>\n      <td>-0.541267</td>\n      <td>ACAEBADDAA</td>\n      <td>-52.223857</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>0.922494</td>\n      <td>-0.828627</td>\n      <td>0.953987</td>\n      <td>0.835863</td>\n      <td>0.112589</td>\n      <td>2.432248</td>\n      <td>0.236815</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.594356</td>\n      <td>-0.983587</td>\n      <td>-0.789391</td>\n      <td>4.188384</td>\n      <td>-2.615815</td>\n      <td>-2.015672</td>\n      <td>7.466349</td>\n      <td>6.045183</td>\n      <td>AGBCBACCBA</td>\n      <td>448.896335</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>-0.645481</td>\n      <td>1.060355</td>\n      <td>-1.213576</td>\n      <td>-1.319743</td>\n      <td>-0.032761</td>\n      <td>0.868289</td>\n      <td>0.082763</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>9</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>-3.408796</td>\n      <td>3.370601</td>\n      <td>0.445238</td>\n      <td>-0.305235</td>\n      <td>-4.579724</td>\n      <td>-0.982572</td>\n      <td>1.438014</td>\n      <td>-1.008720</td>\n      <td>BBADDAECDC</td>\n      <td>143.101347</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"           id      f_00      f_01      f_02      f_03      f_04      f_05  \\\n29168  289957 -0.148378  0.548169  0.829241  0.802299  1.274497  0.114888   \n3141    30286 -0.257653 -0.239395 -1.265026 -1.119950 -0.521108  0.613049   \n16248  160966  0.578058  0.435574  1.036967  0.393754  1.795100 -0.538760   \n\n           f_06  f_07  f_08  f_09  f_10  f_11  f_12  f_13  f_14  f_15  f_16  \\\n29168  1.610880     0     5     2     0     1     0     1     2     2     3   \n3141   1.392635     0     2     0     0     3     1     0     1     2     1   \n16248  0.700666     1     3     3     3     1     1     1     2     0     0   \n\n       f_17  f_18      f_19      f_20      f_21      f_22      f_23      f_24  \\\n29168     1     1 -1.383431 -2.436701  0.738691 -0.357180  3.859422 -0.357368   \n3141      3     2  3.095569  1.966354 -1.913910 -4.345637 -5.080232 -4.358149   \n16248     4     1 -1.120046 -2.191985  0.597896 -1.264482 -0.066934 -1.922217   \n\n           f_25      f_26        f_27        f_28  f_29  f_30  target  \n29168 -1.819748 -0.173728  AEACCADOCC  513.106852     0     0       1  \n3141  -3.480443 -5.962773  ABBCAAAPGE -238.048664     0     0       0  \n16248  0.838191  3.240245  ABBBABCEBB  443.892115     0     0       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>f_00</th>\n      <th>f_01</th>\n      <th>f_02</th>\n      <th>f_03</th>\n      <th>f_04</th>\n      <th>f_05</th>\n      <th>f_06</th>\n      <th>f_07</th>\n      <th>f_08</th>\n      <th>f_09</th>\n      <th>f_10</th>\n      <th>f_11</th>\n      <th>f_12</th>\n      <th>f_13</th>\n      <th>f_14</th>\n      <th>f_15</th>\n      <th>f_16</th>\n      <th>f_17</th>\n      <th>f_18</th>\n      <th>f_19</th>\n      <th>f_20</th>\n      <th>f_21</th>\n      <th>f_22</th>\n      <th>f_23</th>\n      <th>f_24</th>\n      <th>f_25</th>\n      <th>f_26</th>\n      <th>f_27</th>\n      <th>f_28</th>\n      <th>f_29</th>\n      <th>f_30</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29168</th>\n      <td>289957</td>\n      <td>-0.148378</td>\n      <td>0.548169</td>\n      <td>0.829241</td>\n      <td>0.802299</td>\n      <td>1.274497</td>\n      <td>0.114888</td>\n      <td>1.610880</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-1.383431</td>\n      <td>-2.436701</td>\n      <td>0.738691</td>\n      <td>-0.357180</td>\n      <td>3.859422</td>\n      <td>-0.357368</td>\n      <td>-1.819748</td>\n      <td>-0.173728</td>\n      <td>AEACCADOCC</td>\n      <td>513.106852</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3141</th>\n      <td>30286</td>\n      <td>-0.257653</td>\n      <td>-0.239395</td>\n      <td>-1.265026</td>\n      <td>-1.119950</td>\n      <td>-0.521108</td>\n      <td>0.613049</td>\n      <td>1.392635</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3.095569</td>\n      <td>1.966354</td>\n      <td>-1.913910</td>\n      <td>-4.345637</td>\n      <td>-5.080232</td>\n      <td>-4.358149</td>\n      <td>-3.480443</td>\n      <td>-5.962773</td>\n      <td>ABBCAAAPGE</td>\n      <td>-238.048664</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16248</th>\n      <td>160966</td>\n      <td>0.578058</td>\n      <td>0.435574</td>\n      <td>1.036967</td>\n      <td>0.393754</td>\n      <td>1.795100</td>\n      <td>-0.538760</td>\n      <td>0.700666</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>-1.120046</td>\n      <td>-2.191985</td>\n      <td>0.597896</td>\n      <td>-1.264482</td>\n      <td>-0.066934</td>\n      <td>-1.922217</td>\n      <td>0.838191</td>\n      <td>3.240245</td>\n      <td>ABBBABCEBB</td>\n      <td>443.892115</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 5. FE #\n\n# first do TE\n\ntrain, test = train0.copy(), test0.copy()\n\ndisplay(train.head(), test.head())\n_, pred = TargetEncoderMP(train, pred, ['f_27'], 'target')\ntrain, test = TargetEncoderMP(train, test, ['f_27'], 'target')\ndisplay(train.head(), test.head(), pred.head())\n\n# then extract a target\n\nX_train = train.copy()\ny_train = X_train.pop('target')\nX_test = test.copy()\ny_test = X_test.pop('target')\n\n# then do OHE with columntransformer\n\nohe_cols = ['f_29', 'f_30']\nfeature_transformer = ColumnTransformer([\n   (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\"), ohe_cols)],\n   remainder=\"passthrough\")\nprint('Number of features before transaformation: ', X_train.shape)\nX_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\nX_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\npred = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\ndisplay(X_train.head(), X_test.head(), pred.head())\n","metadata":{"execution":{"iopub.status.busy":"2022-07-21T20:06:29.533286Z","iopub.execute_input":"2022-07-21T20:06:29.533657Z","iopub.status.idle":"2022-07-21T20:06:30.608112Z","shell.execute_reply.started":"2022-07-21T20:06:29.533621Z","shell.execute_reply":"2022-07-21T20:06:30.606772Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"   id      f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n0   8  0.866221  0.842351 -1.367634  1.237506  0.682962  0.845666  0.173852   \n1  18  0.922494 -0.828627  0.953987  0.835863  0.112589  2.432248  0.236815   \n2  21 -0.645481  1.060355 -1.213576 -1.319743 -0.032761  0.868289  0.082763   \n3  27 -1.814636 -1.578055 -0.164912  1.024490  0.810403  1.949860  1.704441   \n4  39  0.916766 -0.468947 -0.255398 -0.569036  0.193245  0.775350 -0.274236   \n\n   f_07  f_08  f_09  f_10  f_11  f_12  f_13  f_14  f_15  f_16  f_17  f_18  \\\n0     3     2     1     7     4     3     5     2     3     0     0     4   \n1     0     3     3     1     2     1     2     5     1     1     3     2   \n2     2     3     4     1     2     3     2     0     9     1     2     3   \n3     1     1     3     4     1     3     5     1     0     1     3     4   \n4     2     2     6     0     1     7     3     1     1     7     3     5   \n\n       f_19      f_20      f_21      f_22      f_23      f_24      f_25  \\\n0 -2.568930 -0.796303 -0.786741 -1.241121 -1.245038  1.696402  0.354545   \n1  0.594356 -0.983587 -0.789391  4.188384 -2.615815 -2.015672  7.466349   \n2 -3.408796  3.370601  0.445238 -0.305235 -4.579724 -0.982572  1.438014   \n3  1.247929 -3.367163  0.974690 -0.255284  0.086702 -2.260849  0.981560   \n4  0.593269 -1.350143 -4.503929 -0.129318 -1.132656  0.588172 -3.338356   \n\n       f_26        f_27        f_28  f_29  f_30  target  \n0 -0.541267  ACAEBADDAA  -52.223857     0     0       0  \n1  6.045183  AGBCBACCBA  448.896335     0     2       0  \n2 -1.008720  BBADDAECDC  143.101347     1     1       1  \n3 -3.270380  ACABCBCRCC   36.856304     1     1       0  \n4  0.478027  BCBDAABGCF -262.819456     1     1       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>f_00</th>\n      <th>f_01</th>\n      <th>f_02</th>\n      <th>f_03</th>\n      <th>f_04</th>\n      <th>f_05</th>\n      <th>f_06</th>\n      <th>f_07</th>\n      <th>f_08</th>\n      <th>f_09</th>\n      <th>f_10</th>\n      <th>f_11</th>\n      <th>f_12</th>\n      <th>f_13</th>\n      <th>f_14</th>\n      <th>f_15</th>\n      <th>f_16</th>\n      <th>f_17</th>\n      <th>f_18</th>\n      <th>f_19</th>\n      <th>f_20</th>\n      <th>f_21</th>\n      <th>f_22</th>\n      <th>f_23</th>\n      <th>f_24</th>\n      <th>f_25</th>\n      <th>f_26</th>\n      <th>f_27</th>\n      <th>f_28</th>\n      <th>f_29</th>\n      <th>f_30</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>0.866221</td>\n      <td>0.842351</td>\n      <td>-1.367634</td>\n      <td>1.237506</td>\n      <td>0.682962</td>\n      <td>0.845666</td>\n      <td>0.173852</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>4</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-2.568930</td>\n      <td>-0.796303</td>\n      <td>-0.786741</td>\n      <td>-1.241121</td>\n      <td>-1.245038</td>\n      <td>1.696402</td>\n      <td>0.354545</td>\n      <td>-0.541267</td>\n      <td>ACAEBADDAA</td>\n      <td>-52.223857</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>0.922494</td>\n      <td>-0.828627</td>\n      <td>0.953987</td>\n      <td>0.835863</td>\n      <td>0.112589</td>\n      <td>2.432248</td>\n      <td>0.236815</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.594356</td>\n      <td>-0.983587</td>\n      <td>-0.789391</td>\n      <td>4.188384</td>\n      <td>-2.615815</td>\n      <td>-2.015672</td>\n      <td>7.466349</td>\n      <td>6.045183</td>\n      <td>AGBCBACCBA</td>\n      <td>448.896335</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>-0.645481</td>\n      <td>1.060355</td>\n      <td>-1.213576</td>\n      <td>-1.319743</td>\n      <td>-0.032761</td>\n      <td>0.868289</td>\n      <td>0.082763</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>9</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>-3.408796</td>\n      <td>3.370601</td>\n      <td>0.445238</td>\n      <td>-0.305235</td>\n      <td>-4.579724</td>\n      <td>-0.982572</td>\n      <td>1.438014</td>\n      <td>-1.008720</td>\n      <td>BBADDAECDC</td>\n      <td>143.101347</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27</td>\n      <td>-1.814636</td>\n      <td>-1.578055</td>\n      <td>-0.164912</td>\n      <td>1.024490</td>\n      <td>0.810403</td>\n      <td>1.949860</td>\n      <td>1.704441</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1.247929</td>\n      <td>-3.367163</td>\n      <td>0.974690</td>\n      <td>-0.255284</td>\n      <td>0.086702</td>\n      <td>-2.260849</td>\n      <td>0.981560</td>\n      <td>-3.270380</td>\n      <td>ACABCBCRCC</td>\n      <td>36.856304</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>39</td>\n      <td>0.916766</td>\n      <td>-0.468947</td>\n      <td>-0.255398</td>\n      <td>-0.569036</td>\n      <td>0.193245</td>\n      <td>0.775350</td>\n      <td>-0.274236</td>\n      <td>2</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>5</td>\n      <td>0.593269</td>\n      <td>-1.350143</td>\n      <td>-4.503929</td>\n      <td>-0.129318</td>\n      <td>-1.132656</td>\n      <td>0.588172</td>\n      <td>-3.338356</td>\n      <td>0.478027</td>\n      <td>BCBDAABGCF</td>\n      <td>-262.819456</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"           id      f_00      f_01      f_02      f_03      f_04      f_05  \\\n29168  289957 -0.148378  0.548169  0.829241  0.802299  1.274497  0.114888   \n3141    30286 -0.257653 -0.239395 -1.265026 -1.119950 -0.521108  0.613049   \n16248  160966  0.578058  0.435574  1.036967  0.393754  1.795100 -0.538760   \n56194  557102  0.119832 -1.140194  0.259692  0.768091  0.435252 -0.705126   \n7902    76957  0.186579  0.635994 -1.792145 -0.002432  0.991567  1.208961   \n\n           f_06  f_07  f_08  f_09  f_10  f_11  f_12  f_13  f_14  f_15  f_16  \\\n29168  1.610880     0     5     2     0     1     0     1     2     2     3   \n3141   1.392635     0     2     0     0     3     1     0     1     2     1   \n16248  0.700666     1     3     3     3     1     1     1     2     0     0   \n56194 -0.101193     2     4     4     2     1     1     4     1     7     6   \n7902   0.261658     4     2     3     3     2     4     1     2     2     3   \n\n       f_17  f_18      f_19      f_20      f_21      f_22      f_23      f_24  \\\n29168     1     1 -1.383431 -2.436701  0.738691 -0.357180  3.859422 -0.357368   \n3141      3     2  3.095569  1.966354 -1.913910 -4.345637 -5.080232 -4.358149   \n16248     4     1 -1.120046 -2.191985  0.597896 -1.264482 -0.066934 -1.922217   \n56194     3     6 -0.670141 -2.160991  0.812893  0.443669 -0.593305 -1.319240   \n7902      2     0  0.886578  0.710126  2.281544 -4.812871 -1.067746  3.884482   \n\n           f_25      f_26        f_27        f_28  f_29  f_30  target  \n29168 -1.819748 -0.173728  AEACCADOCC  513.106852     0     0       1  \n3141  -3.480443 -5.962773  ABBCAAAPGE -238.048664     0     0       0  \n16248  0.838191  3.240245  ABBBABCEBB  443.892115     0     0       1  \n56194  0.505617 -1.560496  BABBAAETDB  -23.346895     1     1       1  \n7902  -2.182611  6.669902  BBBDBABDDE  154.033815     1     0       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>f_00</th>\n      <th>f_01</th>\n      <th>f_02</th>\n      <th>f_03</th>\n      <th>f_04</th>\n      <th>f_05</th>\n      <th>f_06</th>\n      <th>f_07</th>\n      <th>f_08</th>\n      <th>f_09</th>\n      <th>f_10</th>\n      <th>f_11</th>\n      <th>f_12</th>\n      <th>f_13</th>\n      <th>f_14</th>\n      <th>f_15</th>\n      <th>f_16</th>\n      <th>f_17</th>\n      <th>f_18</th>\n      <th>f_19</th>\n      <th>f_20</th>\n      <th>f_21</th>\n      <th>f_22</th>\n      <th>f_23</th>\n      <th>f_24</th>\n      <th>f_25</th>\n      <th>f_26</th>\n      <th>f_27</th>\n      <th>f_28</th>\n      <th>f_29</th>\n      <th>f_30</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29168</th>\n      <td>289957</td>\n      <td>-0.148378</td>\n      <td>0.548169</td>\n      <td>0.829241</td>\n      <td>0.802299</td>\n      <td>1.274497</td>\n      <td>0.114888</td>\n      <td>1.610880</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-1.383431</td>\n      <td>-2.436701</td>\n      <td>0.738691</td>\n      <td>-0.357180</td>\n      <td>3.859422</td>\n      <td>-0.357368</td>\n      <td>-1.819748</td>\n      <td>-0.173728</td>\n      <td>AEACCADOCC</td>\n      <td>513.106852</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3141</th>\n      <td>30286</td>\n      <td>-0.257653</td>\n      <td>-0.239395</td>\n      <td>-1.265026</td>\n      <td>-1.119950</td>\n      <td>-0.521108</td>\n      <td>0.613049</td>\n      <td>1.392635</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3.095569</td>\n      <td>1.966354</td>\n      <td>-1.913910</td>\n      <td>-4.345637</td>\n      <td>-5.080232</td>\n      <td>-4.358149</td>\n      <td>-3.480443</td>\n      <td>-5.962773</td>\n      <td>ABBCAAAPGE</td>\n      <td>-238.048664</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16248</th>\n      <td>160966</td>\n      <td>0.578058</td>\n      <td>0.435574</td>\n      <td>1.036967</td>\n      <td>0.393754</td>\n      <td>1.795100</td>\n      <td>-0.538760</td>\n      <td>0.700666</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>-1.120046</td>\n      <td>-2.191985</td>\n      <td>0.597896</td>\n      <td>-1.264482</td>\n      <td>-0.066934</td>\n      <td>-1.922217</td>\n      <td>0.838191</td>\n      <td>3.240245</td>\n      <td>ABBBABCEBB</td>\n      <td>443.892115</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>56194</th>\n      <td>557102</td>\n      <td>0.119832</td>\n      <td>-1.140194</td>\n      <td>0.259692</td>\n      <td>0.768091</td>\n      <td>0.435252</td>\n      <td>-0.705126</td>\n      <td>-0.101193</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>7</td>\n      <td>6</td>\n      <td>3</td>\n      <td>6</td>\n      <td>-0.670141</td>\n      <td>-2.160991</td>\n      <td>0.812893</td>\n      <td>0.443669</td>\n      <td>-0.593305</td>\n      <td>-1.319240</td>\n      <td>0.505617</td>\n      <td>-1.560496</td>\n      <td>BABBAAETDB</td>\n      <td>-23.346895</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7902</th>\n      <td>76957</td>\n      <td>0.186579</td>\n      <td>0.635994</td>\n      <td>-1.792145</td>\n      <td>-0.002432</td>\n      <td>0.991567</td>\n      <td>1.208961</td>\n      <td>0.261658</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.886578</td>\n      <td>0.710126</td>\n      <td>2.281544</td>\n      <td>-4.812871</td>\n      <td>-1.067746</td>\n      <td>3.884482</td>\n      <td>-2.182611</td>\n      <td>6.669902</td>\n      <td>BBBDBABDDE</td>\n      <td>154.033815</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   id      f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n0   8  0.866221  0.842351 -1.367634  1.237506  0.682962  0.845666  0.173852   \n1  18  0.922494 -0.828627  0.953987  0.835863  0.112589  2.432248  0.236815   \n2  21 -0.645481  1.060355 -1.213576 -1.319743 -0.032761  0.868289  0.082763   \n3  27 -1.814636 -1.578055 -0.164912  1.024490  0.810403  1.949860  1.704441   \n4  39  0.916766 -0.468947 -0.255398 -0.569036  0.193245  0.775350 -0.274236   \n\n   f_07  f_08  f_09  f_10  f_11  f_12  f_13  f_14  f_15  f_16  f_17  f_18  \\\n0     3     2     1     7     4     3     5     2     3     0     0     4   \n1     0     3     3     1     2     1     2     5     1     1     3     2   \n2     2     3     4     1     2     3     2     0     9     1     2     3   \n3     1     1     3     4     1     3     5     1     0     1     3     4   \n4     2     2     6     0     1     7     3     1     1     7     3     5   \n\n       f_19      f_20      f_21      f_22      f_23      f_24      f_25  \\\n0 -2.568930 -0.796303 -0.786741 -1.241121 -1.245038  1.696402  0.354545   \n1  0.594356 -0.983587 -0.789391  4.188384 -2.615815 -2.015672  7.466349   \n2 -3.408796  3.370601  0.445238 -0.305235 -4.579724 -0.982572  1.438014   \n3  1.247929 -3.367163  0.974690 -0.255284  0.086702 -2.260849  0.981560   \n4  0.593269 -1.350143 -4.503929 -0.129318 -1.132656  0.588172 -3.338356   \n\n       f_26        f_28  f_29  f_30  target  f_27_encoded  \n0 -0.541267  -52.223857     0     0       0      0.484221  \n1  6.045183  448.896335     0     2       0      0.484221  \n2 -1.008720  143.101347     1     1       1      0.484221  \n3 -3.270380   36.856304     1     1       0      0.484221  \n4  0.478027 -262.819456     1     1       0      0.484221  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>f_00</th>\n      <th>f_01</th>\n      <th>f_02</th>\n      <th>f_03</th>\n      <th>f_04</th>\n      <th>f_05</th>\n      <th>f_06</th>\n      <th>f_07</th>\n      <th>f_08</th>\n      <th>f_09</th>\n      <th>f_10</th>\n      <th>f_11</th>\n      <th>f_12</th>\n      <th>f_13</th>\n      <th>f_14</th>\n      <th>f_15</th>\n      <th>f_16</th>\n      <th>f_17</th>\n      <th>f_18</th>\n      <th>f_19</th>\n      <th>f_20</th>\n      <th>f_21</th>\n      <th>f_22</th>\n      <th>f_23</th>\n      <th>f_24</th>\n      <th>f_25</th>\n      <th>f_26</th>\n      <th>f_28</th>\n      <th>f_29</th>\n      <th>f_30</th>\n      <th>target</th>\n      <th>f_27_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>0.866221</td>\n      <td>0.842351</td>\n      <td>-1.367634</td>\n      <td>1.237506</td>\n      <td>0.682962</td>\n      <td>0.845666</td>\n      <td>0.173852</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>4</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-2.568930</td>\n      <td>-0.796303</td>\n      <td>-0.786741</td>\n      <td>-1.241121</td>\n      <td>-1.245038</td>\n      <td>1.696402</td>\n      <td>0.354545</td>\n      <td>-0.541267</td>\n      <td>-52.223857</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.484221</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>0.922494</td>\n      <td>-0.828627</td>\n      <td>0.953987</td>\n      <td>0.835863</td>\n      <td>0.112589</td>\n      <td>2.432248</td>\n      <td>0.236815</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.594356</td>\n      <td>-0.983587</td>\n      <td>-0.789391</td>\n      <td>4.188384</td>\n      <td>-2.615815</td>\n      <td>-2.015672</td>\n      <td>7.466349</td>\n      <td>6.045183</td>\n      <td>448.896335</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.484221</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>-0.645481</td>\n      <td>1.060355</td>\n      <td>-1.213576</td>\n      <td>-1.319743</td>\n      <td>-0.032761</td>\n      <td>0.868289</td>\n      <td>0.082763</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>9</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>-3.408796</td>\n      <td>3.370601</td>\n      <td>0.445238</td>\n      <td>-0.305235</td>\n      <td>-4.579724</td>\n      <td>-0.982572</td>\n      <td>1.438014</td>\n      <td>-1.008720</td>\n      <td>143.101347</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.484221</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27</td>\n      <td>-1.814636</td>\n      <td>-1.578055</td>\n      <td>-0.164912</td>\n      <td>1.024490</td>\n      <td>0.810403</td>\n      <td>1.949860</td>\n      <td>1.704441</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1.247929</td>\n      <td>-3.367163</td>\n      <td>0.974690</td>\n      <td>-0.255284</td>\n      <td>0.086702</td>\n      <td>-2.260849</td>\n      <td>0.981560</td>\n      <td>-3.270380</td>\n      <td>36.856304</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.484221</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>39</td>\n      <td>0.916766</td>\n      <td>-0.468947</td>\n      <td>-0.255398</td>\n      <td>-0.569036</td>\n      <td>0.193245</td>\n      <td>0.775350</td>\n      <td>-0.274236</td>\n      <td>2</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>5</td>\n      <td>0.593269</td>\n      <td>-1.350143</td>\n      <td>-4.503929</td>\n      <td>-0.129318</td>\n      <td>-1.132656</td>\n      <td>0.588172</td>\n      <td>-3.338356</td>\n      <td>0.478027</td>\n      <td>-262.819456</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.484221</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"           id      f_00      f_01      f_02      f_03      f_04      f_05  \\\n29168  289957 -0.148378  0.548169  0.829241  0.802299  1.274497  0.114888   \n3141    30286 -0.257653 -0.239395 -1.265026 -1.119950 -0.521108  0.613049   \n16248  160966  0.578058  0.435574  1.036967  0.393754  1.795100 -0.538760   \n56194  557102  0.119832 -1.140194  0.259692  0.768091  0.435252 -0.705126   \n7902    76957  0.186579  0.635994 -1.792145 -0.002432  0.991567  1.208961   \n\n           f_06  f_07  f_08  f_09  f_10  f_11  f_12  f_13  f_14  f_15  f_16  \\\n29168  1.610880     0     5     2     0     1     0     1     2     2     3   \n3141   1.392635     0     2     0     0     3     1     0     1     2     1   \n16248  0.700666     1     3     3     3     1     1     1     2     0     0   \n56194 -0.101193     2     4     4     2     1     1     4     1     7     6   \n7902   0.261658     4     2     3     3     2     4     1     2     2     3   \n\n       f_17  f_18      f_19      f_20      f_21      f_22      f_23      f_24  \\\n29168     1     1 -1.383431 -2.436701  0.738691 -0.357180  3.859422 -0.357368   \n3141      3     2  3.095569  1.966354 -1.913910 -4.345637 -5.080232 -4.358149   \n16248     4     1 -1.120046 -2.191985  0.597896 -1.264482 -0.066934 -1.922217   \n56194     3     6 -0.670141 -2.160991  0.812893  0.443669 -0.593305 -1.319240   \n7902      2     0  0.886578  0.710126  2.281544 -4.812871 -1.067746  3.884482   \n\n           f_25      f_26        f_28  f_29  f_30  target  f_27_encoded  \n29168 -1.819748 -0.173728  513.106852     0     0       1      0.548925  \n3141  -3.480443 -5.962773 -238.048664     0     0       0      0.423911  \n16248  0.838191  3.240245  443.892115     0     0       1      0.487789  \n56194  0.505617 -1.560496  -23.346895     1     1       1      0.548876  \n7902  -2.182611  6.669902  154.033815     1     0       1      0.548911  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>f_00</th>\n      <th>f_01</th>\n      <th>f_02</th>\n      <th>f_03</th>\n      <th>f_04</th>\n      <th>f_05</th>\n      <th>f_06</th>\n      <th>f_07</th>\n      <th>f_08</th>\n      <th>f_09</th>\n      <th>f_10</th>\n      <th>f_11</th>\n      <th>f_12</th>\n      <th>f_13</th>\n      <th>f_14</th>\n      <th>f_15</th>\n      <th>f_16</th>\n      <th>f_17</th>\n      <th>f_18</th>\n      <th>f_19</th>\n      <th>f_20</th>\n      <th>f_21</th>\n      <th>f_22</th>\n      <th>f_23</th>\n      <th>f_24</th>\n      <th>f_25</th>\n      <th>f_26</th>\n      <th>f_28</th>\n      <th>f_29</th>\n      <th>f_30</th>\n      <th>target</th>\n      <th>f_27_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29168</th>\n      <td>289957</td>\n      <td>-0.148378</td>\n      <td>0.548169</td>\n      <td>0.829241</td>\n      <td>0.802299</td>\n      <td>1.274497</td>\n      <td>0.114888</td>\n      <td>1.610880</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-1.383431</td>\n      <td>-2.436701</td>\n      <td>0.738691</td>\n      <td>-0.357180</td>\n      <td>3.859422</td>\n      <td>-0.357368</td>\n      <td>-1.819748</td>\n      <td>-0.173728</td>\n      <td>513.106852</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.548925</td>\n    </tr>\n    <tr>\n      <th>3141</th>\n      <td>30286</td>\n      <td>-0.257653</td>\n      <td>-0.239395</td>\n      <td>-1.265026</td>\n      <td>-1.119950</td>\n      <td>-0.521108</td>\n      <td>0.613049</td>\n      <td>1.392635</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3.095569</td>\n      <td>1.966354</td>\n      <td>-1.913910</td>\n      <td>-4.345637</td>\n      <td>-5.080232</td>\n      <td>-4.358149</td>\n      <td>-3.480443</td>\n      <td>-5.962773</td>\n      <td>-238.048664</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.423911</td>\n    </tr>\n    <tr>\n      <th>16248</th>\n      <td>160966</td>\n      <td>0.578058</td>\n      <td>0.435574</td>\n      <td>1.036967</td>\n      <td>0.393754</td>\n      <td>1.795100</td>\n      <td>-0.538760</td>\n      <td>0.700666</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>-1.120046</td>\n      <td>-2.191985</td>\n      <td>0.597896</td>\n      <td>-1.264482</td>\n      <td>-0.066934</td>\n      <td>-1.922217</td>\n      <td>0.838191</td>\n      <td>3.240245</td>\n      <td>443.892115</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.487789</td>\n    </tr>\n    <tr>\n      <th>56194</th>\n      <td>557102</td>\n      <td>0.119832</td>\n      <td>-1.140194</td>\n      <td>0.259692</td>\n      <td>0.768091</td>\n      <td>0.435252</td>\n      <td>-0.705126</td>\n      <td>-0.101193</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>7</td>\n      <td>6</td>\n      <td>3</td>\n      <td>6</td>\n      <td>-0.670141</td>\n      <td>-2.160991</td>\n      <td>0.812893</td>\n      <td>0.443669</td>\n      <td>-0.593305</td>\n      <td>-1.319240</td>\n      <td>0.505617</td>\n      <td>-1.560496</td>\n      <td>-23.346895</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.548876</td>\n    </tr>\n    <tr>\n      <th>7902</th>\n      <td>76957</td>\n      <td>0.186579</td>\n      <td>0.635994</td>\n      <td>-1.792145</td>\n      <td>-0.002432</td>\n      <td>0.991567</td>\n      <td>1.208961</td>\n      <td>0.261658</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.886578</td>\n      <td>0.710126</td>\n      <td>2.281544</td>\n      <td>-4.812871</td>\n      <td>-1.067746</td>\n      <td>3.884482</td>\n      <td>-2.182611</td>\n      <td>6.669902</td>\n      <td>154.033815</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.548911</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Number of features before transaformation:  (90540, 32)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   cat__f_29_0  cat__f_29_1  cat__f_30_0  cat__f_30_1  cat__f_30_2  \\\n0          1.0          0.0          1.0          0.0          0.0   \n1          1.0          0.0          0.0          0.0          1.0   \n2          0.0          1.0          0.0          1.0          0.0   \n3          0.0          1.0          0.0          1.0          0.0   \n4          0.0          1.0          0.0          1.0          0.0   \n\n   remainder__id  remainder__f_00  remainder__f_01  remainder__f_02  \\\n0            8.0         0.866221         0.842351        -1.367634   \n1           18.0         0.922494        -0.828627         0.953987   \n2           21.0        -0.645481         1.060355        -1.213576   \n3           27.0        -1.814636        -1.578055        -0.164912   \n4           39.0         0.916766        -0.468947        -0.255398   \n\n   remainder__f_03  remainder__f_04  remainder__f_05  remainder__f_06  \\\n0         1.237506         0.682962         0.845666         0.173852   \n1         0.835863         0.112589         2.432248         0.236815   \n2        -1.319743        -0.032761         0.868289         0.082763   \n3         1.024490         0.810403         1.949860         1.704441   \n4        -0.569036         0.193245         0.775350        -0.274236   \n\n   remainder__f_07  remainder__f_08  remainder__f_09  remainder__f_10  \\\n0              3.0              2.0              1.0              7.0   \n1              0.0              3.0              3.0              1.0   \n2              2.0              3.0              4.0              1.0   \n3              1.0              1.0              3.0              4.0   \n4              2.0              2.0              6.0              0.0   \n\n   remainder__f_11  remainder__f_12  remainder__f_13  remainder__f_14  \\\n0              4.0              3.0              5.0              2.0   \n1              2.0              1.0              2.0              5.0   \n2              2.0              3.0              2.0              0.0   \n3              1.0              3.0              5.0              1.0   \n4              1.0              7.0              3.0              1.0   \n\n   remainder__f_15  remainder__f_16  remainder__f_17  remainder__f_18  \\\n0              3.0              0.0              0.0              4.0   \n1              1.0              1.0              3.0              2.0   \n2              9.0              1.0              2.0              3.0   \n3              0.0              1.0              3.0              4.0   \n4              1.0              7.0              3.0              5.0   \n\n   remainder__f_19  remainder__f_20  remainder__f_21  remainder__f_22  \\\n0        -2.568930        -0.796303        -0.786741        -1.241121   \n1         0.594356        -0.983587        -0.789391         4.188384   \n2        -3.408796         3.370601         0.445238        -0.305235   \n3         1.247929        -3.367163         0.974690        -0.255284   \n4         0.593269        -1.350143        -4.503929        -0.129318   \n\n   remainder__f_23  remainder__f_24  remainder__f_25  remainder__f_26  \\\n0        -1.245038         1.696402         0.354545        -0.541267   \n1        -2.615815        -2.015672         7.466349         6.045183   \n2        -4.579724        -0.982572         1.438014        -1.008720   \n3         0.086702        -2.260849         0.981560        -3.270380   \n4        -1.132656         0.588172        -3.338356         0.478027   \n\n   remainder__f_28  remainder__f_27_encoded  \n0       -52.223857                 0.484221  \n1       448.896335                 0.484221  \n2       143.101347                 0.484221  \n3        36.856304                 0.484221  \n4      -262.819456                 0.484221  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat__f_29_0</th>\n      <th>cat__f_29_1</th>\n      <th>cat__f_30_0</th>\n      <th>cat__f_30_1</th>\n      <th>cat__f_30_2</th>\n      <th>remainder__id</th>\n      <th>remainder__f_00</th>\n      <th>remainder__f_01</th>\n      <th>remainder__f_02</th>\n      <th>remainder__f_03</th>\n      <th>remainder__f_04</th>\n      <th>remainder__f_05</th>\n      <th>remainder__f_06</th>\n      <th>remainder__f_07</th>\n      <th>remainder__f_08</th>\n      <th>remainder__f_09</th>\n      <th>remainder__f_10</th>\n      <th>remainder__f_11</th>\n      <th>remainder__f_12</th>\n      <th>remainder__f_13</th>\n      <th>remainder__f_14</th>\n      <th>remainder__f_15</th>\n      <th>remainder__f_16</th>\n      <th>remainder__f_17</th>\n      <th>remainder__f_18</th>\n      <th>remainder__f_19</th>\n      <th>remainder__f_20</th>\n      <th>remainder__f_21</th>\n      <th>remainder__f_22</th>\n      <th>remainder__f_23</th>\n      <th>remainder__f_24</th>\n      <th>remainder__f_25</th>\n      <th>remainder__f_26</th>\n      <th>remainder__f_28</th>\n      <th>remainder__f_27_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>0.866221</td>\n      <td>0.842351</td>\n      <td>-1.367634</td>\n      <td>1.237506</td>\n      <td>0.682962</td>\n      <td>0.845666</td>\n      <td>0.173852</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>-2.568930</td>\n      <td>-0.796303</td>\n      <td>-0.786741</td>\n      <td>-1.241121</td>\n      <td>-1.245038</td>\n      <td>1.696402</td>\n      <td>0.354545</td>\n      <td>-0.541267</td>\n      <td>-52.223857</td>\n      <td>0.484221</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>0.922494</td>\n      <td>-0.828627</td>\n      <td>0.953987</td>\n      <td>0.835863</td>\n      <td>0.112589</td>\n      <td>2.432248</td>\n      <td>0.236815</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.594356</td>\n      <td>-0.983587</td>\n      <td>-0.789391</td>\n      <td>4.188384</td>\n      <td>-2.615815</td>\n      <td>-2.015672</td>\n      <td>7.466349</td>\n      <td>6.045183</td>\n      <td>448.896335</td>\n      <td>0.484221</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>-0.645481</td>\n      <td>1.060355</td>\n      <td>-1.213576</td>\n      <td>-1.319743</td>\n      <td>-0.032761</td>\n      <td>0.868289</td>\n      <td>0.082763</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>-3.408796</td>\n      <td>3.370601</td>\n      <td>0.445238</td>\n      <td>-0.305235</td>\n      <td>-4.579724</td>\n      <td>-0.982572</td>\n      <td>1.438014</td>\n      <td>-1.008720</td>\n      <td>143.101347</td>\n      <td>0.484221</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>27.0</td>\n      <td>-1.814636</td>\n      <td>-1.578055</td>\n      <td>-0.164912</td>\n      <td>1.024490</td>\n      <td>0.810403</td>\n      <td>1.949860</td>\n      <td>1.704441</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>1.247929</td>\n      <td>-3.367163</td>\n      <td>0.974690</td>\n      <td>-0.255284</td>\n      <td>0.086702</td>\n      <td>-2.260849</td>\n      <td>0.981560</td>\n      <td>-3.270380</td>\n      <td>36.856304</td>\n      <td>0.484221</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>39.0</td>\n      <td>0.916766</td>\n      <td>-0.468947</td>\n      <td>-0.255398</td>\n      <td>-0.569036</td>\n      <td>0.193245</td>\n      <td>0.775350</td>\n      <td>-0.274236</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>0.593269</td>\n      <td>-1.350143</td>\n      <td>-4.503929</td>\n      <td>-0.129318</td>\n      <td>-1.132656</td>\n      <td>0.588172</td>\n      <td>-3.338356</td>\n      <td>0.478027</td>\n      <td>-262.819456</td>\n      <td>0.484221</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   cat__f_29_0  cat__f_29_1  cat__f_30_0  cat__f_30_1  cat__f_30_2  \\\n0          1.0          0.0          1.0          0.0          0.0   \n1          1.0          0.0          1.0          0.0          0.0   \n2          1.0          0.0          1.0          0.0          0.0   \n3          0.0          1.0          0.0          1.0          0.0   \n4          0.0          1.0          1.0          0.0          0.0   \n\n   remainder__id  remainder__f_00  remainder__f_01  remainder__f_02  \\\n0       289957.0        -0.148378         0.548169         0.829241   \n1        30286.0        -0.257653        -0.239395        -1.265026   \n2       160966.0         0.578058         0.435574         1.036967   \n3       557102.0         0.119832        -1.140194         0.259692   \n4        76957.0         0.186579         0.635994        -1.792145   \n\n   remainder__f_03  remainder__f_04  remainder__f_05  remainder__f_06  \\\n0         0.802299         1.274497         0.114888         1.610880   \n1        -1.119950        -0.521108         0.613049         1.392635   \n2         0.393754         1.795100        -0.538760         0.700666   \n3         0.768091         0.435252        -0.705126        -0.101193   \n4        -0.002432         0.991567         1.208961         0.261658   \n\n   remainder__f_07  remainder__f_08  remainder__f_09  remainder__f_10  \\\n0              0.0              5.0              2.0              0.0   \n1              0.0              2.0              0.0              0.0   \n2              1.0              3.0              3.0              3.0   \n3              2.0              4.0              4.0              2.0   \n4              4.0              2.0              3.0              3.0   \n\n   remainder__f_11  remainder__f_12  remainder__f_13  remainder__f_14  \\\n0              1.0              0.0              1.0              2.0   \n1              3.0              1.0              0.0              1.0   \n2              1.0              1.0              1.0              2.0   \n3              1.0              1.0              4.0              1.0   \n4              2.0              4.0              1.0              2.0   \n\n   remainder__f_15  remainder__f_16  remainder__f_17  remainder__f_18  \\\n0              2.0              3.0              1.0              1.0   \n1              2.0              1.0              3.0              2.0   \n2              0.0              0.0              4.0              1.0   \n3              7.0              6.0              3.0              6.0   \n4              2.0              3.0              2.0              0.0   \n\n   remainder__f_19  remainder__f_20  remainder__f_21  remainder__f_22  \\\n0        -1.383431        -2.436701         0.738691        -0.357180   \n1         3.095569         1.966354        -1.913910        -4.345637   \n2        -1.120046        -2.191985         0.597896        -1.264482   \n3        -0.670141        -2.160991         0.812893         0.443669   \n4         0.886578         0.710126         2.281544        -4.812871   \n\n   remainder__f_23  remainder__f_24  remainder__f_25  remainder__f_26  \\\n0         3.859422        -0.357368        -1.819748        -0.173728   \n1        -5.080232        -4.358149        -3.480443        -5.962773   \n2        -0.066934        -1.922217         0.838191         3.240245   \n3        -0.593305        -1.319240         0.505617        -1.560496   \n4        -1.067746         3.884482        -2.182611         6.669902   \n\n   remainder__f_28  remainder__f_27_encoded  \n0       513.106852                 0.548925  \n1      -238.048664                 0.423911  \n2       443.892115                 0.487789  \n3       -23.346895                 0.548876  \n4       154.033815                 0.548911  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat__f_29_0</th>\n      <th>cat__f_29_1</th>\n      <th>cat__f_30_0</th>\n      <th>cat__f_30_1</th>\n      <th>cat__f_30_2</th>\n      <th>remainder__id</th>\n      <th>remainder__f_00</th>\n      <th>remainder__f_01</th>\n      <th>remainder__f_02</th>\n      <th>remainder__f_03</th>\n      <th>remainder__f_04</th>\n      <th>remainder__f_05</th>\n      <th>remainder__f_06</th>\n      <th>remainder__f_07</th>\n      <th>remainder__f_08</th>\n      <th>remainder__f_09</th>\n      <th>remainder__f_10</th>\n      <th>remainder__f_11</th>\n      <th>remainder__f_12</th>\n      <th>remainder__f_13</th>\n      <th>remainder__f_14</th>\n      <th>remainder__f_15</th>\n      <th>remainder__f_16</th>\n      <th>remainder__f_17</th>\n      <th>remainder__f_18</th>\n      <th>remainder__f_19</th>\n      <th>remainder__f_20</th>\n      <th>remainder__f_21</th>\n      <th>remainder__f_22</th>\n      <th>remainder__f_23</th>\n      <th>remainder__f_24</th>\n      <th>remainder__f_25</th>\n      <th>remainder__f_26</th>\n      <th>remainder__f_28</th>\n      <th>remainder__f_27_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>289957.0</td>\n      <td>-0.148378</td>\n      <td>0.548169</td>\n      <td>0.829241</td>\n      <td>0.802299</td>\n      <td>1.274497</td>\n      <td>0.114888</td>\n      <td>1.610880</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.383431</td>\n      <td>-2.436701</td>\n      <td>0.738691</td>\n      <td>-0.357180</td>\n      <td>3.859422</td>\n      <td>-0.357368</td>\n      <td>-1.819748</td>\n      <td>-0.173728</td>\n      <td>513.106852</td>\n      <td>0.548925</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>30286.0</td>\n      <td>-0.257653</td>\n      <td>-0.239395</td>\n      <td>-1.265026</td>\n      <td>-1.119950</td>\n      <td>-0.521108</td>\n      <td>0.613049</td>\n      <td>1.392635</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.095569</td>\n      <td>1.966354</td>\n      <td>-1.913910</td>\n      <td>-4.345637</td>\n      <td>-5.080232</td>\n      <td>-4.358149</td>\n      <td>-3.480443</td>\n      <td>-5.962773</td>\n      <td>-238.048664</td>\n      <td>0.423911</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>160966.0</td>\n      <td>0.578058</td>\n      <td>0.435574</td>\n      <td>1.036967</td>\n      <td>0.393754</td>\n      <td>1.795100</td>\n      <td>-0.538760</td>\n      <td>0.700666</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>-1.120046</td>\n      <td>-2.191985</td>\n      <td>0.597896</td>\n      <td>-1.264482</td>\n      <td>-0.066934</td>\n      <td>-1.922217</td>\n      <td>0.838191</td>\n      <td>3.240245</td>\n      <td>443.892115</td>\n      <td>0.487789</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>557102.0</td>\n      <td>0.119832</td>\n      <td>-1.140194</td>\n      <td>0.259692</td>\n      <td>0.768091</td>\n      <td>0.435252</td>\n      <td>-0.705126</td>\n      <td>-0.101193</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>-0.670141</td>\n      <td>-2.160991</td>\n      <td>0.812893</td>\n      <td>0.443669</td>\n      <td>-0.593305</td>\n      <td>-1.319240</td>\n      <td>0.505617</td>\n      <td>-1.560496</td>\n      <td>-23.346895</td>\n      <td>0.548876</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>76957.0</td>\n      <td>0.186579</td>\n      <td>0.635994</td>\n      <td>-1.792145</td>\n      <td>-0.002432</td>\n      <td>0.991567</td>\n      <td>1.208961</td>\n      <td>0.261658</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.886578</td>\n      <td>0.710126</td>\n      <td>2.281544</td>\n      <td>-4.812871</td>\n      <td>-1.067746</td>\n      <td>3.884482</td>\n      <td>-2.182611</td>\n      <td>6.669902</td>\n      <td>154.033815</td>\n      <td>0.548911</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 6. fit XGBoost #\n\ntime1 = time.time()\nxgb = XGBClassifier(n_estimators=100, max_depth=6, eta=0.1)\nxgb.fit(X_train, y_train)\ndisplay(time.time()-time1)\n\n\ndisplay('Accuracy: ', accuracy_score(y_train,xgb.predict(X_train)))\ndisplay('F1 score: ', f1_score(y_train,xgb.predict(X_train)))\ndisplay('Recall score: ', recall_score(y_train,xgb.predict(X_train)))\ndisplay('Precision score: ', precision_score(y_train,xgb.predict(X_train)))\n# Performance evaluation:\ndisplay('Accuracy: ', accuracy_score(y_test,xgb.predict(X_test)))\ndisplay('F1 score: ', f1_score(y_test,xgb.predict(X_test)))\ndisplay('Recall score: ', recall_score(y_test,xgb.predict(X_test)))\ndisplay('Precision score: ', precision_score(y_test,xgb.predict(X_test)))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-21T20:06:30.611018Z","iopub.execute_input":"2022-07-21T20:06:30.611511Z","iopub.status.idle":"2022-07-21T20:07:12.127697Z","shell.execute_reply.started":"2022-07-21T20:06:30.611472Z","shell.execute_reply":"2022-07-21T20:07:12.126679Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"40.41128444671631"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Accuracy: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.8439253368676828"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'F1 score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.8362059972413154"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Recall score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.8223184771457882"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Precision score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.8505706470477269"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Accuracy: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.8688977247625359"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'F1 score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.866313774073657"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Recall score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.8594413407821229"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Precision score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.8732970027247956"},"metadata":{}}]},{"cell_type":"code","source":"# optuna hyperparameter optimization\n\ntime1 = time.time()\n\ndef objective(trial, n_splits=2, n_jobs=-1, scale_pos_weight=1, early_stopping_rounds=50):\n\n    cv_regularizer=0.0\n    # Usually values between 0.1 and 0.2 work fine.\n\n    params = {\n        \"tree_method\": 'gpu_hist',\n        \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 700),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 10),\n        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.02, 0.3),\n        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.1, 0.95),\n        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 0.95),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 0.1, 10.0),\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 0.1, 100.0),\n        \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-10, 10.0),\n        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 0.1, 10),\n        \"n_jobs\": n_jobs,\n    }\n\n    X = X_train\n    y = y_train\n\n    model = XGBClassifier(**params)\n    rkf = KFold(n_splits=n_splits, shuffle=True)\n    X_values = X.values\n    y_values = y.values\n    y_pred = np.zeros_like(y_values)\n    y_pred_train = np.zeros_like(y_values)\n    for train_index, test_index in rkf.split(X_values):\n        X_A, X_B = X_values[train_index, :], X_values[test_index, :]\n        y_A, y_B = y_values[train_index], y_values[test_index]\n        model.fit(X_A, y_A, eval_set=[(X_B, y_B)],\n                  early_stopping_rounds=early_stopping_rounds, verbose = False)\n        y_pred[test_index] += model.predict(X_B)\n        y_pred_train[train_index] += model.predict(X_A)\n    score_train = f1_score(y_train, y_pred_train)\n    score_test = f1_score(y_train, y_pred) \n    overfit = score_train-score_test\n    #return (f1_score_test)\n    return (score_test-cv_regularizer*overfit)\n\n\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=40)\nprint('Total time for hypermarameter optimization ', time.time()-time1)\nhp = study.best_params\nfor key, value in hp.items():\n    print(f\"{key:>20s} : {value}\")\nprint(f\"{'best objective value':>20s} : {study.best_value}\")\n\noptuna_hyperpars = study.best_params\noptuna_hyperpars['tree_method']='gpu_hist'\noptuna_hyperpars['scale_pos_weight']=1\n#optuna_hyperpars['early_stopping_rounds']=50\n\noptuna_xgb = XGBClassifier(**optuna_hyperpars)\noptuna_xgb.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-21T20:07:12.129328Z","iopub.execute_input":"2022-07-21T20:07:12.129704Z","iopub.status.idle":"2022-07-21T20:14:20.276786Z","shell.execute_reply.started":"2022-07-21T20:07:12.129666Z","shell.execute_reply":"2022-07-21T20:14:20.275710Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-07-21 20:07:12,144]\u001b[0m A new study created in memory with name: no-name-d29071e3-8349-4b25-9c3e-417b02286ef6\u001b[0m\n\u001b[32m[I 2022-07-21 20:07:27,341]\u001b[0m Trial 0 finished with value: 0.826227249239249 and parameters: {'n_estimators': 636, 'max_depth': 9, 'learning_rate': 0.1914385445454791, 'colsample_bytree': 0.749142250718337, 'subsample': 0.7113455166216284, 'alpha': 1.5215215742410007, 'lambda': 18.107204935645516, 'gamma': 4.092383497351642e-08, 'min_child_weight': 0.10513270778208554}. Best is trial 0 with value: 0.826227249239249.\u001b[0m\n\u001b[32m[I 2022-07-21 20:07:35,311]\u001b[0m Trial 1 finished with value: 0.8293636196431855 and parameters: {'n_estimators': 630, 'max_depth': 6, 'learning_rate': 0.17560762307649327, 'colsample_bytree': 0.7894866578795885, 'subsample': 0.8641063093497012, 'alpha': 3.8905180758963436, 'lambda': 42.54006109882384, 'gamma': 2.0032768111499814e-05, 'min_child_weight': 2.66504730571528}. Best is trial 1 with value: 0.8293636196431855.\u001b[0m\n\u001b[32m[I 2022-07-21 20:07:54,541]\u001b[0m Trial 2 finished with value: 0.8288373053665478 and parameters: {'n_estimators': 623, 'max_depth': 9, 'learning_rate': 0.09064929772959808, 'colsample_bytree': 0.8348018715178606, 'subsample': 0.5193151186137558, 'alpha': 0.12351272361549104, 'lambda': 22.540948428646352, 'gamma': 4.293348682060346e-09, 'min_child_weight': 4.439395550313306}. Best is trial 1 with value: 0.8293636196431855.\u001b[0m\n\u001b[32m[I 2022-07-21 20:08:02,670]\u001b[0m Trial 3 finished with value: 0.8040445738007166 and parameters: {'n_estimators': 578, 'max_depth': 6, 'learning_rate': 0.03848446430541054, 'colsample_bytree': 0.4041917748773596, 'subsample': 0.9386474944730141, 'alpha': 0.5616048636198679, 'lambda': 2.129923035765962, 'gamma': 0.019738974310961936, 'min_child_weight': 0.427622182589046}. Best is trial 1 with value: 0.8293636196431855.\u001b[0m\n\u001b[32m[I 2022-07-21 20:08:06,713]\u001b[0m Trial 4 finished with value: 0.8203522504892369 and parameters: {'n_estimators': 591, 'max_depth': 4, 'learning_rate': 0.2601462705446415, 'colsample_bytree': 0.6737767841871382, 'subsample': 0.8745147315332487, 'alpha': 8.898815500235866, 'lambda': 11.289623181752045, 'gamma': 9.707069116396549e-05, 'min_child_weight': 0.6031747130379085}. Best is trial 1 with value: 0.8293636196431855.\u001b[0m\n\u001b[32m[I 2022-07-21 20:08:12,153]\u001b[0m Trial 5 finished with value: 0.7405319793170915 and parameters: {'n_estimators': 580, 'max_depth': 5, 'learning_rate': 0.08338910117221732, 'colsample_bytree': 0.11635461338945577, 'subsample': 0.5362601304804316, 'alpha': 0.8936506334552207, 'lambda': 95.38687005390845, 'gamma': 0.042131053744421304, 'min_child_weight': 0.19436934586498597}. Best is trial 1 with value: 0.8293636196431855.\u001b[0m\n\u001b[32m[I 2022-07-21 20:08:15,880]\u001b[0m Trial 6 finished with value: 0.8131131628514311 and parameters: {'n_estimators': 154, 'max_depth': 8, 'learning_rate': 0.08421585425185377, 'colsample_bytree': 0.6071155460314469, 'subsample': 0.8356094717927616, 'alpha': 1.5058378511162316, 'lambda': 7.278743638780414, 'gamma': 0.43848752319089646, 'min_child_weight': 6.908389915657233}. Best is trial 1 with value: 0.8293636196431855.\u001b[0m\n\u001b[32m[I 2022-07-21 20:08:17,848]\u001b[0m Trial 7 finished with value: 0.7511634273200108 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.036213593609106295, 'colsample_bytree': 0.4853594636131313, 'subsample': 0.6733371222489293, 'alpha': 0.9782187777632254, 'lambda': 1.0858858337569635, 'gamma': 0.13323441876856693, 'min_child_weight': 0.16071738704185332}. Best is trial 1 with value: 0.8293636196431855.\u001b[0m\n\u001b[32m[I 2022-07-21 20:08:24,785]\u001b[0m Trial 8 finished with value: 0.8182277434613883 and parameters: {'n_estimators': 112, 'max_depth': 10, 'learning_rate': 0.22297306109061332, 'colsample_bytree': 0.9050877293330483, 'subsample': 0.626026715897533, 'alpha': 3.053748997006962, 'lambda': 0.3897427571884064, 'gamma': 0.00034981156595376514, 'min_child_weight': 1.117711539735235}. Best is trial 1 with value: 0.8293636196431855.\u001b[0m\n\u001b[32m[I 2022-07-21 20:08:31,823]\u001b[0m Trial 9 finished with value: 0.8195821224686707 and parameters: {'n_estimators': 361, 'max_depth': 7, 'learning_rate': 0.18956482357179802, 'colsample_bytree': 0.5603918580205917, 'subsample': 0.6202818531612017, 'alpha': 5.757705593997208, 'lambda': 19.207355827188263, 'gamma': 2.7068239281630187e-09, 'min_child_weight': 0.4853066393231313}. Best is trial 1 with value: 0.8293636196431855.\u001b[0m\n\u001b[32m[I 2022-07-21 20:08:37,115]\u001b[0m Trial 10 finished with value: 0.7889325881460015 and parameters: {'n_estimators': 433, 'max_depth': 7, 'learning_rate': 0.2967053191041221, 'colsample_bytree': 0.28086680633737854, 'subsample': 0.8093253651410587, 'alpha': 0.27634054387238516, 'lambda': 0.1019183810494973, 'gamma': 6.685943402833796e-07, 'min_child_weight': 2.24921923151735}. Best is trial 1 with value: 0.8293636196431855.\u001b[0m\n\u001b[32m[I 2022-07-21 20:08:57,644]\u001b[0m Trial 11 finished with value: 0.825633143696091 and parameters: {'n_estimators': 681, 'max_depth': 10, 'learning_rate': 0.1325585151344332, 'colsample_bytree': 0.9408961429466134, 'subsample': 0.502373521505911, 'alpha': 0.11116385731821728, 'lambda': 68.32412706789692, 'gamma': 1.7790101879861647e-10, 'min_child_weight': 5.162460580908349}. Best is trial 1 with value: 0.8293636196431855.\u001b[0m\n\u001b[32m[I 2022-07-21 20:09:09,903]\u001b[0m Trial 12 finished with value: 0.8294890645102003 and parameters: {'n_estimators': 465, 'max_depth': 8, 'learning_rate': 0.1322076456322876, 'colsample_bytree': 0.796033397477616, 'subsample': 0.7708146570183175, 'alpha': 0.11753888250876439, 'lambda': 38.363605207468915, 'gamma': 7.519862262099528e-07, 'min_child_weight': 3.1600106539876682}. Best is trial 12 with value: 0.8294890645102003.\u001b[0m\n\u001b[32m[I 2022-07-21 20:09:16,289]\u001b[0m Trial 13 finished with value: 0.8289417691237192 and parameters: {'n_estimators': 466, 'max_depth': 6, 'learning_rate': 0.13519710033420448, 'colsample_bytree': 0.765842722901633, 'subsample': 0.7738757633779976, 'alpha': 3.8290642381936624, 'lambda': 4.106944433629476, 'gamma': 3.6838407769694714e-06, 'min_child_weight': 2.016301985210622}. Best is trial 12 with value: 0.8294890645102003.\u001b[0m\n\u001b[32m[I 2022-07-21 20:09:25,045]\u001b[0m Trial 14 finished with value: 0.8310428827503791 and parameters: {'n_estimators': 332, 'max_depth': 8, 'learning_rate': 0.15019455616658164, 'colsample_bytree': 0.6975268798825719, 'subsample': 0.9105445094050328, 'alpha': 0.2735735297630836, 'lambda': 43.95639352550274, 'gamma': 0.0009601426128108704, 'min_child_weight': 3.1045517178700113}. Best is trial 14 with value: 0.8310428827503791.\u001b[0m\n\u001b[32m[I 2022-07-21 20:09:34,140]\u001b[0m Trial 15 finished with value: 0.8308307847961554 and parameters: {'n_estimators': 317, 'max_depth': 8, 'learning_rate': 0.13396659063985739, 'colsample_bytree': 0.7000122225389064, 'subsample': 0.9486340179721116, 'alpha': 0.23918560000082617, 'lambda': 33.29503045575085, 'gamma': 0.0018377097599311348, 'min_child_weight': 1.1948991218715936}. Best is trial 14 with value: 0.8310428827503791.\u001b[0m\n\u001b[32m[I 2022-07-21 20:09:35,912]\u001b[0m Trial 16 finished with value: 0.7919560989163656 and parameters: {'n_estimators': 289, 'max_depth': 8, 'learning_rate': 0.22182779952263187, 'colsample_bytree': 0.671726077862706, 'subsample': 0.9297613456560332, 'alpha': 0.3089668038277642, 'lambda': 5.677231529977067, 'gamma': 8.782618997083228, 'min_child_weight': 1.1642142242171571}. Best is trial 14 with value: 0.8310428827503791.\u001b[0m\n\u001b[32m[I 2022-07-21 20:09:43,484]\u001b[0m Trial 17 finished with value: 0.8175148855797026 and parameters: {'n_estimators': 271, 'max_depth': 9, 'learning_rate': 0.10914067056629788, 'colsample_bytree': 0.42267431300623126, 'subsample': 0.8994685703822265, 'alpha': 0.254601020134178, 'lambda': 1.8479843527532376, 'gamma': 0.00155829261738168, 'min_child_weight': 9.840756050029615}. Best is trial 14 with value: 0.8310428827503791.\u001b[0m\n\u001b[32m[I 2022-07-21 20:09:52,860]\u001b[0m Trial 18 finished with value: 0.8302415603211615 and parameters: {'n_estimators': 330, 'max_depth': 8, 'learning_rate': 0.16620525608020462, 'colsample_bytree': 0.6668496813714712, 'subsample': 0.94375032153823, 'alpha': 0.45076609305446147, 'lambda': 43.61018593347256, 'gamma': 0.00457585991320407, 'min_child_weight': 1.5801740120784171}. Best is trial 14 with value: 0.8310428827503791.\u001b[0m\n\u001b[32m[I 2022-07-21 20:09:57,393]\u001b[0m Trial 19 finished with value: 0.8200439338002737 and parameters: {'n_estimators': 218, 'max_depth': 7, 'learning_rate': 0.21329456818581144, 'colsample_bytree': 0.4933219598149094, 'subsample': 0.8934530739111641, 'alpha': 0.2044547871750377, 'lambda': 10.204449896956021, 'gamma': 0.0005344409892506553, 'min_child_weight': 0.7094398285467347}. Best is trial 14 with value: 0.8310428827503791.\u001b[0m\n\u001b[32m[I 2022-07-21 20:10:04,281]\u001b[0m Trial 20 finished with value: 0.8100418796220451 and parameters: {'n_estimators': 513, 'max_depth': 9, 'learning_rate': 0.15052703716367144, 'colsample_bytree': 0.31989364896738626, 'subsample': 0.825332563206136, 'alpha': 0.5334495005930057, 'lambda': 99.62779784314421, 'gamma': 1.5434730465506423, 'min_child_weight': 0.29162100010455444}. Best is trial 14 with value: 0.8310428827503791.\u001b[0m\n\u001b[32m[I 2022-07-21 20:10:14,044]\u001b[0m Trial 21 finished with value: 0.8305394381570633 and parameters: {'n_estimators': 356, 'max_depth': 8, 'learning_rate': 0.16634219206683004, 'colsample_bytree': 0.638921423096761, 'subsample': 0.9444509006484625, 'alpha': 0.4185665747350143, 'lambda': 39.314238702984916, 'gamma': 0.004975754738844747, 'min_child_weight': 1.7839705655539555}. Best is trial 14 with value: 0.8310428827503791.\u001b[0m\n\u001b[32m[I 2022-07-21 20:10:25,028]\u001b[0m Trial 22 finished with value: 0.8295488531529667 and parameters: {'n_estimators': 378, 'max_depth': 8, 'learning_rate': 0.11260684563808342, 'colsample_bytree': 0.6227712397450972, 'subsample': 0.9069181497615658, 'alpha': 0.17924873623531082, 'lambda': 27.1793768363266, 'gamma': 0.003199631995053416, 'min_child_weight': 1.3251937738859125}. Best is trial 14 with value: 0.8310428827503791.\u001b[0m\n\u001b[32m[I 2022-07-21 20:10:30,911]\u001b[0m Trial 23 finished with value: 0.8276886580605041 and parameters: {'n_estimators': 273, 'max_depth': 7, 'learning_rate': 0.15435942395679314, 'colsample_bytree': 0.7074293435594141, 'subsample': 0.8635983877168447, 'alpha': 0.35061980550770616, 'lambda': 56.501546631661675, 'gamma': 2.624238645945157e-05, 'min_child_weight': 0.8215641538933333}. Best is trial 14 with value: 0.8310428827503791.\u001b[0m\n\u001b[32m[I 2022-07-21 20:10:41,943]\u001b[0m Trial 24 finished with value: 0.8328872244368115 and parameters: {'n_estimators': 325, 'max_depth': 9, 'learning_rate': 0.06637425899160632, 'colsample_bytree': 0.8553379064277559, 'subsample': 0.9159695147415622, 'alpha': 0.7503762769553006, 'lambda': 15.243984262946594, 'gamma': 0.012219202365781515, 'min_child_weight': 4.232016759590844}. Best is trial 24 with value: 0.8328872244368115.\u001b[0m\n\u001b[32m[I 2022-07-21 20:10:55,453]\u001b[0m Trial 25 finished with value: 0.83465091694627 and parameters: {'n_estimators': 307, 'max_depth': 10, 'learning_rate': 0.06451038258193971, 'colsample_bytree': 0.8408838900336248, 'subsample': 0.794804182694289, 'alpha': 0.7488009529415233, 'lambda': 12.367057230618599, 'gamma': 0.02729096983981581, 'min_child_weight': 3.930982881778336}. Best is trial 25 with value: 0.83465091694627.\u001b[0m\n\u001b[32m[I 2022-07-21 20:11:05,595]\u001b[0m Trial 26 finished with value: 0.8286392550935743 and parameters: {'n_estimators': 220, 'max_depth': 10, 'learning_rate': 0.061282540881015896, 'colsample_bytree': 0.8581045758935133, 'subsample': 0.7833894280648963, 'alpha': 0.6566520402977712, 'lambda': 11.72972594685686, 'gamma': 0.045243713775359955, 'min_child_weight': 3.9265238817422867}. Best is trial 25 with value: 0.83465091694627.\u001b[0m\n\u001b[32m[I 2022-07-21 20:11:21,505]\u001b[0m Trial 27 finished with value: 0.8340711271573283 and parameters: {'n_estimators': 417, 'max_depth': 10, 'learning_rate': 0.05821918990267409, 'colsample_bytree': 0.8822243057167595, 'subsample': 0.7478157514952052, 'alpha': 1.4026668650926848, 'lambda': 16.031155955289982, 'gamma': 0.2796157877220729, 'min_child_weight': 6.940381443518568}. Best is trial 25 with value: 0.83465091694627.\u001b[0m\n\u001b[32m[I 2022-07-21 20:11:36,911]\u001b[0m Trial 28 finished with value: 0.8238485513101697 and parameters: {'n_estimators': 432, 'max_depth': 10, 'learning_rate': 0.02069402978669954, 'colsample_bytree': 0.8834014679866703, 'subsample': 0.728803186070256, 'alpha': 1.8068658513805453, 'lambda': 3.4406583795670542, 'gamma': 1.1951458874101708, 'min_child_weight': 9.958263423903194}. Best is trial 25 with value: 0.83465091694627.\u001b[0m\n\u001b[32m[I 2022-07-21 20:11:41,310]\u001b[0m Trial 29 finished with value: 0.8108820570926455 and parameters: {'n_estimators': 512, 'max_depth': 9, 'learning_rate': 0.05641437921311223, 'colsample_bytree': 0.9300020087943143, 'subsample': 0.7133307113863059, 'alpha': 1.6031165146796693, 'lambda': 14.928840655358231, 'gamma': 8.440421443259938, 'min_child_weight': 6.5906982859854155}. Best is trial 25 with value: 0.83465091694627.\u001b[0m\n\u001b[32m[I 2022-07-21 20:11:55,797]\u001b[0m Trial 30 finished with value: 0.8351310061224255 and parameters: {'n_estimators': 405, 'max_depth': 10, 'learning_rate': 0.06189615715323164, 'colsample_bytree': 0.8218611318887707, 'subsample': 0.6711052844401243, 'alpha': 2.21766561962424, 'lambda': 6.992044205187363, 'gamma': 0.5885468408561074, 'min_child_weight': 6.595830729317315}. Best is trial 30 with value: 0.8351310061224255.\u001b[0m\n\u001b[32m[I 2022-07-21 20:12:10,926]\u001b[0m Trial 31 finished with value: 0.8347252696757 and parameters: {'n_estimators': 403, 'max_depth': 10, 'learning_rate': 0.06324535471654888, 'colsample_bytree': 0.8270924030713904, 'subsample': 0.6770053163997837, 'alpha': 1.2456834869450901, 'lambda': 7.291436349190176, 'gamma': 0.21794910018815217, 'min_child_weight': 6.477999414644088}. Best is trial 30 with value: 0.8351310061224255.\u001b[0m\n\u001b[32m[I 2022-07-21 20:12:25,745]\u001b[0m Trial 32 finished with value: 0.833185519632347 and parameters: {'n_estimators': 406, 'max_depth': 10, 'learning_rate': 0.04522222034676761, 'colsample_bytree': 0.8120476568057894, 'subsample': 0.6826024211744338, 'alpha': 2.342530792805675, 'lambda': 6.7570766286485355, 'gamma': 0.1960421336192079, 'min_child_weight': 6.6930639047067615}. Best is trial 30 with value: 0.8351310061224255.\u001b[0m\n\u001b[32m[I 2022-07-21 20:12:38,131]\u001b[0m Trial 33 finished with value: 0.8314617073366972 and parameters: {'n_estimators': 504, 'max_depth': 10, 'learning_rate': 0.10020168264965243, 'colsample_bytree': 0.7303508925211429, 'subsample': 0.7434953971201869, 'alpha': 1.2006881125107927, 'lambda': 4.838884856254979, 'gamma': 1.229957353440675, 'min_child_weight': 5.2636453445008025}. Best is trial 30 with value: 0.8351310061224255.\u001b[0m\n\u001b[32m[I 2022-07-21 20:12:54,484]\u001b[0m Trial 34 finished with value: 0.8310806924713866 and parameters: {'n_estimators': 435, 'max_depth': 10, 'learning_rate': 0.07521565132454273, 'colsample_bytree': 0.7626038967750333, 'subsample': 0.6723665326523331, 'alpha': 2.190921064382144, 'lambda': 2.5426400206323794, 'gamma': 0.11119406594577881, 'min_child_weight': 7.189638995654123}. Best is trial 30 with value: 0.8351310061224255.\u001b[0m\n\u001b[32m[I 2022-07-21 20:13:08,007]\u001b[0m Trial 35 finished with value: 0.8295942940763018 and parameters: {'n_estimators': 382, 'max_depth': 9, 'learning_rate': 0.02993637059007062, 'colsample_bytree': 0.8489638867156618, 'subsample': 0.6392977777259659, 'alpha': 1.2434365973463948, 'lambda': 1.4175236950720187, 'gamma': 0.532783814600536, 'min_child_weight': 3.426048650151487}. Best is trial 30 with value: 0.8351310061224255.\u001b[0m\n\u001b[32m[I 2022-07-21 20:13:28,084]\u001b[0m Trial 36 finished with value: 0.8374444227433048 and parameters: {'n_estimators': 543, 'max_depth': 10, 'learning_rate': 0.05367627363372013, 'colsample_bytree': 0.812745702543195, 'subsample': 0.7481926902521382, 'alpha': 2.737048067746892, 'lambda': 8.44524988424516, 'gamma': 0.04239413588771567, 'min_child_weight': 8.158149051817619}. Best is trial 36 with value: 0.8374444227433048.\u001b[0m\n\u001b[32m[I 2022-07-21 20:13:46,952]\u001b[0m Trial 37 finished with value: 0.834730029543286 and parameters: {'n_estimators': 553, 'max_depth': 9, 'learning_rate': 0.04899212115964358, 'colsample_bytree': 0.8114154588470093, 'subsample': 0.7007483001742739, 'alpha': 5.955568351422481, 'lambda': 8.201035006261206, 'gamma': 0.023837712308161167, 'min_child_weight': 2.5897440014682642}. Best is trial 36 with value: 0.8374444227433048.\u001b[0m\n\u001b[32m[I 2022-07-21 20:14:05,315]\u001b[0m Trial 38 finished with value: 0.8309912647170526 and parameters: {'n_estimators': 540, 'max_depth': 9, 'learning_rate': 0.044592726343568624, 'colsample_bytree': 0.7834110657452708, 'subsample': 0.5782192322145706, 'alpha': 6.3326135581467105, 'lambda': 8.209987934156437, 'gamma': 9.087386940189592e-05, 'min_child_weight': 2.368073121875756}. Best is trial 36 with value: 0.8374444227433048.\u001b[0m\n\u001b[32m[I 2022-07-21 20:14:11,580]\u001b[0m Trial 39 finished with value: 0.8256663602941177 and parameters: {'n_estimators': 648, 'max_depth': 9, 'learning_rate': 0.09311500567326911, 'colsample_bytree': 0.7468921176041037, 'subsample': 0.6977610690682718, 'alpha': 9.568853313885606, 'lambda': 0.812061029077909, 'gamma': 2.4539998483537038, 'min_child_weight': 5.273171085933164}. Best is trial 36 with value: 0.8374444227433048.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  419.4376940727234\n        n_estimators : 543\n           max_depth : 10\n       learning_rate : 0.05367627363372013\n    colsample_bytree : 0.812745702543195\n           subsample : 0.7481926902521382\n               alpha : 2.737048067746892\n              lambda : 8.44524988424516\n               gamma : 0.04239413588771567\n    min_child_weight : 8.158149051817619\nbest objective value : 0.8374444227433048\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(alpha=2.737048067746892, base_score=0.5, booster='gbtree',\n              callbacks=None, colsample_bylevel=1, colsample_bynode=1,\n              colsample_bytree=0.812745702543195, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None,\n              gamma=0.04239413588771567, gpu_id=0, grow_policy='depthwise',\n              importance_type=None, interaction_constraints='',\n              lambda=8.44524988424516, learning_rate=0.05367627363372013,\n              max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=10,\n              max_leaves=0, min_child_weight=8.158149051817619, missing=nan,\n              monotone_constraints='()', n_estimators=543, n_jobs=0,\n              num_parallel_tree=1, predictor='auto', random_state=0, ...)"},"metadata":{}}]},{"cell_type":"code","source":"display('Accuracy: ', accuracy_score(y_train,optuna_xgb.predict(X_train)))\ndisplay('F1 score: ', f1_score(y_train,optuna_xgb.predict(X_train)))\ndisplay('Recall score: ', recall_score(y_train,optuna_xgb.predict(X_train)))\ndisplay('Precision score: ', precision_score(y_train,optuna_xgb.predict(X_train)))\n# Performance evaluation:\ndisplay('Accuracy: ', accuracy_score(y_test,optuna_xgb.predict(X_test)))\ndisplay('F1 score: ', f1_score(y_test,optuna_xgb.predict(X_test)))\ndisplay('Recall score: ', recall_score(y_test,optuna_xgb.predict(X_test)))\ndisplay('Precision score: ', precision_score(y_test,optuna_xgb.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2022-07-21T20:14:20.278220Z","iopub.execute_input":"2022-07-21T20:14:20.278720Z","iopub.status.idle":"2022-07-21T20:14:31.867514Z","shell.execute_reply.started":"2022-07-21T20:14:20.278682Z","shell.execute_reply":"2022-07-21T20:14:31.866465Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"'Accuracy: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.9386127678374199"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'F1 score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.9362804668332836"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Recall score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.9309016300011399"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Precision score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.9417218237586772"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Accuracy: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.9652087475149106"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'F1 score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.9644027573737145"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Recall score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.9535195530726257"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Precision score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.9755372656607224"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 7. Do FI analysisany","metadata":{"execution":{"iopub.status.busy":"2022-07-21T20:14:31.869064Z","iopub.execute_input":"2022-07-21T20:14:31.869427Z","iopub.status.idle":"2022-07-21T20:14:31.874306Z","shell.execute_reply.started":"2022-07-21T20:14:31.869391Z","shell.execute_reply":"2022-07-21T20:14:31.872936Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
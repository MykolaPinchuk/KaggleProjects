{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This script is developed based on 'KProject_HousePrice_i5'","metadata":{}},{"cell_type":"markdown","source":"### Outline:\n0. Load libraries and custom functions.\n1. Load data.\n2. Preliminary data analysis: explore features and a target, delete unneeded features, create new features.\n3. Train-test split.\n4. Missing values. In some cases it may be useful to explore skew and perform log-transform before imputing missing values.\n5. Feature engineering. Transform skewed variables, do OHC and scaling.\n6. Fit models.\n7. Evaluate models.\n8. Feature importance, error analysis. Based on the results, go to 2. and iterate.\n9. Make predictions.","metadata":{}},{"cell_type":"code","source":"# 0. Load libraries #\n\nimport numpy as np\nimport pandas as pd\nimport os, time, warnings\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.svm import SVC, SVR\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, r2_score, mean_squared_error\nfrom sklearn.inspection import permutation_importance\nfrom scipy.special import inv_boxcox\nfrom xgboost import XGBClassifier, XGBRegressor\n\npd.set_option('display.max_columns', 20)\npd.set_option('mode.chained_assignment', None)\npd.set_option('display.expand_frame_repr', False)\nwarnings.filterwarnings('ignore')\n\ndef draw_histograms(df, variables, n_rows, n_cols):\n    # stolen from https://stackoverflow.com/questions/29530355/plotting-multiple-histograms-in-grid\n    fig=plt.figure()\n    for i, var_name in enumerate(variables):\n        ax=fig.add_subplot(n_rows,n_cols,i+1)\n        df[var_name].hist(bins=10,ax=ax)\n        ax.set_title(var_name+\" Distribution\")\n    fig.tight_layout()  \n    plt.show()\n\n\ndef fillna_mp_i1(df_train, df_test, df_pred, num_features, cat_features, num_fill='median', cat_fill='mode'):\n    \"\"\"This function speeds up filling missing values for 3 main datasets using different imputation methods.\n    Later may replace it with some subclass.\n    Example: fillna_mp_i1(X_train, X_test, X_pred, num_cols, cat_cols)\"\"\"\n    # set df_pred to None if it does not exist\n    if (cat_fill=='mode'):\n    \n        df_train[cat_features] = df_train[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n        df_test[cat_features] = df_test[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n        if (df_pred is not None):\n            df_pred[cat_features] = df_pred[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n            \n    if (cat_fill=='missing'):\n    \n        df_train[cat_features] = df_train[cat_features].fillna(value='missing')\n        df_test[cat_features] = df_test[cat_features].fillna(value='missing')\n        if (df_pred is not None):\n            df_pred[cat_features] = df_pred[cat_features].fillna(value='missing')\n        \n    if (num_fill=='median'):\n        df_train[num_features] = df_train[num_features].fillna(value=df_train[num_features].median())\n        df_test[num_features] = df_test[num_features].fillna(value=df_train[num_features].median())\n        if (df_pred is not None):\n            df_pred[num_features] = df_pred[num_features].fillna(value=df_train[num_features].median())    \n    \n    all_good = (\n    (np.prod(df_train[num_features+cat_features].shape)==df_train[num_features+cat_features].count().sum()) and \n    (np.prod(df_test[num_features+cat_features].shape) == df_test[num_features+cat_features].count().sum()) and \n    (np.prod(df_pred[num_features+cat_features].shape) == df_pred[num_features+cat_features].count().sum()))\n    if (all_good):\n        print('Missing values imputed successfully')\n    else:\n        print('There are still some missing values...')\n    \n    \n    \ndef add_misDummy_mp_i1(df_train, df_test, df_pred, features):\n    \"\"\"This function creates new dummy columns for missing features.\n    Example: add_misDummy_mp_i1(X_train, X_test, X_pred, ['Age'])\"\"\"\n    # set df_pred to None if it does not exist\n    for feature_name in features:\n        misColName = 'mis'+feature_name\n        df_train.loc[df_train[feature_name].isnull(), misColName]=1\n        df_train.loc[df_train[feature_name].notnull(), misColName]=0\n        df_test.loc[df_test[feature_name].isnull(), misColName]=1\n        df_test.loc[df_test[feature_name].notnull(), misColName]=0\n        if (df_pred is not None):\n            df_pred.loc[df_pred[feature_name].isnull(), misColName]=1\n            df_pred.loc[df_pred[feature_name].notnull(), misColName]=0\n   \n\ndef discretize_mp_i1(df_train, df_test, df_pred, feature, ntiles, delete_feature=False):\n    \"\"\"This function divides a continuous feature into quantile groups.\n    Example: discretize_mp_i1(X_train, X_test, X_pred, 'Age', 15)\"\"\"\n    # set df_pred to None if it does not exist\n    _,bin = pd.qcut(df_train[feature], ntiles, retbins = True, labels = False, duplicates = 'drop')\n    df_train[feature+'Ntile'] = pd.cut(df_train[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    df_test[feature+'Ntile'] = pd.cut(df_test[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    if (df_pred is not None):\n        df_pred[feature+'Ntile'] = pd.cut(df_pred[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    if (delete_feature==True):\n        df_train.drop(columns=[feature], inplace=True)\n        df_test.drop(columns=[feature], inplace=True)\n        df_pred.drop(columns=[feature], inplace=True)\n    print('Discretized ',feature, ' into ', len(bin)-1, ' bins')\n\n\ndef log_transformer_mp_i1(df_train, df_test, df_pred, feature_subset=False, min_skew=3):\n    \"\"\"This function divides a continuous feature into quantile groups.\n    Example: log_transformer_mp_i1(X_train, X_test, X_pred, feature_subset=num_cols)\"\"\"\n    # set df_pred to None if it does not exist\n    if (feature_subset==False):\n        features_totransform = df_train.columns\n    else:\n        features_totransform = feature_subset.copy()\n    skewed_vars = list(df_train.skew()[abs(df_train.skew())>min_skew].index)\n    for col in list(set(skewed_vars)&set(features_totransform)):\n        df_train[col] = np.log1p(df_train[col])\n        df_test[col] = np.log1p(df_test[col])\n        if (df_pred is not None):\n            df_pred[col] = np.log1p(df_pred[col])\n    print('Skewed columns log-transformed: ', list(set(skewed_vars)&set(features_totransform)))\n    \n    \ndef add_dummyfeatures(df_train, df_test, df_pred, feature_dict):\n    \"\"\"This function adds dummy feature when some feature is equal to value, specified in a dictionary.\n    Example: add_dummyfeatures(X_train, X_test, X_pred, {'RoomService':0, 'Spa':0, 'VRDeck':0, 'ShoppingMall':0})\"\"\"\n    input_dimensions = np.array([df_train.shape[1], df_test.shape[1], df_pred.shape[1]])\n    for i in range(len(list(feature_dict.items()))):\n        feature,value = list(feature_dict.keys())[i], list(feature_dict.values())[i]\n        df_train.loc[df_train[feature]==value,(str(feature)+str(value))]=1\n        df_train.loc[df_train[feature]!=value,(str(feature)+str(value))]=0\n        df_test.loc[df_test[feature]==value,(str(feature)+str(value))]=1\n        df_test.loc[df_test[feature]!=value,(str(feature)+str(value))]=0\n        df_pred.loc[df_pred[feature]==value,(str(feature)+str(value))]=1\n        df_pred.loc[df_pred[feature]!=value,(str(feature)+str(value))]=0\n    output_dimensions = np.array([df_train.shape[1], df_test.shape[1], df_pred.shape[1]])\n    print(output_dimensions-input_dimensions, ' variables created') \n    ","metadata":{"execution":{"iopub.status.busy":"2022-10-27T22:38:11.774541Z","iopub.execute_input":"2022-10-27T22:38:11.774918Z","iopub.status.idle":"2022-10-27T22:38:11.810661Z","shell.execute_reply.started":"2022-10-27T22:38:11.774880Z","shell.execute_reply":"2022-10-27T22:38:11.809942Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# 1. Load data #\n\ntime0 = time.time()\npath = '../input/house-prices-advanced-regression-techniques/train.csv'\ndf = pd.read_csv(path) \ndf0 = df.copy()\n\npred=pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\npred0 = pred.copy()\n\nprint(df.shape, pred.shape)\ndf\n\nirrelevant_features = pd.read_csv('../input/homeprice-features30/KP20_irrel_features_30.csv')\n\n# 2. pEDA #\n\ncols_tokeep = ['Id', 'SalePrice', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'ExterCond', \n               'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', 'HeatingQC', '1stFlrSF', '2ndFlrSF', 'GrLivArea',  \n               'KitchenQual', 'GarageArea', 'GarageCars', 'TotRmsAbvGrd', 'BedroomAbvGr', 'FullBath', \n               'HalfBath', 'MiscVal', 'LotFrontage', \n               'ExterQual', 'MSSubClass', 'MSZoning', 'LotShape', 'LandContour', 'LotConfig', 'Neighborhood',\n               'Condition1', 'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd',\n               'Foundation', 'Heating', 'CentralAir', 'Electrical', 'Functional', 'PavedDrive',\n               'SaleType', 'SaleCondition', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', \n               'BsmtExposure', 'BsmtFinType1', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']\ndf = df[cols_tokeep]\nX_pred = pred[list(set(cols_tokeep) - set(['SalePrice']))]\n\n# preliminary feature engineering:\ndf['GrLivArea_log'] = np.log1p(df['GrLivArea'])\nX_pred['GrLivArea_log'] = np.log1p(X_pred['GrLivArea'])\n# w/o logtransform, scatterplot looks better. not sure whether log tranform helps.\n\n\n# 3. train-test split #\n\ntrain_y = df['SalePrice']\ntrain_x = df.drop(columns = ['SalePrice'])\n\nord_cols = ['ExterCond', 'HeatingQC', 'KitchenQual', 'ExterQual', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond']\n#num_cols = [col for col in train_x.columns if train_x[col].nunique() > 12]\nnum_cols = ['Id', 'LotArea', 'YearBuilt', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', \n            'GrLivArea', 'GarageArea', 'MiscVal', 'LotFrontage', 'MasVnrArea',\n           'TotRmsAbvGrd', 'GarageCars', 'BedroomAbvGr', 'OverallCond', 'OverallQual', 'GrLivArea_log']\ncat_cols = list(set(train_x.columns)-set(num_cols)-set(ord_cols))\n# for now, view ordinal features as categorical features\nprint(\"Numerical features \", num_cols, \"\\n\",\n      'Ordinal features', ord_cols, '\\n',\n      \"Categorical features \", cat_cols)\n\ntrain_x[ord_cols] = train_x[ord_cols].replace(['Po', 'Fa', 'TA', 'Gd', 'Ex'], [1,2,3,4,5])\nX_pred[ord_cols] = X_pred[ord_cols].replace(['Po', 'Fa', 'TA', 'Gd', 'Ex'], [1,2,3,4,5])\n\nX_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.01, random_state=2)\nprint(X_train.shape, X_test.shape, y_train.shape, X_pred.shape)\n\n# 4. Missing values #\n\nfillna_mp_i1(X_train, X_test, X_pred, num_cols, cat_cols, num_fill = 'median', cat_fill='missing')\n\n# fill na for ordinal columns. missing values if those columns ususally mean that that feature DNE, so 0.\nX_train[ord_cols] = X_train[ord_cols].fillna(value=0)\nX_test[ord_cols] = X_test[ord_cols].fillna(value=0)\nX_pred[ord_cols] = X_pred[ord_cols].fillna(value=0)\n\n# 5. Feature engineering #\n\n# add dummy features\nadd_dummyfeatures(X_train, X_test, X_pred, {'OverallQual':1, 'OverallQual':8, 'OverallQual':9, 'OverallQual':10})\n\nlog_transformer_mp_i1(X_train, X_test, X_pred, feature_subset=num_cols)\n\nfeature_transformer = ColumnTransformer([\n    (\"num\", StandardScaler(), num_cols+ord_cols),\n    (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\"), cat_cols),\n    ])\n\nX_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\nX_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\nX_pred = pd.DataFrame(feature_transformer.transform(X_pred), columns=feature_transformer.get_feature_names_out())\n\n# there are many dummies... may wish to use pca here later.\n\nprint(X_train.shape, X_test.shape, y_train.shape, X_pred.shape)\n# another way to deal with redundant features is to delete those, which do not help in feature importance:\ncols = list(X_train.columns)\ncols_few = list(set(cols)-set(list(irrelevant_features.loc[irrelevant_features.freq>19, 'col'])))\ncols_veryfew = list(set(cols)-set(list(irrelevant_features.loc[irrelevant_features.freq>15, 'col'])))\ncols_veryveryfew = list(set(cols)-set(list(irrelevant_features.loc[irrelevant_features.freq>9, 'col'])))\nprint('Feature sets: ', len(cols), len(cols_few), len(cols_veryfew), len(cols_veryveryfew))\n# after running _v5 of this script for like 30 times, \n# I believe that the feature set of 56 features is the best due to decreasing overfitting.","metadata":{"execution":{"iopub.status.busy":"2022-10-27T22:38:11.812831Z","iopub.execute_input":"2022-10-27T22:38:11.813644Z","iopub.status.idle":"2022-10-27T22:38:12.037362Z","shell.execute_reply.started":"2022-10-27T22:38:11.813612Z","shell.execute_reply":"2022-10-27T22:38:12.036416Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(1460, 81) (1459, 80)\nNumerical features  ['Id', 'LotArea', 'YearBuilt', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageArea', 'MiscVal', 'LotFrontage', 'MasVnrArea', 'TotRmsAbvGrd', 'GarageCars', 'BedroomAbvGr', 'OverallCond', 'OverallQual', 'GrLivArea_log'] \n Ordinal features ['ExterCond', 'HeatingQC', 'KitchenQual', 'ExterQual', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond'] \n Categorical features  ['SaleType', 'FullBath', 'MSSubClass', 'Heating', 'Electrical', 'LotShape', 'BsmtExposure', 'RoofStyle', 'Condition1', 'LandContour', 'BldgType', 'MasVnrType', 'GarageFinish', 'Foundation', 'PavedDrive', 'HouseStyle', 'HalfBath', 'Exterior1st', 'GarageType', 'MSZoning', 'Exterior2nd', 'Neighborhood', 'Functional', 'BsmtFinType1', 'SaleCondition', 'LotConfig', 'CentralAir']\n(1445, 54) (15, 54) (1445,) (1459, 54)\nMissing values imputed successfully\n[1 1 1]  variables created\nSkewed columns log-transformed:  ['LotArea', 'BsmtFinSF2', 'MiscVal']\n(1445, 224) (15, 224) (1445,) (1459, 224)\nFeature sets:  224 121 91 55\n","output_type":"stream"}]},{"cell_type":"code","source":"# 6. Model Fitting #\n\nprint(X_train.shape)\n\nlr = LinearRegression()\nlr.fit(X_train[cols_veryveryfew], y_train)\nprint('OLS ', mean_squared_error(y_train, lr.predict(X_train[cols_veryveryfew])))\n\ntime1 = time.time()\nsvr4 = SVR()\ngrid_param = {'C': [50000, 100000, 200000, 400000, 600000, 900000]}\nsvrm4 = GridSearchCV(svr4, grid_param, cv=8, scoring='neg_root_mean_squared_error')\nsvrm4.fit(X_train[cols_veryveryfew], y_train)\nprint('SVR 56 cols', \n      svrm4.best_params_, \n      svrm4.best_score_, \n      np.sqrt(mean_squared_error(y_train, svrm4.predict(X_train[cols_veryveryfew]))), \n      time.time()-time1)\n\nxgbb = XGBRegressor(n_estimators=200,\n                   max_depth=5,\n                   eta=0.06,\n                   subsample=0.8,\n                   colsample_bytree=0.6)\nxgbb.fit(X_train[cols_veryveryfew], y_train)\n\nxgb4 = XGBRegressor()\ngrid_param = {'n_estimators':[200], \n              'max_depth':[2,3,4,5], \n              'eta':[0.04, 0.06, 0.08, 0.1],\n             'subsample':[0.7], \n              'colsample_bytree':[0.5]}\nxgbm4 = GridSearchCV(xgb4, grid_param, cv=8, scoring='neg_root_mean_squared_error')\nxgbm4.fit(X_train[cols_veryveryfew], y_train)\nprint('XGB 56 cols', \n      xgbm4.best_params_, \n      xgbm4.best_score_, \n      np.sqrt(mean_squared_error(y_train, xgbm4.predict(X_train[cols_veryveryfew]))), \n      time.time()-time1)\n\n# 7. Model Evaluation #\n\nprint('SVR 56', np.sqrt(mean_squared_error(y_test, svrm4.predict(X_test[cols_veryveryfew]))))\nprint('XGB 56', np.sqrt(mean_squared_error(y_test, xgbm4.predict(X_test[cols_veryveryfew]))))\n\n# sometimes ridge may fail really bad.\nprint('Total Time is ', time.time()-time0)\n\n# all 3 models perform best with the smallest features set (56 features)","metadata":{"execution":{"iopub.status.busy":"2022-10-27T22:44:04.294632Z","iopub.execute_input":"2022-10-27T22:44:04.294898Z","iopub.status.idle":"2022-10-27T22:44:53.727935Z","shell.execute_reply.started":"2022-10-27T22:44:04.294869Z","shell.execute_reply":"2022-10-27T22:44:53.726987Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(1445, 224)\nOLS  940569570.3653979\nSVR 56 cols {'C': 400000} -24838.943023766722 9407.464303121382 22.546037673950195\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/905863676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m               'colsample_bytree':[0.5]}\n\u001b[1;32m     26\u001b[0m \u001b[0mxgbm4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_root_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mxgbm4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_veryveryfew\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m print('XGB 56 cols', \n\u001b[1;32m     29\u001b[0m       \u001b[0mxgbm4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m         )\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1733\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1734\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1736\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# time1 = time.time()\n# xgb3 = XGBRegressor()\n# grid_param = {'n_estimators':[400,500], 'max_depth':[3,4,5], 'eta':[0.025, 0.035, 0.05, 0.06, 0.07, 0.08], 'subsample':[0.6],\n#              'colsample_bytree':[0.2]}\n# xgbm3 = GridSearchCV(xgb3, grid_param, scoring='neg_root_mean_squared_error', cv=4, verbose=1)\n# xgbm3.fit(X_train[cols_veryveryfew], y_train)\n# print('XGB 56 cols', xgbm3.best_params_, xgbm3.best_score_, np.sqrt(mean_squared_error(y_train, xgbm3.predict(X_train[cols_veryveryfew]))), time.time()-time1)\n# print('XGB 56', np.sqrt(mean_squared_error(y_test, xgbm3.predict(X_test[cols_veryveryfew]))))\n","metadata":{"execution":{"iopub.status.busy":"2022-10-27T22:39:44.305309Z","iopub.status.idle":"2022-10-27T22:39:44.306073Z","shell.execute_reply.started":"2022-10-27T22:39:44.305870Z","shell.execute_reply":"2022-10-27T22:39:44.305890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('train lr 56', np.sqrt(mean_squared_error(y_train, lr.predict(X_train[cols_veryveryfew]))))\nprint('train SVR 56', np.sqrt(mean_squared_error(y_train, svrm4.predict(X_train[cols_veryveryfew]))))\nprint('train xgb 56', np.sqrt(mean_squared_error(y_train, xgbb.predict(X_train[cols_veryveryfew]))))\nprint('test lr 56', np.sqrt(mean_squared_error(y_test, lr.predict(X_test[cols_veryveryfew]))))\nprint('test SVR 56', np.sqrt(mean_squared_error(y_test, svrm4.predict(X_test[cols_veryveryfew]))))\nprint('test xgb 56', np.sqrt(mean_squared_error(y_test, xgbb.predict(X_test[cols_veryveryfew]))))","metadata":{"execution":{"iopub.status.busy":"2022-10-27T22:49:30.975193Z","iopub.execute_input":"2022-10-27T22:49:30.975442Z","iopub.status.idle":"2022-10-27T22:49:31.969539Z","shell.execute_reply.started":"2022-10-27T22:49:30.975413Z","shell.execute_reply":"2022-10-27T22:49:31.969071Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"train lr 56 30668.70669534987\ntrain SVR 56 9407.464303121382\ntrain xgb 56 8996.301111825484\ntest lr 56 22568.400941729713\ntest SVR 56 33096.39100001603\ntest xgb 56 24508.902015229287\n","output_type":"stream"}]},{"cell_type":"code","source":"# 8. Feature importance #\n\nresults = permutation_importance(xgbb, X_test[cols_veryveryfew], y_test, n_jobs=-1)\nfi = pd.DataFrame({'col':X_test[cols_veryveryfew].columns, 'FI':results.importances_mean})\nfi = fi.sort_values('FI', ascending = False)\nfi\n# OverallQual and GrLivArea ate the two most important features","metadata":{"execution":{"iopub.status.busy":"2022-10-27T22:50:20.445448Z","iopub.execute_input":"2022-10-27T22:50:20.445730Z","iopub.status.idle":"2022-10-27T22:50:23.007906Z","shell.execute_reply.started":"2022-10-27T22:50:20.445700Z","shell.execute_reply":"2022-10-27T22:50:23.007133Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                           col        FI\n11          num__GrLivArea_log  0.128308\n10            num__OverallQual  0.125048\n51            num__OverallCond  0.039769\n0                 num__LotArea  0.036809\n15              num__GrLivArea  0.033852\n20   cat__Neighborhood_Crawfor  0.028638\n49    cat__Exterior1st_BrkFace  0.026266\n16              num__YearBuilt  0.026236\n50               num__1stFlrSF  0.013787\n34             num__BsmtFinSF1  0.012424\n41               num__2ndFlrSF  0.009268\n26            num__TotalBsmtSF  0.008563\n17  cat__SaleCondition_Abnorml  0.006221\n6            num__BedroomAbvGr  0.005491\n40           cat__SaleType_New  0.002990\n31             cat__HalfBath_1  0.002692\n4         cat__BsmtExposure_No  0.002481\n18        cat__Condition1_Norm  0.002212\n35          cat__BldgType_1Fam  0.001972\n2       cat__GarageType_Attchd  0.001542\n32             num__BsmtFinSF2  0.001158\n3       cat__Condition1_Artery  0.001090\n8              num__GarageCond  0.001031\n48             num__GarageQual  0.000718\n21      cat__LotConfig_CulDSac  0.000703\n39            cat__MSZoning_RL  0.000614\n25              num__ExterCond  0.000239\n28               num__BsmtCond  0.000156\n30             cat__FullBath_1  0.000128\n37        cat__BsmtExposure_Gd  0.000000\n52   cat__Neighborhood_ClearCr  0.000000\n53          cat__MSSubClass_90  0.000000\n46           cat__CentralAir_N  0.000000\n42         cat__Functional_Typ  0.000000\n43   cat__Neighborhood_StoneBr  0.000000\n44          cat__MSSubClass_80  0.000000\n38   cat__Neighborhood_Edwards  0.000000\n27       cat__MSZoning_C (all)  0.000000\n12        cat__BldgType_Duplex  0.000000\n5           cat__MSSubClass_30  0.000000\n24           cat__CentralAir_Y  0.000000\n23   cat__Neighborhood_BrkSide  0.000000\n22        cat__LandContour_Bnk  0.000000\n33     cat__Neighborhood_NAmes  0.000000\n14        cat__HouseStyle_SLvl  0.000000\n9    cat__Neighborhood_NoRidge -0.000026\n13          cat__MSSubClass_60 -0.000383\n19            cat__MSZoning_RM -0.000462\n47       cat__BsmtFinType1_GLQ -0.002030\n1               num__HeatingQC -0.009842\n54               num__BsmtQual -0.011874\n29             num__GarageCars -0.017151\n36             num__GarageArea -0.017396\n45            num__KitchenQual -0.019508\n7               num__ExterQual -0.020554","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>FI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>num__GrLivArea_log</td>\n      <td>0.128308</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>num__OverallQual</td>\n      <td>0.125048</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>num__OverallCond</td>\n      <td>0.039769</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>num__LotArea</td>\n      <td>0.036809</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>num__GrLivArea</td>\n      <td>0.033852</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>cat__Neighborhood_Crawfor</td>\n      <td>0.028638</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>cat__Exterior1st_BrkFace</td>\n      <td>0.026266</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>num__YearBuilt</td>\n      <td>0.026236</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>num__1stFlrSF</td>\n      <td>0.013787</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>num__BsmtFinSF1</td>\n      <td>0.012424</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>num__2ndFlrSF</td>\n      <td>0.009268</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>num__TotalBsmtSF</td>\n      <td>0.008563</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>cat__SaleCondition_Abnorml</td>\n      <td>0.006221</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>num__BedroomAbvGr</td>\n      <td>0.005491</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>cat__SaleType_New</td>\n      <td>0.002990</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>cat__HalfBath_1</td>\n      <td>0.002692</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cat__BsmtExposure_No</td>\n      <td>0.002481</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>cat__Condition1_Norm</td>\n      <td>0.002212</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>cat__BldgType_1Fam</td>\n      <td>0.001972</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cat__GarageType_Attchd</td>\n      <td>0.001542</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>num__BsmtFinSF2</td>\n      <td>0.001158</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cat__Condition1_Artery</td>\n      <td>0.001090</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>num__GarageCond</td>\n      <td>0.001031</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>num__GarageQual</td>\n      <td>0.000718</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>cat__LotConfig_CulDSac</td>\n      <td>0.000703</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>cat__MSZoning_RL</td>\n      <td>0.000614</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>num__ExterCond</td>\n      <td>0.000239</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>num__BsmtCond</td>\n      <td>0.000156</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>cat__FullBath_1</td>\n      <td>0.000128</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>cat__BsmtExposure_Gd</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>cat__Neighborhood_ClearCr</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>cat__MSSubClass_90</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>cat__CentralAir_N</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>cat__Functional_Typ</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>cat__Neighborhood_StoneBr</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>cat__MSSubClass_80</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>cat__Neighborhood_Edwards</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>cat__MSZoning_C (all)</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>cat__BldgType_Duplex</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>cat__MSSubClass_30</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>cat__CentralAir_Y</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>cat__Neighborhood_BrkSide</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>cat__LandContour_Bnk</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>cat__Neighborhood_NAmes</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>cat__HouseStyle_SLvl</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>cat__Neighborhood_NoRidge</td>\n      <td>-0.000026</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>cat__MSSubClass_60</td>\n      <td>-0.000383</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>cat__MSZoning_RM</td>\n      <td>-0.000462</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>cat__BsmtFinType1_GLQ</td>\n      <td>-0.002030</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>num__HeatingQC</td>\n      <td>-0.009842</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>num__BsmtQual</td>\n      <td>-0.011874</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>num__GarageCars</td>\n      <td>-0.017151</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>num__GarageArea</td>\n      <td>-0.017396</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>num__KitchenQual</td>\n      <td>-0.019508</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>num__ExterQual</td>\n      <td>-0.020554</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pred","metadata":{"execution":{"iopub.status.busy":"2022-10-27T22:39:44.308409Z","iopub.status.idle":"2022-10-27T22:39:44.309108Z","shell.execute_reply.started":"2022-10-27T22:39:44.308740Z","shell.execute_reply":"2022-10-27T22:39:44.308783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission_df_vc = pd.DataFrame({'Id': pred.Id, 'SalePrice': yhat}, columns=['Id', 'SalePrice'])\n#submission_df_svm = pd.DataFrame({'Id': pred.Id, 'SalePrice': svrm4.predict(X_pred[cols_veryveryfew])}, columns=['Id', 'SalePrice'])\nsubmission_df_bt = pd.DataFrame({'Id': pred.Id, 'SalePrice': xgbm3.predict(X_pred[cols_veryveryfew])}, columns=['Id', 'SalePrice'])\n\n#submission_df_vc.to_csv('KP11_vc.csv',index=False)\n#submission_df_svm.to_csv('KP20_svr.csv',index=False)\n#submission_df_rf.to_csv('KP11_rf.csv',index=False)\nsubmission_df_bt.to_csv('KP20_bt.csv',index=False)\n\nos.chdir(r'/kaggle/working')\n\nfrom IPython.display import FileLink\nFileLink(r'KP20_bt.csv')","metadata":{"execution":{"iopub.status.busy":"2022-10-27T22:39:44.310088Z","iopub.status.idle":"2022-10-27T22:39:44.310378Z","shell.execute_reply.started":"2022-10-27T22:39:44.310227Z","shell.execute_reply":"2022-10-27T22:39:44.310241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(data=df, x='OverallQual', y='SalePrice')","metadata":{"execution":{"iopub.status.busy":"2022-10-27T22:39:44.311067Z","iopub.status.idle":"2022-10-27T22:39:44.311313Z","shell.execute_reply.started":"2022-10-27T22:39:44.311180Z","shell.execute_reply":"2022-10-27T22:39:44.311194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(data=df, x='GrLivArea', y='SalePrice')\n# transformed","metadata":{"execution":{"iopub.status.busy":"2022-10-27T22:39:44.312165Z","iopub.status.idle":"2022-10-27T22:39:44.312409Z","shell.execute_reply.started":"2022-10-27T22:39:44.312278Z","shell.execute_reply":"2022-10-27T22:39:44.312291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(data=df, x='GrLivArea', y='SalePrice')\n# not transformed","metadata":{"execution":{"iopub.status.busy":"2022-10-27T22:39:44.312971Z","iopub.status.idle":"2022-10-27T22:39:44.313211Z","shell.execute_reply.started":"2022-10-27T22:39:44.313084Z","shell.execute_reply":"2022-10-27T22:39:44.313097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x[['OverallQual', 'GrLivArea']].skew()","metadata":{"execution":{"iopub.status.busy":"2022-10-27T22:39:44.314411Z","iopub.status.idle":"2022-10-27T22:39:44.314667Z","shell.execute_reply.started":"2022-10-27T22:39:44.314521Z","shell.execute_reply":"2022-10-27T22:39:44.314534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x[['GrLivArea']].hist()","metadata":{"execution":{"iopub.status.busy":"2022-10-27T22:39:44.315315Z","iopub.status.idle":"2022-10-27T22:39:44.315556Z","shell.execute_reply.started":"2022-10-27T22:39:44.315428Z","shell.execute_reply":"2022-10-27T22:39:44.315442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
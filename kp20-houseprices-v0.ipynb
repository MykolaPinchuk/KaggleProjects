{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This script is developed based on 'KProject_HousePrice_i5'","metadata":{}},{"cell_type":"markdown","source":"### Outline:\n0. Load libraries and custom functions.\n1. Load data.\n2. Preliminary data analysis: explore features and a target, delete unneeded features, create new features.\n3. Train-test split.\n4. Missing values. In some cases it may be useful to explore skew and perform log-transform before imputing missing values.\n5. Feature engineering. Transform skewed variables, do OHC and scaling.\n6. Fit models.\n7. Evaluate models.\n8. Feature importance, error analysis. Based on the results, go to 2. and iterate.\n9. Make predictions.","metadata":{}},{"cell_type":"code","source":"# 0. Load libraries #\n\nimport numpy as np\nimport pandas as pd\nimport os, time, warnings\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.svm import SVC, SVR\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, r2_score\nfrom sklearn.inspection import permutation_importance\nfrom scipy.special import inv_boxcox\nfrom xgboost import XGBClassifier, XGBRegressor\n\npd.set_option('display.max_columns', 20)\npd.set_option('mode.chained_assignment', None)\npd.set_option('display.expand_frame_repr', False)\nwarnings.filterwarnings('ignore')\n\ndef draw_histograms(df, variables, n_rows, n_cols):\n    # stolen from https://stackoverflow.com/questions/29530355/plotting-multiple-histograms-in-grid\n    fig=plt.figure()\n    for i, var_name in enumerate(variables):\n        ax=fig.add_subplot(n_rows,n_cols,i+1)\n        df[var_name].hist(bins=10,ax=ax)\n        ax.set_title(var_name+\" Distribution\")\n    fig.tight_layout()  \n    plt.show()\n\n\ndef fillna_mp_i1(df_train, df_test, df_pred, num_features, cat_features, num_fill='median', cat_fill='mode'):\n    \"\"\"This function speeds up filling missing values for 3 main datasets using different imputation methods.\n    Later may replace it with some subclass.\n    Example: fillna_mp_i1(X_train, X_test, X_pred, num_cols, cat_cols)\"\"\"\n    # set df_pred to None if it does not exist\n    if (cat_fill=='mode'):\n    \n        df_train[cat_features] = df_train[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n        df_test[cat_features] = df_test[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n        if (df_pred is not None):\n            df_pred[cat_features] = df_pred[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n            \n    if (cat_fill=='missing'):\n    \n        df_train[cat_features] = df_train[cat_features].fillna(value='missing')\n        df_test[cat_features] = df_test[cat_features].fillna(value='missing')\n        if (df_pred is not None):\n            df_pred[cat_features] = df_pred[cat_features].fillna(value='missing')\n        \n    if (num_fill=='median'):\n        df_train[num_features] = df_train[num_features].fillna(value=df_train[num_features].median())\n        df_test[num_features] = df_test[num_features].fillna(value=df_train[num_features].median())\n        if (df_pred is not None):\n            df_pred[num_features] = df_pred[num_features].fillna(value=df_train[num_features].median())    \n    \n    all_good = (\n    (np.prod(df_train[num_features+cat_features].shape)==df_train[num_features+cat_features].count().sum()) and \n    (np.prod(df_test[num_features+cat_features].shape) == df_test[num_features+cat_features].count().sum()) and \n    (np.prod(df_pred[num_features+cat_features].shape) == df_pred[num_features+cat_features].count().sum()))\n    if (all_good):\n        print('Missing values imputed successfully')\n    else:\n        print('There are still some missing values...')\n    \n    \n    \ndef add_misDummy_mp_i1(df_train, df_test, df_pred, features):\n    \"\"\"This function creates new dummy columns for missing features.\n    Example: add_misDummy_mp_i1(X_train, X_test, X_pred, ['Age'])\"\"\"\n    # set df_pred to None if it does not exist\n    for feature_name in features:\n        misColName = 'mis'+feature_name\n        df_train.loc[df_train[feature_name].isnull(), misColName]=1\n        df_train.loc[df_train[feature_name].notnull(), misColName]=0\n        df_test.loc[df_test[feature_name].isnull(), misColName]=1\n        df_test.loc[df_test[feature_name].notnull(), misColName]=0\n        if (df_pred is not None):\n            df_pred.loc[df_pred[feature_name].isnull(), misColName]=1\n            df_pred.loc[df_pred[feature_name].notnull(), misColName]=0\n   \n\ndef discretize_mp_i1(df_train, df_test, df_pred, feature, ntiles, delete_feature=False):\n    \"\"\"This function divides a continuous feature into quantile groups.\n    Example: discretize_mp_i1(X_train, X_test, X_pred, 'Age', 15)\"\"\"\n    # set df_pred to None if it does not exist\n    _,bin = pd.qcut(df_train[feature], ntiles, retbins = True, labels = False, duplicates = 'drop')\n    df_train[feature+'Ntile'] = pd.cut(df_train[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    df_test[feature+'Ntile'] = pd.cut(df_test[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    if (df_pred is not None):\n        df_pred[feature+'Ntile'] = pd.cut(df_pred[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    if (delete_feature==True):\n        df_train.drop(columns=[feature], inplace=True)\n        df_test.drop(columns=[feature], inplace=True)\n        df_pred.drop(columns=[feature], inplace=True)\n    print('Discretized ',feature, ' into ', len(bin)-1, ' bins')\n\n\ndef log_transformer_mp_i1(df_train, df_test, df_pred, feature_subset=False, min_skew=3):\n    \"\"\"This function divides a continuous feature into quantile groups.\n    Example: log_transformer_mp_i1(X_train, X_test, X_pred, feature_subset=num_cols)\"\"\"\n    # set df_pred to None if it does not exist\n    if (feature_subset==False):\n        features_totransform = df_train.columns\n    else:\n        features_totransform = feature_subset.copy()\n    skewed_vars = list(df_train.skew()[abs(df_train.skew())>min_skew].index)\n    for col in list(set(skewed_vars)&set(features_totransform)):\n        df_train[col] = np.log1p(df_train[col])\n        df_test[col] = np.log1p(df_test[col])\n        if (df_pred is not None):\n            df_pred[col] = np.log1p(df_pred[col])\n    print('Skewed columns log-transformed: ', list(set(skewed_vars)&set(features_totransform)))\n    \n    \ndef add_dummyfeatures(df_train, df_test, df_pred, feature_dict):\n    \"\"\"This function adds dummy feature when some feature is equal to value, specified in a dictionary.\n    Example: add_dummyfeatures(X_train, X_test, X_pred, {'RoomService':0, 'Spa':0, 'VRDeck':0, 'ShoppingMall':0})\"\"\"\n    input_dimensions = np.array([df_train.shape[1], df_test.shape[1], df_pred.shape[1]])\n    for i in range(len(list(feature_dict.items()))):\n        feature,value = list(feature_dict.keys())[i], list(feature_dict.values())[i]\n        df_train.loc[df_train[feature]==value,(str(feature)+str(value))]=1\n        df_train.loc[df_train[feature]!=value,(str(feature)+str(value))]=0\n        df_test.loc[df_test[feature]==value,(str(feature)+str(value))]=1\n        df_test.loc[df_test[feature]!=value,(str(feature)+str(value))]=0\n        df_pred.loc[df_pred[feature]==value,(str(feature)+str(value))]=1\n        df_pred.loc[df_pred[feature]!=value,(str(feature)+str(value))]=0\n    output_dimensions = np.array([df_train.shape[1], df_test.shape[1], df_pred.shape[1]])\n    print(output_dimensions-input_dimensions, ' variables created') \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-27T20:22:22.230227Z","iopub.execute_input":"2022-05-27T20:22:22.230687Z","iopub.status.idle":"2022-05-27T20:22:22.274901Z","shell.execute_reply.started":"2022-05-27T20:22:22.230631Z","shell.execute_reply":"2022-05-27T20:22:22.273891Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# 1. Load data #\n\ntime0 = time.time()\npath = '../input/house-prices-advanced-regression-techniques/train.csv'\ndf = pd.read_csv(path) \ndf0 = df.copy()\n\npred=pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\npred0 = pred.copy()\n\nprint(df.shape, pred.shape)\ndf","metadata":{"execution":{"iopub.status.busy":"2022-05-27T20:09:41.716103Z","iopub.execute_input":"2022-05-27T20:09:41.716658Z","iopub.status.idle":"2022-05-27T20:09:41.835385Z","shell.execute_reply.started":"2022-05-27T20:09:41.716596Z","shell.execute_reply":"2022-05-27T20:09:41.834584Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(1460, 81) (1459, 80)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal MoSold YrSold  SaleType  SaleCondition  SalePrice\n0        1          60       RL         65.0     8450   Pave   NaN      Reg         Lvl    AllPub  ...        0    NaN    NaN         NaN       0      2   2008        WD         Normal     208500\n1        2          20       RL         80.0     9600   Pave   NaN      Reg         Lvl    AllPub  ...        0    NaN    NaN         NaN       0      5   2007        WD         Normal     181500\n2        3          60       RL         68.0    11250   Pave   NaN      IR1         Lvl    AllPub  ...        0    NaN    NaN         NaN       0      9   2008        WD         Normal     223500\n3        4          70       RL         60.0     9550   Pave   NaN      IR1         Lvl    AllPub  ...        0    NaN    NaN         NaN       0      2   2006        WD        Abnorml     140000\n4        5          60       RL         84.0    14260   Pave   NaN      IR1         Lvl    AllPub  ...        0    NaN    NaN         NaN       0     12   2008        WD         Normal     250000\n...    ...         ...      ...          ...      ...    ...   ...      ...         ...       ...  ...      ...    ...    ...         ...     ...    ...    ...       ...            ...        ...\n1455  1456          60       RL         62.0     7917   Pave   NaN      Reg         Lvl    AllPub  ...        0    NaN    NaN         NaN       0      8   2007        WD         Normal     175000\n1456  1457          20       RL         85.0    13175   Pave   NaN      Reg         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0      2   2010        WD         Normal     210000\n1457  1458          70       RL         66.0     9042   Pave   NaN      Reg         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500      5   2010        WD         Normal     266500\n1458  1459          20       RL         68.0     9717   Pave   NaN      Reg         Lvl    AllPub  ...        0    NaN    NaN         NaN       0      4   2010        WD         Normal     142125\n1459  1460          20       RL         75.0     9937   Pave   NaN      Reg         Lvl    AllPub  ...        0    NaN    NaN         NaN       0      6   2008        WD         Normal     147500\n\n[1460 rows x 81 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>1456</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>175000</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>1457</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>210000</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>1458</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>GdPrv</td>\n      <td>Shed</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>266500</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>1459</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>142125</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>1460</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>147500</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 81 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 2. pEDA #\n\ncols_tokeep = ['Id', 'SalePrice', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'ExterCond', \n               'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', 'HeatingQC', '1stFlrSF', '2ndFlrSF', 'GrLivArea',  \n               'KitchenQual', 'GarageArea', 'GarageCars', 'TotRmsAbvGrd', 'BedroomAbvGr', 'FullBath', \n               'HalfBath', 'MiscVal', 'LotFrontage', \n               'ExterQual', 'MSSubClass', 'MSZoning', 'LotShape', 'LandContour', 'LotConfig', 'Neighborhood',\n               'Condition1', 'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd',\n               'Foundation', 'Heating', 'CentralAir', 'Electrical', 'Functional', 'PavedDrive',\n               'SaleType', 'SaleCondition', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', \n               'BsmtExposure', 'BsmtFinType1', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']\ndf = df[cols_tokeep]\nX_pred = pred[list(set(cols_tokeep) - set(['SalePrice']))]","metadata":{"execution":{"iopub.status.busy":"2022-05-27T20:09:56.019305Z","iopub.execute_input":"2022-05-27T20:09:56.019779Z","iopub.status.idle":"2022-05-27T20:09:56.033835Z","shell.execute_reply.started":"2022-05-27T20:09:56.019742Z","shell.execute_reply":"2022-05-27T20:09:56.033122Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# 3. train-test split #\n\ntrain_y = df['SalePrice']\ntrain_x = df.drop(columns = ['SalePrice'])\n\nord_cols = ['ExterCond', 'HeatingQC', 'KitchenQual', 'ExterQual', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond']\n#num_cols = [col for col in train_x.columns if train_x[col].nunique() > 12]\nnum_cols = ['Id', 'LotArea', 'YearBuilt', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', \n            'GrLivArea', 'GarageArea', 'MiscVal', 'LotFrontage', 'MasVnrArea',\n           'TotRmsAbvGrd', 'GarageCars', 'BedroomAbvGr', 'OverallCond', 'OverallQual']\ncat_cols = list(set(train_x.columns)-set(num_cols))\n# for now, view ordinal features as categorical features\nprint(\"Numerical features \", num_cols, \"\\n\",\n      \"Categorical features \", cat_cols)\n\nX_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=1)\nprint(X_train.shape, X_test.shape, y_train.shape, X_pred.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T20:09:57.864133Z","iopub.execute_input":"2022-05-27T20:09:57.864427Z","iopub.status.idle":"2022-05-27T20:09:57.884856Z","shell.execute_reply.started":"2022-05-27T20:09:57.864392Z","shell.execute_reply":"2022-05-27T20:09:57.883782Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Numerical features  ['Id', 'LotArea', 'YearBuilt', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageArea', 'MiscVal', 'LotFrontage', 'MasVnrArea', 'TotRmsAbvGrd', 'GarageCars', 'BedroomAbvGr', 'OverallCond', 'OverallQual'] \n Categorical features  ['GarageQual', 'BsmtFinType1', 'SaleType', 'MasVnrType', 'SaleCondition', 'Exterior2nd', 'ExterCond', 'GarageFinish', 'Functional', 'FullBath', 'BsmtCond', 'GarageCond', 'ExterQual', 'Electrical', 'Exterior1st', 'LotConfig', 'MSSubClass', 'LotShape', 'PavedDrive', 'Condition1', 'Foundation', 'BldgType', 'BsmtExposure', 'Neighborhood', 'BsmtQual', 'HalfBath', 'GarageType', 'KitchenQual', 'LandContour', 'HeatingQC', 'HouseStyle', 'RoofStyle', 'MSZoning', 'CentralAir', 'Heating']\n(1168, 53) (292, 53) (1168,) (1459, 53)\n","output_type":"stream"}]},{"cell_type":"code","source":"# 4. Missing values #\n\nfillna_mp_i1(X_train, X_test, X_pred, num_cols, cat_cols, num_fill = 'median', cat_fill='missing')","metadata":{"execution":{"iopub.status.busy":"2022-05-27T20:10:00.248768Z","iopub.execute_input":"2022-05-27T20:10:00.249724Z","iopub.status.idle":"2022-05-27T20:10:00.336974Z","shell.execute_reply.started":"2022-05-27T20:10:00.249665Z","shell.execute_reply":"2022-05-27T20:10:00.335977Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Missing values imputed successfully\n","output_type":"stream"}]},{"cell_type":"code","source":"# 5. Feature engineering #\n\nlog_transformer_mp_i1(X_train, X_test, X_pred, feature_subset=num_cols)\n\nfeature_transformer = ColumnTransformer([\n    (\"num\", StandardScaler(), num_cols),\n    (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\"), cat_cols),\n    ])\n\nX_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\nX_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\nX_pred = pd.DataFrame(feature_transformer.transform(X_pred), columns=feature_transformer.get_feature_names_out())\n\n# there are many dummies... may wish to use pca here later.","metadata":{"execution":{"iopub.status.busy":"2022-05-27T20:10:02.346749Z","iopub.execute_input":"2022-05-27T20:10:02.347488Z","iopub.status.idle":"2022-05-27T20:10:02.467028Z","shell.execute_reply.started":"2022-05-27T20:10:02.347447Z","shell.execute_reply":"2022-05-27T20:10:02.466056Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Skewed columns log-transformed:  ['MiscVal', 'BsmtFinSF2', 'LotArea']\n","output_type":"stream"}]},{"cell_type":"code","source":"# 6. Model Fitting #\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\nprint('OLS ', r2_score(y_train, lr.predict(X_train)))\n\ntime1 = time.time()\nrd = Ridge()\ngrid_param = {'alpha': [1, 3, 10, 20, 30, 100]}\nrdm = GridSearchCV(rd, grid_param, cv=8)\nrdm.fit(X_train, y_train)\nprint('Ridge ', rdm.best_params_, rdm.best_score_, r2_score(y_train, rdm.predict(X_train)), time.time()-time1)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-27T20:16:44.697996Z","iopub.execute_input":"2022-05-27T20:16:44.698338Z","iopub.status.idle":"2022-05-27T20:16:47.665836Z","shell.execute_reply.started":"2022-05-27T20:16:44.698304Z","shell.execute_reply":"2022-05-27T20:16:47.664878Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"OLS  0.8995363762076309\nRidge  {'alpha': 20} 0.8167886696253511 0.8843486251775785 2.8979852199554443\n","output_type":"stream"}]},{"cell_type":"code","source":"time1 = time.time()\nsvr = SVR()\ngrid_param = {'C': [100000, 300000, 1000000]}\nsvrm = GridSearchCV(svr, grid_param, cv=4)\nsvrm.fit(X_train, y_train)\nprint('SVR ', svrm.best_params_, svrm.best_score_, r2_score(y_train, svrm.predict(X_train)), time.time()-time1)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-27T20:18:38.837915Z","iopub.execute_input":"2022-05-27T20:18:38.838224Z","iopub.status.idle":"2022-05-27T20:18:45.354293Z","shell.execute_reply.started":"2022-05-27T20:18:38.838191Z","shell.execute_reply":"2022-05-27T20:18:45.353319Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"SVR  {'C': 300000} 0.8817055173626371 0.985837698500527 6.50957727432251\n","output_type":"stream"}]},{"cell_type":"code","source":"time1 = time.time()\nxgb = XGBRegressor()\ngrid_param = {'n_estimators':[100], 'max_depth':[2,4,6], 'eta':[0.05, 0.15]}\nxgbm = GridSearchCV(xgb, grid_param, cv=2)\nxgbm.fit(X_train, y_train)\nprint('XGB ', xgbm.best_params_, xgbm.best_score_, r2_score(y_train, xgbm.predict(X_train)), time.time()-time1)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-27T20:22:29.114800Z","iopub.execute_input":"2022-05-27T20:22:29.115306Z","iopub.status.idle":"2022-05-27T20:22:36.809171Z","shell.execute_reply.started":"2022-05-27T20:22:29.115252Z","shell.execute_reply":"2022-05-27T20:22:36.808498Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"XGB  {'eta': 0.15, 'max_depth': 4, 'n_estimators': 100} 0.85378481500762 0.9845751751958818 7.686840057373047\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 7. Model Evaluation #\n\nprint('Ridge ', r2_score(y_test, rdm.predict(X_test)))\nprint('SVR ', r2_score(y_test, svrm.predict(X_test)))\nprint('XGB ', r2_score(y_test, xgbm.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T20:24:17.072238Z","iopub.execute_input":"2022-05-27T20:24:17.072519Z","iopub.status.idle":"2022-05-27T20:24:17.284220Z","shell.execute_reply.started":"2022-05-27T20:24:17.072490Z","shell.execute_reply":"2022-05-27T20:24:17.283564Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Ridge  0.8782128485749758\nSVR  0.867812320778665\nXGB  0.9097772296858068\n","output_type":"stream"}]},{"cell_type":"code","source":"# 8. Feature importance #","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Outline:\n\n0. Load libraries and custom functions.\n1. Load data.\n2. Preliminary data analysis: explore features and a target, delete unneeded features, create new features.\n3. Train-test split.\n4. Missing values. In some cases it may be useful to explore skew and perform log-transform before imputing missing values.\n5. Feature engineering. Transform skewed variables, do OHC and scaling.\n6. Fit models.\n7. Evaluate models.\n8. Feature importance, error analysis. Based on the results, go to 2. and iterate.\n9. Make predictions.","metadata":{}},{"cell_type":"markdown","source":"To do: \n- try directly using roc curve.\n- use feature importance to eliminate most features. does not work.\n- try pca. does not work.\n- [if evth fails] try nn.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, time, warnings, random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, roc_curve\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.decomposition import PCA\nfrom xgboost import XGBClassifier\n\npd.set_option('display.max_columns', 20)\npd.set_option('mode.chained_assignment', None)\npd.set_option('display.expand_frame_repr', False)\nwarnings.filterwarnings('ignore')\n\ndef draw_histograms(df, variables, n_rows, n_cols):\n    # stolen from https://stackoverflow.com/questions/29530355/plotting-multiple-histograms-in-grid\n    fig=plt.figure()\n    for i, var_name in enumerate(variables):\n        ax=fig.add_subplot(n_rows,n_cols,i+1)\n        df[var_name].hist(bins=10,ax=ax)\n        ax.set_title(var_name+\" Distribution\")\n    fig.tight_layout()  \n    plt.show()\n\n\ndef fillna_mp_i1(df_train, df_test, df_pred, num_features, cat_features, num_fill='median', cat_fill='mode'):\n    \"\"\"This function speeds up filling missing values for 3 main datasets using different imputation methods.\n    Later may replace it with some subclass.\n    Example: fillna_mp_i1(X_train, X_test, X_pred, num_cols, cat_cols)\"\"\"\n    # set df_pred to None if it does not exist\n    if not ((cat_fill=='mode') and (num_fill=='median')):\n        print ('Imputation method not Implemented yet!')\n        return None\n    \n    df_train[num_features] = df_train[num_features].fillna(value=df_train[num_features].median())\n    df_test[num_features] = df_test[num_features].fillna(value=df_train[num_features].median())\n    df_train[cat_features] = df_train[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n    df_test[cat_features] = df_test[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n    if (df_pred is not None):\n        df_pred[num_features] = df_pred[num_features].fillna(value=df_train[num_features].median())\n        df_pred[cat_features] = df_pred[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n    df_train[num_features+cat_features].count\n    \n    all_good = (\n    (np.prod(df_train[num_features+cat_features].shape)==df_train[num_features+cat_features].count().sum()) and \n    (np.prod(df_test[num_features+cat_features].shape) == df_test[num_features+cat_features].count().sum()) and \n    (np.prod(df_pred[num_features+cat_features].shape) == df_pred[num_features+cat_features].count().sum()))\n    if (all_good):\n        print('Missing values imputed successfully')\n    else:\n        print('There are still some missing values...')\n    \ndef add_misDummy_mp_i1(df_train, df_test, df_pred, features):\n    \"\"\"This function creates new dummy columns for missing features.\n    Example: add_misDummy_mp_i1(X_train, X_test, X_pred, ['Age'])\"\"\"\n    # set df_pred to None if it does not exist\n    for feature_name in features:\n        misColName = 'mis'+feature_name\n        df_train.loc[df_train[feature_name].isnull(), misColName]=1\n        df_train.loc[df_train[feature_name].notnull(), misColName]=0\n        df_test.loc[df_test[feature_name].isnull(), misColName]=1\n        df_test.loc[df_test[feature_name].notnull(), misColName]=0\n        if (df_pred is not None):\n            df_pred.loc[df_pred[feature_name].isnull(), misColName]=1\n            df_pred.loc[df_pred[feature_name].notnull(), misColName]=0\n   \n\ndef discretize_mp_i1(df_train, df_test, df_pred, feature, ntiles, delete_feature=False):\n    \"\"\"This function divides a continuous feature into quantile groups.\n    Example: discretize_mp_i1(X_train, X_test, X_pred, 'Age', 15)\"\"\"\n    # set df_pred to None if it does not exist\n    _,bin = pd.qcut(df_train[feature], ntiles, retbins = True, labels = False, duplicates = 'drop')\n    df_train[feature+'Ntile'] = pd.cut(df_train[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    df_test[feature+'Ntile'] = pd.cut(df_test[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    if (df_pred is not None):\n        df_pred[feature+'Ntile'] = pd.cut(df_pred[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    if (delete_feature==True):\n        df_train.drop(columns=[feature], inplace=True)\n        df_test.drop(columns=[feature], inplace=True)\n        df_pred.drop(columns=[feature], inplace=True)\n    print('Discretized ',feature, ' into ', len(bin)-1, ' bins')\n\n\ndef log_transformer_mp_i1(df_train, df_test, df_pred, feature_subset=False, min_skew=3):\n    \"\"\"This function divides a continuous feature into quantile groups.\n    Example: log_transformer_mp_i1(X_train, X_test, X_pred, feature_subset=num_cols)\"\"\"\n    # set df_pred to None if it does not exist\n    if (feature_subset==False):\n        features_totransform = df_train.columns\n    else:\n        features_totransform = feature_subset.copy()\n    skewed_vars = list(df_train.skew()[abs(df_train.skew())>min_skew].index)\n    for col in list(set(skewed_vars)&set(features_totransform)):\n        df_train[col] = np.log1p(df_train[col])\n        df_test[col] = np.log1p(df_test[col])\n        if (df_pred is not None):\n            df_pred[col] = np.log1p(df_pred[col])\n    print('Skewed columns log-transformed: ', list(set(skewed_vars)&set(features_totransform)))\n    \n    \ndef add_dummyfeatures(df_train, df_test, df_pred, feature_dict):\n    \"\"\"This function adds dummy feature when some feature is equal to value, specified in a dictionary.\n    Example: add_dummyfeatures(X_train, X_test, X_pred, {'RoomService':0, 'Spa':0, 'VRDeck':0, 'ShoppingMall':0})\"\"\"\n    input_dimensions = np.array([df_train.shape[1], df_test.shape[1], df_pred.shape[1]])\n    for i in range(len(list(feature_dict.items()))):\n        feature,value = list(feature_dict.keys())[i], list(feature_dict.values())[i]\n        df_train.loc[df_train[feature]==value,(str(feature)+str(value))]=1\n        df_train.loc[df_train[feature]!=value,(str(feature)+str(value))]=0\n        df_test.loc[df_test[feature]==value,(str(feature)+str(value))]=1\n        df_test.loc[df_test[feature]!=value,(str(feature)+str(value))]=0\n        df_pred.loc[df_pred[feature]==value,(str(feature)+str(value))]=1\n        df_pred.loc[df_pred[feature]!=value,(str(feature)+str(value))]=0\n    output_dimensions = np.array([df_train.shape[1], df_test.shape[1], df_pred.shape[1]])\n    print(output_dimensions-input_dimensions, ' variables created') \n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:32:02.152748Z","iopub.execute_input":"2022-05-25T01:32:02.153217Z","iopub.status.idle":"2022-05-25T01:32:02.192085Z","shell.execute_reply.started":"2022-05-25T01:32:02.153179Z","shell.execute_reply":"2022-05-25T01:32:02.191247Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# 1. Import data #\n\ntime0 = time.time()\n\npath = '../input/santander-customer-transaction-prediction/train.csv'\ndf = pd.read_csv(path) \ndf0 = df.copy()\ndf = df.sample(50000)\n\n#df.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'],inplace=True)\npred=pd.read_csv('../input/santander-customer-transaction-prediction/test.csv')\npred0 = pred.copy()\n#pred.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'],inplace=True)\n\nprint(df.shape, pred.shape)\nprint(df.target.mean())\n# unbalanced responsed variable\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:32:06.094273Z","iopub.execute_input":"2022-05-25T01:32:06.095027Z","iopub.status.idle":"2022-05-25T01:32:18.767553Z","shell.execute_reply.started":"2022-05-25T01:32:06.094990Z","shell.execute_reply":"2022-05-25T01:32:18.766503Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"(50000, 202) (200000, 201)\n0.09932\n","output_type":"stream"},{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"             ID_code  target    var_0   var_1    var_2   var_3    var_4    var_5   var_6    var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  var_197  var_198  var_199\n29766    train_29766       0   4.0575  3.1282  10.9422  5.7491  10.9238   5.1884  4.2180  17.1228  ...   5.9104   6.0949   0.2068   0.9172  20.5987   0.9002  -3.0356  10.4767  19.3722  12.5272\n160350  train_160350       0  11.0842  0.7578  12.2900  6.2904   9.2915   5.6645  7.3467  16.6274  ...  -0.9506   8.1208   1.2807   0.9828  15.3905   0.5163  -2.4259   9.5435  13.7225  -6.3445\n77021    train_77021       0   9.7420 -3.0096   9.9384  8.7416   9.4978 -16.4983  6.4157  11.6054  ...   0.2453   7.1780   2.4672   5.6003  11.1643  -1.0242   8.4328   9.4066  17.3258  -1.8064\n170658  train_170658       0  12.7545 -7.1376  12.4236  6.5482  12.4901 -10.8539  5.7909  14.2150  ...  -1.8734   4.0006  -0.6499   0.9699  17.6060  -0.9760  10.5717   9.6052  14.4371 -24.0395\n57252    train_57252       0  12.7732 -1.2835  17.8990  6.6622  11.8737   5.2050  6.0504  17.6241  ...  -1.4776   3.3151   3.4010   1.8828  16.4264   1.6129  -3.6881   9.3074  16.2287 -15.9875\n\n[5 rows x 202 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_code</th>\n      <th>target</th>\n      <th>var_0</th>\n      <th>var_1</th>\n      <th>var_2</th>\n      <th>var_3</th>\n      <th>var_4</th>\n      <th>var_5</th>\n      <th>var_6</th>\n      <th>var_7</th>\n      <th>...</th>\n      <th>var_190</th>\n      <th>var_191</th>\n      <th>var_192</th>\n      <th>var_193</th>\n      <th>var_194</th>\n      <th>var_195</th>\n      <th>var_196</th>\n      <th>var_197</th>\n      <th>var_198</th>\n      <th>var_199</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29766</th>\n      <td>train_29766</td>\n      <td>0</td>\n      <td>4.0575</td>\n      <td>3.1282</td>\n      <td>10.9422</td>\n      <td>5.7491</td>\n      <td>10.9238</td>\n      <td>5.1884</td>\n      <td>4.2180</td>\n      <td>17.1228</td>\n      <td>...</td>\n      <td>5.9104</td>\n      <td>6.0949</td>\n      <td>0.2068</td>\n      <td>0.9172</td>\n      <td>20.5987</td>\n      <td>0.9002</td>\n      <td>-3.0356</td>\n      <td>10.4767</td>\n      <td>19.3722</td>\n      <td>12.5272</td>\n    </tr>\n    <tr>\n      <th>160350</th>\n      <td>train_160350</td>\n      <td>0</td>\n      <td>11.0842</td>\n      <td>0.7578</td>\n      <td>12.2900</td>\n      <td>6.2904</td>\n      <td>9.2915</td>\n      <td>5.6645</td>\n      <td>7.3467</td>\n      <td>16.6274</td>\n      <td>...</td>\n      <td>-0.9506</td>\n      <td>8.1208</td>\n      <td>1.2807</td>\n      <td>0.9828</td>\n      <td>15.3905</td>\n      <td>0.5163</td>\n      <td>-2.4259</td>\n      <td>9.5435</td>\n      <td>13.7225</td>\n      <td>-6.3445</td>\n    </tr>\n    <tr>\n      <th>77021</th>\n      <td>train_77021</td>\n      <td>0</td>\n      <td>9.7420</td>\n      <td>-3.0096</td>\n      <td>9.9384</td>\n      <td>8.7416</td>\n      <td>9.4978</td>\n      <td>-16.4983</td>\n      <td>6.4157</td>\n      <td>11.6054</td>\n      <td>...</td>\n      <td>0.2453</td>\n      <td>7.1780</td>\n      <td>2.4672</td>\n      <td>5.6003</td>\n      <td>11.1643</td>\n      <td>-1.0242</td>\n      <td>8.4328</td>\n      <td>9.4066</td>\n      <td>17.3258</td>\n      <td>-1.8064</td>\n    </tr>\n    <tr>\n      <th>170658</th>\n      <td>train_170658</td>\n      <td>0</td>\n      <td>12.7545</td>\n      <td>-7.1376</td>\n      <td>12.4236</td>\n      <td>6.5482</td>\n      <td>12.4901</td>\n      <td>-10.8539</td>\n      <td>5.7909</td>\n      <td>14.2150</td>\n      <td>...</td>\n      <td>-1.8734</td>\n      <td>4.0006</td>\n      <td>-0.6499</td>\n      <td>0.9699</td>\n      <td>17.6060</td>\n      <td>-0.9760</td>\n      <td>10.5717</td>\n      <td>9.6052</td>\n      <td>14.4371</td>\n      <td>-24.0395</td>\n    </tr>\n    <tr>\n      <th>57252</th>\n      <td>train_57252</td>\n      <td>0</td>\n      <td>12.7732</td>\n      <td>-1.2835</td>\n      <td>17.8990</td>\n      <td>6.6622</td>\n      <td>11.8737</td>\n      <td>5.2050</td>\n      <td>6.0504</td>\n      <td>17.6241</td>\n      <td>...</td>\n      <td>-1.4776</td>\n      <td>3.3151</td>\n      <td>3.4010</td>\n      <td>1.8828</td>\n      <td>16.4264</td>\n      <td>1.6129</td>\n      <td>-3.6881</td>\n      <td>9.3074</td>\n      <td>16.2287</td>\n      <td>-15.9875</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 202 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 2. EDA #\n\n# with all features unnamed normally-distributed features, there is not much EDA and feature engineering to do.\ndf.drop(columns = ['ID_code'], inplace= True)\n\n# 3. Train-test split #\n\ntrain_y = df[['target']]\ntrain_x = df.drop(columns = ['target'])\nX_pred = pred.copy()\nX_pred.drop(columns = ['ID_code'], inplace= True)\n#train_x = train_x[features_i1]\n#X_pred = X_pred[features_i1]\n\nX_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.02, random_state=1)\nprint(X_train.shape, X_test.shape, y_train.shape, X_pred.shape)\n\nX_train.count().sum() == np.prod(X_train.shape)\n# no missing values, good.","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:32:18.769443Z","iopub.execute_input":"2022-05-25T01:32:18.769817Z","iopub.status.idle":"2022-05-25T01:32:19.180706Z","shell.execute_reply.started":"2022-05-25T01:32:18.769778Z","shell.execute_reply":"2022-05-25T01:32:19.179977Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"(49000, 200) (1000, 200) (49000, 1) (200000, 200)\n","output_type":"stream"},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# 5. feature engineering #\n\nss = StandardScaler()\n\nfor col in X_train.columns:\n    X_train[[col]] = ss.fit_transform(X_train[[col]])\n    X_test[[col]] = ss.transform(X_test[[col]])\n    X_pred[[col]] = ss.transform(X_pred[[col]])\n\n#X_test.iloc[:,:30].describe()\nrandom.seed(1)\nfewfeatures = random.sample(list(X_train.columns),5)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:32:27.419695Z","iopub.execute_input":"2022-05-25T01:32:27.420170Z","iopub.status.idle":"2022-05-25T01:32:29.049956Z","shell.execute_reply.started":"2022-05-25T01:32:27.420134Z","shell.execute_reply":"2022-05-25T01:32:29.049091Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# 5.1 try PCA \n\n#pca = PCA(n_components=100)\n#X_train = pca.fit_transform(X_train)\n#X_test = pca.transform(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:33:54.933360Z","iopub.execute_input":"2022-05-25T01:33:54.933651Z","iopub.status.idle":"2022-05-25T01:33:57.830835Z","shell.execute_reply.started":"2022-05-25T01:33:54.933618Z","shell.execute_reply":"2022-05-25T01:33:57.829919Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:34:05.312135Z","iopub.execute_input":"2022-05-25T01:34:05.312450Z","iopub.status.idle":"2022-05-25T01:34:05.327195Z","shell.execute_reply.started":"2022-05-25T01:34:05.312414Z","shell.execute_reply":"2022-05-25T01:34:05.325978Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"array([[-1.47896839,  1.49130082,  0.00890269, ...,  0.11907016,\n        -1.45367916, -0.02672313],\n       [-0.11243186, -0.80810058,  0.66568296, ...,  0.1414197 ,\n        -1.1915048 , -0.37776644],\n       [-0.86432551, -0.13644105, -1.57463357, ...,  1.47395466,\n         1.38866493,  0.04686168],\n       ...,\n       [-0.43895756,  1.14252199,  1.41333481, ..., -0.74365259,\n         0.09456825,  0.93623754],\n       [-0.80432707,  0.16645594, -0.21297424, ..., -0.57880697,\n        -0.94506783, -1.2441951 ],\n       [-0.5152883 ,  0.71151737,  0.40286025, ...,  0.4692386 ,\n         0.00521073,  0.60564372]])"},"metadata":{}}]},{"cell_type":"code","source":"# 6. Fit models #\n\ntime1 = time.time()\nlr = LogisticRegression()\nparam_grid = {'C':[0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]}\nlrm = GridSearchCV(lr, param_grid, cv=2, scoring='f1')\nlrm.fit(X_train, y_train)\nprint('Logistic ', lrm.best_params_, lrm.best_score_, f1_score(y_train, lrm.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:34:16.348176Z","iopub.execute_input":"2022-05-25T01:34:16.348681Z","iopub.status.idle":"2022-05-25T01:34:18.254887Z","shell.execute_reply.started":"2022-05-25T01:34:16.348633Z","shell.execute_reply":"2022-05-25T01:34:18.252049Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Logistic  {'C': 3} 0.31554391409898885 0.3167604752970607 1.896143913269043\n","output_type":"stream"}]},{"cell_type":"code","source":"time1 = time.time()\nknn = KNeighborsClassifier(n_jobs=-1)\nparam_grid = dict(n_neighbors=range(10, 41, 10))\nknnm = GridSearchCV(knn, param_grid, cv=2)\nknnm.fit(X_train[fewfeatures], y_train)\nprint('KNN ', knnm.best_params_, f1_score(y_train, knnm.predict(X_train[fewfeatures])), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T19:17:50.53617Z","iopub.execute_input":"2022-05-24T19:17:50.537107Z","iopub.status.idle":"2022-05-24T19:18:05.034227Z","shell.execute_reply.started":"2022-05-24T19:17:50.53706Z","shell.execute_reply":"2022-05-24T19:18:05.033241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time1 = time.time()\nrf = RandomForestClassifier(n_jobs=-1)\nparam_grid = {'n_estimators':[100], 'max_depth':[4,5,6], 'max_features':[10]}\nrfm = GridSearchCV(rf, param_grid, cv=2, scoring = 'f1')\nrfm.fit(X_train, y_train)\nprint('RF ', rfm.best_params_, rfm.best_score_, f1_score(y_train, rfm.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T19:57:29.021285Z","iopub.execute_input":"2022-05-24T19:57:29.021553Z","iopub.status.idle":"2022-05-24T19:58:28.183378Z","shell.execute_reply.started":"2022-05-24T19:57:29.021518Z","shell.execute_reply":"2022-05-24T19:58:28.182486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time1 = time.time()\nparam_grid_nb = {\n    'var_smoothing': np.logspace(-3,-7, num=17)\n}\nnb = GaussianNB()\nnbm = GridSearchCV(nb, param_grid_nb, cv=4, scoring='f1')\nnbm.fit(X_train, y_train)\nprint('NB ', nbm.best_params_, nbm.best_score_, f1_score(y_train, nbm.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:34:29.325382Z","iopub.execute_input":"2022-05-25T01:34:29.325652Z","iopub.status.idle":"2022-05-25T01:34:34.425442Z","shell.execute_reply.started":"2022-05-25T01:34:29.325623Z","shell.execute_reply":"2022-05-25T01:34:34.424464Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"NB  {'var_smoothing': 3.1622776601683795e-05} 0.334513549052591 0.3462897526501767 5.09296441078186\n","output_type":"stream"}]},{"cell_type":"code","source":"time1 = time.time()\nxgb = XGBClassifier(tree_method='gpu_hist', gpu_id=0, min_child_weight=3, n_jobs=-1)\nparam_grid = {'n_estimators':[200], 'max_depth':[2,3], 'eta':[0.35],\n'subsample':[0.3],'colsample_bytree':[0.6]}\nxgbm = GridSearchCV(xgb, param_grid, cv=2, scoring='f1')\nxgbm.fit(X_train, y_train)\nprint('XGB ', xgbm.best_params_, xgbm.best_score_, f1_score(y_train, xgbm.predict(X_train)), time.time()-time1)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:34:41.973132Z","iopub.execute_input":"2022-05-25T01:34:41.973469Z","iopub.status.idle":"2022-05-25T01:34:43.889177Z","shell.execute_reply.started":"2022-05-25T01:34:41.973435Z","shell.execute_reply":"2022-05-25T01:34:43.888385Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"XGB  {'colsample_bytree': 0.6, 'eta': 0.35, 'max_depth': 2, 'n_estimators': 200, 'subsample': 0.3} 0.34585549578355335 0.4165251839275608 1.9083058834075928\n","output_type":"stream"}]},{"cell_type":"code","source":"# 7. accuracy #\n\nprint('Out of Sample:')\nprint('Logistic ', f1_score(y_test, lrm.predict(X_test)))\n#print('SVM ', accuracy_score(y_test, svmm.predict(X_test)))\n#print('KNN ', accuracy_score(y_test, knnm.predict(X_test[fewfeatures])))\nprint('Bayes ', f1_score(y_test, nbm.predict(X_test)))\n#print('RF ', f1_score(y_test, rfm.predict(X_test)))\nprint('XGB ', f1_score(y_test, xgbm.predict(X_test)))\nprint('Total time ', time.time()-time0)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:34:54.045709Z","iopub.execute_input":"2022-05-25T01:34:54.046548Z","iopub.status.idle":"2022-05-25T01:34:54.075484Z","shell.execute_reply.started":"2022-05-25T01:34:54.046507Z","shell.execute_reply":"2022-05-25T01:34:54.074683Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Out of Sample:\nLogistic  0.25\nBayes  0.25925925925925924\nXGB  0.21238938053097342\nTotal time  167.97339057922363\n","output_type":"stream"}]},{"cell_type":"code","source":"# VotingClassifier:\n\nestimator = []\n#estimator.append(('LR', LogisticRegression(C=10)))\nestimator.append(('NB', GaussianNB(var_smoothing = 1e-5)))\n#estimator.append(('RF', RandomForestClassifier(max_depth=4, max_features=10, n_estimators=100)))\nestimator.append(('XGB', XGBClassifier(tree_method='gpu_hist', gpu_id=0, min_child_weight=3, n_jobs=-1,\n                                       eta=0.35, max_depth=3, n_estimators=200, \n                                       subsample=0.3, colsample_bytree=0.6)))\nvot_soft = VotingClassifier(estimators = estimator, voting ='soft')\nvot_soft.fit(X_train, y_train)\nvot_hard = VotingClassifier(estimators = estimator, voting ='hard')\nvot_hard.fit(X_train, y_train)\nprint('VotingClassifiers3 in sample', f1_score(y_train, vot_soft.predict(X_train)), f1_score(y_train, vot_hard.predict(X_train)))\nprint('VotingClassifiers3 out of sample', f1_score(y_test, vot_soft.predict(X_test)), f1_score(y_test, vot_hard.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:35:04.721486Z","iopub.execute_input":"2022-05-25T01:35:04.721778Z","iopub.status.idle":"2022-05-25T01:35:06.469374Z","shell.execute_reply.started":"2022-05-25T01:35:04.721732Z","shell.execute_reply":"2022-05-25T01:35:06.468477Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"VotingClassifiers3 in sample 0.4316588785046729 0.3222748815165876\nVotingClassifiers3 out of sample 0.27027027027027023 0.1473684210526316\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 8. feature importance #\n\nresults = permutation_importance(xgbm, X_test, y_test, scoring='f1', n_jobs=-1)\nfi_lr = pd.DataFrame({'col':X_test.columns, 'FI':results.importances_mean})\nfi_lr.sort_values('FI', ascending = False)[:20]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:12:20.056686Z","iopub.execute_input":"2022-05-25T01:12:20.057122Z","iopub.status.idle":"2022-05-25T01:12:35.278639Z","shell.execute_reply.started":"2022-05-25T01:12:20.057082Z","shell.execute_reply":"2022-05-25T01:12:35.277713Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"         col        FI\n145  var_145  0.044367\n1      var_1  0.042451\n26    var_26  0.040462\n146  var_146  0.039477\n127  var_127  0.032903\n169  var_169  0.031797\n81    var_81  0.028117\n109  var_109  0.026571\n179  var_179  0.026385\n91    var_91  0.025633\n174  var_174  0.025623\n9      var_9  0.024355\n90    var_90  0.024305\n164  var_164  0.022434\n40    var_40  0.021958\n104  var_104  0.021517\n110  var_110  0.021222\n94    var_94  0.019661\n133  var_133  0.019573\n115  var_115  0.019132","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>FI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>145</th>\n      <td>var_145</td>\n      <td>0.044367</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>var_1</td>\n      <td>0.042451</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>var_26</td>\n      <td>0.040462</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>var_146</td>\n      <td>0.039477</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>var_127</td>\n      <td>0.032903</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>var_169</td>\n      <td>0.031797</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>var_81</td>\n      <td>0.028117</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>var_109</td>\n      <td>0.026571</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>var_179</td>\n      <td>0.026385</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>var_91</td>\n      <td>0.025633</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>var_174</td>\n      <td>0.025623</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>var_9</td>\n      <td>0.024355</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>var_90</td>\n      <td>0.024305</td>\n    </tr>\n    <tr>\n      <th>164</th>\n      <td>var_164</td>\n      <td>0.022434</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>var_40</td>\n      <td>0.021958</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>var_104</td>\n      <td>0.021517</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>var_110</td>\n      <td>0.021222</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>var_94</td>\n      <td>0.019661</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>var_133</td>\n      <td>0.019573</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>var_115</td>\n      <td>0.019132</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"temp = fi_lr.sort_values('FI', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:13:12.687743Z","iopub.execute_input":"2022-05-25T01:13:12.688354Z","iopub.status.idle":"2022-05-25T01:13:12.693348Z","shell.execute_reply.started":"2022-05-25T01:13:12.688310Z","shell.execute_reply":"2022-05-25T01:13:12.692617Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"features_i1 = list(temp.loc[temp.FI>0]['col'])\nfeatures_i1","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:16:09.009184Z","iopub.execute_input":"2022-05-25T01:16:09.009456Z","iopub.status.idle":"2022-05-25T01:16:09.017688Z","shell.execute_reply.started":"2022-05-25T01:16:09.009425Z","shell.execute_reply":"2022-05-25T01:16:09.017042Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"['var_145',\n 'var_1',\n 'var_26',\n 'var_146',\n 'var_127',\n 'var_169',\n 'var_81',\n 'var_109',\n 'var_179',\n 'var_91',\n 'var_174',\n 'var_9',\n 'var_90',\n 'var_164',\n 'var_40',\n 'var_104',\n 'var_110',\n 'var_94',\n 'var_133',\n 'var_115',\n 'var_119',\n 'var_105',\n 'var_22',\n 'var_186',\n 'var_86',\n 'var_8',\n 'var_106',\n 'var_195',\n 'var_197',\n 'var_168',\n 'var_67',\n 'var_137',\n 'var_198',\n 'var_2',\n 'var_0',\n 'var_36',\n 'var_177',\n 'var_132',\n 'var_191',\n 'var_33',\n 'var_149',\n 'var_154',\n 'var_58',\n 'var_93',\n 'var_157',\n 'var_160',\n 'var_114',\n 'var_87',\n 'var_28',\n 'var_118',\n 'var_76',\n 'var_129',\n 'var_75',\n 'var_193',\n 'var_5',\n 'var_131',\n 'var_43',\n 'var_88',\n 'var_151',\n 'var_62',\n 'var_116',\n 'var_190',\n 'var_165',\n 'var_97',\n 'var_184',\n 'var_16',\n 'var_6',\n 'var_60',\n 'var_156',\n 'var_32',\n 'var_125',\n 'var_172',\n 'var_141',\n 'var_135',\n 'var_70',\n 'var_196',\n 'var_13',\n 'var_138',\n 'var_74',\n 'var_182',\n 'var_53',\n 'var_178',\n 'var_52',\n 'var_143',\n 'var_99',\n 'var_83',\n 'var_10',\n 'var_159',\n 'var_117',\n 'var_85',\n 'var_147',\n 'var_111',\n 'var_82',\n 'var_155',\n 'var_95',\n 'var_103',\n 'var_42',\n 'var_163',\n 'var_124',\n 'var_128',\n 'var_45',\n 'var_123',\n 'var_68',\n 'var_37',\n 'var_56',\n 'var_34',\n 'var_199',\n 'var_29',\n 'var_51',\n 'var_30',\n 'var_57',\n 'var_175',\n 'var_66',\n 'var_192']"},"metadata":{}}]},{"cell_type":"code","source":"temp","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:15:13.999309Z","iopub.execute_input":"2022-05-25T01:15:13.999604Z","iopub.status.idle":"2022-05-25T01:15:14.015447Z","shell.execute_reply.started":"2022-05-25T01:15:13.999570Z","shell.execute_reply":"2022-05-25T01:15:14.014605Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"         col        FI\n145  var_145  0.044367\n1      var_1  0.042451\n26    var_26  0.040462\n146  var_146  0.039477\n127  var_127  0.032903\n..       ...       ...\n89    var_89 -0.012431\n122  var_122 -0.012645\n25    var_25 -0.014718\n78    var_78 -0.015582\n161  var_161 -0.017385\n\n[200 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>FI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>145</th>\n      <td>var_145</td>\n      <td>0.044367</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>var_1</td>\n      <td>0.042451</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>var_26</td>\n      <td>0.040462</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>var_146</td>\n      <td>0.039477</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>var_127</td>\n      <td>0.032903</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>var_89</td>\n      <td>-0.012431</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>var_122</td>\n      <td>-0.012645</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>var_25</td>\n      <td>-0.014718</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>var_78</td>\n      <td>-0.015582</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>var_161</td>\n      <td>-0.017385</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 9. predictions #\n\nsubmission_df_vc = pd.DataFrame({'ID_code': pred0.ID_code, 'target': vot_soft.predict(X_pred)}, columns=['ID_code', 'target'])\n#submission_df_svm = pd.DataFrame({'PassengerId': pred0.PassengerId, 'Transported': svmm.predict(X_pred)}, columns=['PassengerId', 'Transported'])\n#submission_df_rf = pd.DataFrame({'PassengerId': pred0.PassengerId, 'Transported': rfm.predict(X_pred)}, columns=['PassengerId', 'Transported'])\n#submission_df_bt = pd.DataFrame({'PassengerId': pred0.PassengerId, 'Transported': xgbm.predict(X_pred)}, columns=['PassengerId', 'Transported'])\n\n#submission_df_bt.Transported = np.array([bool(x) for x in submission_df_bt.Transported])\n\nsubmission_df_vc.to_csv('KP12_vc.csv',index=False)\n#submission_df_svm.to_csv('KP11_svm.csv',index=False)\n#submission_df_rf.to_csv('KP11_rf.csv',index=False)\n#submission_df_bt.to_csv('KP11_bt.csv',index=False)\n\nos.chdir(r'/kaggle/working')\n\nfrom IPython.display import FileLink\nFileLink(r'KP12_vc.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T23:48:44.047972Z","iopub.execute_input":"2022-05-24T23:48:44.048272Z","iopub.status.idle":"2022-05-24T23:48:45.986504Z","shell.execute_reply.started":"2022-05-24T23:48:44.048242Z","shell.execute_reply":"2022-05-24T23:48:45.985538Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/KP12_vc.csv","text/html":"<a href='KP12_vc.csv' target='_blank'>KP12_vc.csv</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"X_pred","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:22.399496Z","iopub.execute_input":"2022-05-25T01:18:22.399862Z","iopub.status.idle":"2022-05-25T01:18:22.455644Z","shell.execute_reply.started":"2022-05-25T01:18:22.399822Z","shell.execute_reply":"2022-05-25T01:18:22.454847Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"           var_0     var_1     var_2     var_3     var_4     var_5     var_6     var_7     var_8     var_9  ...   var_190   var_191   var_192   var_193   var_194   var_195   var_196   var_197   var_198   var_199\n0       0.125259  2.331709  0.840949  1.289605  0.214591  0.343497  0.500328  0.498248  0.554992  1.001973  ... -1.178210  1.464626 -2.277710 -0.225311 -1.354710  1.835909  0.378425  1.965291 -0.132127 -0.520262\n1      -0.704888  0.713600  0.217328 -0.787407 -1.167470  0.136490  0.696696  0.604629 -1.411729 -1.293410  ...  1.622107  0.464314 -0.673566  1.697615 -0.759920  0.438390 -0.692806  1.045309  1.077906 -1.693878\n2      -1.702851 -2.165893 -0.222903  0.124033 -0.508745  1.889922 -0.600053  1.078570  0.371622  0.624980  ... -0.869678  1.180586  0.030273 -0.293137 -1.587454  1.597932 -1.722437 -2.000625  1.331453 -1.904867\n3      -0.702595  0.074712  0.488614 -0.107486 -1.384861  1.048441 -0.548510  1.169817  0.928041 -0.092423  ...  1.392703  0.544515 -0.187850  0.057841 -0.883992  2.326684  0.303593  0.349415 -0.944551 -0.088507\n4       0.334891  0.369669  1.285680  0.467983 -1.225527 -0.443859  1.665165 -1.740619  0.811932 -0.346638  ...  0.220951  0.576270 -0.441299  0.006871  0.508454 -0.097761 -1.365872 -1.755181 -0.643722 -0.564779\n...          ...       ...       ...       ...       ...       ...       ...       ...       ...       ...  ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...\n199995  0.813620  0.653914 -0.112240  0.002547 -1.538443  0.117149 -0.642832 -0.525834 -0.904277 -0.468040  ... -0.255156  0.746363  1.852877 -1.181289 -1.622275  0.946936 -1.266689  0.270600  0.773801  0.782003\n199996 -0.316305 -1.865382 -1.280514  1.149078  1.117849  1.028733  0.315259  0.679018  1.443543 -0.985373  ...  0.392231 -0.259093 -0.078416 -0.235430  0.301028 -0.552713  0.128332  0.221164  0.761824 -1.674047\n199997  0.312035  0.967171  0.180528  0.474982  0.985535  2.082463 -0.031241  0.530942  0.412778 -1.487491  ...  0.424352 -1.588042  0.377725 -0.855108  0.670026 -0.721643 -1.181164  0.310170 -1.350300 -1.818380\n199998  0.946793  0.275268  1.107508  0.338224  0.085616 -0.788901 -1.406168  0.077658  1.512427  1.077404  ...  0.045549  0.353584  0.227212  0.604056 -0.304221  0.929376 -0.855927 -0.866531 -2.348542  0.294384\n199999 -0.070948  0.850651 -0.189999 -0.356870 -0.655280  0.782512 -0.608240 -0.605686 -0.263293  0.213833  ... -0.674937  0.612937 -0.389459  0.387754  0.680134 -0.813378 -0.896575  1.550941 -0.508726 -0.423519\n\n[200000 rows x 200 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var_0</th>\n      <th>var_1</th>\n      <th>var_2</th>\n      <th>var_3</th>\n      <th>var_4</th>\n      <th>var_5</th>\n      <th>var_6</th>\n      <th>var_7</th>\n      <th>var_8</th>\n      <th>var_9</th>\n      <th>...</th>\n      <th>var_190</th>\n      <th>var_191</th>\n      <th>var_192</th>\n      <th>var_193</th>\n      <th>var_194</th>\n      <th>var_195</th>\n      <th>var_196</th>\n      <th>var_197</th>\n      <th>var_198</th>\n      <th>var_199</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.125259</td>\n      <td>2.331709</td>\n      <td>0.840949</td>\n      <td>1.289605</td>\n      <td>0.214591</td>\n      <td>0.343497</td>\n      <td>0.500328</td>\n      <td>0.498248</td>\n      <td>0.554992</td>\n      <td>1.001973</td>\n      <td>...</td>\n      <td>-1.178210</td>\n      <td>1.464626</td>\n      <td>-2.277710</td>\n      <td>-0.225311</td>\n      <td>-1.354710</td>\n      <td>1.835909</td>\n      <td>0.378425</td>\n      <td>1.965291</td>\n      <td>-0.132127</td>\n      <td>-0.520262</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.704888</td>\n      <td>0.713600</td>\n      <td>0.217328</td>\n      <td>-0.787407</td>\n      <td>-1.167470</td>\n      <td>0.136490</td>\n      <td>0.696696</td>\n      <td>0.604629</td>\n      <td>-1.411729</td>\n      <td>-1.293410</td>\n      <td>...</td>\n      <td>1.622107</td>\n      <td>0.464314</td>\n      <td>-0.673566</td>\n      <td>1.697615</td>\n      <td>-0.759920</td>\n      <td>0.438390</td>\n      <td>-0.692806</td>\n      <td>1.045309</td>\n      <td>1.077906</td>\n      <td>-1.693878</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.702851</td>\n      <td>-2.165893</td>\n      <td>-0.222903</td>\n      <td>0.124033</td>\n      <td>-0.508745</td>\n      <td>1.889922</td>\n      <td>-0.600053</td>\n      <td>1.078570</td>\n      <td>0.371622</td>\n      <td>0.624980</td>\n      <td>...</td>\n      <td>-0.869678</td>\n      <td>1.180586</td>\n      <td>0.030273</td>\n      <td>-0.293137</td>\n      <td>-1.587454</td>\n      <td>1.597932</td>\n      <td>-1.722437</td>\n      <td>-2.000625</td>\n      <td>1.331453</td>\n      <td>-1.904867</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.702595</td>\n      <td>0.074712</td>\n      <td>0.488614</td>\n      <td>-0.107486</td>\n      <td>-1.384861</td>\n      <td>1.048441</td>\n      <td>-0.548510</td>\n      <td>1.169817</td>\n      <td>0.928041</td>\n      <td>-0.092423</td>\n      <td>...</td>\n      <td>1.392703</td>\n      <td>0.544515</td>\n      <td>-0.187850</td>\n      <td>0.057841</td>\n      <td>-0.883992</td>\n      <td>2.326684</td>\n      <td>0.303593</td>\n      <td>0.349415</td>\n      <td>-0.944551</td>\n      <td>-0.088507</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.334891</td>\n      <td>0.369669</td>\n      <td>1.285680</td>\n      <td>0.467983</td>\n      <td>-1.225527</td>\n      <td>-0.443859</td>\n      <td>1.665165</td>\n      <td>-1.740619</td>\n      <td>0.811932</td>\n      <td>-0.346638</td>\n      <td>...</td>\n      <td>0.220951</td>\n      <td>0.576270</td>\n      <td>-0.441299</td>\n      <td>0.006871</td>\n      <td>0.508454</td>\n      <td>-0.097761</td>\n      <td>-1.365872</td>\n      <td>-1.755181</td>\n      <td>-0.643722</td>\n      <td>-0.564779</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>0.813620</td>\n      <td>0.653914</td>\n      <td>-0.112240</td>\n      <td>0.002547</td>\n      <td>-1.538443</td>\n      <td>0.117149</td>\n      <td>-0.642832</td>\n      <td>-0.525834</td>\n      <td>-0.904277</td>\n      <td>-0.468040</td>\n      <td>...</td>\n      <td>-0.255156</td>\n      <td>0.746363</td>\n      <td>1.852877</td>\n      <td>-1.181289</td>\n      <td>-1.622275</td>\n      <td>0.946936</td>\n      <td>-1.266689</td>\n      <td>0.270600</td>\n      <td>0.773801</td>\n      <td>0.782003</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>-0.316305</td>\n      <td>-1.865382</td>\n      <td>-1.280514</td>\n      <td>1.149078</td>\n      <td>1.117849</td>\n      <td>1.028733</td>\n      <td>0.315259</td>\n      <td>0.679018</td>\n      <td>1.443543</td>\n      <td>-0.985373</td>\n      <td>...</td>\n      <td>0.392231</td>\n      <td>-0.259093</td>\n      <td>-0.078416</td>\n      <td>-0.235430</td>\n      <td>0.301028</td>\n      <td>-0.552713</td>\n      <td>0.128332</td>\n      <td>0.221164</td>\n      <td>0.761824</td>\n      <td>-1.674047</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>0.312035</td>\n      <td>0.967171</td>\n      <td>0.180528</td>\n      <td>0.474982</td>\n      <td>0.985535</td>\n      <td>2.082463</td>\n      <td>-0.031241</td>\n      <td>0.530942</td>\n      <td>0.412778</td>\n      <td>-1.487491</td>\n      <td>...</td>\n      <td>0.424352</td>\n      <td>-1.588042</td>\n      <td>0.377725</td>\n      <td>-0.855108</td>\n      <td>0.670026</td>\n      <td>-0.721643</td>\n      <td>-1.181164</td>\n      <td>0.310170</td>\n      <td>-1.350300</td>\n      <td>-1.818380</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>0.946793</td>\n      <td>0.275268</td>\n      <td>1.107508</td>\n      <td>0.338224</td>\n      <td>0.085616</td>\n      <td>-0.788901</td>\n      <td>-1.406168</td>\n      <td>0.077658</td>\n      <td>1.512427</td>\n      <td>1.077404</td>\n      <td>...</td>\n      <td>0.045549</td>\n      <td>0.353584</td>\n      <td>0.227212</td>\n      <td>0.604056</td>\n      <td>-0.304221</td>\n      <td>0.929376</td>\n      <td>-0.855927</td>\n      <td>-0.866531</td>\n      <td>-2.348542</td>\n      <td>0.294384</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>-0.070948</td>\n      <td>0.850651</td>\n      <td>-0.189999</td>\n      <td>-0.356870</td>\n      <td>-0.655280</td>\n      <td>0.782512</td>\n      <td>-0.608240</td>\n      <td>-0.605686</td>\n      <td>-0.263293</td>\n      <td>0.213833</td>\n      <td>...</td>\n      <td>-0.674937</td>\n      <td>0.612937</td>\n      <td>-0.389459</td>\n      <td>0.387754</td>\n      <td>0.680134</td>\n      <td>-0.813378</td>\n      <td>-0.896575</td>\n      <td>1.550941</td>\n      <td>-0.508726</td>\n      <td>-0.423519</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 200 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:18:07.016318Z","iopub.execute_input":"2022-05-25T01:18:07.016893Z","iopub.status.idle":"2022-05-25T01:18:07.056498Z","shell.execute_reply.started":"2022-05-25T01:18:07.016856Z","shell.execute_reply":"2022-05-25T01:18:07.055663Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"        var_145   var_1  var_26  var_146  var_127  var_169   var_81  var_109  var_179  var_91  ...   var_56   var_34  var_199   var_29   var_51   var_30  var_57  var_175  var_66  var_192\n63485    3.7302 -6.5343  3.5244  12.5729  -2.5786   5.5541  17.0787  13.4587  -0.8599  6.9761  ...  10.3291  12.1366   6.9620   1.8351  25.5535 -15.5938  6.8119  10.9163  6.4143   1.7578\n62112    5.7610  6.5115  9.1616   7.9293   6.5498   5.8648  10.2828  24.5511   7.1604  6.7877  ...  16.2924  11.3314 -19.1191   8.5291  15.3414 -16.7469  6.2807  13.4937  6.1077   1.2087\n21978    8.4847 -2.3043 -5.0289  12.5389   5.4715   5.4766  12.7119  20.4244   1.9686  6.7359  ...  20.7685  11.0577  -9.0884   7.9931  15.3078 -13.2923  5.5607  12.6695  7.4567   2.8253\n31851    5.9911 -5.4637 -6.9243  12.4996   0.2053   4.8540  15.9185  19.0704   7.1132  7.1453  ...  14.9180  11.2198 -10.8850   5.9737   6.1923 -10.7076  5.7365   8.0737  7.1607   2.1305\n56894    1.8250 -0.9907  5.0259  13.0393   3.8482   5.4160  15.9166  18.7577   0.4515  6.8716  ...  10.8098  11.0897 -10.5049   1.8259  20.2231  -8.5295  6.9632   9.2688  6.2233   4.7463\n...         ...     ...     ...      ...      ...      ...      ...      ...      ...     ...  ...      ...      ...      ...      ...      ...      ...     ...      ...     ...      ...\n85546   -0.8488 -5.3114 -0.9775  11.7203   1.2664   6.0708  16.4149  22.3338   2.2093  7.0156  ...  12.3681  11.1337  -4.8848  11.7524  20.5557   4.0395  6.5628  12.9680  6.6213   2.7904\n66401    5.2884  0.6840 -1.6091  17.3113  -1.0054   6.1161  12.0078  13.1328  -1.9426  7.1055  ...  19.7999  11.0900   1.1993   1.9996   4.1981  -7.6903  5.8222   9.2910  8.2988   0.2941\n180711   6.7302  1.2606 -6.1734  10.8160   2.0804   5.9161  13.7476  18.3676  -1.5794  6.9773  ...  22.3933  11.9135 -17.3833   6.8985   4.6935 -21.6111  5.7956   8.5723  6.3251   2.6507\n158339   7.6564 -4.9032  3.1733  16.0088   1.7351   5.8368  16.2128  22.0024   0.9193  6.6638  ...  15.3887  11.4414   0.0608   4.0958  14.2601 -14.4895  6.4237   6.6656  5.0913   1.8980\n183618   6.3875 -5.5349 -1.5520  15.4095  -2.7407   5.1501  16.4453  17.4946   3.9642  6.8569  ...  18.3259  10.6110 -12.4615   2.7501   0.4703 -16.1946  6.0796  14.2822  5.9402  -0.6943\n\n[50000 rows x 114 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var_145</th>\n      <th>var_1</th>\n      <th>var_26</th>\n      <th>var_146</th>\n      <th>var_127</th>\n      <th>var_169</th>\n      <th>var_81</th>\n      <th>var_109</th>\n      <th>var_179</th>\n      <th>var_91</th>\n      <th>...</th>\n      <th>var_56</th>\n      <th>var_34</th>\n      <th>var_199</th>\n      <th>var_29</th>\n      <th>var_51</th>\n      <th>var_30</th>\n      <th>var_57</th>\n      <th>var_175</th>\n      <th>var_66</th>\n      <th>var_192</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>63485</th>\n      <td>3.7302</td>\n      <td>-6.5343</td>\n      <td>3.5244</td>\n      <td>12.5729</td>\n      <td>-2.5786</td>\n      <td>5.5541</td>\n      <td>17.0787</td>\n      <td>13.4587</td>\n      <td>-0.8599</td>\n      <td>6.9761</td>\n      <td>...</td>\n      <td>10.3291</td>\n      <td>12.1366</td>\n      <td>6.9620</td>\n      <td>1.8351</td>\n      <td>25.5535</td>\n      <td>-15.5938</td>\n      <td>6.8119</td>\n      <td>10.9163</td>\n      <td>6.4143</td>\n      <td>1.7578</td>\n    </tr>\n    <tr>\n      <th>62112</th>\n      <td>5.7610</td>\n      <td>6.5115</td>\n      <td>9.1616</td>\n      <td>7.9293</td>\n      <td>6.5498</td>\n      <td>5.8648</td>\n      <td>10.2828</td>\n      <td>24.5511</td>\n      <td>7.1604</td>\n      <td>6.7877</td>\n      <td>...</td>\n      <td>16.2924</td>\n      <td>11.3314</td>\n      <td>-19.1191</td>\n      <td>8.5291</td>\n      <td>15.3414</td>\n      <td>-16.7469</td>\n      <td>6.2807</td>\n      <td>13.4937</td>\n      <td>6.1077</td>\n      <td>1.2087</td>\n    </tr>\n    <tr>\n      <th>21978</th>\n      <td>8.4847</td>\n      <td>-2.3043</td>\n      <td>-5.0289</td>\n      <td>12.5389</td>\n      <td>5.4715</td>\n      <td>5.4766</td>\n      <td>12.7119</td>\n      <td>20.4244</td>\n      <td>1.9686</td>\n      <td>6.7359</td>\n      <td>...</td>\n      <td>20.7685</td>\n      <td>11.0577</td>\n      <td>-9.0884</td>\n      <td>7.9931</td>\n      <td>15.3078</td>\n      <td>-13.2923</td>\n      <td>5.5607</td>\n      <td>12.6695</td>\n      <td>7.4567</td>\n      <td>2.8253</td>\n    </tr>\n    <tr>\n      <th>31851</th>\n      <td>5.9911</td>\n      <td>-5.4637</td>\n      <td>-6.9243</td>\n      <td>12.4996</td>\n      <td>0.2053</td>\n      <td>4.8540</td>\n      <td>15.9185</td>\n      <td>19.0704</td>\n      <td>7.1132</td>\n      <td>7.1453</td>\n      <td>...</td>\n      <td>14.9180</td>\n      <td>11.2198</td>\n      <td>-10.8850</td>\n      <td>5.9737</td>\n      <td>6.1923</td>\n      <td>-10.7076</td>\n      <td>5.7365</td>\n      <td>8.0737</td>\n      <td>7.1607</td>\n      <td>2.1305</td>\n    </tr>\n    <tr>\n      <th>56894</th>\n      <td>1.8250</td>\n      <td>-0.9907</td>\n      <td>5.0259</td>\n      <td>13.0393</td>\n      <td>3.8482</td>\n      <td>5.4160</td>\n      <td>15.9166</td>\n      <td>18.7577</td>\n      <td>0.4515</td>\n      <td>6.8716</td>\n      <td>...</td>\n      <td>10.8098</td>\n      <td>11.0897</td>\n      <td>-10.5049</td>\n      <td>1.8259</td>\n      <td>20.2231</td>\n      <td>-8.5295</td>\n      <td>6.9632</td>\n      <td>9.2688</td>\n      <td>6.2233</td>\n      <td>4.7463</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>85546</th>\n      <td>-0.8488</td>\n      <td>-5.3114</td>\n      <td>-0.9775</td>\n      <td>11.7203</td>\n      <td>1.2664</td>\n      <td>6.0708</td>\n      <td>16.4149</td>\n      <td>22.3338</td>\n      <td>2.2093</td>\n      <td>7.0156</td>\n      <td>...</td>\n      <td>12.3681</td>\n      <td>11.1337</td>\n      <td>-4.8848</td>\n      <td>11.7524</td>\n      <td>20.5557</td>\n      <td>4.0395</td>\n      <td>6.5628</td>\n      <td>12.9680</td>\n      <td>6.6213</td>\n      <td>2.7904</td>\n    </tr>\n    <tr>\n      <th>66401</th>\n      <td>5.2884</td>\n      <td>0.6840</td>\n      <td>-1.6091</td>\n      <td>17.3113</td>\n      <td>-1.0054</td>\n      <td>6.1161</td>\n      <td>12.0078</td>\n      <td>13.1328</td>\n      <td>-1.9426</td>\n      <td>7.1055</td>\n      <td>...</td>\n      <td>19.7999</td>\n      <td>11.0900</td>\n      <td>1.1993</td>\n      <td>1.9996</td>\n      <td>4.1981</td>\n      <td>-7.6903</td>\n      <td>5.8222</td>\n      <td>9.2910</td>\n      <td>8.2988</td>\n      <td>0.2941</td>\n    </tr>\n    <tr>\n      <th>180711</th>\n      <td>6.7302</td>\n      <td>1.2606</td>\n      <td>-6.1734</td>\n      <td>10.8160</td>\n      <td>2.0804</td>\n      <td>5.9161</td>\n      <td>13.7476</td>\n      <td>18.3676</td>\n      <td>-1.5794</td>\n      <td>6.9773</td>\n      <td>...</td>\n      <td>22.3933</td>\n      <td>11.9135</td>\n      <td>-17.3833</td>\n      <td>6.8985</td>\n      <td>4.6935</td>\n      <td>-21.6111</td>\n      <td>5.7956</td>\n      <td>8.5723</td>\n      <td>6.3251</td>\n      <td>2.6507</td>\n    </tr>\n    <tr>\n      <th>158339</th>\n      <td>7.6564</td>\n      <td>-4.9032</td>\n      <td>3.1733</td>\n      <td>16.0088</td>\n      <td>1.7351</td>\n      <td>5.8368</td>\n      <td>16.2128</td>\n      <td>22.0024</td>\n      <td>0.9193</td>\n      <td>6.6638</td>\n      <td>...</td>\n      <td>15.3887</td>\n      <td>11.4414</td>\n      <td>0.0608</td>\n      <td>4.0958</td>\n      <td>14.2601</td>\n      <td>-14.4895</td>\n      <td>6.4237</td>\n      <td>6.6656</td>\n      <td>5.0913</td>\n      <td>1.8980</td>\n    </tr>\n    <tr>\n      <th>183618</th>\n      <td>6.3875</td>\n      <td>-5.5349</td>\n      <td>-1.5520</td>\n      <td>15.4095</td>\n      <td>-2.7407</td>\n      <td>5.1501</td>\n      <td>16.4453</td>\n      <td>17.4946</td>\n      <td>3.9642</td>\n      <td>6.8569</td>\n      <td>...</td>\n      <td>18.3259</td>\n      <td>10.6110</td>\n      <td>-12.4615</td>\n      <td>2.7501</td>\n      <td>0.4703</td>\n      <td>-16.1946</td>\n      <td>6.0796</td>\n      <td>14.2822</td>\n      <td>5.9402</td>\n      <td>-0.6943</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 114 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"np.logspace(-3,-7, num=17)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:25:44.046205Z","iopub.execute_input":"2022-05-25T01:25:44.046784Z","iopub.status.idle":"2022-05-25T01:25:44.055627Z","shell.execute_reply.started":"2022-05-25T01:25:44.046728Z","shell.execute_reply":"2022-05-25T01:25:44.054796Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"array([1.00000000e-03, 5.62341325e-04, 3.16227766e-04, 1.77827941e-04,\n       1.00000000e-04, 5.62341325e-05, 3.16227766e-05, 1.77827941e-05,\n       1.00000000e-05, 5.62341325e-06, 3.16227766e-06, 1.77827941e-06,\n       1.00000000e-06, 5.62341325e-07, 3.16227766e-07, 1.77827941e-07,\n       1.00000000e-07])"},"metadata":{}}]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Outline:\n\n0. Load libraries and custom functions.\n1. Load data.\n2. Preliminary data analysis: explore features and a target, delete unneeded features, create new features.\n3. Train-test split.\n4. Missing values. In some cases it may be useful to explore skew and perform log-transform before imputing missing values.\n5. Feature engineering. Transform skewed variables, do OHC and scaling.\n6. Fit models.\n7. Evaluate models.\n8. Feature importance, error analysis. Based on the results, go to 2. and iterate.\n9. Make predictions.","metadata":{}},{"cell_type":"markdown","source":"To do: try directly using roc curve.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, time, warnings, random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, roc_curve\nfrom sklearn.inspection import permutation_importance\nfrom xgboost import XGBClassifier\n\npd.set_option('display.max_columns', 20)\npd.set_option('mode.chained_assignment', None)\npd.set_option('display.expand_frame_repr', False)\nwarnings.filterwarnings('ignore')\n\ndef draw_histograms(df, variables, n_rows, n_cols):\n    # stolen from https://stackoverflow.com/questions/29530355/plotting-multiple-histograms-in-grid\n    fig=plt.figure()\n    for i, var_name in enumerate(variables):\n        ax=fig.add_subplot(n_rows,n_cols,i+1)\n        df[var_name].hist(bins=10,ax=ax)\n        ax.set_title(var_name+\" Distribution\")\n    fig.tight_layout()  \n    plt.show()\n\n\ndef fillna_mp_i1(df_train, df_test, df_pred, num_features, cat_features, num_fill='median', cat_fill='mode'):\n    \"\"\"This function speeds up filling missing values for 3 main datasets using different imputation methods.\n    Later may replace it with some subclass.\n    Example: fillna_mp_i1(X_train, X_test, X_pred, num_cols, cat_cols)\"\"\"\n    # set df_pred to None if it does not exist\n    if not ((cat_fill=='mode') and (num_fill=='median')):\n        print ('Imputation method not Implemented yet!')\n        return None\n    \n    df_train[num_features] = df_train[num_features].fillna(value=df_train[num_features].median())\n    df_test[num_features] = df_test[num_features].fillna(value=df_train[num_features].median())\n    df_train[cat_features] = df_train[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n    df_test[cat_features] = df_test[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n    if (df_pred is not None):\n        df_pred[num_features] = df_pred[num_features].fillna(value=df_train[num_features].median())\n        df_pred[cat_features] = df_pred[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n    df_train[num_features+cat_features].count\n    \n    all_good = (\n    (np.prod(df_train[num_features+cat_features].shape)==df_train[num_features+cat_features].count().sum()) and \n    (np.prod(df_test[num_features+cat_features].shape) == df_test[num_features+cat_features].count().sum()) and \n    (np.prod(df_pred[num_features+cat_features].shape) == df_pred[num_features+cat_features].count().sum()))\n    if (all_good):\n        print('Missing values imputed successfully')\n    else:\n        print('There are still some missing values...')\n    \ndef add_misDummy_mp_i1(df_train, df_test, df_pred, features):\n    \"\"\"This function creates new dummy columns for missing features.\n    Example: add_misDummy_mp_i1(X_train, X_test, X_pred, ['Age'])\"\"\"\n    # set df_pred to None if it does not exist\n    for feature_name in features:\n        misColName = 'mis'+feature_name\n        df_train.loc[df_train[feature_name].isnull(), misColName]=1\n        df_train.loc[df_train[feature_name].notnull(), misColName]=0\n        df_test.loc[df_test[feature_name].isnull(), misColName]=1\n        df_test.loc[df_test[feature_name].notnull(), misColName]=0\n        if (df_pred is not None):\n            df_pred.loc[df_pred[feature_name].isnull(), misColName]=1\n            df_pred.loc[df_pred[feature_name].notnull(), misColName]=0\n   \n\ndef discretize_mp_i1(df_train, df_test, df_pred, feature, ntiles, delete_feature=False):\n    \"\"\"This function divides a continuous feature into quantile groups.\n    Example: discretize_mp_i1(X_train, X_test, X_pred, 'Age', 15)\"\"\"\n    # set df_pred to None if it does not exist\n    _,bin = pd.qcut(df_train[feature], ntiles, retbins = True, labels = False, duplicates = 'drop')\n    df_train[feature+'Ntile'] = pd.cut(df_train[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    df_test[feature+'Ntile'] = pd.cut(df_test[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    if (df_pred is not None):\n        df_pred[feature+'Ntile'] = pd.cut(df_pred[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    if (delete_feature==True):\n        df_train.drop(columns=[feature], inplace=True)\n        df_test.drop(columns=[feature], inplace=True)\n        df_pred.drop(columns=[feature], inplace=True)\n    print('Discretized ',feature, ' into ', len(bin)-1, ' bins')\n\n\ndef log_transformer_mp_i1(df_train, df_test, df_pred, feature_subset=False, min_skew=3):\n    \"\"\"This function divides a continuous feature into quantile groups.\n    Example: log_transformer_mp_i1(X_train, X_test, X_pred, feature_subset=num_cols)\"\"\"\n    # set df_pred to None if it does not exist\n    if (feature_subset==False):\n        features_totransform = df_train.columns\n    else:\n        features_totransform = feature_subset.copy()\n    skewed_vars = list(df_train.skew()[abs(df_train.skew())>min_skew].index)\n    for col in list(set(skewed_vars)&set(features_totransform)):\n        df_train[col] = np.log1p(df_train[col])\n        df_test[col] = np.log1p(df_test[col])\n        if (df_pred is not None):\n            df_pred[col] = np.log1p(df_pred[col])\n    print('Skewed columns log-transformed: ', list(set(skewed_vars)&set(features_totransform)))\n    \n    \ndef add_dummyfeatures(df_train, df_test, df_pred, feature_dict):\n    \"\"\"This function adds dummy feature when some feature is equal to value, specified in a dictionary.\n    Example: add_dummyfeatures(X_train, X_test, X_pred, {'RoomService':0, 'Spa':0, 'VRDeck':0, 'ShoppingMall':0})\"\"\"\n    input_dimensions = np.array([df_train.shape[1], df_test.shape[1], df_pred.shape[1]])\n    for i in range(len(list(feature_dict.items()))):\n        feature,value = list(feature_dict.keys())[i], list(feature_dict.values())[i]\n        df_train.loc[df_train[feature]==value,(str(feature)+str(value))]=1\n        df_train.loc[df_train[feature]!=value,(str(feature)+str(value))]=0\n        df_test.loc[df_test[feature]==value,(str(feature)+str(value))]=1\n        df_test.loc[df_test[feature]!=value,(str(feature)+str(value))]=0\n        df_pred.loc[df_pred[feature]==value,(str(feature)+str(value))]=1\n        df_pred.loc[df_pred[feature]!=value,(str(feature)+str(value))]=0\n    output_dimensions = np.array([df_train.shape[1], df_test.shape[1], df_pred.shape[1]])\n    print(output_dimensions-input_dimensions, ' variables created') \n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-24T23:39:51.282514Z","iopub.execute_input":"2022-05-24T23:39:51.282952Z","iopub.status.idle":"2022-05-24T23:39:53.116455Z","shell.execute_reply.started":"2022-05-24T23:39:51.282848Z","shell.execute_reply":"2022-05-24T23:39:53.115488Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# 1. Import data #\n\ntime0 = time.time()\n\npath = '../input/santander-customer-transaction-prediction/train.csv'\ndf = pd.read_csv(path) \ndf0 = df.copy()\n#df = df.sample(50000)\n\n#df.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'],inplace=True)\npred=pd.read_csv('../input/santander-customer-transaction-prediction/test.csv')\npred0 = pred.copy()\n#pred.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'],inplace=True)\n\nprint(df.shape, pred.shape)\nprint(df.target.mean())\n# unbalanced responsed variable\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T23:40:00.494456Z","iopub.execute_input":"2022-05-24T23:40:00.495300Z","iopub.status.idle":"2022-05-24T23:40:19.705871Z","shell.execute_reply.started":"2022-05-24T23:40:00.495254Z","shell.execute_reply":"2022-05-24T23:40:19.704824Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(200000, 202) (200000, 201)\n0.10049\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  var_197  var_198  var_199\n0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   7.8784   8.5635  12.7803  -1.0914\n1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   8.1267   8.7889  18.3560   1.9518\n2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417  -6.5213   8.2675  14.7222   0.3965\n3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706  -2.9275  10.2922  17.9697  -8.9996\n4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   3.9267   9.5031  17.9974  -8.8104\n\n[5 rows x 202 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_code</th>\n      <th>target</th>\n      <th>var_0</th>\n      <th>var_1</th>\n      <th>var_2</th>\n      <th>var_3</th>\n      <th>var_4</th>\n      <th>var_5</th>\n      <th>var_6</th>\n      <th>var_7</th>\n      <th>...</th>\n      <th>var_190</th>\n      <th>var_191</th>\n      <th>var_192</th>\n      <th>var_193</th>\n      <th>var_194</th>\n      <th>var_195</th>\n      <th>var_196</th>\n      <th>var_197</th>\n      <th>var_198</th>\n      <th>var_199</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>0</td>\n      <td>8.9255</td>\n      <td>-6.7863</td>\n      <td>11.9081</td>\n      <td>5.0930</td>\n      <td>11.4607</td>\n      <td>-9.2834</td>\n      <td>5.1187</td>\n      <td>18.6266</td>\n      <td>...</td>\n      <td>4.4354</td>\n      <td>3.9642</td>\n      <td>3.1364</td>\n      <td>1.6910</td>\n      <td>18.5227</td>\n      <td>-2.3978</td>\n      <td>7.8784</td>\n      <td>8.5635</td>\n      <td>12.7803</td>\n      <td>-1.0914</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>0</td>\n      <td>11.5006</td>\n      <td>-4.1473</td>\n      <td>13.8588</td>\n      <td>5.3890</td>\n      <td>12.3622</td>\n      <td>7.0433</td>\n      <td>5.6208</td>\n      <td>16.5338</td>\n      <td>...</td>\n      <td>7.6421</td>\n      <td>7.7214</td>\n      <td>2.5837</td>\n      <td>10.9516</td>\n      <td>15.4305</td>\n      <td>2.0339</td>\n      <td>8.1267</td>\n      <td>8.7889</td>\n      <td>18.3560</td>\n      <td>1.9518</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>0</td>\n      <td>8.6093</td>\n      <td>-2.7457</td>\n      <td>12.0805</td>\n      <td>7.8928</td>\n      <td>10.5825</td>\n      <td>-9.0837</td>\n      <td>6.9427</td>\n      <td>14.6155</td>\n      <td>...</td>\n      <td>2.9057</td>\n      <td>9.7905</td>\n      <td>1.6704</td>\n      <td>1.6858</td>\n      <td>21.6042</td>\n      <td>3.1417</td>\n      <td>-6.5213</td>\n      <td>8.2675</td>\n      <td>14.7222</td>\n      <td>0.3965</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>0</td>\n      <td>11.0604</td>\n      <td>-2.1518</td>\n      <td>8.9522</td>\n      <td>7.1957</td>\n      <td>12.5846</td>\n      <td>-1.8361</td>\n      <td>5.8428</td>\n      <td>14.9250</td>\n      <td>...</td>\n      <td>4.4666</td>\n      <td>4.7433</td>\n      <td>0.7178</td>\n      <td>1.4214</td>\n      <td>23.0347</td>\n      <td>-1.2706</td>\n      <td>-2.9275</td>\n      <td>10.2922</td>\n      <td>17.9697</td>\n      <td>-8.9996</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>0</td>\n      <td>9.8369</td>\n      <td>-1.4834</td>\n      <td>12.8746</td>\n      <td>6.6375</td>\n      <td>12.2772</td>\n      <td>2.4486</td>\n      <td>5.9405</td>\n      <td>19.2514</td>\n      <td>...</td>\n      <td>-1.4905</td>\n      <td>9.5214</td>\n      <td>-0.1508</td>\n      <td>9.1942</td>\n      <td>13.2876</td>\n      <td>-1.5121</td>\n      <td>3.9267</td>\n      <td>9.5031</td>\n      <td>17.9974</td>\n      <td>-8.8104</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 202 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 2. EDA #\n\n# with all features unnamed normally-distributed features, there is not much EDA and feature engineering to do.\ndf.drop(columns = ['ID_code'], inplace= True)\n\n\n# 3. Train-test split #\n\ntrain_y = df[['target']]\ntrain_x = df.drop(columns = ['target'])\nX_pred = pred.copy()\nX_pred.drop(columns = ['ID_code'], inplace= True)\n\nX_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.02, random_state=1)\nprint(X_train.shape, X_test.shape, y_train.shape, X_pred.shape)\n\nX_train.count().sum() == np.prod(X_train.shape)\n# no missing values, good.","metadata":{"execution":{"iopub.status.busy":"2022-05-24T23:40:29.981319Z","iopub.execute_input":"2022-05-24T23:40:29.981636Z","iopub.status.idle":"2022-05-24T23:40:30.749173Z","shell.execute_reply.started":"2022-05-24T23:40:29.981605Z","shell.execute_reply":"2022-05-24T23:40:30.748130Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(196000, 200) (4000, 200) (196000, 1) (200000, 201)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# 5. feature engineering #\n\nss = StandardScaler()\n\nfor col in X_train.columns:\n    X_train[[col]] = ss.fit_transform(X_train[[col]])\n    X_test[[col]] = ss.transform(X_test[[col]])\n    X_pred[[col]] = ss.transform(X_pred[[col]])\n\n#X_test.iloc[:,:30].describe()\nrandom.seed(1)\nfewfeatures = random.sample(list(X_train.columns),5)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T23:40:34.758961Z","iopub.execute_input":"2022-05-24T23:40:34.759553Z","iopub.status.idle":"2022-05-24T23:40:37.320069Z","shell.execute_reply.started":"2022-05-24T23:40:34.759520Z","shell.execute_reply":"2022-05-24T23:40:37.318975Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"fewfeatures","metadata":{"execution":{"iopub.status.busy":"2022-05-24T19:41:05.880584Z","iopub.execute_input":"2022-05-24T19:41:05.881307Z","iopub.status.idle":"2022-05-24T19:41:05.888409Z","shell.execute_reply.started":"2022-05-24T19:41:05.88127Z","shell.execute_reply":"2022-05-24T19:41:05.887654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. Fit models #\n\ntime1 = time.time()\nlr = LogisticRegression()\nparam_grid = {'C':[0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]}\nlrm = GridSearchCV(lr, param_grid, cv=2, scoring='f1')\nlrm.fit(X_train, y_train)\nprint('Logistic ', lrm.best_params_, lrm.best_score_, f1_score(y_train, lrm.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T23:40:40.836606Z","iopub.execute_input":"2022-05-24T23:40:40.837386Z","iopub.status.idle":"2022-05-24T23:40:57.825601Z","shell.execute_reply.started":"2022-05-24T23:40:40.837346Z","shell.execute_reply":"2022-05-24T23:40:57.824487Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Logistic  {'C': 1} 0.3882953318402199 0.3897663585413786 16.97671627998352\n","output_type":"stream"}]},{"cell_type":"code","source":"time1 = time.time()\nknn = KNeighborsClassifier(n_jobs=-1)\nparam_grid = dict(n_neighbors=range(10, 41, 10))\nknnm = GridSearchCV(knn, param_grid, cv=2)\nknnm.fit(X_train[fewfeatures], y_train)\nprint('KNN ', knnm.best_params_, f1_score(y_train, knnm.predict(X_train[fewfeatures])), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T19:17:50.53617Z","iopub.execute_input":"2022-05-24T19:17:50.537107Z","iopub.status.idle":"2022-05-24T19:18:05.034227Z","shell.execute_reply.started":"2022-05-24T19:17:50.53706Z","shell.execute_reply":"2022-05-24T19:18:05.033241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time1 = time.time()\nrf = RandomForestClassifier(n_jobs=-1)\nparam_grid = {'n_estimators':[100], 'max_depth':[4,5,6], 'max_features':[10]}\nrfm = GridSearchCV(rf, param_grid, cv=2, scoring = 'f1')\nrfm.fit(X_train, y_train)\nprint('RF ', rfm.best_params_, rfm.best_score_, f1_score(y_train, rfm.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T19:57:29.021285Z","iopub.execute_input":"2022-05-24T19:57:29.021553Z","iopub.status.idle":"2022-05-24T19:58:28.183378Z","shell.execute_reply.started":"2022-05-24T19:57:29.021518Z","shell.execute_reply":"2022-05-24T19:58:28.182486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time1 = time.time()\nnb = GaussianNB()\nnb.fit(X_train, y_train)\nprint('RF ', f1_score(y_train, nb.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T23:41:05.513915Z","iopub.execute_input":"2022-05-24T23:41:05.514212Z","iopub.status.idle":"2022-05-24T23:41:07.066339Z","shell.execute_reply.started":"2022-05-24T23:41:05.514179Z","shell.execute_reply":"2022-05-24T23:41:07.065350Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"RF  0.4854427414497022 1.5461335182189941\n","output_type":"stream"}]},{"cell_type":"code","source":"time1 = time.time()\nxgb = XGBClassifier(tree_method='gpu_hist', gpu_id=0, min_child_weight=3, n_jobs=-1)\nparam_grid = {'n_estimators':[200], 'max_depth':[2,3], 'eta':[0.35],\n'subsample':[0.3],'colsample_bytree':[0.6]}\nxgbm = GridSearchCV(xgb, param_grid, cv=2, scoring='f1')\nxgbm.fit(X_train, y_train)\nprint('XGB ', xgbm.best_params_, xgbm.best_score_, f1_score(y_train, xgbm.predict(X_train)), time.time()-time1)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-24T23:41:12.223575Z","iopub.execute_input":"2022-05-24T23:41:12.224244Z","iopub.status.idle":"2022-05-24T23:41:27.863515Z","shell.execute_reply.started":"2022-05-24T23:41:12.224210Z","shell.execute_reply":"2022-05-24T23:41:27.861417Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"XGB  {'colsample_bytree': 0.6, 'eta': 0.35, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.3} 0.45578656783654314 0.5263783426873555 15.62980055809021\n","output_type":"stream"}]},{"cell_type":"code","source":"# 7. accuracy #\n\nprint('Out of Sample:')\nprint('Logistic ', f1_score(y_test, lrm.predict(X_test)))\n#print('SVM ', accuracy_score(y_test, svmm.predict(X_test)))\n#print('KNN ', accuracy_score(y_test, knnm.predict(X_test[fewfeatures])))\nprint('Bayes ', f1_score(y_test, nb.predict(X_test)))\n#print('RF ', f1_score(y_test, rfm.predict(X_test)))\nprint('XGB ', f1_score(y_test, xgbm.predict(X_test)))\nprint('Total time ', time.time()-time0)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T23:42:05.816776Z","iopub.execute_input":"2022-05-24T23:42:05.817107Z","iopub.status.idle":"2022-05-24T23:42:05.930904Z","shell.execute_reply.started":"2022-05-24T23:42:05.817074Z","shell.execute_reply":"2022-05-24T23:42:05.929844Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Out of Sample:\nLogistic  0.36121673003802285\nBayes  0.47755834829443444\nXGB  0.4618055555555556\nTotal time  125.4236011505127\n","output_type":"stream"}]},{"cell_type":"code","source":"# VotingClassifier:\n\nestimator = []\n#estimator.append(('LR', LogisticRegression(C=10)))\nestimator.append(('NB', GaussianNB()))\n#estimator.append(('RF', RandomForestClassifier(max_depth=4, max_features=10, n_estimators=100)))\nestimator.append(('XGB', XGBClassifier(tree_method='gpu_hist', gpu_id=0, min_child_weight=3, n_jobs=-1,\n                                       eta=0.35, max_depth=3, n_estimators=200, \n                                       subsample=0.3, colsample_bytree=0.6)))\nvot_soft = VotingClassifier(estimators = estimator, voting ='soft')\nvot_soft.fit(X_train, y_train)\nvot_hard = VotingClassifier(estimators = estimator, voting ='hard')\nvot_hard.fit(X_train, y_train)\nprint('VotingClassifiers3 in sample', f1_score(y_train, vot_soft.predict(X_train)), f1_score(y_train, vot_hard.predict(X_train)))\nprint('VotingClassifiers3 out of sample', f1_score(y_test, vot_soft.predict(X_test)), f1_score(y_test, vot_hard.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T23:42:17.305130Z","iopub.execute_input":"2022-05-24T23:42:17.305414Z","iopub.status.idle":"2022-05-24T23:42:29.018197Z","shell.execute_reply.started":"2022-05-24T23:42:17.305383Z","shell.execute_reply":"2022-05-24T23:42:29.017190Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"VotingClassifiers3 in sample 0.5139417845484222 0.440863416449572\nVotingClassifiers3 out of sample 0.48736462093862815 0.4087301587301587\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 8. feature importance #\n\nresults = permutation_importance(xgbm, X_test, y_test, scoring='f1', n_jobs=-1)\nfi_lr = pd.DataFrame({'col':X_test.columns, 'FI':results.importances_mean})\nfi_lr.sort_values('FI', ascending = False)[:20]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T20:07:56.341752Z","iopub.execute_input":"2022-05-24T20:07:56.342041Z","iopub.status.idle":"2022-05-24T20:08:24.081197Z","shell.execute_reply.started":"2022-05-24T20:07:56.342009Z","shell.execute_reply":"2022-05-24T20:08:24.080182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fi_lr.sort_values('FI', ascending = False)[:20]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T20:03:05.149014Z","iopub.execute_input":"2022-05-24T20:03:05.149278Z","iopub.status.idle":"2022-05-24T20:03:05.164735Z","shell.execute_reply.started":"2022-05-24T20:03:05.14925Z","shell.execute_reply":"2022-05-24T20:03:05.163923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fi_lr0 = fi_lr.copy()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T20:03:38.452233Z","iopub.execute_input":"2022-05-24T20:03:38.452501Z","iopub.status.idle":"2022-05-24T20:03:38.456783Z","shell.execute_reply.started":"2022-05-24T20:03:38.452469Z","shell.execute_reply":"2022-05-24T20:03:38.456037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fi_lr0","metadata":{"execution":{"iopub.status.busy":"2022-05-24T20:03:45.028556Z","iopub.execute_input":"2022-05-24T20:03:45.029346Z","iopub.status.idle":"2022-05-24T20:03:45.04431Z","shell.execute_reply.started":"2022-05-24T20:03:45.029291Z","shell.execute_reply":"2022-05-24T20:03:45.043638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 9. predictions #\n\nsubmission_df_vc = pd.DataFrame({'ID_code': pred0.ID_code, 'target': vot_soft.predict(X_pred)}, columns=['ID_code', 'target'])\n#submission_df_svm = pd.DataFrame({'PassengerId': pred0.PassengerId, 'Transported': svmm.predict(X_pred)}, columns=['PassengerId', 'Transported'])\n#submission_df_rf = pd.DataFrame({'PassengerId': pred0.PassengerId, 'Transported': rfm.predict(X_pred)}, columns=['PassengerId', 'Transported'])\n#submission_df_bt = pd.DataFrame({'PassengerId': pred0.PassengerId, 'Transported': xgbm.predict(X_pred)}, columns=['PassengerId', 'Transported'])\n\n#submission_df_bt.Transported = np.array([bool(x) for x in submission_df_bt.Transported])\n\nsubmission_df_vc.to_csv('KP12_vc.csv',index=False)\n#submission_df_svm.to_csv('KP11_svm.csv',index=False)\n#submission_df_rf.to_csv('KP11_rf.csv',index=False)\n#submission_df_bt.to_csv('KP11_bt.csv',index=False)\n\nos.chdir(r'/kaggle/working')\n\nfrom IPython.display import FileLink\nFileLink(r'KP12_vc.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T23:48:44.047972Z","iopub.execute_input":"2022-05-24T23:48:44.048272Z","iopub.status.idle":"2022-05-24T23:48:45.986504Z","shell.execute_reply.started":"2022-05-24T23:48:44.048242Z","shell.execute_reply":"2022-05-24T23:48:45.985538Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/KP12_vc.csv","text/html":"<a href='KP12_vc.csv' target='_blank'>KP12_vc.csv</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"X_pred","metadata":{"execution":{"iopub.status.busy":"2022-05-24T23:47:32.739884Z","iopub.execute_input":"2022-05-24T23:47:32.740196Z","iopub.status.idle":"2022-05-24T23:47:32.821788Z","shell.execute_reply.started":"2022-05-24T23:47:32.740164Z","shell.execute_reply":"2022-05-24T23:47:32.819583Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"            ID_code     var_0     var_1     var_2     var_3     var_4     var_5     var_6     var_7     var_8  ...   var_190   var_191   var_192   var_193   var_194   var_195   var_196   var_197   var_198   var_199\n0            test_0  0.127087  2.322370  0.846979  1.288318  0.218112  0.342256  0.508443  0.503612  0.554499  ... -1.182277  1.458812 -2.271659 -0.221054 -1.365634  1.825848  0.378365  1.966051 -0.132039 -0.516213\n1            test_1 -0.707088  0.711392  0.222760 -0.788846 -1.158427  0.134767  0.704979  0.610152 -1.410404  ...  1.618333  0.461755 -0.668092  1.702392 -0.770655  0.433733 -0.694176  1.045342  1.082220 -1.690171\n2            test_2 -1.709895 -2.155410 -0.217892  0.122661 -0.502334  1.892279 -0.592875  1.084797  0.371299  ... -0.873712  1.175696  0.035494 -0.288898 -1.598452  1.588791 -1.725067 -2.002999  1.336653 -1.901222\n3            test_3 -0.704785  0.075321  0.494306 -0.108875 -1.374949  1.048840 -0.541289  1.176179  0.927203  ...  1.388905  0.541696 -0.182550  0.062175 -0.894767  2.314726  0.303441  0.348898 -0.947301 -0.084332\n4            test_4  0.337736  0.368977  1.292136  0.466636 -1.216252 -0.446931  1.674273 -1.738581  0.811202  ...  0.217030  0.573348 -0.435908  0.011191  0.498121 -0.100345 -1.368067 -1.757361 -0.645421 -0.560743\n...             ...       ...       ...       ...       ...       ...       ...       ...       ...       ...  ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...\n199995  test_199995  0.818789  0.651969 -0.107123  0.001165 -1.527918  0.115382 -0.635691 -0.521991 -0.903421  ... -0.259127  0.742886  1.857444 -1.177290 -1.633284  0.940313 -1.268761  0.270020  0.777053  0.786432\n199996  test_199996 -0.316620 -1.856223 -1.276517  1.147782  1.117762  1.029086  0.323216  0.684651  1.442229  ...  0.388328 -0.259297 -0.073156 -0.231175  0.290629 -0.553538  0.127966  0.220546  0.765034 -1.670334\n199997  test_199997  0.314770  0.963846  0.185926  0.473636  0.985977  2.085267 -0.023578  0.536355  0.412417  ...  0.420452 -1.583921  0.382822 -0.851020  0.659744 -0.721815 -1.183132  0.309622 -1.354467 -1.814710\n199998  test_199998  0.952608  0.274992  1.113794  0.336868  0.089653 -0.792776 -1.399678  0.082398  1.511049  ...  0.041610  0.351386  0.232363  0.608538 -0.314812  0.922821 -0.857498 -0.868008 -2.356195  0.298671\n199999  test_199999 -0.070072  0.847839 -0.184956 -0.358278 -0.648283  0.782292 -0.601069 -0.601962 -0.263030  ... -0.678952  0.609895 -0.384087  0.392177  0.669856 -0.813195 -0.898195  1.551374 -0.509954 -0.419442\n\n[200000 rows x 201 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_code</th>\n      <th>var_0</th>\n      <th>var_1</th>\n      <th>var_2</th>\n      <th>var_3</th>\n      <th>var_4</th>\n      <th>var_5</th>\n      <th>var_6</th>\n      <th>var_7</th>\n      <th>var_8</th>\n      <th>...</th>\n      <th>var_190</th>\n      <th>var_191</th>\n      <th>var_192</th>\n      <th>var_193</th>\n      <th>var_194</th>\n      <th>var_195</th>\n      <th>var_196</th>\n      <th>var_197</th>\n      <th>var_198</th>\n      <th>var_199</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0</td>\n      <td>0.127087</td>\n      <td>2.322370</td>\n      <td>0.846979</td>\n      <td>1.288318</td>\n      <td>0.218112</td>\n      <td>0.342256</td>\n      <td>0.508443</td>\n      <td>0.503612</td>\n      <td>0.554499</td>\n      <td>...</td>\n      <td>-1.182277</td>\n      <td>1.458812</td>\n      <td>-2.271659</td>\n      <td>-0.221054</td>\n      <td>-1.365634</td>\n      <td>1.825848</td>\n      <td>0.378365</td>\n      <td>1.966051</td>\n      <td>-0.132039</td>\n      <td>-0.516213</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1</td>\n      <td>-0.707088</td>\n      <td>0.711392</td>\n      <td>0.222760</td>\n      <td>-0.788846</td>\n      <td>-1.158427</td>\n      <td>0.134767</td>\n      <td>0.704979</td>\n      <td>0.610152</td>\n      <td>-1.410404</td>\n      <td>...</td>\n      <td>1.618333</td>\n      <td>0.461755</td>\n      <td>-0.668092</td>\n      <td>1.702392</td>\n      <td>-0.770655</td>\n      <td>0.433733</td>\n      <td>-0.694176</td>\n      <td>1.045342</td>\n      <td>1.082220</td>\n      <td>-1.690171</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2</td>\n      <td>-1.709895</td>\n      <td>-2.155410</td>\n      <td>-0.217892</td>\n      <td>0.122661</td>\n      <td>-0.502334</td>\n      <td>1.892279</td>\n      <td>-0.592875</td>\n      <td>1.084797</td>\n      <td>0.371299</td>\n      <td>...</td>\n      <td>-0.873712</td>\n      <td>1.175696</td>\n      <td>0.035494</td>\n      <td>-0.288898</td>\n      <td>-1.598452</td>\n      <td>1.588791</td>\n      <td>-1.725067</td>\n      <td>-2.002999</td>\n      <td>1.336653</td>\n      <td>-1.901222</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3</td>\n      <td>-0.704785</td>\n      <td>0.075321</td>\n      <td>0.494306</td>\n      <td>-0.108875</td>\n      <td>-1.374949</td>\n      <td>1.048840</td>\n      <td>-0.541289</td>\n      <td>1.176179</td>\n      <td>0.927203</td>\n      <td>...</td>\n      <td>1.388905</td>\n      <td>0.541696</td>\n      <td>-0.182550</td>\n      <td>0.062175</td>\n      <td>-0.894767</td>\n      <td>2.314726</td>\n      <td>0.303441</td>\n      <td>0.348898</td>\n      <td>-0.947301</td>\n      <td>-0.084332</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4</td>\n      <td>0.337736</td>\n      <td>0.368977</td>\n      <td>1.292136</td>\n      <td>0.466636</td>\n      <td>-1.216252</td>\n      <td>-0.446931</td>\n      <td>1.674273</td>\n      <td>-1.738581</td>\n      <td>0.811202</td>\n      <td>...</td>\n      <td>0.217030</td>\n      <td>0.573348</td>\n      <td>-0.435908</td>\n      <td>0.011191</td>\n      <td>0.498121</td>\n      <td>-0.100345</td>\n      <td>-1.368067</td>\n      <td>-1.757361</td>\n      <td>-0.645421</td>\n      <td>-0.560743</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>test_199995</td>\n      <td>0.818789</td>\n      <td>0.651969</td>\n      <td>-0.107123</td>\n      <td>0.001165</td>\n      <td>-1.527918</td>\n      <td>0.115382</td>\n      <td>-0.635691</td>\n      <td>-0.521991</td>\n      <td>-0.903421</td>\n      <td>...</td>\n      <td>-0.259127</td>\n      <td>0.742886</td>\n      <td>1.857444</td>\n      <td>-1.177290</td>\n      <td>-1.633284</td>\n      <td>0.940313</td>\n      <td>-1.268761</td>\n      <td>0.270020</td>\n      <td>0.777053</td>\n      <td>0.786432</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>test_199996</td>\n      <td>-0.316620</td>\n      <td>-1.856223</td>\n      <td>-1.276517</td>\n      <td>1.147782</td>\n      <td>1.117762</td>\n      <td>1.029086</td>\n      <td>0.323216</td>\n      <td>0.684651</td>\n      <td>1.442229</td>\n      <td>...</td>\n      <td>0.388328</td>\n      <td>-0.259297</td>\n      <td>-0.073156</td>\n      <td>-0.231175</td>\n      <td>0.290629</td>\n      <td>-0.553538</td>\n      <td>0.127966</td>\n      <td>0.220546</td>\n      <td>0.765034</td>\n      <td>-1.670334</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>test_199997</td>\n      <td>0.314770</td>\n      <td>0.963846</td>\n      <td>0.185926</td>\n      <td>0.473636</td>\n      <td>0.985977</td>\n      <td>2.085267</td>\n      <td>-0.023578</td>\n      <td>0.536355</td>\n      <td>0.412417</td>\n      <td>...</td>\n      <td>0.420452</td>\n      <td>-1.583921</td>\n      <td>0.382822</td>\n      <td>-0.851020</td>\n      <td>0.659744</td>\n      <td>-0.721815</td>\n      <td>-1.183132</td>\n      <td>0.309622</td>\n      <td>-1.354467</td>\n      <td>-1.814710</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>test_199998</td>\n      <td>0.952608</td>\n      <td>0.274992</td>\n      <td>1.113794</td>\n      <td>0.336868</td>\n      <td>0.089653</td>\n      <td>-0.792776</td>\n      <td>-1.399678</td>\n      <td>0.082398</td>\n      <td>1.511049</td>\n      <td>...</td>\n      <td>0.041610</td>\n      <td>0.351386</td>\n      <td>0.232363</td>\n      <td>0.608538</td>\n      <td>-0.314812</td>\n      <td>0.922821</td>\n      <td>-0.857498</td>\n      <td>-0.868008</td>\n      <td>-2.356195</td>\n      <td>0.298671</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>test_199999</td>\n      <td>-0.070072</td>\n      <td>0.847839</td>\n      <td>-0.184956</td>\n      <td>-0.358278</td>\n      <td>-0.648283</td>\n      <td>0.782292</td>\n      <td>-0.601069</td>\n      <td>-0.601962</td>\n      <td>-0.263030</td>\n      <td>...</td>\n      <td>-0.678952</td>\n      <td>0.609895</td>\n      <td>-0.384087</td>\n      <td>0.392177</td>\n      <td>0.669856</td>\n      <td>-0.813195</td>\n      <td>-0.898195</td>\n      <td>1.551374</td>\n      <td>-0.509954</td>\n      <td>-0.419442</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 201 columns</p>\n</div>"},"metadata":{}}]}]}
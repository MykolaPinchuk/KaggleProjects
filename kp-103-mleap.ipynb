{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This is a new version of MLEAP scripts, started in late Aug 2022.\nIt will combine IProject_MLEAP_ANN and IP_MLEAP script, while improving them.","metadata":{}},{"cell_type":"markdown","source":"#### Outline\n\n1. Load libraries and data.\n2. pEDA. Look at feature distribution, fix them if they do not look right.\n3. Train-test split. Most likely couple years into test set. 2015-2018?. Impute missing values.\n4. Transform numerical features, add ohe for inds.\n5. Fit classic models: ols as a baseline, then xgb.\n6. Fir DL.\n\n\nNotes:\nideally, I want to use time-based cross-validation.\nsince I have panel data, it is not a trivial task.\nneed to find some solution online.\ne.g., https://towardsdatascience.com/time-based-cross-validation-d259b13d42b8.\n","metadata":{}},{"cell_type":"code","source":"# 0. Import libraries #\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, time, math, re, warnings, random, gc, dill, optuna\nimport statsmodels.api as sm\nfrom random import sample\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNetCV\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn.inspection import permutation_importance\nfrom category_encoders import MEstimateEncoder\nfrom xgboost import XGBRegressor\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nplt.style.use('seaborn-white')\nwarnings.simplefilter(action='ignore')\npd.set_option('display.max_columns', 110)\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:39:06.397579Z","iopub.execute_input":"2022-08-24T23:39:06.398016Z","iopub.status.idle":"2022-08-24T23:39:06.415640Z","shell.execute_reply.started":"2022-08-24T23:39:06.397980Z","shell.execute_reply":"2022-08-24T23:39:06.413476Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"### target encoding ###\n# source: https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices/notebook\n\nclass CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=4)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:39:06.421765Z","iopub.execute_input":"2022-08-24T23:39:06.422452Z","iopub.status.idle":"2022-08-24T23:39:06.440891Z","shell.execute_reply.started":"2022-08-24T23:39:06.422414Z","shell.execute_reply":"2022-08-24T23:39:06.439907Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:39:06.447711Z","iopub.execute_input":"2022-08-24T23:39:06.450324Z","iopub.status.idle":"2022-08-24T23:39:06.461865Z","shell.execute_reply.started":"2022-08-24T23:39:06.450288Z","shell.execute_reply":"2022-08-24T23:39:06.460830Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"REPLICAS:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"# 1. Import data #\n\nmin_prd = 381\n\ntime0 = time.time()\ndf = pd.read_csv('../input/cpcrsp-46/IMLEAP_v4.csv')\ndf.dropna(axis=0, subset=['bm', 'lbm', 'llme', 'lop', 'op', 'linv', 'mom122', 'beta_bw', 'ind'], inplace=True)\ndf.reset_index(inplace=True, drop=True)\n#df = df.sample(500000)\ndf = df[df.year.isin(range(1990, 2010))]\ndisplay(df.shape, df.head(), df.count())","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:39:06.467288Z","iopub.execute_input":"2022-08-24T23:39:06.469866Z","iopub.status.idle":"2022-08-24T23:39:20.683474Z","shell.execute_reply.started":"2022-08-24T23:39:06.469827Z","shell.execute_reply":"2022-08-24T23:39:20.682230Z"},"trusted":true},"execution_count":103,"outputs":[{"output_type":"display_data","data":{"text/plain":"(581451, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    PERMNO  prd  mom482     mom242  year    RET   ind        bm        op  \\\n6    10005  381     NaN -65.203618  1990  -0.57  30.0  0.490174 -0.214332   \n7    10005  382     NaN -65.224843  1990 -25.57  30.0  0.490174 -0.214332   \n8    10005  383     NaN -72.706514  1990  -0.64  30.0  0.490174 -0.214332   \n9    10005  384     NaN -67.514581  1990  -0.69  30.0  0.490174 -0.214332   \n10   10005  385     NaN -62.951924  1990  -0.68  30.0  0.490174 -0.214332   \n\n     gp       inv      mom11     mom122  amhd  ivol_capm  ivol_ff5   beta_bw  \\\n6   0.0 -0.230583  -0.610000 -38.367763   NaN   0.765013  0.647098  0.522012   \n7   0.0 -0.230583  -0.570000 -38.404947   NaN   0.765013  0.647098  0.499827   \n8   0.0 -0.230583 -22.380465 -38.380158   NaN   5.732938  5.391287  0.492262   \n9   0.0 -0.230583  -0.640000 -53.826992   NaN   0.765013  0.647098  0.493277   \n10  0.0 -0.230583  -0.690000 -44.500763   NaN   0.765013  0.647098  0.538328   \n\n       MAX     vol1m     vol6m    vol12m  BAspr      size      lbm       lop  \\\n6   1.4066  0.866870  4.132801  3.099129    NaN -0.647218  0.75014 -0.084639   \n7   1.4066  0.866870  4.132835  3.099130    NaN -0.647218  0.75014 -0.084639   \n8   1.4066  5.455535  4.690786  3.473044    NaN -0.934794  0.75014 -0.084639   \n9   1.4066  0.866870  3.725968  3.473051    NaN -0.934794  0.75014 -0.084639   \n10  1.4066  0.866870  3.725977  3.313428    NaN -0.934794  0.75014 -0.084639   \n\n         lgp      linv      llme  l1amhd      l1MAX  l1BAspr  l3amhd  \\\n6   0.015282  0.306039 -0.241753     NaN  21.135115      NaN     NaN   \n7   0.015282  0.306039 -0.241753     NaN   1.406600      NaN     NaN   \n8   0.015282  0.306039 -0.241753     NaN   1.406600      NaN     NaN   \n9   0.015282  0.306039 -0.241753     NaN   1.406600      NaN     NaN   \n10  0.015282  0.306039 -0.424011     NaN   1.406600      NaN     NaN   \n\n        l3MAX  l3BAspr  l6amhd   l6MAX  l6BAspr  l12amhd     l12MAX  l12BAspr  \\\n6    1.406600      NaN     NaN  1.4066      NaN      NaN  21.135115       NaN   \n7    1.406600      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n8   21.135115      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n9    1.406600      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n10   1.406600      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n\n    l12mom122  l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n6  -37.167231      0.765013     0.647098    0.710294  4.235715   3.516000  \n7  -43.659716      0.765013     0.647098    0.735236  3.367831   3.336151  \n8  -43.710657      0.765013     0.647098    0.741531  3.367760   3.336121  \n9  -43.806772      0.765013     0.647098    0.750895  2.328417   3.336079  \n10 -29.825580      3.624354     3.579437    0.776122  1.485171   3.263052  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>10005</td>\n      <td>381</td>\n      <td>NaN</td>\n      <td>-65.203618</td>\n      <td>1990</td>\n      <td>-0.57</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.610000</td>\n      <td>-38.367763</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.522012</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>4.132801</td>\n      <td>3.099129</td>\n      <td>NaN</td>\n      <td>-0.647218</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>-37.167231</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.710294</td>\n      <td>4.235715</td>\n      <td>3.516000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10005</td>\n      <td>382</td>\n      <td>NaN</td>\n      <td>-65.224843</td>\n      <td>1990</td>\n      <td>-25.57</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.570000</td>\n      <td>-38.404947</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.499827</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>4.132835</td>\n      <td>3.099130</td>\n      <td>NaN</td>\n      <td>-0.647218</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-43.659716</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.735236</td>\n      <td>3.367831</td>\n      <td>3.336151</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10005</td>\n      <td>383</td>\n      <td>NaN</td>\n      <td>-72.706514</td>\n      <td>1990</td>\n      <td>-0.64</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-22.380465</td>\n      <td>-38.380158</td>\n      <td>NaN</td>\n      <td>5.732938</td>\n      <td>5.391287</td>\n      <td>0.492262</td>\n      <td>1.4066</td>\n      <td>5.455535</td>\n      <td>4.690786</td>\n      <td>3.473044</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-43.710657</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.741531</td>\n      <td>3.367760</td>\n      <td>3.336121</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10005</td>\n      <td>384</td>\n      <td>NaN</td>\n      <td>-67.514581</td>\n      <td>1990</td>\n      <td>-0.69</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.640000</td>\n      <td>-53.826992</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.493277</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>3.725968</td>\n      <td>3.473051</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-43.806772</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.750895</td>\n      <td>2.328417</td>\n      <td>3.336079</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10005</td>\n      <td>385</td>\n      <td>NaN</td>\n      <td>-62.951924</td>\n      <td>1990</td>\n      <td>-0.68</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.690000</td>\n      <td>-44.500763</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.538328</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>3.725977</td>\n      <td>3.313428</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.424011</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-29.825580</td>\n      <td>3.624354</td>\n      <td>3.579437</td>\n      <td>0.776122</td>\n      <td>1.485171</td>\n      <td>3.263052</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          581451\nprd             581451\nmom482          496486\nmom242          571581\nyear            581451\nRET             581451\nind             581451\nbm              581451\nop              581451\ngp              581451\ninv             580886\nmom11           581451\nmom122          581451\namhd            505115\nivol_capm       581433\nivol_ff5        581433\nbeta_bw         581451\nMAX             581451\nvol1m           581416\nvol6m           580805\nvol12m          579763\nBAspr           509794\nsize            581451\nlbm             581451\nlop             581451\nlgp             581451\nlinv            581451\nllme            581451\nl1amhd          505015\nl1MAX           581430\nl1BAspr         508389\nl3amhd          504772\nl3MAX           581285\nl3BAspr         505333\nl6amhd          504319\nl6MAX           581160\nl6BAspr         500951\nl12amhd         503185\nl12MAX          581430\nl12BAspr        492490\nl12mom122       579796\nl12ivol_capm    580902\nl12ivol_ff5     580902\nl12beta_bw      581074\nl12vol6m        580000\nl12vol12m       574214\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# 2. pEDA #\n\ndf.RET.hist()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:39:20.685566Z","iopub.execute_input":"2022-08-24T23:39:20.686489Z","iopub.status.idle":"2022-08-24T23:39:20.901027Z","shell.execute_reply.started":"2022-08-24T23:39:20.686449Z","shell.execute_reply":"2022-08-24T23:39:20.900096Z"},"trusted":true},"execution_count":104,"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"# explore feature distibution, adjust if seems unreasonable","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:39:20.902403Z","iopub.execute_input":"2022-08-24T23:39:20.903930Z","iopub.status.idle":"2022-08-24T23:39:20.910010Z","shell.execute_reply.started":"2022-08-24T23:39:20.903901Z","shell.execute_reply":"2022-08-24T23:39:20.909018Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"# add dummies for some missing features\n\nfeatures_miss_dummies = ['amhd', 'BAspr']\n\nfor col in features_miss_dummies:\n    df[col+'_miss'] = df[col].isnull().astype(int)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:39:20.911385Z","iopub.execute_input":"2022-08-24T23:39:20.911748Z","iopub.status.idle":"2022-08-24T23:39:20.956065Z","shell.execute_reply.started":"2022-08-24T23:39:20.911711Z","shell.execute_reply":"2022-08-24T23:39:20.955027Z"},"trusted":true},"execution_count":106,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"    PERMNO  prd  mom482     mom242  year    RET   ind        bm        op  \\\n6    10005  381     NaN -65.203618  1990  -0.57  30.0  0.490174 -0.214332   \n7    10005  382     NaN -65.224843  1990 -25.57  30.0  0.490174 -0.214332   \n8    10005  383     NaN -72.706514  1990  -0.64  30.0  0.490174 -0.214332   \n9    10005  384     NaN -67.514581  1990  -0.69  30.0  0.490174 -0.214332   \n10   10005  385     NaN -62.951924  1990  -0.68  30.0  0.490174 -0.214332   \n\n     gp       inv      mom11     mom122  amhd  ivol_capm  ivol_ff5   beta_bw  \\\n6   0.0 -0.230583  -0.610000 -38.367763   NaN   0.765013  0.647098  0.522012   \n7   0.0 -0.230583  -0.570000 -38.404947   NaN   0.765013  0.647098  0.499827   \n8   0.0 -0.230583 -22.380465 -38.380158   NaN   5.732938  5.391287  0.492262   \n9   0.0 -0.230583  -0.640000 -53.826992   NaN   0.765013  0.647098  0.493277   \n10  0.0 -0.230583  -0.690000 -44.500763   NaN   0.765013  0.647098  0.538328   \n\n       MAX     vol1m     vol6m    vol12m  BAspr      size      lbm       lop  \\\n6   1.4066  0.866870  4.132801  3.099129    NaN -0.647218  0.75014 -0.084639   \n7   1.4066  0.866870  4.132835  3.099130    NaN -0.647218  0.75014 -0.084639   \n8   1.4066  5.455535  4.690786  3.473044    NaN -0.934794  0.75014 -0.084639   \n9   1.4066  0.866870  3.725968  3.473051    NaN -0.934794  0.75014 -0.084639   \n10  1.4066  0.866870  3.725977  3.313428    NaN -0.934794  0.75014 -0.084639   \n\n         lgp      linv      llme  l1amhd      l1MAX  l1BAspr  l3amhd  \\\n6   0.015282  0.306039 -0.241753     NaN  21.135115      NaN     NaN   \n7   0.015282  0.306039 -0.241753     NaN   1.406600      NaN     NaN   \n8   0.015282  0.306039 -0.241753     NaN   1.406600      NaN     NaN   \n9   0.015282  0.306039 -0.241753     NaN   1.406600      NaN     NaN   \n10  0.015282  0.306039 -0.424011     NaN   1.406600      NaN     NaN   \n\n        l3MAX  l3BAspr  l6amhd   l6MAX  l6BAspr  l12amhd     l12MAX  l12BAspr  \\\n6    1.406600      NaN     NaN  1.4066      NaN      NaN  21.135115       NaN   \n7    1.406600      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n8   21.135115      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n9    1.406600      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n10   1.406600      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n\n    l12mom122  l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \\\n6  -37.167231      0.765013     0.647098    0.710294  4.235715   3.516000   \n7  -43.659716      0.765013     0.647098    0.735236  3.367831   3.336151   \n8  -43.710657      0.765013     0.647098    0.741531  3.367760   3.336121   \n9  -43.806772      0.765013     0.647098    0.750895  2.328417   3.336079   \n10 -29.825580      3.624354     3.579437    0.776122  1.485171   3.263052   \n\n    amhd_miss  BAspr_miss  \n6           1           1  \n7           1           1  \n8           1           1  \n9           1           1  \n10          1           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>amhd_miss</th>\n      <th>BAspr_miss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>10005</td>\n      <td>381</td>\n      <td>NaN</td>\n      <td>-65.203618</td>\n      <td>1990</td>\n      <td>-0.57</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.610000</td>\n      <td>-38.367763</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.522012</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>4.132801</td>\n      <td>3.099129</td>\n      <td>NaN</td>\n      <td>-0.647218</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>-37.167231</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.710294</td>\n      <td>4.235715</td>\n      <td>3.516000</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10005</td>\n      <td>382</td>\n      <td>NaN</td>\n      <td>-65.224843</td>\n      <td>1990</td>\n      <td>-25.57</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.570000</td>\n      <td>-38.404947</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.499827</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>4.132835</td>\n      <td>3.099130</td>\n      <td>NaN</td>\n      <td>-0.647218</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-43.659716</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.735236</td>\n      <td>3.367831</td>\n      <td>3.336151</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10005</td>\n      <td>383</td>\n      <td>NaN</td>\n      <td>-72.706514</td>\n      <td>1990</td>\n      <td>-0.64</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-22.380465</td>\n      <td>-38.380158</td>\n      <td>NaN</td>\n      <td>5.732938</td>\n      <td>5.391287</td>\n      <td>0.492262</td>\n      <td>1.4066</td>\n      <td>5.455535</td>\n      <td>4.690786</td>\n      <td>3.473044</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-43.710657</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.741531</td>\n      <td>3.367760</td>\n      <td>3.336121</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10005</td>\n      <td>384</td>\n      <td>NaN</td>\n      <td>-67.514581</td>\n      <td>1990</td>\n      <td>-0.69</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.640000</td>\n      <td>-53.826992</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.493277</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>3.725968</td>\n      <td>3.473051</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-43.806772</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.750895</td>\n      <td>2.328417</td>\n      <td>3.336079</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10005</td>\n      <td>385</td>\n      <td>NaN</td>\n      <td>-62.951924</td>\n      <td>1990</td>\n      <td>-0.68</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.690000</td>\n      <td>-44.500763</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.538328</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>3.725977</td>\n      <td>3.313428</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.424011</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-29.825580</td>\n      <td>3.624354</td>\n      <td>3.579437</td>\n      <td>0.776122</td>\n      <td>1.485171</td>\n      <td>3.263052</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 3. Train-test split #\n\ntemp_cols = ['PERMNO', 'prd', 'year']\n\ntrain = df[df.prd<(min_prd+60)]\ntest = df[df.prd==(min_prd+60)]\ntrain.drop(columns=temp_cols, inplace=True)\ntest.drop(columns=temp_cols, inplace=True)\ndisplay(train.shape, test.shape, train.head(3), test.head(3))","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:42:11.142210Z","iopub.execute_input":"2022-08-24T23:42:11.142590Z","iopub.status.idle":"2022-08-24T23:42:11.257600Z","shell.execute_reply.started":"2022-08-24T23:42:11.142559Z","shell.execute_reply":"2022-08-24T23:42:11.256540Z"},"trusted":true},"execution_count":108,"outputs":[{"output_type":"display_data","data":{"text/plain":"(151842, 45)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(2544, 45)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   mom482     mom242    RET   ind        bm        op   gp       inv  \\\n6     NaN -65.203618  -0.57  30.0  0.490174 -0.214332  0.0 -0.230583   \n7     NaN -65.224843 -25.57  30.0  0.490174 -0.214332  0.0 -0.230583   \n8     NaN -72.706514  -0.64  30.0  0.490174 -0.214332  0.0 -0.230583   \n\n       mom11     mom122  amhd  ivol_capm  ivol_ff5   beta_bw     MAX  \\\n6  -0.610000 -38.367763   NaN   0.765013  0.647098  0.522012  1.4066   \n7  -0.570000 -38.404947   NaN   0.765013  0.647098  0.499827  1.4066   \n8 -22.380465 -38.380158   NaN   5.732938  5.391287  0.492262  1.4066   \n\n      vol1m     vol6m    vol12m  BAspr      size      lbm       lop       lgp  \\\n6  0.866870  4.132801  3.099129    NaN -0.647218  0.75014 -0.084639  0.015282   \n7  0.866870  4.132835  3.099130    NaN -0.647218  0.75014 -0.084639  0.015282   \n8  5.455535  4.690786  3.473044    NaN -0.934794  0.75014 -0.084639  0.015282   \n\n       linv      llme  l1amhd      l1MAX  l1BAspr  l3amhd      l3MAX  l3BAspr  \\\n6  0.306039 -0.241753     NaN  21.135115      NaN     NaN   1.406600      NaN   \n7  0.306039 -0.241753     NaN   1.406600      NaN     NaN   1.406600      NaN   \n8  0.306039 -0.241753     NaN   1.406600      NaN     NaN  21.135115      NaN   \n\n   l6amhd   l6MAX  l6BAspr  l12amhd     l12MAX  l12BAspr  l12mom122  \\\n6     NaN  1.4066      NaN      NaN  21.135115       NaN -37.167231   \n7     NaN  1.4066      NaN      NaN   1.406600       NaN -43.659716   \n8     NaN  1.4066      NaN      NaN   1.406600       NaN -43.710657   \n\n   l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  amhd_miss  \\\n6      0.765013     0.647098    0.710294  4.235715   3.516000          1   \n7      0.765013     0.647098    0.735236  3.367831   3.336151          1   \n8      0.765013     0.647098    0.741531  3.367760   3.336121          1   \n\n   BAspr_miss  \n6           1  \n7           1  \n8           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>amhd_miss</th>\n      <th>BAspr_miss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>-65.203618</td>\n      <td>-0.57</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.610000</td>\n      <td>-38.367763</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.522012</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>4.132801</td>\n      <td>3.099129</td>\n      <td>NaN</td>\n      <td>-0.647218</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>-37.167231</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.710294</td>\n      <td>4.235715</td>\n      <td>3.516000</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>-65.224843</td>\n      <td>-25.57</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.570000</td>\n      <td>-38.404947</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.499827</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>4.132835</td>\n      <td>3.099130</td>\n      <td>NaN</td>\n      <td>-0.647218</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-43.659716</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.735236</td>\n      <td>3.367831</td>\n      <td>3.336151</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>-72.706514</td>\n      <td>-0.64</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-22.380465</td>\n      <td>-38.380158</td>\n      <td>NaN</td>\n      <td>5.732938</td>\n      <td>5.391287</td>\n      <td>0.492262</td>\n      <td>1.4066</td>\n      <td>5.455535</td>\n      <td>4.690786</td>\n      <td>3.473044</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-43.710657</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.741531</td>\n      <td>3.367760</td>\n      <td>3.336121</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"         mom482      mom242      RET   ind        bm        op        gp  \\\n305  -52.312316  -46.967739   4.5800  12.0 -1.896125  0.081622  0.510535   \n342  190.634307  170.270066 -10.8046  49.0 -1.862198  0.132619  0.757579   \n574  -53.013446  -66.328875  11.8249  21.0  0.177905 -0.082748  0.119668   \n\n          inv    mom11      mom122      amhd  ivol_capm  ivol_ff5   beta_bw  \\\n305 -0.101827 -11.5511    6.309380  2.778245   3.727031  3.549946  1.096501   \n342  0.335288  -6.2371  105.899232  3.248493   2.666218  2.284620  0.693450   \n574 -0.103007 -11.3491  -51.336416  2.239765   5.899688  5.075038  0.916279   \n\n         MAX     vol1m     vol6m    vol12m     BAspr      size       lbm  \\\n305   7.4790  3.931532  2.979029  3.420743  4.651163  3.930452 -1.623669   \n342   7.5420  2.762798  2.876936  3.023678  1.538462  4.532237 -1.567054   \n574  10.7633  6.349370  3.500791  4.053772  5.769231  4.429410  0.670110   \n\n          lop       lgp      linv      llme    l1amhd    l1MAX   l1BAspr  \\\n305  0.013844  0.291257  0.800300  3.961848  2.727015   7.1249  4.651163   \n342  0.019597  0.839508 -0.112930  3.631882  3.821606  18.3306  2.112676   \n574  0.063815  0.291788  0.003223  5.233018  2.144554   7.3894  1.960784   \n\n       l3amhd   l3MAX   l3BAspr    l6amhd   l6MAX   l6BAspr   l12amhd  \\\n305  2.800786  6.6497  2.040816  2.701712  3.2647  4.545455  2.614138   \n342  3.981594  5.2462  2.380952  4.302508  3.6897  1.149425  4.874860   \n574  1.872630  2.7999  2.816901  1.950575  1.7101  2.500000  2.459010   \n\n      l12MAX  l12BAspr  l12mom122  l12ivol_capm  l12ivol_ff5  l12beta_bw  \\\n305   7.1249  2.272727 -52.929807      3.158877     2.559848    0.934201   \n342  18.3306  3.571429  60.701689      2.527816     2.276596    0.329704   \n574   7.3894  3.508772 -22.503955      3.237493     3.095980    0.226650   \n\n     l12vol6m  l12vol12m  amhd_miss  BAspr_miss  \n305  3.785383   3.654135          0           0  \n342  3.260048   3.923731          0           0  \n574  2.600822   2.612941          0           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>amhd_miss</th>\n      <th>BAspr_miss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>305</th>\n      <td>-52.312316</td>\n      <td>-46.967739</td>\n      <td>4.5800</td>\n      <td>12.0</td>\n      <td>-1.896125</td>\n      <td>0.081622</td>\n      <td>0.510535</td>\n      <td>-0.101827</td>\n      <td>-11.5511</td>\n      <td>6.309380</td>\n      <td>2.778245</td>\n      <td>3.727031</td>\n      <td>3.549946</td>\n      <td>1.096501</td>\n      <td>7.4790</td>\n      <td>3.931532</td>\n      <td>2.979029</td>\n      <td>3.420743</td>\n      <td>4.651163</td>\n      <td>3.930452</td>\n      <td>-1.623669</td>\n      <td>0.013844</td>\n      <td>0.291257</td>\n      <td>0.800300</td>\n      <td>3.961848</td>\n      <td>2.727015</td>\n      <td>7.1249</td>\n      <td>4.651163</td>\n      <td>2.800786</td>\n      <td>6.6497</td>\n      <td>2.040816</td>\n      <td>2.701712</td>\n      <td>3.2647</td>\n      <td>4.545455</td>\n      <td>2.614138</td>\n      <td>7.1249</td>\n      <td>2.272727</td>\n      <td>-52.929807</td>\n      <td>3.158877</td>\n      <td>2.559848</td>\n      <td>0.934201</td>\n      <td>3.785383</td>\n      <td>3.654135</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>190.634307</td>\n      <td>170.270066</td>\n      <td>-10.8046</td>\n      <td>49.0</td>\n      <td>-1.862198</td>\n      <td>0.132619</td>\n      <td>0.757579</td>\n      <td>0.335288</td>\n      <td>-6.2371</td>\n      <td>105.899232</td>\n      <td>3.248493</td>\n      <td>2.666218</td>\n      <td>2.284620</td>\n      <td>0.693450</td>\n      <td>7.5420</td>\n      <td>2.762798</td>\n      <td>2.876936</td>\n      <td>3.023678</td>\n      <td>1.538462</td>\n      <td>4.532237</td>\n      <td>-1.567054</td>\n      <td>0.019597</td>\n      <td>0.839508</td>\n      <td>-0.112930</td>\n      <td>3.631882</td>\n      <td>3.821606</td>\n      <td>18.3306</td>\n      <td>2.112676</td>\n      <td>3.981594</td>\n      <td>5.2462</td>\n      <td>2.380952</td>\n      <td>4.302508</td>\n      <td>3.6897</td>\n      <td>1.149425</td>\n      <td>4.874860</td>\n      <td>18.3306</td>\n      <td>3.571429</td>\n      <td>60.701689</td>\n      <td>2.527816</td>\n      <td>2.276596</td>\n      <td>0.329704</td>\n      <td>3.260048</td>\n      <td>3.923731</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>574</th>\n      <td>-53.013446</td>\n      <td>-66.328875</td>\n      <td>11.8249</td>\n      <td>21.0</td>\n      <td>0.177905</td>\n      <td>-0.082748</td>\n      <td>0.119668</td>\n      <td>-0.103007</td>\n      <td>-11.3491</td>\n      <td>-51.336416</td>\n      <td>2.239765</td>\n      <td>5.899688</td>\n      <td>5.075038</td>\n      <td>0.916279</td>\n      <td>10.7633</td>\n      <td>6.349370</td>\n      <td>3.500791</td>\n      <td>4.053772</td>\n      <td>5.769231</td>\n      <td>4.429410</td>\n      <td>0.670110</td>\n      <td>0.063815</td>\n      <td>0.291788</td>\n      <td>0.003223</td>\n      <td>5.233018</td>\n      <td>2.144554</td>\n      <td>7.3894</td>\n      <td>1.960784</td>\n      <td>1.872630</td>\n      <td>2.7999</td>\n      <td>2.816901</td>\n      <td>1.950575</td>\n      <td>1.7101</td>\n      <td>2.500000</td>\n      <td>2.459010</td>\n      <td>7.3894</td>\n      <td>3.508772</td>\n      <td>-22.503955</td>\n      <td>3.237493</td>\n      <td>3.095980</td>\n      <td>0.226650</td>\n      <td>2.600822</td>\n      <td>2.612941</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 4. Missing values #\n\ncol_ignore = ['RET']\ncol_cat = ['ind']\ncol_num = [x for x in train.columns if x not in col_ignore+col_cat]\n\nfor col in col_num:\n    train[col] = train[col].fillna(train[col].median())\n    test[col] = test[col].fillna(train[col].median())\n\nfor col in col_cat:\n    train[col] = train[col].fillna(value=-1000)\n    test[col] = test[col].fillna(value=-1000)\n    \ndisplay(train.count())","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:42:50.852367Z","iopub.execute_input":"2022-08-24T23:42:50.852942Z","iopub.status.idle":"2022-08-24T23:42:51.086780Z","shell.execute_reply.started":"2022-08-24T23:42:50.852908Z","shell.execute_reply":"2022-08-24T23:42:51.085850Z"},"trusted":true},"execution_count":109,"outputs":[{"output_type":"display_data","data":{"text/plain":"mom482          151842\nmom242          151842\nRET             151842\nind             151842\nbm              151842\nop              151842\ngp              151842\ninv             151842\nmom11           151842\nmom122          151842\namhd            151842\nivol_capm       151842\nivol_ff5        151842\nbeta_bw         151842\nMAX             151842\nvol1m           151842\nvol6m           151842\nvol12m          151842\nBAspr           151842\nsize            151842\nlbm             151842\nlop             151842\nlgp             151842\nlinv            151842\nllme            151842\nl1amhd          151842\nl1MAX           151842\nl1BAspr         151842\nl3amhd          151842\nl3MAX           151842\nl3BAspr         151842\nl6amhd          151842\nl6MAX           151842\nl6BAspr         151842\nl12amhd         151842\nl12MAX          151842\nl12BAspr        151842\nl12mom122       151842\nl12ivol_capm    151842\nl12ivol_ff5     151842\nl12beta_bw      151842\nl12vol6m        151842\nl12vol12m       151842\namhd_miss       151842\nBAspr_miss      151842\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# [optional] Target Encoding\n","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:12:06.890871Z","iopub.execute_input":"2022-08-24T23:12:06.891533Z","iopub.status.idle":"2022-08-24T23:12:06.896582Z","shell.execute_reply.started":"2022-08-24T23:12:06.891489Z","shell.execute_reply":"2022-08-24T23:12:06.895429Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"X_train = train.copy()\ny_train = X_train.pop('RET')\n\nX_test = test.copy()\ny_test = X_test.pop('RET')","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:43:51.045698Z","iopub.execute_input":"2022-08-24T23:43:51.046080Z","iopub.status.idle":"2022-08-24T23:43:51.063599Z","shell.execute_reply.started":"2022-08-24T23:43:51.046048Z","shell.execute_reply":"2022-08-24T23:43:51.062465Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"# 5. Feature engineering #\n\ntime1 = time.time()\n\nfeature_transformer = ColumnTransformer([\n    (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\", drop='if_binary'), col_cat),\n    ('num', StandardScaler(), col_num)])\n\nprint('Number of features before transformation: ', X_train.shape)\nX_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\nX_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\nprint('time to do feature proprocessing: ', time.time()-time1)\nprint('Number of features after transformation: ', X_train.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:43:55.253242Z","iopub.execute_input":"2022-08-24T23:43:55.254274Z","iopub.status.idle":"2022-08-24T23:43:55.594633Z","shell.execute_reply.started":"2022-08-24T23:43:55.254230Z","shell.execute_reply":"2022-08-24T23:43:55.593644Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"Number of features before transformation:  (151842, 44)\ntime to do feature proprocessing:  0.33363819122314453\nNumber of features after transformation:  (151842, 92)\n","output_type":"stream"}]},{"cell_type":"code","source":"# 6. Model fitting #\n\n# first, some trivial baselines:\nprint('mae of a constant model', mean_absolute_error(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\nprint('R2 of a constant model', r2_score(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\n\ntime1 = time.time()\nxgb1 = XGBRegressor(tree_method = 'gpu_hist', n_estimators=300, max_depth=6, eta=0.05, colsample_bytree=0.6)\nxgb1.fit(X_train, y_train)\nprint('XGB train:', mean_absolute_error(y_train, xgb1.predict(X_train)), r2_score(y_train, xgb1.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:44:07.595999Z","iopub.execute_input":"2022-08-24T23:44:07.596695Z","iopub.status.idle":"2022-08-24T23:44:11.720612Z","shell.execute_reply.started":"2022-08-24T23:44:07.596659Z","shell.execute_reply":"2022-08-24T23:44:11.719802Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"mae of a constant model 11.620785167397445\nR2 of a constant model 0.0\nXGB train: 10.430981677326693 0.1570521115946395 4.102670669555664\n","output_type":"stream"}]},{"cell_type":"code","source":"time1 = time.time()\nxgb = XGBRegressor(tree_method = 'gpu_hist')\nparam_grid = {'n_estimators':[300, 500], 'max_depth':[2,3,4], 'eta':[0.015, 0.3, 0.05],\n             'subsample':[0.6], 'colsample_bytree':[0.6]}\nxgbm = GridSearchCV(xgb, param_grid, cv=2, verbose=2, scoring='neg_mean_absolute_error')\nxgbm.fit(X_train, y_train)\nprint('XGB', xgbm.best_params_, xgbm.best_score_, time.time()-time1)\n# this runs for 40 min and finds \n# 'eta': 0.02, 'max_depth': 6, 'n_estimators': 500, 0.01095415380877135\nprint('XGB train:', mean_absolute_error(y_train, xgbm.predict(X_train)), r2_score(y_train, xgbm.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:44:35.584777Z","iopub.execute_input":"2022-08-24T23:44:35.585951Z","iopub.status.idle":"2022-08-24T23:45:46.831525Z","shell.execute_reply.started":"2022-08-24T23:44:35.585896Z","shell.execute_reply":"2022-08-24T23:45:46.830687Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"Fitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=500, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=500, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=6, n_estimators=300, subsample=0.6; total time=   2.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=6, n_estimators=300, subsample=0.6; total time=   2.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=6, n_estimators=500, subsample=0.6; total time=   3.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=6, n_estimators=500, subsample=0.6; total time=   3.8s\n[CV] END colsample_bytree=0.6, eta=0.04, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.04, max_depth=2, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.04, max_depth=2, n_estimators=500, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.04, max_depth=2, n_estimators=500, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.04, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.04, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.04, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.04, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.04, max_depth=6, n_estimators=300, subsample=0.6; total time=   2.5s\n[CV] END colsample_bytree=0.6, eta=0.04, max_depth=6, n_estimators=300, subsample=0.6; total time=   2.4s\n[CV] END colsample_bytree=0.6, eta=0.04, max_depth=6, n_estimators=500, subsample=0.6; total time=   4.0s\n[CV] END colsample_bytree=0.6, eta=0.04, max_depth=6, n_estimators=500, subsample=0.6; total time=   4.0s\n[CV] END colsample_bytree=0.6, eta=0.06, max_depth=2, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.06, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.06, max_depth=2, n_estimators=500, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.06, max_depth=2, n_estimators=500, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.06, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.06, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.06, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.06, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.06, max_depth=6, n_estimators=300, subsample=0.6; total time=   2.5s\n[CV] END colsample_bytree=0.6, eta=0.06, max_depth=6, n_estimators=300, subsample=0.6; total time=   2.4s\n[CV] END colsample_bytree=0.6, eta=0.06, max_depth=6, n_estimators=500, subsample=0.6; total time=   3.8s\n[CV] END colsample_bytree=0.6, eta=0.06, max_depth=6, n_estimators=500, subsample=0.6; total time=   4.0s\nXGB {'colsample_bytree': 0.6, 'eta': 0.02, 'max_depth': 2, 'n_estimators': 500, 'subsample': 0.6} -10.96136633708812 70.24919629096985\nXGB train: 10.932944931385597 0.015052149606649246 71.23664474487305\n","output_type":"stream"}]},{"cell_type":"code","source":"# time1 = time.time()\n\n# def objective(trial, cv_runs=1, n_splits=2, n_jobs=-1):\n\n#     cv_regularizer=0.01\n#     # Usually values between 0.1 and 0.2 work fine.\n\n#     params = {\n#         \"tree_method\": 'gpu_hist',\n#         \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n#         \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n#         \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n#         \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.005, 0.2),\n#         \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.1, 0.95),\n#         \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 0.95),\n#         \"alpha\": trial.suggest_loguniform(\"alpha\", 0.1, 20.0),\n#         \"lambda\": trial.suggest_loguniform(\"lambda\", 0.1, 150.0),\n#         \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-10, 10.0),\n#         \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 0.1, 10)    }\n#     # usually it makes sense to resrtict hyperparameter space from some solutions which Optuna will find\n#     # e.g., for tmx-joined data only (downsampled tmx), optuna keeps selecting depths of 2 and 3.\n#     # for my purposes (smooth left side of prc, close to 1), those solutions are no good.\n\n#     temp_out = []\n\n#     for i in range(cv_runs):\n\n#         X = X_train\n#         y = y_train\n\n#         model = XGBRegressor(**params, njobs=-1)\n#         rkf = KFold(n_splits=n_splits, shuffle=True)\n#         X_values = X.values\n#         y_values = y.values\n#         y_pred = np.zeros_like(y_values)\n#         y_pred_train = np.zeros_like(y_values)\n#         for train_index, test_index in rkf.split(X_values):\n#             X_A, X_B = X_values[train_index, :], X_values[test_index, :]\n#             y_A, y_B = y_values[train_index], y_values[test_index]\n#             model.fit(X_A, y_A, eval_set=[(X_B, y_B)], verbose = False)\n#             y_pred[test_index] += model.predict(X_B)\n                      \n            \n#         #score_train = roc_auc_score(y_train, y_pred_train)\n#         score_test = mean_absolute_error(y_train, y_pred) \n#         #overfit = score_train-score_test\n#         #temp_out.append(score_test-cv_regularizer*overfit)\n#         temp_out.append(score_test)\n\n#     return (np.mean(temp_out))\n\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(objective, n_trials=30)\n\n# print('Total time for hypermarameter optimization ', time.time()-time1)\n# hp = study.best_params\n# for key, value in hp.items():\n#     print(f\"{key:>20s} : {value}\")\n# print(f\"{'best objective value':>20s} : {study.best_value}\")\n\n# optuna_hyperpars = study.best_params\n# optuna_hyperpars['tree_method']='gpu_hist'\n\n# optuna_xgb = XGBRegressor(**optuna_hyperpars)\n# optuna_xgb.fit(X_train, y_train)\n# print('Optuna XGB train:', \n#       mean_absolute_error(y_train, optuna_xgb.predict(X_train)), r2_score(y_train, optuna_xgb.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:46:06.484453Z","iopub.execute_input":"2022-08-24T23:46:06.484809Z","iopub.status.idle":"2022-08-24T23:53:04.882679Z","shell.execute_reply.started":"2022-08-24T23:46:06.484779Z","shell.execute_reply":"2022-08-24T23:53:04.881916Z"},"trusted":true},"execution_count":115,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-08-24 23:46:06,496]\u001b[0m A new study created in memory with name: no-name-5899c2a6-1e9c-45f0-867f-b5c8d04531b5\u001b[0m\n\u001b[32m[I 2022-08-24 23:46:08,843]\u001b[0m Trial 0 finished with value: 11.062386406243789 and parameters: {'n_estimators': 183, 'max_depth': 4, 'learning_rate': 0.14951239119858067, 'colsample_bytree': 0.3227666017236151, 'subsample': 0.6634755481305934, 'alpha': 2.6683951715182603, 'lambda': 0.7944142581307534, 'gamma': 5.693282603641172, 'min_child_weight': 0.29973231223569663}. Best is trial 0 with value: 11.062386406243789.\u001b[0m\n\u001b[32m[I 2022-08-24 23:46:15,413]\u001b[0m Trial 1 finished with value: 11.44074121643136 and parameters: {'n_estimators': 393, 'max_depth': 6, 'learning_rate': 0.19797663812669192, 'colsample_bytree': 0.11882552449869285, 'subsample': 0.8119682019775221, 'alpha': 5.244752216912319, 'lambda': 2.1648838126231453, 'gamma': 9.477597245019747e-05, 'min_child_weight': 3.7260130033624184}. Best is trial 0 with value: 11.062386406243789.\u001b[0m\n\u001b[32m[I 2022-08-24 23:46:24,501]\u001b[0m Trial 2 finished with value: 11.164066982466991 and parameters: {'n_estimators': 339, 'max_depth': 7, 'learning_rate': 0.1029277702376844, 'colsample_bytree': 0.3207126553786152, 'subsample': 0.9398667162234033, 'alpha': 0.30248247079511503, 'lambda': 23.00289303738376, 'gamma': 1.017204410910462e-08, 'min_child_weight': 7.507876755980239}. Best is trial 0 with value: 11.062386406243789.\u001b[0m\n\u001b[32m[I 2022-08-24 23:46:28,973]\u001b[0m Trial 3 finished with value: 10.989214693990188 and parameters: {'n_estimators': 447, 'max_depth': 4, 'learning_rate': 0.034717362285212584, 'colsample_bytree': 0.6531601565343468, 'subsample': 0.6568593725573433, 'alpha': 5.182938492015629, 'lambda': 0.32795824830773934, 'gamma': 0.36437349052910895, 'min_child_weight': 1.8408254933108907}. Best is trial 3 with value: 10.989214693990188.\u001b[0m\n\u001b[32m[I 2022-08-24 23:46:35,814]\u001b[0m Trial 4 finished with value: 10.973245894556 and parameters: {'n_estimators': 176, 'max_depth': 8, 'learning_rate': 0.020528325568515315, 'colsample_bytree': 0.11642969549770152, 'subsample': 0.6761765035712601, 'alpha': 13.35659709755895, 'lambda': 0.4038508131273168, 'gamma': 4.5882527750361885e-09, 'min_child_weight': 1.2796310095320333}. Best is trial 4 with value: 10.973245894556.\u001b[0m\n\u001b[32m[I 2022-08-24 23:46:38,851]\u001b[0m Trial 5 finished with value: 11.126324973141125 and parameters: {'n_estimators': 165, 'max_depth': 5, 'learning_rate': 0.15891150362431866, 'colsample_bytree': 0.9402854791274675, 'subsample': 0.50319620562723, 'alpha': 0.11551302806216171, 'lambda': 45.38942027436872, 'gamma': 1.4664824317356306e-09, 'min_child_weight': 3.8788796251775395}. Best is trial 4 with value: 10.973245894556.\u001b[0m\n\u001b[32m[I 2022-08-24 23:46:48,124]\u001b[0m Trial 6 finished with value: 11.202734737564606 and parameters: {'n_estimators': 408, 'max_depth': 7, 'learning_rate': 0.08255053357977832, 'colsample_bytree': 0.20963145003719982, 'subsample': 0.8225312358896841, 'alpha': 1.5596647721323433, 'lambda': 0.1895528311093236, 'gamma': 0.0003824265605423423, 'min_child_weight': 6.875922500014809}. Best is trial 4 with value: 10.973245894556.\u001b[0m\n\u001b[32m[I 2022-08-24 23:47:09,332]\u001b[0m Trial 7 finished with value: 11.5830895570198 and parameters: {'n_estimators': 250, 'max_depth': 10, 'learning_rate': 0.1883843946073606, 'colsample_bytree': 0.17815567397125381, 'subsample': 0.8358634803987786, 'alpha': 0.8513819610529062, 'lambda': 13.883678404716434, 'gamma': 0.003216256859555338, 'min_child_weight': 2.9153193828360213}. Best is trial 4 with value: 10.973245894556.\u001b[0m\n\u001b[32m[I 2022-08-24 23:47:13,209]\u001b[0m Trial 8 finished with value: 11.22819250952518 and parameters: {'n_estimators': 110, 'max_depth': 7, 'learning_rate': 0.12736479315707006, 'colsample_bytree': 0.8643075020855223, 'subsample': 0.5210148483168676, 'alpha': 14.117438726346005, 'lambda': 1.528237336793322, 'gamma': 2.572616458133714e-05, 'min_child_weight': 6.682236057707328}. Best is trial 4 with value: 10.973245894556.\u001b[0m\n\u001b[32m[I 2022-08-24 23:47:14,971]\u001b[0m Trial 9 finished with value: 11.046135570504992 and parameters: {'n_estimators': 128, 'max_depth': 3, 'learning_rate': 0.19569986265102254, 'colsample_bytree': 0.7151155483059812, 'subsample': 0.5460161411827394, 'alpha': 0.6253205787665131, 'lambda': 0.8170839699244197, 'gamma': 0.641865765800321, 'min_child_weight': 3.663496415393675}. Best is trial 4 with value: 10.973245894556.\u001b[0m\n\u001b[32m[I 2022-08-24 23:47:43,366]\u001b[0m Trial 10 finished with value: 10.974072786096245 and parameters: {'n_estimators': 247, 'max_depth': 10, 'learning_rate': 0.015929751230422784, 'colsample_bytree': 0.496822485460341, 'subsample': 0.7099182284088256, 'alpha': 18.10716712656591, 'lambda': 8.046074102644981, 'gamma': 8.648238928371858e-08, 'min_child_weight': 0.643456278421344}. Best is trial 4 with value: 10.973245894556.\u001b[0m\n\u001b[32m[I 2022-08-24 23:48:10,292]\u001b[0m Trial 11 finished with value: 11.024858936887624 and parameters: {'n_estimators': 245, 'max_depth': 10, 'learning_rate': 0.025760036624993966, 'colsample_bytree': 0.46353268091877864, 'subsample': 0.6932795256915885, 'alpha': 17.171664697319358, 'lambda': 5.164903159829117, 'gamma': 1.799335094878834e-07, 'min_child_weight': 0.7318580224903969}. Best is trial 4 with value: 10.973245894556.\u001b[0m\n\u001b[32m[I 2022-08-24 23:48:29,886]\u001b[0m Trial 12 finished with value: 10.925263094849582 and parameters: {'n_estimators': 251, 'max_depth': 9, 'learning_rate': 0.00552085361772124, 'colsample_bytree': 0.5277864219584348, 'subsample': 0.606405534975936, 'alpha': 7.793587721599955, 'lambda': 97.86225592919749, 'gamma': 3.4178310856885307e-07, 'min_child_weight': 0.6847952631196979}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:48:44,971]\u001b[0m Trial 13 finished with value: 11.071366872285356 and parameters: {'n_estimators': 309, 'max_depth': 8, 'learning_rate': 0.05790568266561477, 'colsample_bytree': 0.6551166422912829, 'subsample': 0.5999045861155966, 'alpha': 5.783930801182024, 'lambda': 135.17169840869036, 'gamma': 1.0655755277151923e-10, 'min_child_weight': 0.10563889247420233}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:48:58,555]\u001b[0m Trial 14 finished with value: 10.952555214335849 and parameters: {'n_estimators': 206, 'max_depth': 9, 'learning_rate': 0.005181909242778493, 'colsample_bytree': 0.3780155092061659, 'subsample': 0.6020386663669977, 'alpha': 9.881475278442279, 'lambda': 0.12065672884277032, 'gamma': 1.8874389603613193e-06, 'min_child_weight': 1.3706010158181707}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:49:13,004]\u001b[0m Trial 15 finished with value: 11.190433612641815 and parameters: {'n_estimators': 218, 'max_depth': 9, 'learning_rate': 0.05624240393804924, 'colsample_bytree': 0.35885891421923627, 'subsample': 0.5991443524808137, 'alpha': 7.281853694099546, 'lambda': 0.12097684555016569, 'gamma': 3.092505539015067e-06, 'min_child_weight': 0.41636911958923484}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:49:37,459]\u001b[0m Trial 16 finished with value: 10.925363935573898 and parameters: {'n_estimators': 316, 'max_depth': 9, 'learning_rate': 0.005026628121418464, 'colsample_bytree': 0.5732186268592774, 'subsample': 0.5839926268682798, 'alpha': 2.8869283106854553, 'lambda': 123.13078157225665, 'gamma': 9.020085753301997e-07, 'min_child_weight': 0.2256852203770825}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:50:02,658]\u001b[0m Trial 17 finished with value: 11.04964802829322 and parameters: {'n_estimators': 346, 'max_depth': 9, 'learning_rate': 0.051524833599381654, 'colsample_bytree': 0.5770571858485716, 'subsample': 0.7532784195211358, 'alpha': 2.936381719741472, 'lambda': 142.5559241871664, 'gamma': 0.00942253514642658, 'min_child_weight': 0.160362809852922}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:50:06,017]\u001b[0m Trial 18 finished with value: 10.982926422837929 and parameters: {'n_estimators': 497, 'max_depth': 2, 'learning_rate': 0.09290151281302225, 'colsample_bytree': 0.7915034263287791, 'subsample': 0.569400238866074, 'alpha': 2.249058903705893, 'lambda': 52.42714237478646, 'gamma': 5.320868932225404e-07, 'min_child_weight': 0.267305101951689}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:50:19,465]\u001b[0m Trial 19 finished with value: 11.015351170122099 and parameters: {'n_estimators': 291, 'max_depth': 8, 'learning_rate': 0.03999216382888072, 'colsample_bytree': 0.558472124311158, 'subsample': 0.6334519457237877, 'alpha': 0.9484226577137972, 'lambda': 67.88543427695745, 'gamma': 1.1599034552469774e-05, 'min_child_weight': 0.43859272821600287}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:50:25,634]\u001b[0m Trial 20 finished with value: 11.070403608035587 and parameters: {'n_estimators': 293, 'max_depth': 6, 'learning_rate': 0.07542409054644725, 'colsample_bytree': 0.4525792165933868, 'subsample': 0.7582279961784995, 'alpha': 3.296167474951026, 'lambda': 23.038287248240103, 'gamma': 1.6279264870809097e-10, 'min_child_weight': 0.19494964442176702}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:50:42,262]\u001b[0m Trial 21 finished with value: 10.933016088248 and parameters: {'n_estimators': 231, 'max_depth': 9, 'learning_rate': 0.009933913452750649, 'colsample_bytree': 0.3871836467771599, 'subsample': 0.601830091341125, 'alpha': 9.121438244125601, 'lambda': 78.4685229920589, 'gamma': 6.232530208552029e-07, 'min_child_weight': 1.082314690130947}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:51:06,849]\u001b[0m Trial 22 finished with value: 10.93865781014932 and parameters: {'n_estimators': 337, 'max_depth': 9, 'learning_rate': 0.00863427463073885, 'colsample_bytree': 0.6151823808638355, 'subsample': 0.5601078181161937, 'alpha': 7.273882349889873, 'lambda': 81.4407789478309, 'gamma': 3.514595742584603e-08, 'min_child_weight': 0.7494280584158078}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:51:19,256]\u001b[0m Trial 23 finished with value: 10.989573134415375 and parameters: {'n_estimators': 273, 'max_depth': 8, 'learning_rate': 0.03088100734723205, 'colsample_bytree': 0.424532084190983, 'subsample': 0.6193536137398931, 'alpha': 4.0339934256955265, 'lambda': 34.10772470883929, 'gamma': 2.114939749620546e-06, 'min_child_weight': 0.49723493686728004}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:51:55,247]\u001b[0m Trial 24 finished with value: 10.93724610283652 and parameters: {'n_estimators': 374, 'max_depth': 10, 'learning_rate': 0.007328476849369726, 'colsample_bytree': 0.25546577918309415, 'subsample': 0.5660737931512129, 'alpha': 1.8652626695872632, 'lambda': 79.14953354739538, 'gamma': 3.8487669035582996e-07, 'min_child_weight': 1.0006842635043018}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:52:10,040]\u001b[0m Trial 25 finished with value: 11.011996571232165 and parameters: {'n_estimators': 219, 'max_depth': 9, 'learning_rate': 0.04947907505246718, 'colsample_bytree': 0.5216780306280628, 'subsample': 0.7364275082951831, 'alpha': 11.371328155702892, 'lambda': 141.11793478660755, 'gamma': 0.000441896878042717, 'min_child_weight': 2.086770123220891}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:52:16,351]\u001b[0m Trial 26 finished with value: 10.971884227184114 and parameters: {'n_estimators': 315, 'max_depth': 6, 'learning_rate': 0.024608645444665705, 'colsample_bytree': 0.7068233502602064, 'subsample': 0.6402156760864295, 'alpha': 7.787791143393851, 'lambda': 13.108668180075352, 'gamma': 3.0373576519558616e-08, 'min_child_weight': 0.10461022381585879}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:52:23,410]\u001b[0m Trial 27 finished with value: 11.046435374062881 and parameters: {'n_estimators': 142, 'max_depth': 8, 'learning_rate': 0.0729351887820138, 'colsample_bytree': 0.40623747901108354, 'subsample': 0.5887770574486768, 'alpha': 4.3344153600419935, 'lambda': 36.795246375956474, 'gamma': 1.9419488038982867e-09, 'min_child_weight': 0.27215788285901427}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:52:31,006]\u001b[0m Trial 28 finished with value: 11.02547813257253 and parameters: {'n_estimators': 248, 'max_depth': 7, 'learning_rate': 0.042666840701858916, 'colsample_bytree': 0.5294544831146515, 'subsample': 0.5087057196855165, 'alpha': 1.3199181312947676, 'lambda': 18.584298597656883, 'gamma': 1.0248568919017471e-05, 'min_child_weight': 1.0228676068797926}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n\u001b[32m[I 2022-08-24 23:52:52,263]\u001b[0m Trial 29 finished with value: 11.19234575600992 and parameters: {'n_estimators': 197, 'max_depth': 10, 'learning_rate': 0.11947787303540991, 'colsample_bytree': 0.3006210185058399, 'subsample': 0.656178460584002, 'alpha': 2.801802477792336, 'lambda': 109.35979379502778, 'gamma': 0.0001104795137541801, 'min_child_weight': 0.17498184611861095}. Best is trial 12 with value: 10.925263094849582.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  405.7701807022095\n        n_estimators : 251\n           max_depth : 9\n       learning_rate : 0.00552085361772124\n    colsample_bytree : 0.5277864219584348\n           subsample : 0.606405534975936\n               alpha : 7.793587721599955\n              lambda : 97.86225592919749\n               gamma : 3.4178310856885307e-07\n    min_child_weight : 0.6847952631196979\nbest objective value : 10.925263094849582\nOptuna XGB train: 10.781206984149076 0.04133710910132482 418.38148379325867\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate performance of XGB models:\n\nprint('XGB test:', mean_absolute_error(y_test, xgb1.predict(X_test)), r2_score(y_test, xgb1.predict(X_test)))\nprint('XGB GS test:', mean_absolute_error(y_test, xgbm.predict(X_test)), r2_score(y_test, xgbm.predict(X_test)))\nprint('Optuna XGB test:', mean_absolute_error(y_test, optuna_xgb.predict(X_test)), r2_score(y_test, optuna_xgb.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2022-08-24T23:53:48.197991Z","iopub.execute_input":"2022-08-24T23:53:48.198355Z","iopub.status.idle":"2022-08-24T23:53:48.324900Z","shell.execute_reply.started":"2022-08-24T23:53:48.198323Z","shell.execute_reply":"2022-08-24T23:53:48.324158Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stdout","text":"XGB test: 10.233213915191632 -0.003467503699573271\nXGB GS test: 10.163871457977189 0.027802299459069535\nOptuna XGB test: 10.207752342040264 0.006956006121909386\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_size = 0.1\n# df.reset_index(inplace=True, drop=True)\n# #random.seed(2)\n# test_index = random.sample(list(df.index), int(test_size*df.shape[0]))\n# train = df.iloc[list(set(df.index)-set(test_index))]\n# test = df.iloc[test_index]\n# train.reset_index(drop=True, inplace=True)\n# test.reset_index(drop=True, inplace=True)\n# display(train.shape, test.shape, train.head(3), test.head(3))","metadata":{"execution":{"iopub.status.busy":"2022-08-24T22:10:56.715852Z","iopub.status.idle":"2022-08-24T22:10:56.716304Z","shell.execute_reply.started":"2022-08-24T22:10:56.716076Z","shell.execute_reply":"2022-08-24T22:10:56.716096Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This is a new version of MLEAP scripts, started in late Aug 2022.\nIt will combine IProject_MLEAP_ANN and IP_MLEAP script, while improving them.","metadata":{}},{"cell_type":"markdown","source":"#### Outline\n\n1. Load libraries and data.\n2. pEDA. Look at feature distribution, fix them if they do not look right.\n3. Train-test split. Most likely couple years into test set. 2015-2018?. Impute missing values.\n4. Transform numerical features, add ohe for inds.\n5. Fit xgb as a baseline, then xgb optuna.\n6. Fit DL.\n\n","metadata":{}},{"cell_type":"code","source":"# 0. Import libraries #\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport os, time, math, re, warnings, random, gc, dill, optuna, pickle, shap\nimport statsmodels.api as sm\nfrom random import sample\n\nfrom sklearn.model_selection import train_test_split, KFold, PredefinedSplit\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNetCV\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn.inspection import permutation_importance\nfrom category_encoders import MEstimateEncoder\nfrom xgboost import XGBRegressor\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import regularizers\n\nplt.style.use('seaborn-white')\nwarnings.simplefilter(action='ignore')\npd.set_option('display.max_columns', 110)\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T02:31:53.557901Z","iopub.execute_input":"2022-09-07T02:31:53.558292Z","iopub.status.idle":"2022-09-07T02:32:04.847555Z","shell.execute_reply.started":"2022-09-07T02:31:53.558200Z","shell.execute_reply":"2022-09-07T02:32:04.846574Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"### target encoding ###\n# source: https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices/notebook\n\nclass CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=4)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded","metadata":{"execution":{"iopub.status.busy":"2022-09-07T02:32:04.850377Z","iopub.execute_input":"2022-09-07T02:32:04.851310Z","iopub.status.idle":"2022-09-07T02:32:04.862409Z","shell.execute_reply.started":"2022-09-07T02:32:04.851270Z","shell.execute_reply":"2022-09-07T02:32:04.861435Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T02:32:04.863651Z","iopub.execute_input":"2022-09-07T02:32:04.864828Z","iopub.status.idle":"2022-09-07T02:32:04.891893Z","shell.execute_reply.started":"2022-09-07T02:32:04.864776Z","shell.execute_reply":"2022-09-07T02:32:04.890763Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"REPLICAS:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"#min_prd_list = range(100, 676, 25)\nmin_prd_list = [250]\n# min_prd_list = [150, 250, 350, 450, 550, 650]\n#min_prd = min_prd_list[0]\nwindows_width = 3*12\ncv_regularizer=0.2\noptuna_trials = 20\ntime0 = time.time()\n\nresults = pd.DataFrame(columns = ['min_prd', 'xgbf_train', 'xgbf_val', 'xgbf_test', \n                                  'xgbgs_train', 'xgbgs_val', 'xgbgs_test', \n                                  'xgbo_train', 'xgbo_val', 'xgbo_test'])\nresults.min_prd = min_prd_list\n\nfor min_prd in min_prd_list:\n\n    with open('../input/mleap-46-preprocessed/MLEAP_46_v7.pkl', 'rb') as pickled_one:\n        df = pickle.load(pickled_one)\n    df = df[df.prd.isin(range(min_prd-1, min_prd+windows_width+10))]\n    df_cnt = df.count()\n    empty_cols = list(df_cnt[df_cnt<int(df.shape[0]/2)].index)\n    df.drop(columns=empty_cols, inplace=True)\n    #display(df.shape, df.head(), df.year.describe(), df.count())\n\n    features_miss_dummies = ['amhd', 'BAspr']\n    for col in features_miss_dummies:\n        if col in df.columns:\n            df[col+'_miss'] = df[col].isnull().astype(int)\n\n    temp_cols = ['PERMNO', 'year', 'prd']\n    df.reset_index(inplace=True, drop=True)\n    X = df.copy()\n    y = X.pop('RET')\n\n    train_indx = X.prd<(min_prd+windows_width-1)\n    val_indx = X['prd'].isin(range(min_prd+windows_width-1, min_prd+windows_width+2))\n    val_indx_extra = X['prd'].isin(range(min_prd+windows_width+5, min_prd+windows_width+8))\n    test_indx = X['prd'].isin(range(min_prd+windows_width+2, min_prd+windows_width+5))\n\n    X_train = X[train_indx]\n    X_val = X[val_indx]\n    X_val_extra = X[val_indx_extra]\n    X_test = X[test_indx]\n    y_train = y[train_indx]\n    y_val = y[val_indx]\n    y_val_extra = y[val_indx_extra]\n    y_test = y[test_indx]\n\n    #display(X_train.head(3), X_train.tail(3), y_train.head(3), y_train.tail(3))\n    display(X_train.shape, X_val.shape, X_test.shape, X_train.prd.describe(), X_val.prd.describe(), X_test.prd.describe())\n\n    X_train.drop(columns=temp_cols, inplace=True)\n    X_val.drop(columns=temp_cols, inplace=True)\n    X_val_extra.drop(columns=temp_cols, inplace=True)\n    X_test.drop(columns=temp_cols, inplace=True)\n\n    #display(X_train.tail())\n    col_cat = ['ind']\n    col_num = [x for x in X_train.columns if x not in col_cat]\n    for col in col_num:\n        X_train[col] = X_train[col].fillna(X_train[col].median())\n        X_val[col] = X_val[col].fillna(X_train[col].median())\n        X_val_extra[col] = X_val_extra[col].fillna(X_train[col].median())\n        X_test[col] = X_test[col].fillna(X_train[col].median())\n    for col in col_cat:\n        X_train[col] = X_train[col].fillna(value=-1000)\n        X_val[col] = X_val[col].fillna(value=-1000)\n        X_val_extra[col] = X_val_extra[col].fillna(value=-1000)\n        X_test[col] = X_test[col].fillna(value=-1000)\n\n    #display(X_train.tail())\n    feature_transformer = ColumnTransformer([('num', StandardScaler(), col_num),\n                                            (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\", drop='if_binary'), col_cat)], \n                                            remainder=\"passthrough\")\n\n    print('Number of features before transformation: ', X_train.shape)\n    train_index, val_index, val_index_extra, test_index = X_train.index, X_val.index, X_val_extra.index, X_test.index\n    X_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\n    X_val = pd.DataFrame(feature_transformer.transform(X_val), columns=feature_transformer.get_feature_names_out())\n    X_val_extra = pd.DataFrame(feature_transformer.transform(X_val_extra), columns=feature_transformer.get_feature_names_out())\n    X_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\n    print('time to do feature proprocessing: ')\n    print('Number of features after transformation: ', X_train.shape, X_val.shape, X_val_extra.shape, X_test.shape)\n    X_train.index = train_index\n    X_val.index = val_index\n    X_val_extra.index = val_index_extra\n    X_test.index = test_index\n    #display(X_train.tail())\n\n    X = pd.concat([X_train, X_val])\n    y = pd.concat([y_train, y_val])\n    #display(X,y)\n\n    X_ = pd.concat([X_train, X_val, X_val_extra])\n    y_ = pd.concat([y_train, y_val, y_val_extra])\n    #display(X,y, X_,y_)\n\n    print('mae of a constant model', mean_absolute_error(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\n    print('R2 of a constant model', r2_score(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\n\n    xgb1 = XGBRegressor(tree_method = 'gpu_hist', n_estimators=400, max_depth=4, eta=0.02, colsample_bytree=0.4, subsample=0.6)\n    xgb1.fit(X_train, y_train)\n    print('fixed XGB train:', mean_absolute_error(y_train, xgb1.predict(X_train)), r2_score(y_train, xgb1.predict(X_train)))\n    print('XGB val:', mean_absolute_error(y_val, xgb1.predict(X_val)), r2_score(y_val, xgb1.predict(X_val)))\n    print('XGB val extra:', mean_absolute_error(y_val_extra, xgb1.predict(X_val_extra)), r2_score(y_val_extra, xgb1.predict(X_val_extra)))\n    print('XGB test:', mean_absolute_error(y_test, xgb1.predict(X_test)), r2_score(y_test, xgb1.predict(X_test)))\n\n    results.loc[results.min_prd==min_prd,'xgbf_train':'xgbf_test'] = \\\n    [r2_score(y_train, xgb1.predict(X_train)), \n    r2_score(y_val, xgb1.predict(X_val)),\n    r2_score(y_test, xgb1.predict(X_test))]\n\n    time1 = time.time()\n\n    # Create a list where train data indices are -1 and validation data indices are 0\n    split_index = [-1 if x in X_train.index else 0 for x in X.index]\n    pds = PredefinedSplit(test_fold = split_index)\n\n    xgb = XGBRegressor(tree_method = 'gpu_hist')\n    param_grid = {'n_estimators':[400, 600, 800], 'max_depth':[2,3,4,5], 'eta':[0.006, 0.012, 0.02], \n                  'subsample':[0.6], 'colsample_bytree':[0.6]}\n    xgbgs = GridSearchCV(estimator = xgb, cv=pds, param_grid=param_grid)\n\n    # Fit with all data\n    xgbgs.fit(X_, y_)\n\n    print('gs XGB', xgbgs.best_params_, xgbgs.best_score_, time.time()-time1)\n    print('XGB train:', mean_absolute_error(y_train, xgbgs.predict(X_train)), r2_score(y_train, xgbgs.predict(X_train)))\n    print('XGB validation:', mean_absolute_error(y_val, xgbgs.predict(X_val)), r2_score(y_val, xgbgs.predict(X_val)))\n    print('XGB validation extra:', mean_absolute_error(y_val_extra, xgbgs.predict(X_val_extra)), r2_score(y_val_extra, xgbgs.predict(X_val_extra)))\n    print('XGB test:', mean_absolute_error(y_test, xgbgs.predict(X_test)), r2_score(y_test, xgbgs.predict(X_test)))\n\n    results.loc[results.min_prd==min_prd,'xgbgs_train':'xgbgs_test'] = \\\n    [r2_score(y_train, xgbgs.predict(X_train)), \n    r2_score(y_val, xgbgs.predict(X_val)),\n    r2_score(y_test, xgbgs.predict(X_test))]\n\n    time1 = time.time()\n    def objective(trial, cv_runs=1, n_splits=2, n_jobs=-1):\n\n        params = {\n        \"tree_method\": 'gpu_hist',\n        \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 800, 1500),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 6),\n        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.0005, 0.03),\n        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.05, 0.95),\n        \"subsample\": trial.suggest_uniform(\"subsample\", 0.1, 0.95),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 0.1, 50.0),\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 0.1, 500.0),\n        \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-10, 100.0),\n        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 0.1, 50)    }\n\n        model = XGBRegressor(**params, njobs=-1)\n        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose = False)\n\n        score_train = r2_score(y_train, model.predict(X_train))\n        score_val = r2_score(y_val, model.predict(X_val))\n        score_val_extra = r2_score(y_val_extra, model.predict(X_val_extra)) \n        score_val = (score_val+score_val_extra)/2\n        overfit = np.abs(score_train-score_val)\n\n        return score_val-cv_regularizer*overfit\n\n\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=optuna_trials)\n    print('Total time for hypermarameter optimization ', time.time()-time1)\n    hp = study.best_params\n    for key, value in hp.items():\n        print(f\"{key:>20s} : {value}\")\n    print(f\"{'best objective value':>20s} : {study.best_value}\")\n    optuna_hyperpars = study.best_params\n    optuna_hyperpars['tree_method']='gpu_hist'\n    optuna_xgb = XGBRegressor(**optuna_hyperpars)\n    optuna_xgb.fit(X, y)\n    print('Optuna XGB train: \\n', \n          mean_absolute_error(y_train, optuna_xgb.predict(X_train)), r2_score(y_train, optuna_xgb.predict(X_train)), '\\nvalidation \\n',\n          mean_absolute_error(y_val, optuna_xgb.predict(X_val)), r2_score(y_val, optuna_xgb.predict(X_val)),\n          mean_absolute_error(y_val_extra, optuna_xgb.predict(X_val_extra)), r2_score(y_val_extra, optuna_xgb.predict(X_val_extra)), '\\ntest \\n',\n          mean_absolute_error(y_test, optuna_xgb.predict(X_test)), r2_score(y_test, optuna_xgb.predict(X_test)))\n\n    results.loc[results.min_prd==min_prd,'xgbo_train':'xgbo_test'] = \\\n    [r2_score(y_train, optuna_xgb.predict(X_train)), \n    r2_score(y_val, optuna_xgb.predict(X_val)),\n    r2_score(y_test, optuna_xgb.predict(X_test))]\n\n    display(results)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T02:32:04.894830Z","iopub.execute_input":"2022-09-07T02:32:04.895597Z","iopub.status.idle":"2022-09-07T02:33:41.644648Z","shell.execute_reply.started":"2022-09-07T02:32:04.895559Z","shell.execute_reply":"2022-09-07T02:33:41.643186Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"(79162, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(6405, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(6311, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    79162.000000\nmean       266.337409\nstd         10.396123\nmin        249.000000\n25%        257.000000\n50%        266.000000\n75%        275.000000\nmax        284.000000\nName: prd, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    6405.000000\nmean      285.996565\nstd         0.816362\nmin       285.000000\n25%       285.000000\n50%       286.000000\n75%       287.000000\nmax       287.000000\nName: prd, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    6311.000000\nmean      288.997782\nstd         0.816235\nmin       288.000000\n25%       288.000000\n50%       289.000000\n75%       290.000000\nmax       290.000000\nName: prd, dtype: float64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (79162, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (79162, 85) (6405, 85) (6616, 85) (6311, 85)\nmae of a constant model 8.616058689352922\nR2 of a constant model 0.0\nfixed XGB train: 8.094503280537975 0.08807399835850738\nXGB val: 7.80268307196985 -0.012211276662149384\nXGB val extra: 9.182509786895938 0.006809524790626353\nXGB test: 7.84572645024662 0.015254350212336232\ngs XGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 5, 'n_estimators': 400, 'subsample': 0.6} -0.009211110247068666 59.40769338607788\nXGB train: 8.232025093474888 0.060695330008433745\nXGB validation: 7.630334731974988 0.032497740585895496\nXGB validation extra: 8.985427732621966 0.05388213675932696\nXGB test: 7.787969462570123 0.02523901836111997\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-07 02:33:17,156]\u001b[0m A new study created in memory with name: no-name-3732eb95-c29e-4ce2-a02b-96858ba1b8d7\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:17,740]\u001b[0m Trial 0 finished with value: -0.001119068575314297 and parameters: {'n_estimators': 946, 'max_depth': 4, 'learning_rate': 0.004270647975075681, 'colsample_bytree': 0.6163791546863153, 'subsample': 0.574202364666656, 'alpha': 4.3498692682390425, 'lambda': 0.15207716995804282, 'gamma': 2.372842449462998e-07, 'min_child_weight': 0.14854688140239278}. Best is trial 0 with value: -0.001119068575314297.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:18,290]\u001b[0m Trial 1 finished with value: -0.0016043740162963172 and parameters: {'n_estimators': 1333, 'max_depth': 3, 'learning_rate': 0.01062279426169428, 'colsample_bytree': 0.4086710357227423, 'subsample': 0.37405346674224105, 'alpha': 28.546233391787986, 'lambda': 2.943425900543851, 'gamma': 0.0036690115941419355, 'min_child_weight': 47.36955443624111}. Best is trial 0 with value: -0.001119068575314297.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:19,049]\u001b[0m Trial 2 finished with value: -0.0017731057366582761 and parameters: {'n_estimators': 1118, 'max_depth': 6, 'learning_rate': 0.028262927267924363, 'colsample_bytree': 0.6062148545655791, 'subsample': 0.6030445808427972, 'alpha': 0.2930038667783317, 'lambda': 1.6436291764363586, 'gamma': 2.548657349998704e-09, 'min_child_weight': 1.0862717440453653}. Best is trial 0 with value: -0.001119068575314297.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:19,707]\u001b[0m Trial 3 finished with value: -0.0012829968595970075 and parameters: {'n_estimators': 819, 'max_depth': 6, 'learning_rate': 0.028462071909013415, 'colsample_bytree': 0.3086268042275314, 'subsample': 0.7956049237492719, 'alpha': 2.2296723346568488, 'lambda': 91.9156463183039, 'gamma': 0.010339307693969877, 'min_child_weight': 13.767303167099444}. Best is trial 0 with value: -0.001119068575314297.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:20,217]\u001b[0m Trial 4 finished with value: -0.0009169109550575261 and parameters: {'n_estimators': 1272, 'max_depth': 3, 'learning_rate': 0.015168509164955796, 'colsample_bytree': 0.5332043958091185, 'subsample': 0.3856618070427189, 'alpha': 6.200719153287914, 'lambda': 481.16866686817184, 'gamma': 0.00036265027818039545, 'min_child_weight': 0.4969087719576753}. Best is trial 4 with value: -0.0009169109550575261.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:20,965]\u001b[0m Trial 5 finished with value: -0.0008097229695911423 and parameters: {'n_estimators': 1133, 'max_depth': 6, 'learning_rate': 0.006978643929062089, 'colsample_bytree': 0.13641271201242955, 'subsample': 0.7273891500722367, 'alpha': 0.3449907406500165, 'lambda': 25.23688830620339, 'gamma': 4.0811542362219273e-10, 'min_child_weight': 11.441490668331722}. Best is trial 5 with value: -0.0008097229695911423.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:21,524]\u001b[0m Trial 6 finished with value: -0.0013160968131768814 and parameters: {'n_estimators': 1120, 'max_depth': 4, 'learning_rate': 0.02685371313582397, 'colsample_bytree': 0.674841545925431, 'subsample': 0.7463460333337103, 'alpha': 13.705738864127609, 'lambda': 0.13594275548392648, 'gamma': 4.3238417896384914e-07, 'min_child_weight': 0.7116619174750384}. Best is trial 5 with value: -0.0008097229695911423.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:22,224]\u001b[0m Trial 7 finished with value: 0.0006201266937303717 and parameters: {'n_estimators': 1411, 'max_depth': 5, 'learning_rate': 0.014647165905299181, 'colsample_bytree': 0.057462860132831084, 'subsample': 0.30426114391631986, 'alpha': 1.772894243535911, 'lambda': 0.30584675783775894, 'gamma': 4.411392902694554, 'min_child_weight': 0.31429379582155054}. Best is trial 7 with value: 0.0006201266937303717.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:22,975]\u001b[0m Trial 8 finished with value: -0.0008852817365083254 and parameters: {'n_estimators': 916, 'max_depth': 6, 'learning_rate': 0.0017046110330745227, 'colsample_bytree': 0.09608973444202228, 'subsample': 0.45912219679324506, 'alpha': 5.715589672769808, 'lambda': 116.38415370033334, 'gamma': 2.9412331087476214e-08, 'min_child_weight': 0.5123222607666927}. Best is trial 7 with value: 0.0006201266937303717.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:23,491]\u001b[0m Trial 9 finished with value: -0.0009454305298944643 and parameters: {'n_estimators': 1120, 'max_depth': 3, 'learning_rate': 0.00813921779540169, 'colsample_bytree': 0.7438193788801971, 'subsample': 0.6799806406475699, 'alpha': 0.614575773782107, 'lambda': 0.16155918389162244, 'gamma': 6.923044847023939e-05, 'min_child_weight': 15.344358092835122}. Best is trial 7 with value: 0.0006201266937303717.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:24,154]\u001b[0m Trial 10 finished with value: -0.0010434467008192617 and parameters: {'n_estimators': 1441, 'max_depth': 5, 'learning_rate': 0.02137212678430004, 'colsample_bytree': 0.9090008915574106, 'subsample': 0.12597597136784328, 'alpha': 1.1723901380487167, 'lambda': 0.8080147811857381, 'gamma': 21.347886996976683, 'min_child_weight': 0.11166771238809642}. Best is trial 7 with value: 0.0006201266937303717.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:24,829]\u001b[0m Trial 11 finished with value: -0.0004986983783830557 and parameters: {'n_estimators': 1499, 'max_depth': 5, 'learning_rate': 0.014435102206236252, 'colsample_bytree': 0.10752225780135784, 'subsample': 0.9200676446266711, 'alpha': 0.1537281666569163, 'lambda': 17.793479475256138, 'gamma': 91.03468584836857, 'min_child_weight': 3.7932011705636186}. Best is trial 7 with value: 0.0006201266937303717.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:25,450]\u001b[0m Trial 12 finished with value: -0.0011518394028181334 and parameters: {'n_estimators': 1499, 'max_depth': 5, 'learning_rate': 0.015852800804362337, 'colsample_bytree': 0.2566920940840829, 'subsample': 0.9498808644211642, 'alpha': 0.1211583937294239, 'lambda': 13.352092932237452, 'gamma': 17.125568557784245, 'min_child_weight': 3.092241373191275}. Best is trial 7 with value: 0.0006201266937303717.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:26,144]\u001b[0m Trial 13 finished with value: 0.0005016426242239413 and parameters: {'n_estimators': 1352, 'max_depth': 5, 'learning_rate': 0.01539754839805526, 'colsample_bytree': 0.07899535785435025, 'subsample': 0.1987172732705007, 'alpha': 0.10165915409085406, 'lambda': 6.64739765946902, 'gamma': 0.42696932387201547, 'min_child_weight': 3.7972896428274567}. Best is trial 7 with value: 0.0006201266937303717.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:26,658]\u001b[0m Trial 14 finished with value: -0.0016032496588717748 and parameters: {'n_estimators': 1311, 'max_depth': 2, 'learning_rate': 0.020647285688279473, 'colsample_bytree': 0.26140682194573983, 'subsample': 0.16937980624568555, 'alpha': 1.3881745689521794, 'lambda': 0.8321296762583712, 'gamma': 0.22649939664601826, 'min_child_weight': 1.7335149739196138}. Best is trial 7 with value: 0.0006201266937303717.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:27,462]\u001b[0m Trial 15 finished with value: 0.000947819412687667 and parameters: {'n_estimators': 1375, 'max_depth': 5, 'learning_rate': 0.019929726651437517, 'colsample_bytree': 0.05842683976026282, 'subsample': 0.2662374015625422, 'alpha': 39.63379490082687, 'lambda': 4.571720279106687, 'gamma': 0.27247228706551796, 'min_child_weight': 0.24566537497095056}. Best is trial 15 with value: 0.000947819412687667.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:28,174]\u001b[0m Trial 16 finished with value: -0.0012256723883772747 and parameters: {'n_estimators': 1218, 'max_depth': 4, 'learning_rate': 0.02088997049599107, 'colsample_bytree': 0.4063470764291696, 'subsample': 0.30355375436303406, 'alpha': 49.77243784800117, 'lambda': 0.45102464275972726, 'gamma': 0.5263156082213689, 'min_child_weight': 0.23326785722373383}. Best is trial 15 with value: 0.000947819412687667.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:29,038]\u001b[0m Trial 17 finished with value: -0.001458295143313393 and parameters: {'n_estimators': 1400, 'max_depth': 5, 'learning_rate': 0.02406541207421918, 'colsample_bytree': 0.1799231406470502, 'subsample': 0.29755982422345956, 'alpha': 12.909790507182235, 'lambda': 4.176492584224309, 'gamma': 2.7117614919361915e-05, 'min_child_weight': 0.28607494295315594}. Best is trial 15 with value: 0.000947819412687667.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:29,822]\u001b[0m Trial 18 finished with value: -0.0014674390350787993 and parameters: {'n_estimators': 1235, 'max_depth': 5, 'learning_rate': 0.011584320178090628, 'colsample_bytree': 0.36714723589106674, 'subsample': 0.25561542608628995, 'alpha': 2.6214892025359147, 'lambda': 0.5742438155181324, 'gamma': 0.01702674764950723, 'min_child_weight': 0.3535029183295885}. Best is trial 15 with value: 0.000947819412687667.\u001b[0m\n\u001b[32m[I 2022-09-07 02:33:30,418]\u001b[0m Trial 19 finished with value: -0.0014464829491863229 and parameters: {'n_estimators': 1411, 'max_depth': 4, 'learning_rate': 0.018720087024627657, 'colsample_bytree': 0.17744495173930563, 'subsample': 0.42043420833310313, 'alpha': 13.94520059432203, 'lambda': 50.2510996619496, 'gamma': 2.159444771236366, 'min_child_weight': 1.2924577850312116}. Best is trial 15 with value: 0.000947819412687667.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  13.263981342315674\n        n_estimators : 1375\n           max_depth : 5\n       learning_rate : 0.019929726651437517\n    colsample_bytree : 0.05842683976026282\n           subsample : 0.2662374015625422\n               alpha : 39.63379490082687\n              lambda : 4.571720279106687\n               gamma : 0.27247228706551796\n    min_child_weight : 0.24566537497095056\nbest objective value : 0.000947819412687667\nOptuna XGB train: \n 8.03335723304702 0.10330175875875336 \nvalidation \n 7.570765320947045 0.055830841808726106 9.127238669701311 0.01814320028108385 \ntest \n 7.772181060341148 0.03166602260905438\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   min_prd xgbf_train  xgbf_val xgbf_test xgbgs_train xgbgs_val xgbgs_test  \\\n0      250   0.088074 -0.012211  0.015254    0.060695  0.032498   0.025239   \n\n  xgbo_train  xgbo_val xgbo_test  \n0   0.103302  0.055831  0.031666  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>min_prd</th>\n      <th>xgbf_train</th>\n      <th>xgbf_val</th>\n      <th>xgbf_test</th>\n      <th>xgbgs_train</th>\n      <th>xgbgs_val</th>\n      <th>xgbgs_test</th>\n      <th>xgbo_train</th>\n      <th>xgbo_val</th>\n      <th>xgbo_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>250</td>\n      <td>0.088074</td>\n      <td>-0.012211</td>\n      <td>0.015254</td>\n      <td>0.060695</td>\n      <td>0.032498</td>\n      <td>0.025239</td>\n      <td>0.103302</td>\n      <td>0.055831</td>\n      <td>0.031666</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"display(results.iloc[:,1:].mean())\n# cv_regularizer = 0.5\n# optuna_trials = 80\nprint(time.time()-time0)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:44.706000Z","iopub.execute_input":"2022-09-07T01:00:44.706645Z","iopub.status.idle":"2022-09-07T01:00:44.720757Z","shell.execute_reply.started":"2022-09-07T01:00:44.706606Z","shell.execute_reply":"2022-09-07T01:00:44.719629Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"xgbf_train     0.087900\nxgbf_val       0.070671\nxgbf_test      0.034123\nxgbgs_train    0.076466\nxgbgs_val      0.159127\nxgbgs_test     0.036790\nxgbo_train     0.080860\nxgbo_val       0.153196\nxgbo_test      0.029946\ndtype: float64"},"metadata":{}},{"name":"stdout","text":"237.29979705810547\n","output_type":"stream"}]},{"cell_type":"code","source":"# general point:\n# compared to NN, xgb is harder to regularize\n# in NN, you can simply shrink coefficient towards constant prediction.\n# in xgb, you can not do that. the only way to regularize is via hyperparameters.\n# in other words, by tweaking hyperpars, in NN you can approach R^2=0.0 prediction from a constant model arbitrarily close\n# in xgb, you can not do that.\n# by setting eta as low as 0.1% you can bring r2 down to 0.1%, but lowering eta further actyally increases abs(r2).\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:44.722180Z","iopub.execute_input":"2022-09-07T01:00:44.722899Z","iopub.status.idle":"2022-09-07T01:00:44.732572Z","shell.execute_reply.started":"2022-09-07T01:00:44.722861Z","shell.execute_reply":"2022-09-07T01:00:44.731486Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"optuna_xgb","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:44.734056Z","iopub.execute_input":"2022-09-07T01:00:44.735151Z","iopub.status.idle":"2022-09-07T01:00:44.752332Z","shell.execute_reply.started":"2022-09-07T01:00:44.735109Z","shell.execute_reply":"2022-09-07T01:00:44.749700Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(alpha=0.1415753949568421, base_score=0.5, booster='gbtree',\n             callbacks=None, colsample_bylevel=1, colsample_bynode=1,\n             colsample_bytree=0.41611119613442266, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None,\n             gamma=8.57776528027647e-09, gpu_id=0, grow_policy='depthwise',\n             importance_type=None, interaction_constraints='',\n             lambda=8.888077381572515, learning_rate=0.019754948141593447,\n             max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=3,\n             max_leaves=0, min_child_weight=1.7911947788279619, missing=nan,\n             monotone_constraints='()', n_estimators=1477, n_jobs=0,\n             num_parallel_tree=1, predictor='auto', random_state=0, ...)"},"metadata":{}}]},{"cell_type":"code","source":"explainerxgbc = shap.TreeExplainer(optuna_xgb)\nshap_values_XGBoost_test = explainerxgbc.shap_values(X_test)\n\nvals = np.abs(shap_values_XGBoost_test).mean(0)\nfeature_names = X_test.columns\nfeature_importance = pd.DataFrame(list(zip(feature_names, vals)),\n                                 columns=['col_name','feature_importance_vals'])\nfeature_importance.sort_values(by=['feature_importance_vals'],\n                              ascending=False, inplace=True)\n\nshap.summary_plot(shap_values_XGBoost_test, X_test, \n                  plot_type=\"bar\", plot_size=(6,6), max_display=20)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T02:33:56.871506Z","iopub.execute_input":"2022-09-07T02:33:56.871854Z","iopub.status.idle":"2022-09-07T02:33:58.739676Z","shell.execute_reply.started":"2022-09-07T02:33:56.871825Z","shell.execute_reply":"2022-09-07T02:33:58.738662Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x432 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate performance of XGB models:\nr2_xgb1 = r2_score(y_test, xgb1.predict(X_test))\nr2_xgbgs = r2_score(y_test, xgbgs.predict(X_test))\nr2_xgbo = r2_score(y_test, optuna_xgb.predict(X_test))\n\nprint('Min_prd: ', min_prd)\nprint('Constant guess: ', mean_absolute_error(y_test, np.ones(len(y_test))*y_test.mean()), \n      r2_score(y_test, np.ones(len(y_test))*y_test.mean()))\nprint('XGB test:', mean_absolute_error(y_test, xgb1.predict(X_test)), r2_xgb1)\nprint('XGB GS test:', mean_absolute_error(y_test, xgbgs.predict(X_test)), r2_xgbgs)\nprint('Optuna XGB test:', mean_absolute_error(y_test, optuna_xgb.predict(X_test)), r2_xgbo)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:45.734083Z","iopub.execute_input":"2022-09-07T01:00:45.735110Z","iopub.status.idle":"2022-09-07T01:00:45.995382Z","shell.execute_reply.started":"2022-09-07T01:00:45.735071Z","shell.execute_reply":"2022-09-07T01:00:45.993473Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Min_prd:  650\nConstant guess:  8.70343870957194 0.0\nXGB test: 8.464771770272549 0.04196543276367293\nXGB GS test: 8.439680663549156 0.040450396213600026\nOptuna XGB test: 8.452829179435007 0.037441996330436655\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total time for a script: ', time.time()-time0)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:45.999930Z","iopub.execute_input":"2022-09-07T01:00:46.000463Z","iopub.status.idle":"2022-09-07T01:00:46.007960Z","shell.execute_reply.started":"2022-09-07T01:00:46.000415Z","shell.execute_reply":"2022-09-07T01:00:46.005868Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Total time for a script:  238.5843210220337\n","output_type":"stream"}]},{"cell_type":"code","source":"results.iloc[:,1:].mean()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:46.009902Z","iopub.execute_input":"2022-09-07T01:00:46.010796Z","iopub.status.idle":"2022-09-07T01:00:46.026075Z","shell.execute_reply.started":"2022-09-07T01:00:46.010740Z","shell.execute_reply":"2022-09-07T01:00:46.024960Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"xgbf_train     0.087900\nxgbf_val       0.070671\nxgbf_test      0.034123\nxgbgs_train    0.076466\nxgbgs_val      0.159127\nxgbgs_test     0.036790\nxgbo_train     0.080860\nxgbo_val       0.153196\nxgbo_test      0.029946\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# 3yr window, trials=20, cv_reg=0.03: 0.88%. runs 1 hr.\n# 3yr, t=40, cv_reg=0.04: 0.96%.\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:46.027950Z","iopub.execute_input":"2022-09-07T01:00:46.028441Z","iopub.status.idle":"2022-09-07T01:00:46.033781Z","shell.execute_reply.started":"2022-09-07T01:00:46.028405Z","shell.execute_reply":"2022-09-07T01:00:46.032572Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"display(X_train, X_val, X_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:46.035611Z","iopub.execute_input":"2022-09-07T01:00:46.036162Z","iopub.status.idle":"2022-09-07T01:00:46.382725Z","shell.execute_reply.started":"2022-09-07T01:00:46.036125Z","shell.execute_reply":"2022-09-07T01:00:46.381810Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"       num__mom482  num__mom242   num__bm   num__op   num__gp  num__inv  \\\n0        -0.500811     0.216499 -0.340384 -0.328582  0.045307 -0.588233   \n1         0.160589     0.161776 -0.340384 -0.328582  0.045307 -0.588233   \n2         0.575119     0.265471 -0.282249 -0.211330 -0.007926  0.443927   \n3         0.815074     0.890410 -0.282249 -0.211330 -0.007926  0.443927   \n4         0.933095     1.326763 -0.282249 -0.211330 -0.007926  0.443927   \n...            ...          ...       ...       ...       ...       ...   \n78273    -0.152043     0.211762 -1.380615  0.341591 -0.616479 -1.181068   \n78274    -0.152043     0.365979 -1.380615  0.341591 -0.616479 -1.181068   \n78275    -0.152043     0.172720 -1.380615  0.341591 -0.616479 -1.181068   \n78276    -0.152043     0.125273 -1.380615  0.341591 -0.616479 -1.181068   \n78277    -0.152043     0.199470 -1.380615  0.341591 -0.616479 -1.181068   \n\n       num__mom11  num__mom122  num__amhd  num__ivol_capm  num__ivol_ff5  \\\n0       -0.093832     0.000390   0.618694       -0.598732      -0.668599   \n1       -0.209729    -0.031615   0.581445       -0.907245      -0.887352   \n2        2.504443     0.095002   0.569546       -0.379325      -0.203368   \n3        0.677506     1.240795   0.551723       -0.785948      -0.791334   \n4        0.606145     1.563619   0.520774       -0.657968      -0.637011   \n...           ...          ...        ...             ...            ...   \n78273    0.105060    -0.067179  -0.833931       -0.678315      -0.620012   \n78274    0.504697     0.030860  -0.852461       -0.907245      -0.887352   \n78275   -0.155180     0.308838  -0.858578       -0.854257      -0.887352   \n78276    0.553158    -0.147552  -0.858601       -0.486667      -0.753886   \n78277    0.578670     0.098636  -0.852650       -0.513213      -0.549666   \n\n       num__beta_bw  num__MAX  num__vol1m  num__vol6m  num__vol12m  \\\n0         -0.045083 -0.636752   -0.547769   -0.197902    -0.146483   \n1         -0.147561 -0.930676   -1.012115   -0.545421    -0.204533   \n2         -0.209169  0.164629   -0.553321   -0.751682    -0.206327   \n3         -0.258246 -0.498815   -0.926922   -0.837305    -0.233204   \n4         -0.108027 -0.202545   -0.731773   -0.912226    -0.371910   \n...             ...       ...         ...         ...          ...   \n78273     -0.529956 -0.726330   -0.883644   -0.568782    -0.837818   \n78274     -0.654774 -0.851084   -0.969702   -0.566360    -0.841361   \n78275     -0.696841 -0.875052   -0.938885   -0.616002    -0.852235   \n78276     -0.786535 -0.586396   -0.573308   -0.583994    -0.883229   \n78277     -0.862609 -0.493572   -0.754182   -0.575445    -0.859598   \n\n       num__BAspr  num__size  num__lbm  num__lop  num__lgp  num__linv  \\\n0       -0.138587  -0.629521 -0.541304  0.771667  0.622910  -0.842829   \n1       -0.016439  -0.634032 -0.541304  0.771667  0.622910  -0.842829   \n2       -0.326794  -0.527200 -0.378242 -0.328445  0.040105  -0.591069   \n3       -0.016652  -0.491969 -0.378242 -0.328445  0.040105  -0.591069   \n4       -0.187430  -0.460080 -0.378242 -0.328445  0.040105  -0.591069   \n...           ...        ...       ...       ...       ...        ...   \n78273   -0.387942   0.744157 -0.680315  0.045389 -0.815751   0.263971   \n78274   -0.402058   0.771630 -0.680315  0.045389 -0.815751   0.263971   \n78275   -0.402058   0.769599 -0.680315  0.045389 -0.815751   0.263971   \n78276   -0.402058   0.791150 -0.680315  0.045389 -0.815751   0.263971   \n78277   -0.402058   0.830383 -0.680315  0.045389 -0.815751   0.263971   \n\n       num__llme  num__l1amhd  num__l1MAX  num__l1BAspr  num__l3amhd  \\\n0      -0.604599     0.619048   -0.539101     -0.162381     0.640642   \n1      -0.598933     0.613128   -0.640300     -0.139207     0.636029   \n2      -0.622427     0.575878   -0.934985     -0.017309     0.607452   \n3      -0.709632     0.563978    0.163157     -0.327029     0.601532   \n4      -0.707738     0.546154   -0.502006     -0.017522     0.564280   \n...          ...          ...         ...           ...          ...   \n78273   0.771868    -0.839093    1.905235     -0.402139    -0.835373   \n78274   0.766944    -0.839565   -0.730109     -0.388052    -0.839237   \n78275   0.754989    -0.858096   -0.855187     -0.402139    -0.850753   \n78276   0.813726    -0.864214   -0.879217     -0.402139    -0.851225   \n78277   0.805669    -0.864236   -0.589813     -0.402139    -0.869757   \n\n       num__l3MAX  num__l3BAspr  num__l6amhd  num__l6MAX  num__l6BAspr  \\\n0       -0.255652     -0.064216     0.663339    0.842260     -0.043732   \n1       -0.350676     -0.080901     0.654569    0.985874     -0.104737   \n2       -0.544536     -0.163588     0.647515    0.815119     -0.037338   \n3       -0.646577     -0.140418     0.623360   -0.296632     -0.073990   \n4       -0.943714     -0.018536     0.618745   -0.390212     -0.090278   \n...           ...           ...          ...         ...           ...   \n78273   -0.826126     -0.403315    -0.835424   -0.730009     -0.405024   \n78274   -0.739355     -0.403153    -0.834337   -0.709379     -0.392811   \n78275    1.920142     -0.403315    -0.837364   -0.640977     -0.405024   \n78276   -0.737134     -0.389230    -0.853118   -0.858436     -0.405024   \n78277   -0.863253     -0.403315    -0.856983   -0.772983     -0.404866   \n\n       num__l12amhd  num__l12MAX  num__l12BAspr  num__l12mom122  \\\n0          0.610264    -0.539101      -0.158755       -0.190705   \n1          0.628126    -0.640300      -0.037412        0.150876   \n2          0.630172    -0.934985      -0.219313        0.357740   \n3          0.633321     0.163157      -0.178803       -0.361082   \n4          0.639270    -0.502006       0.030898       -0.008430   \n...             ...          ...            ...             ...   \n78273     -0.910094     1.905235      -0.405480        0.324973   \n78274     -0.887051    -0.730109      -0.370414        0.346716   \n78275     -0.868129    -0.855187      -0.405480        0.220208   \n78276     -0.857690    -0.879217      -0.405480       -0.081957   \n78277     -0.859085    -0.589813      -0.405480        0.092781   \n\n       num__l12ivol_capm  num__l12ivol_ff5  num__l12beta_bw  num__l12vol6m  \\\n0              -0.419162         -0.318870         0.700359      -0.292789   \n1              -0.712379         -0.660494         0.536133      -0.415928   \n2              -0.192800         -0.119984         0.589740      -0.395724   \n3              -0.647774         -0.732243         0.731954      -0.485705   \n4              -0.037824          0.107947         0.014322      -0.279744   \n...                  ...               ...              ...            ...   \n78273          -0.770838         -0.669282        -0.879701      -0.948424   \n78274          -0.945976         -0.870085        -0.826236      -1.006173   \n78275          -0.674529         -0.743757        -0.829343      -1.013382   \n78276          -0.435216         -0.471655        -0.541129      -0.954561   \n78277          -0.950414         -0.849883        -0.555705      -0.986327   \n\n       num__l12vol12m  num__amhd_miss  num__BAspr_miss  cat__ind_1.0  \\\n0           -0.036506       -0.150249        -0.037746           0.0   \n1           -0.223150       -0.150249        -0.037746           0.0   \n2           -0.341288       -0.150249        -0.037746           0.0   \n3           -0.355413       -0.150249        -0.037746           0.0   \n4           -0.322183       -0.150249        -0.037746           0.0   \n...               ...             ...              ...           ...   \n78273       -1.041228       -0.150249        -0.037746           0.0   \n78274       -1.076735       -0.150249        -0.037746           0.0   \n78275       -1.057706       -0.150249        -0.037746           0.0   \n78276       -1.039620       -0.150249        -0.037746           0.0   \n78277       -1.032359       -0.150249        -0.037746           0.0   \n\n       cat__ind_2.0  cat__ind_3.0  cat__ind_4.0  cat__ind_5.0  cat__ind_6.0  \\\n0               0.0           0.0           0.0           0.0           0.0   \n1               0.0           0.0           0.0           0.0           0.0   \n2               0.0           0.0           0.0           0.0           0.0   \n3               0.0           0.0           0.0           0.0           0.0   \n4               0.0           0.0           0.0           0.0           0.0   \n...             ...           ...           ...           ...           ...   \n78273           0.0           0.0           0.0           0.0           0.0   \n78274           0.0           0.0           0.0           0.0           0.0   \n78275           0.0           0.0           0.0           0.0           0.0   \n78276           0.0           0.0           0.0           0.0           0.0   \n78277           0.0           0.0           0.0           0.0           0.0   \n\n       cat__ind_7.0  cat__ind_8.0  cat__ind_9.0  cat__ind_10.0  cat__ind_11.0  \\\n0               0.0           0.0           0.0            0.0            0.0   \n1               0.0           0.0           0.0            0.0            0.0   \n2               0.0           0.0           0.0            0.0            0.0   \n3               0.0           0.0           0.0            0.0            0.0   \n4               0.0           0.0           0.0            0.0            0.0   \n...             ...           ...           ...            ...            ...   \n78273           1.0           0.0           0.0            0.0            0.0   \n78274           1.0           0.0           0.0            0.0            0.0   \n78275           1.0           0.0           0.0            0.0            0.0   \n78276           1.0           0.0           0.0            0.0            0.0   \n78277           1.0           0.0           0.0            0.0            0.0   \n\n       cat__ind_12.0  cat__ind_13.0  cat__ind_14.0  cat__ind_15.0  \\\n0                0.0            0.0            0.0            1.0   \n1                0.0            0.0            0.0            1.0   \n2                0.0            0.0            0.0            1.0   \n3                0.0            0.0            0.0            1.0   \n4                0.0            0.0            0.0            1.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_16.0  cat__ind_17.0  cat__ind_18.0  cat__ind_19.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_20.0  cat__ind_21.0  cat__ind_22.0  cat__ind_23.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_24.0  cat__ind_25.0  cat__ind_26.0  cat__ind_27.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_28.0  cat__ind_29.0  cat__ind_30.0  cat__ind_31.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_32.0  cat__ind_33.0  cat__ind_34.0  cat__ind_35.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_36.0  cat__ind_37.0  cat__ind_38.0  cat__ind_39.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_40.0  cat__ind_41.0  cat__ind_42.0  cat__ind_43.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_44.0  cat__ind_45.0  cat__ind_46.0  cat__ind_47.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_48.0  cat__ind_49.0  \n0                0.0            0.0  \n1                0.0            0.0  \n2                0.0            0.0  \n3                0.0            0.0  \n4                0.0            0.0  \n...              ...            ...  \n78273            0.0            0.0  \n78274            0.0            0.0  \n78275            0.0            0.0  \n78276            0.0            0.0  \n78277            0.0            0.0  \n\n[61151 rows x 92 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num__mom482</th>\n      <th>num__mom242</th>\n      <th>num__bm</th>\n      <th>num__op</th>\n      <th>num__gp</th>\n      <th>num__inv</th>\n      <th>num__mom11</th>\n      <th>num__mom122</th>\n      <th>num__amhd</th>\n      <th>num__ivol_capm</th>\n      <th>num__ivol_ff5</th>\n      <th>num__beta_bw</th>\n      <th>num__MAX</th>\n      <th>num__vol1m</th>\n      <th>num__vol6m</th>\n      <th>num__vol12m</th>\n      <th>num__BAspr</th>\n      <th>num__size</th>\n      <th>num__lbm</th>\n      <th>num__lop</th>\n      <th>num__lgp</th>\n      <th>num__linv</th>\n      <th>num__llme</th>\n      <th>num__l1amhd</th>\n      <th>num__l1MAX</th>\n      <th>num__l1BAspr</th>\n      <th>num__l3amhd</th>\n      <th>num__l3MAX</th>\n      <th>num__l3BAspr</th>\n      <th>num__l6amhd</th>\n      <th>num__l6MAX</th>\n      <th>num__l6BAspr</th>\n      <th>num__l12amhd</th>\n      <th>num__l12MAX</th>\n      <th>num__l12BAspr</th>\n      <th>num__l12mom122</th>\n      <th>num__l12ivol_capm</th>\n      <th>num__l12ivol_ff5</th>\n      <th>num__l12beta_bw</th>\n      <th>num__l12vol6m</th>\n      <th>num__l12vol12m</th>\n      <th>num__amhd_miss</th>\n      <th>num__BAspr_miss</th>\n      <th>cat__ind_1.0</th>\n      <th>cat__ind_2.0</th>\n      <th>cat__ind_3.0</th>\n      <th>cat__ind_4.0</th>\n      <th>cat__ind_5.0</th>\n      <th>cat__ind_6.0</th>\n      <th>cat__ind_7.0</th>\n      <th>cat__ind_8.0</th>\n      <th>cat__ind_9.0</th>\n      <th>cat__ind_10.0</th>\n      <th>cat__ind_11.0</th>\n      <th>cat__ind_12.0</th>\n      <th>cat__ind_13.0</th>\n      <th>cat__ind_14.0</th>\n      <th>cat__ind_15.0</th>\n      <th>cat__ind_16.0</th>\n      <th>cat__ind_17.0</th>\n      <th>cat__ind_18.0</th>\n      <th>cat__ind_19.0</th>\n      <th>cat__ind_20.0</th>\n      <th>cat__ind_21.0</th>\n      <th>cat__ind_22.0</th>\n      <th>cat__ind_23.0</th>\n      <th>cat__ind_24.0</th>\n      <th>cat__ind_25.0</th>\n      <th>cat__ind_26.0</th>\n      <th>cat__ind_27.0</th>\n      <th>cat__ind_28.0</th>\n      <th>cat__ind_29.0</th>\n      <th>cat__ind_30.0</th>\n      <th>cat__ind_31.0</th>\n      <th>cat__ind_32.0</th>\n      <th>cat__ind_33.0</th>\n      <th>cat__ind_34.0</th>\n      <th>cat__ind_35.0</th>\n      <th>cat__ind_36.0</th>\n      <th>cat__ind_37.0</th>\n      <th>cat__ind_38.0</th>\n      <th>cat__ind_39.0</th>\n      <th>cat__ind_40.0</th>\n      <th>cat__ind_41.0</th>\n      <th>cat__ind_42.0</th>\n      <th>cat__ind_43.0</th>\n      <th>cat__ind_44.0</th>\n      <th>cat__ind_45.0</th>\n      <th>cat__ind_46.0</th>\n      <th>cat__ind_47.0</th>\n      <th>cat__ind_48.0</th>\n      <th>cat__ind_49.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.500811</td>\n      <td>0.216499</td>\n      <td>-0.340384</td>\n      <td>-0.328582</td>\n      <td>0.045307</td>\n      <td>-0.588233</td>\n      <td>-0.093832</td>\n      <td>0.000390</td>\n      <td>0.618694</td>\n      <td>-0.598732</td>\n      <td>-0.668599</td>\n      <td>-0.045083</td>\n      <td>-0.636752</td>\n      <td>-0.547769</td>\n      <td>-0.197902</td>\n      <td>-0.146483</td>\n      <td>-0.138587</td>\n      <td>-0.629521</td>\n      <td>-0.541304</td>\n      <td>0.771667</td>\n      <td>0.622910</td>\n      <td>-0.842829</td>\n      <td>-0.604599</td>\n      <td>0.619048</td>\n      <td>-0.539101</td>\n      <td>-0.162381</td>\n      <td>0.640642</td>\n      <td>-0.255652</td>\n      <td>-0.064216</td>\n      <td>0.663339</td>\n      <td>0.842260</td>\n      <td>-0.043732</td>\n      <td>0.610264</td>\n      <td>-0.539101</td>\n      <td>-0.158755</td>\n      <td>-0.190705</td>\n      <td>-0.419162</td>\n      <td>-0.318870</td>\n      <td>0.700359</td>\n      <td>-0.292789</td>\n      <td>-0.036506</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.160589</td>\n      <td>0.161776</td>\n      <td>-0.340384</td>\n      <td>-0.328582</td>\n      <td>0.045307</td>\n      <td>-0.588233</td>\n      <td>-0.209729</td>\n      <td>-0.031615</td>\n      <td>0.581445</td>\n      <td>-0.907245</td>\n      <td>-0.887352</td>\n      <td>-0.147561</td>\n      <td>-0.930676</td>\n      <td>-1.012115</td>\n      <td>-0.545421</td>\n      <td>-0.204533</td>\n      <td>-0.016439</td>\n      <td>-0.634032</td>\n      <td>-0.541304</td>\n      <td>0.771667</td>\n      <td>0.622910</td>\n      <td>-0.842829</td>\n      <td>-0.598933</td>\n      <td>0.613128</td>\n      <td>-0.640300</td>\n      <td>-0.139207</td>\n      <td>0.636029</td>\n      <td>-0.350676</td>\n      <td>-0.080901</td>\n      <td>0.654569</td>\n      <td>0.985874</td>\n      <td>-0.104737</td>\n      <td>0.628126</td>\n      <td>-0.640300</td>\n      <td>-0.037412</td>\n      <td>0.150876</td>\n      <td>-0.712379</td>\n      <td>-0.660494</td>\n      <td>0.536133</td>\n      <td>-0.415928</td>\n      <td>-0.223150</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.575119</td>\n      <td>0.265471</td>\n      <td>-0.282249</td>\n      <td>-0.211330</td>\n      <td>-0.007926</td>\n      <td>0.443927</td>\n      <td>2.504443</td>\n      <td>0.095002</td>\n      <td>0.569546</td>\n      <td>-0.379325</td>\n      <td>-0.203368</td>\n      <td>-0.209169</td>\n      <td>0.164629</td>\n      <td>-0.553321</td>\n      <td>-0.751682</td>\n      <td>-0.206327</td>\n      <td>-0.326794</td>\n      <td>-0.527200</td>\n      <td>-0.378242</td>\n      <td>-0.328445</td>\n      <td>0.040105</td>\n      <td>-0.591069</td>\n      <td>-0.622427</td>\n      <td>0.575878</td>\n      <td>-0.934985</td>\n      <td>-0.017309</td>\n      <td>0.607452</td>\n      <td>-0.544536</td>\n      <td>-0.163588</td>\n      <td>0.647515</td>\n      <td>0.815119</td>\n      <td>-0.037338</td>\n      <td>0.630172</td>\n      <td>-0.934985</td>\n      <td>-0.219313</td>\n      <td>0.357740</td>\n      <td>-0.192800</td>\n      <td>-0.119984</td>\n      <td>0.589740</td>\n      <td>-0.395724</td>\n      <td>-0.341288</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.815074</td>\n      <td>0.890410</td>\n      <td>-0.282249</td>\n      <td>-0.211330</td>\n      <td>-0.007926</td>\n      <td>0.443927</td>\n      <td>0.677506</td>\n      <td>1.240795</td>\n      <td>0.551723</td>\n      <td>-0.785948</td>\n      <td>-0.791334</td>\n      <td>-0.258246</td>\n      <td>-0.498815</td>\n      <td>-0.926922</td>\n      <td>-0.837305</td>\n      <td>-0.233204</td>\n      <td>-0.016652</td>\n      <td>-0.491969</td>\n      <td>-0.378242</td>\n      <td>-0.328445</td>\n      <td>0.040105</td>\n      <td>-0.591069</td>\n      <td>-0.709632</td>\n      <td>0.563978</td>\n      <td>0.163157</td>\n      <td>-0.327029</td>\n      <td>0.601532</td>\n      <td>-0.646577</td>\n      <td>-0.140418</td>\n      <td>0.623360</td>\n      <td>-0.296632</td>\n      <td>-0.073990</td>\n      <td>0.633321</td>\n      <td>0.163157</td>\n      <td>-0.178803</td>\n      <td>-0.361082</td>\n      <td>-0.647774</td>\n      <td>-0.732243</td>\n      <td>0.731954</td>\n      <td>-0.485705</td>\n      <td>-0.355413</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.933095</td>\n      <td>1.326763</td>\n      <td>-0.282249</td>\n      <td>-0.211330</td>\n      <td>-0.007926</td>\n      <td>0.443927</td>\n      <td>0.606145</td>\n      <td>1.563619</td>\n      <td>0.520774</td>\n      <td>-0.657968</td>\n      <td>-0.637011</td>\n      <td>-0.108027</td>\n      <td>-0.202545</td>\n      <td>-0.731773</td>\n      <td>-0.912226</td>\n      <td>-0.371910</td>\n      <td>-0.187430</td>\n      <td>-0.460080</td>\n      <td>-0.378242</td>\n      <td>-0.328445</td>\n      <td>0.040105</td>\n      <td>-0.591069</td>\n      <td>-0.707738</td>\n      <td>0.546154</td>\n      <td>-0.502006</td>\n      <td>-0.017522</td>\n      <td>0.564280</td>\n      <td>-0.943714</td>\n      <td>-0.018536</td>\n      <td>0.618745</td>\n      <td>-0.390212</td>\n      <td>-0.090278</td>\n      <td>0.639270</td>\n      <td>-0.502006</td>\n      <td>0.030898</td>\n      <td>-0.008430</td>\n      <td>-0.037824</td>\n      <td>0.107947</td>\n      <td>0.014322</td>\n      <td>-0.279744</td>\n      <td>-0.322183</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78273</th>\n      <td>-0.152043</td>\n      <td>0.211762</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>0.105060</td>\n      <td>-0.067179</td>\n      <td>-0.833931</td>\n      <td>-0.678315</td>\n      <td>-0.620012</td>\n      <td>-0.529956</td>\n      <td>-0.726330</td>\n      <td>-0.883644</td>\n      <td>-0.568782</td>\n      <td>-0.837818</td>\n      <td>-0.387942</td>\n      <td>0.744157</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.771868</td>\n      <td>-0.839093</td>\n      <td>1.905235</td>\n      <td>-0.402139</td>\n      <td>-0.835373</td>\n      <td>-0.826126</td>\n      <td>-0.403315</td>\n      <td>-0.835424</td>\n      <td>-0.730009</td>\n      <td>-0.405024</td>\n      <td>-0.910094</td>\n      <td>1.905235</td>\n      <td>-0.405480</td>\n      <td>0.324973</td>\n      <td>-0.770838</td>\n      <td>-0.669282</td>\n      <td>-0.879701</td>\n      <td>-0.948424</td>\n      <td>-1.041228</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78274</th>\n      <td>-0.152043</td>\n      <td>0.365979</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>0.504697</td>\n      <td>0.030860</td>\n      <td>-0.852461</td>\n      <td>-0.907245</td>\n      <td>-0.887352</td>\n      <td>-0.654774</td>\n      <td>-0.851084</td>\n      <td>-0.969702</td>\n      <td>-0.566360</td>\n      <td>-0.841361</td>\n      <td>-0.402058</td>\n      <td>0.771630</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.766944</td>\n      <td>-0.839565</td>\n      <td>-0.730109</td>\n      <td>-0.388052</td>\n      <td>-0.839237</td>\n      <td>-0.739355</td>\n      <td>-0.403153</td>\n      <td>-0.834337</td>\n      <td>-0.709379</td>\n      <td>-0.392811</td>\n      <td>-0.887051</td>\n      <td>-0.730109</td>\n      <td>-0.370414</td>\n      <td>0.346716</td>\n      <td>-0.945976</td>\n      <td>-0.870085</td>\n      <td>-0.826236</td>\n      <td>-1.006173</td>\n      <td>-1.076735</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78275</th>\n      <td>-0.152043</td>\n      <td>0.172720</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>-0.155180</td>\n      <td>0.308838</td>\n      <td>-0.858578</td>\n      <td>-0.854257</td>\n      <td>-0.887352</td>\n      <td>-0.696841</td>\n      <td>-0.875052</td>\n      <td>-0.938885</td>\n      <td>-0.616002</td>\n      <td>-0.852235</td>\n      <td>-0.402058</td>\n      <td>0.769599</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.754989</td>\n      <td>-0.858096</td>\n      <td>-0.855187</td>\n      <td>-0.402139</td>\n      <td>-0.850753</td>\n      <td>1.920142</td>\n      <td>-0.403315</td>\n      <td>-0.837364</td>\n      <td>-0.640977</td>\n      <td>-0.405024</td>\n      <td>-0.868129</td>\n      <td>-0.855187</td>\n      <td>-0.405480</td>\n      <td>0.220208</td>\n      <td>-0.674529</td>\n      <td>-0.743757</td>\n      <td>-0.829343</td>\n      <td>-1.013382</td>\n      <td>-1.057706</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78276</th>\n      <td>-0.152043</td>\n      <td>0.125273</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>0.553158</td>\n      <td>-0.147552</td>\n      <td>-0.858601</td>\n      <td>-0.486667</td>\n      <td>-0.753886</td>\n      <td>-0.786535</td>\n      <td>-0.586396</td>\n      <td>-0.573308</td>\n      <td>-0.583994</td>\n      <td>-0.883229</td>\n      <td>-0.402058</td>\n      <td>0.791150</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.813726</td>\n      <td>-0.864214</td>\n      <td>-0.879217</td>\n      <td>-0.402139</td>\n      <td>-0.851225</td>\n      <td>-0.737134</td>\n      <td>-0.389230</td>\n      <td>-0.853118</td>\n      <td>-0.858436</td>\n      <td>-0.405024</td>\n      <td>-0.857690</td>\n      <td>-0.879217</td>\n      <td>-0.405480</td>\n      <td>-0.081957</td>\n      <td>-0.435216</td>\n      <td>-0.471655</td>\n      <td>-0.541129</td>\n      <td>-0.954561</td>\n      <td>-1.039620</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78277</th>\n      <td>-0.152043</td>\n      <td>0.199470</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>0.578670</td>\n      <td>0.098636</td>\n      <td>-0.852650</td>\n      <td>-0.513213</td>\n      <td>-0.549666</td>\n      <td>-0.862609</td>\n      <td>-0.493572</td>\n      <td>-0.754182</td>\n      <td>-0.575445</td>\n      <td>-0.859598</td>\n      <td>-0.402058</td>\n      <td>0.830383</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.805669</td>\n      <td>-0.864236</td>\n      <td>-0.589813</td>\n      <td>-0.402139</td>\n      <td>-0.869757</td>\n      <td>-0.863253</td>\n      <td>-0.403315</td>\n      <td>-0.856983</td>\n      <td>-0.772983</td>\n      <td>-0.404866</td>\n      <td>-0.859085</td>\n      <td>-0.589813</td>\n      <td>-0.405480</td>\n      <td>0.092781</td>\n      <td>-0.950414</td>\n      <td>-0.849883</td>\n      <td>-0.555705</td>\n      <td>-0.986327</td>\n      <td>-1.032359</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>61151 rows  92 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"       num__mom482  num__mom242   num__bm   num__op   num__gp  num__inv  \\\n36        0.017571    -1.255213 -0.369900 -0.031204  0.115022 -0.006492   \n37       -0.122740    -1.136954 -0.369900 -0.031204  0.115022 -0.006492   \n38        0.226189    -1.110995 -0.780439 -0.481518 -0.095930 -0.717797   \n64       -0.152043    -0.096694 -0.344948 -1.067199  1.968471 -0.689230   \n65       -0.152043    -0.096694 -0.278284 -1.027436  1.432911 -1.591683   \n...            ...          ...       ...       ...       ...       ...   \n78246    -0.152043    -1.123797  0.580376  0.338238 -0.909588 -0.317748   \n78247    -0.152043    -1.263248  1.132903 -0.671171 -1.397125 -0.509075   \n78278    -0.152043    -0.030471 -1.380615  0.341591 -0.616479 -1.181068   \n78279    -0.152043     0.283512 -1.380615  0.341591 -0.616479 -1.181068   \n78280     1.198636     0.016462 -1.789752  0.085412 -0.507287 -0.598994   \n\n       num__mom11  num__mom122  num__amhd  num__ivol_capm  num__ivol_ff5  \\\n36      -1.009764     1.071891   0.479974       -0.180693      -0.157000   \n37      -0.125082     1.144146   0.498559       -0.659567      -0.713933   \n38       0.923598     0.774266   0.513240       -0.270934      -0.273592   \n64      -2.351983    -1.349284   2.068987        3.883441       3.748632   \n65       1.057888    -2.066496   2.068987        4.081030       3.979960   \n...           ...          ...        ...             ...            ...   \n78246   -1.735374    -1.189147  -0.912364        0.030683       0.184636   \n78247   -0.281250    -1.616178  -0.914026       -0.757077      -0.819137   \n78278   -0.398589     0.319302  -0.847606       -0.457602      -0.391194   \n78279    0.391453     0.157390  -0.838832       -0.849395      -0.867005   \n78280   -0.932847     0.152863  -0.838376       -0.695451      -0.643683   \n\n       num__beta_bw  num__MAX  num__vol1m  num__vol6m  num__vol12m  \\\n36        -0.183768 -0.515268   -0.347572   -0.228553    -0.208170   \n37        -0.249618 -0.733894   -0.690161   -0.241237    -0.218720   \n38        -0.453558 -0.282635   -0.394608   -0.291224    -0.355168   \n64        -2.415869  0.749706    4.022481    2.049071     1.584084   \n65        -2.406530  3.994730    4.122402    2.794204     2.031846   \n...             ...       ...         ...         ...          ...   \n78246      1.408413 -0.725032    0.075438    0.340738     0.020141   \n78247      1.276622 -0.707755   -0.778868   -0.167411     0.020129   \n78278     -0.836977 -0.578082   -0.415400   -0.916476    -0.831464   \n78279     -0.789223 -0.680442   -0.852647   -0.910567    -0.827425   \n78280     -0.739484 -0.590016   -0.709366   -0.863951    -0.805263   \n\n       num__BAspr  num__size  num__lbm  num__lop  num__lgp  num__linv  \\\n36       0.023861  -0.498862 -0.729077  0.419892  0.520345  -0.288298   \n37       0.393677  -0.499506 -0.729077  0.419892  0.520345  -0.288298   \n38       0.272001  -0.454238 -0.408215 -0.033124  0.109300  -0.026699   \n64       2.188332  -2.319097 -1.115141 -0.143111  2.377806  -0.732182   \n65       3.064452  -2.268268 -0.382877 -1.061952  1.948956  -0.689050   \n...           ...        ...       ...       ...       ...        ...   \n78246   -0.385702   0.682241  0.537244 -0.079524 -1.149430   0.595084   \n78247   -0.383555   0.674351  0.556766  0.333763 -0.907684  -0.328660   \n78278   -0.402058   0.817380 -0.680315  0.045389 -0.815751   0.263971   \n78279   -0.393765   0.835050 -0.680315  0.045389 -0.815751   0.263971   \n78280   -0.376198   0.795630 -1.434570  0.337093 -0.616757  -1.166201   \n\n       num__llme  num__l1amhd  num__l1MAX  num__l1BAspr  num__l3amhd  \\\n36     -0.617712     0.454084    0.465902      0.021436     0.400562   \n37     -0.669699     0.474402   -0.518501      0.022908     0.423160   \n38     -0.627657     0.492988   -0.737694      0.391967     0.442480   \n64     -1.551684     2.063489    0.123108      1.834347     2.051957   \n65     -1.701090     2.063489    0.749748      2.182949     2.051957   \n...          ...          ...         ...           ...          ...   \n78246   0.998694    -0.935036   -0.290222     -0.391434    -0.971474   \n78247   1.034725    -0.918001   -0.728808     -0.385816    -0.953446   \n78278   0.807354    -0.858285   -0.496749     -0.402139    -0.875875   \n78279   0.811065    -0.853241   -0.581478     -0.402139    -0.875898   \n78280   0.834602    -0.844466   -0.684103     -0.393863    -0.869946   \n\n       num__l3MAX  num__l3BAspr  num__l6amhd  num__l6MAX  num__l6BAspr  \\\n36      -0.237429      0.423626     0.288105    0.777438     -0.126923   \n37      -0.359081      0.048667     0.334052   -0.811733      0.131124   \n38       0.468830      0.020204     0.363010    0.066329      0.163772   \n64      -0.335407      1.603946     2.024413    2.226897      0.104445   \n65       1.405445      2.491250     2.035117    0.059071      1.725945   \n...           ...           ...          ...         ...           ...   \n78246   -0.050510     -0.391478    -1.041212    0.000487     -0.392559   \n78247   -0.531008     -0.390212    -1.027701    0.270291     -0.390777   \n78278   -0.887482     -0.403315    -0.868502    1.846090     -0.405024   \n78279   -0.595670     -0.403315    -0.868975   -0.770796     -0.391274   \n78280   -0.501832     -0.403315    -0.887512   -0.894998     -0.405024   \n\n       num__l12amhd  num__l12MAX  num__l12BAspr  num__l12mom122  \\\n36        -0.008636     0.465902      -0.115740       -1.740134   \n37         0.015623    -0.518501      -0.056377       -1.882481   \n38         0.089343    -0.737694      -0.008474       -1.877967   \n64         1.995707     0.123108      -0.092068       -0.910604   \n65         1.993128     0.749748       1.335923       -1.223386   \n...             ...          ...            ...             ...   \n78246     -1.037594    -0.290222      -0.403731       -0.164819   \n78247     -1.047336    -0.728808      -0.405428        0.013950   \n78278     -0.856769    -0.496749      -0.405480        0.027287   \n78279     -0.863835    -0.581478      -0.405480       -0.077624   \n78280     -0.862748    -0.684103      -0.393512        0.159732   \n\n       num__l12ivol_capm  num__l12ivol_ff5  num__l12beta_bw  num__l12vol6m  \\\n36             -0.637351         -0.715329        -0.585179      -0.413230   \n37             -0.675613         -0.722268        -0.659664      -0.425989   \n38              0.774472          0.782417        -0.208721      -0.238738   \n64              1.110320          1.169139        -2.729320       0.660596   \n65              0.524419          0.467423        -1.695742       0.589892   \n...                  ...               ...              ...            ...   \n78246          -0.817938         -0.837669        -0.364856      -0.820085   \n78247          -0.820570         -0.819109        -0.305213      -0.852782   \n78278          -0.828575         -0.727009        -0.407072      -1.081661   \n78279          -0.855083         -0.773845        -0.459198      -1.086932   \n78280          -0.909681         -0.856119        -0.275987      -1.101124   \n\n       num__l12vol12m  num__amhd_miss  num__BAspr_miss  cat__ind_1.0  \\\n36          -0.080031       -0.150249        -0.037746           0.0   \n37          -0.088143       -0.150249        -0.037746           0.0   \n38          -0.195021       -0.150249        -0.037746           0.0   \n64          -0.216356       -0.150249        -0.037746           0.0   \n65          -0.216356       -0.150249        -0.037746           0.0   \n...               ...             ...              ...           ...   \n78246       -0.964781       -0.150249        -0.037746           0.0   \n78247       -0.980294       -0.150249        -0.037746           0.0   \n78278       -1.103256       -0.150249        -0.037746           0.0   \n78279       -1.117821       -0.150249        -0.037746           0.0   \n78280       -1.134378       -0.150249        -0.037746           0.0   \n\n       cat__ind_2.0  cat__ind_3.0  cat__ind_4.0  cat__ind_5.0  cat__ind_6.0  \\\n36              0.0           0.0           0.0           0.0           0.0   \n37              0.0           0.0           0.0           0.0           0.0   \n38              0.0           0.0           0.0           0.0           0.0   \n64              0.0           0.0           0.0           0.0           0.0   \n65              0.0           0.0           0.0           0.0           0.0   \n...             ...           ...           ...           ...           ...   \n78246           0.0           0.0           0.0           0.0           0.0   \n78247           0.0           0.0           0.0           0.0           0.0   \n78278           0.0           0.0           0.0           0.0           0.0   \n78279           0.0           0.0           0.0           0.0           0.0   \n78280           0.0           0.0           0.0           0.0           0.0   \n\n       cat__ind_7.0  cat__ind_8.0  cat__ind_9.0  cat__ind_10.0  cat__ind_11.0  \\\n36              0.0           0.0           0.0            0.0            0.0   \n37              0.0           0.0           0.0            0.0            0.0   \n38              0.0           0.0           0.0            0.0            0.0   \n64              0.0           0.0           0.0            0.0            0.0   \n65              0.0           0.0           0.0            0.0            0.0   \n...             ...           ...           ...            ...            ...   \n78246           0.0           0.0           0.0            0.0            0.0   \n78247           0.0           0.0           0.0            0.0            0.0   \n78278           1.0           0.0           0.0            0.0            0.0   \n78279           1.0           0.0           0.0            0.0            0.0   \n78280           1.0           0.0           0.0            0.0            0.0   \n\n       cat__ind_12.0  cat__ind_13.0  cat__ind_14.0  cat__ind_15.0  \\\n36               0.0            0.0            0.0            1.0   \n37               0.0            0.0            0.0            1.0   \n38               0.0            0.0            0.0            1.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_16.0  cat__ind_17.0  cat__ind_18.0  cat__ind_19.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_20.0  cat__ind_21.0  cat__ind_22.0  cat__ind_23.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_24.0  cat__ind_25.0  cat__ind_26.0  cat__ind_27.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_28.0  cat__ind_29.0  cat__ind_30.0  cat__ind_31.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            1.0            0.0   \n78247            0.0            0.0            1.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_32.0  cat__ind_33.0  cat__ind_34.0  cat__ind_35.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_36.0  cat__ind_37.0  cat__ind_38.0  cat__ind_39.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_40.0  cat__ind_41.0  cat__ind_42.0  cat__ind_43.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            1.0            0.0   \n65               0.0            0.0            1.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_44.0  cat__ind_45.0  cat__ind_46.0  cat__ind_47.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_48.0  cat__ind_49.0  \n36               0.0            0.0  \n37               0.0            0.0  \n38               0.0            0.0  \n64               0.0            0.0  \n65               0.0            0.0  \n...              ...            ...  \n78246            0.0            0.0  \n78247            0.0            0.0  \n78278            0.0            0.0  \n78279            0.0            0.0  \n78280            0.0            0.0  \n\n[4761 rows x 92 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num__mom482</th>\n      <th>num__mom242</th>\n      <th>num__bm</th>\n      <th>num__op</th>\n      <th>num__gp</th>\n      <th>num__inv</th>\n      <th>num__mom11</th>\n      <th>num__mom122</th>\n      <th>num__amhd</th>\n      <th>num__ivol_capm</th>\n      <th>num__ivol_ff5</th>\n      <th>num__beta_bw</th>\n      <th>num__MAX</th>\n      <th>num__vol1m</th>\n      <th>num__vol6m</th>\n      <th>num__vol12m</th>\n      <th>num__BAspr</th>\n      <th>num__size</th>\n      <th>num__lbm</th>\n      <th>num__lop</th>\n      <th>num__lgp</th>\n      <th>num__linv</th>\n      <th>num__llme</th>\n      <th>num__l1amhd</th>\n      <th>num__l1MAX</th>\n      <th>num__l1BAspr</th>\n      <th>num__l3amhd</th>\n      <th>num__l3MAX</th>\n      <th>num__l3BAspr</th>\n      <th>num__l6amhd</th>\n      <th>num__l6MAX</th>\n      <th>num__l6BAspr</th>\n      <th>num__l12amhd</th>\n      <th>num__l12MAX</th>\n      <th>num__l12BAspr</th>\n      <th>num__l12mom122</th>\n      <th>num__l12ivol_capm</th>\n      <th>num__l12ivol_ff5</th>\n      <th>num__l12beta_bw</th>\n      <th>num__l12vol6m</th>\n      <th>num__l12vol12m</th>\n      <th>num__amhd_miss</th>\n      <th>num__BAspr_miss</th>\n      <th>cat__ind_1.0</th>\n      <th>cat__ind_2.0</th>\n      <th>cat__ind_3.0</th>\n      <th>cat__ind_4.0</th>\n      <th>cat__ind_5.0</th>\n      <th>cat__ind_6.0</th>\n      <th>cat__ind_7.0</th>\n      <th>cat__ind_8.0</th>\n      <th>cat__ind_9.0</th>\n      <th>cat__ind_10.0</th>\n      <th>cat__ind_11.0</th>\n      <th>cat__ind_12.0</th>\n      <th>cat__ind_13.0</th>\n      <th>cat__ind_14.0</th>\n      <th>cat__ind_15.0</th>\n      <th>cat__ind_16.0</th>\n      <th>cat__ind_17.0</th>\n      <th>cat__ind_18.0</th>\n      <th>cat__ind_19.0</th>\n      <th>cat__ind_20.0</th>\n      <th>cat__ind_21.0</th>\n      <th>cat__ind_22.0</th>\n      <th>cat__ind_23.0</th>\n      <th>cat__ind_24.0</th>\n      <th>cat__ind_25.0</th>\n      <th>cat__ind_26.0</th>\n      <th>cat__ind_27.0</th>\n      <th>cat__ind_28.0</th>\n      <th>cat__ind_29.0</th>\n      <th>cat__ind_30.0</th>\n      <th>cat__ind_31.0</th>\n      <th>cat__ind_32.0</th>\n      <th>cat__ind_33.0</th>\n      <th>cat__ind_34.0</th>\n      <th>cat__ind_35.0</th>\n      <th>cat__ind_36.0</th>\n      <th>cat__ind_37.0</th>\n      <th>cat__ind_38.0</th>\n      <th>cat__ind_39.0</th>\n      <th>cat__ind_40.0</th>\n      <th>cat__ind_41.0</th>\n      <th>cat__ind_42.0</th>\n      <th>cat__ind_43.0</th>\n      <th>cat__ind_44.0</th>\n      <th>cat__ind_45.0</th>\n      <th>cat__ind_46.0</th>\n      <th>cat__ind_47.0</th>\n      <th>cat__ind_48.0</th>\n      <th>cat__ind_49.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36</th>\n      <td>0.017571</td>\n      <td>-1.255213</td>\n      <td>-0.369900</td>\n      <td>-0.031204</td>\n      <td>0.115022</td>\n      <td>-0.006492</td>\n      <td>-1.009764</td>\n      <td>1.071891</td>\n      <td>0.479974</td>\n      <td>-0.180693</td>\n      <td>-0.157000</td>\n      <td>-0.183768</td>\n      <td>-0.515268</td>\n      <td>-0.347572</td>\n      <td>-0.228553</td>\n      <td>-0.208170</td>\n      <td>0.023861</td>\n      <td>-0.498862</td>\n      <td>-0.729077</td>\n      <td>0.419892</td>\n      <td>0.520345</td>\n      <td>-0.288298</td>\n      <td>-0.617712</td>\n      <td>0.454084</td>\n      <td>0.465902</td>\n      <td>0.021436</td>\n      <td>0.400562</td>\n      <td>-0.237429</td>\n      <td>0.423626</td>\n      <td>0.288105</td>\n      <td>0.777438</td>\n      <td>-0.126923</td>\n      <td>-0.008636</td>\n      <td>0.465902</td>\n      <td>-0.115740</td>\n      <td>-1.740134</td>\n      <td>-0.637351</td>\n      <td>-0.715329</td>\n      <td>-0.585179</td>\n      <td>-0.413230</td>\n      <td>-0.080031</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>-0.122740</td>\n      <td>-1.136954</td>\n      <td>-0.369900</td>\n      <td>-0.031204</td>\n      <td>0.115022</td>\n      <td>-0.006492</td>\n      <td>-0.125082</td>\n      <td>1.144146</td>\n      <td>0.498559</td>\n      <td>-0.659567</td>\n      <td>-0.713933</td>\n      <td>-0.249618</td>\n      <td>-0.733894</td>\n      <td>-0.690161</td>\n      <td>-0.241237</td>\n      <td>-0.218720</td>\n      <td>0.393677</td>\n      <td>-0.499506</td>\n      <td>-0.729077</td>\n      <td>0.419892</td>\n      <td>0.520345</td>\n      <td>-0.288298</td>\n      <td>-0.669699</td>\n      <td>0.474402</td>\n      <td>-0.518501</td>\n      <td>0.022908</td>\n      <td>0.423160</td>\n      <td>-0.359081</td>\n      <td>0.048667</td>\n      <td>0.334052</td>\n      <td>-0.811733</td>\n      <td>0.131124</td>\n      <td>0.015623</td>\n      <td>-0.518501</td>\n      <td>-0.056377</td>\n      <td>-1.882481</td>\n      <td>-0.675613</td>\n      <td>-0.722268</td>\n      <td>-0.659664</td>\n      <td>-0.425989</td>\n      <td>-0.088143</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0.226189</td>\n      <td>-1.110995</td>\n      <td>-0.780439</td>\n      <td>-0.481518</td>\n      <td>-0.095930</td>\n      <td>-0.717797</td>\n      <td>0.923598</td>\n      <td>0.774266</td>\n      <td>0.513240</td>\n      <td>-0.270934</td>\n      <td>-0.273592</td>\n      <td>-0.453558</td>\n      <td>-0.282635</td>\n      <td>-0.394608</td>\n      <td>-0.291224</td>\n      <td>-0.355168</td>\n      <td>0.272001</td>\n      <td>-0.454238</td>\n      <td>-0.408215</td>\n      <td>-0.033124</td>\n      <td>0.109300</td>\n      <td>-0.026699</td>\n      <td>-0.627657</td>\n      <td>0.492988</td>\n      <td>-0.737694</td>\n      <td>0.391967</td>\n      <td>0.442480</td>\n      <td>0.468830</td>\n      <td>0.020204</td>\n      <td>0.363010</td>\n      <td>0.066329</td>\n      <td>0.163772</td>\n      <td>0.089343</td>\n      <td>-0.737694</td>\n      <td>-0.008474</td>\n      <td>-1.877967</td>\n      <td>0.774472</td>\n      <td>0.782417</td>\n      <td>-0.208721</td>\n      <td>-0.238738</td>\n      <td>-0.195021</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>-0.152043</td>\n      <td>-0.096694</td>\n      <td>-0.344948</td>\n      <td>-1.067199</td>\n      <td>1.968471</td>\n      <td>-0.689230</td>\n      <td>-2.351983</td>\n      <td>-1.349284</td>\n      <td>2.068987</td>\n      <td>3.883441</td>\n      <td>3.748632</td>\n      <td>-2.415869</td>\n      <td>0.749706</td>\n      <td>4.022481</td>\n      <td>2.049071</td>\n      <td>1.584084</td>\n      <td>2.188332</td>\n      <td>-2.319097</td>\n      <td>-1.115141</td>\n      <td>-0.143111</td>\n      <td>2.377806</td>\n      <td>-0.732182</td>\n      <td>-1.551684</td>\n      <td>2.063489</td>\n      <td>0.123108</td>\n      <td>1.834347</td>\n      <td>2.051957</td>\n      <td>-0.335407</td>\n      <td>1.603946</td>\n      <td>2.024413</td>\n      <td>2.226897</td>\n      <td>0.104445</td>\n      <td>1.995707</td>\n      <td>0.123108</td>\n      <td>-0.092068</td>\n      <td>-0.910604</td>\n      <td>1.110320</td>\n      <td>1.169139</td>\n      <td>-2.729320</td>\n      <td>0.660596</td>\n      <td>-0.216356</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>-0.152043</td>\n      <td>-0.096694</td>\n      <td>-0.278284</td>\n      <td>-1.027436</td>\n      <td>1.432911</td>\n      <td>-1.591683</td>\n      <td>1.057888</td>\n      <td>-2.066496</td>\n      <td>2.068987</td>\n      <td>4.081030</td>\n      <td>3.979960</td>\n      <td>-2.406530</td>\n      <td>3.994730</td>\n      <td>4.122402</td>\n      <td>2.794204</td>\n      <td>2.031846</td>\n      <td>3.064452</td>\n      <td>-2.268268</td>\n      <td>-0.382877</td>\n      <td>-1.061952</td>\n      <td>1.948956</td>\n      <td>-0.689050</td>\n      <td>-1.701090</td>\n      <td>2.063489</td>\n      <td>0.749748</td>\n      <td>2.182949</td>\n      <td>2.051957</td>\n      <td>1.405445</td>\n      <td>2.491250</td>\n      <td>2.035117</td>\n      <td>0.059071</td>\n      <td>1.725945</td>\n      <td>1.993128</td>\n      <td>0.749748</td>\n      <td>1.335923</td>\n      <td>-1.223386</td>\n      <td>0.524419</td>\n      <td>0.467423</td>\n      <td>-1.695742</td>\n      <td>0.589892</td>\n      <td>-0.216356</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78246</th>\n      <td>-0.152043</td>\n      <td>-1.123797</td>\n      <td>0.580376</td>\n      <td>0.338238</td>\n      <td>-0.909588</td>\n      <td>-0.317748</td>\n      <td>-1.735374</td>\n      <td>-1.189147</td>\n      <td>-0.912364</td>\n      <td>0.030683</td>\n      <td>0.184636</td>\n      <td>1.408413</td>\n      <td>-0.725032</td>\n      <td>0.075438</td>\n      <td>0.340738</td>\n      <td>0.020141</td>\n      <td>-0.385702</td>\n      <td>0.682241</td>\n      <td>0.537244</td>\n      <td>-0.079524</td>\n      <td>-1.149430</td>\n      <td>0.595084</td>\n      <td>0.998694</td>\n      <td>-0.935036</td>\n      <td>-0.290222</td>\n      <td>-0.391434</td>\n      <td>-0.971474</td>\n      <td>-0.050510</td>\n      <td>-0.391478</td>\n      <td>-1.041212</td>\n      <td>0.000487</td>\n      <td>-0.392559</td>\n      <td>-1.037594</td>\n      <td>-0.290222</td>\n      <td>-0.403731</td>\n      <td>-0.164819</td>\n      <td>-0.817938</td>\n      <td>-0.837669</td>\n      <td>-0.364856</td>\n      <td>-0.820085</td>\n      <td>-0.964781</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78247</th>\n      <td>-0.152043</td>\n      <td>-1.263248</td>\n      <td>1.132903</td>\n      <td>-0.671171</td>\n      <td>-1.397125</td>\n      <td>-0.509075</td>\n      <td>-0.281250</td>\n      <td>-1.616178</td>\n      <td>-0.914026</td>\n      <td>-0.757077</td>\n      <td>-0.819137</td>\n      <td>1.276622</td>\n      <td>-0.707755</td>\n      <td>-0.778868</td>\n      <td>-0.167411</td>\n      <td>0.020129</td>\n      <td>-0.383555</td>\n      <td>0.674351</td>\n      <td>0.556766</td>\n      <td>0.333763</td>\n      <td>-0.907684</td>\n      <td>-0.328660</td>\n      <td>1.034725</td>\n      <td>-0.918001</td>\n      <td>-0.728808</td>\n      <td>-0.385816</td>\n      <td>-0.953446</td>\n      <td>-0.531008</td>\n      <td>-0.390212</td>\n      <td>-1.027701</td>\n      <td>0.270291</td>\n      <td>-0.390777</td>\n      <td>-1.047336</td>\n      <td>-0.728808</td>\n      <td>-0.405428</td>\n      <td>0.013950</td>\n      <td>-0.820570</td>\n      <td>-0.819109</td>\n      <td>-0.305213</td>\n      <td>-0.852782</td>\n      <td>-0.980294</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78278</th>\n      <td>-0.152043</td>\n      <td>-0.030471</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>-0.398589</td>\n      <td>0.319302</td>\n      <td>-0.847606</td>\n      <td>-0.457602</td>\n      <td>-0.391194</td>\n      <td>-0.836977</td>\n      <td>-0.578082</td>\n      <td>-0.415400</td>\n      <td>-0.916476</td>\n      <td>-0.831464</td>\n      <td>-0.402058</td>\n      <td>0.817380</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.807354</td>\n      <td>-0.858285</td>\n      <td>-0.496749</td>\n      <td>-0.402139</td>\n      <td>-0.875875</td>\n      <td>-0.887482</td>\n      <td>-0.403315</td>\n      <td>-0.868502</td>\n      <td>1.846090</td>\n      <td>-0.405024</td>\n      <td>-0.856769</td>\n      <td>-0.496749</td>\n      <td>-0.405480</td>\n      <td>0.027287</td>\n      <td>-0.828575</td>\n      <td>-0.727009</td>\n      <td>-0.407072</td>\n      <td>-1.081661</td>\n      <td>-1.103256</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78279</th>\n      <td>-0.152043</td>\n      <td>0.283512</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>0.391453</td>\n      <td>0.157390</td>\n      <td>-0.838832</td>\n      <td>-0.849395</td>\n      <td>-0.867005</td>\n      <td>-0.789223</td>\n      <td>-0.680442</td>\n      <td>-0.852647</td>\n      <td>-0.910567</td>\n      <td>-0.827425</td>\n      <td>-0.393765</td>\n      <td>0.835050</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.811065</td>\n      <td>-0.853241</td>\n      <td>-0.581478</td>\n      <td>-0.402139</td>\n      <td>-0.875898</td>\n      <td>-0.595670</td>\n      <td>-0.403315</td>\n      <td>-0.868975</td>\n      <td>-0.770796</td>\n      <td>-0.391274</td>\n      <td>-0.863835</td>\n      <td>-0.581478</td>\n      <td>-0.405480</td>\n      <td>-0.077624</td>\n      <td>-0.855083</td>\n      <td>-0.773845</td>\n      <td>-0.459198</td>\n      <td>-1.086932</td>\n      <td>-1.117821</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78280</th>\n      <td>1.198636</td>\n      <td>0.016462</td>\n      <td>-1.789752</td>\n      <td>0.085412</td>\n      <td>-0.507287</td>\n      <td>-0.598994</td>\n      <td>-0.932847</td>\n      <td>0.152863</td>\n      <td>-0.838376</td>\n      <td>-0.695451</td>\n      <td>-0.643683</td>\n      <td>-0.739484</td>\n      <td>-0.590016</td>\n      <td>-0.709366</td>\n      <td>-0.863951</td>\n      <td>-0.805263</td>\n      <td>-0.376198</td>\n      <td>0.795630</td>\n      <td>-1.434570</td>\n      <td>0.337093</td>\n      <td>-0.616757</td>\n      <td>-1.166201</td>\n      <td>0.834602</td>\n      <td>-0.844466</td>\n      <td>-0.684103</td>\n      <td>-0.393863</td>\n      <td>-0.869946</td>\n      <td>-0.501832</td>\n      <td>-0.403315</td>\n      <td>-0.887512</td>\n      <td>-0.894998</td>\n      <td>-0.405024</td>\n      <td>-0.862748</td>\n      <td>-0.684103</td>\n      <td>-0.393512</td>\n      <td>0.159732</td>\n      <td>-0.909681</td>\n      <td>-0.856119</td>\n      <td>-0.275987</td>\n      <td>-1.101124</td>\n      <td>-1.134378</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4761 rows  92 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"       num__mom482  num__mom242   num__bm   num__op   num__gp  num__inv  \\\n39        0.114148    -1.221555 -0.780439 -0.481518 -0.095930 -0.717797   \n40        0.708016    -1.025009 -0.780439 -0.481518 -0.095930 -0.717797   \n41        0.588727    -0.674185 -0.780439 -0.481518 -0.095930 -0.717797   \n66       -0.152043    -0.096694 -0.278284 -1.027436  1.432911 -1.591683   \n67       -0.152043    -0.096694 -0.278284 -1.027436  1.432911 -1.591683   \n...            ...          ...       ...       ...       ...       ...   \n78249    -1.292315    -1.429734  1.132903 -0.671171 -1.397125 -0.509075   \n78250    -1.424066    -1.635540  1.132903 -0.671171 -1.397125 -0.509075   \n78281     1.492163     0.296948 -1.789752  0.085412 -0.507287 -0.598994   \n78282     1.772541     0.142887 -1.789752  0.085412 -0.507287 -0.598994   \n78283     1.554300    -0.010265 -1.789752  0.085412 -0.507287 -0.598994   \n\n       num__mom11  num__mom122  num__amhd  num__ivol_capm  num__ivol_ff5  \\\n39      -1.353610     0.558254   0.508204        0.601670       0.549860   \n40       1.152138    -0.015554   0.507482       -0.108999      -0.048967   \n41       0.418507     0.782500   0.494919        0.960556       0.585115   \n66      -1.606161    -2.066496   2.068987        3.950431       4.096534   \n67      -2.351983    -2.066496   2.068987        2.766578       3.128399   \n...           ...          ...        ...             ...            ...   \n78249    0.018750    -2.037527  -0.848603        1.191216       0.654402   \n78250   -1.187960    -1.857585  -0.816400        1.288830       0.587613   \n78281    0.288522     0.224005  -0.842586       -0.704322      -0.733165   \n78282   -0.469609     0.474893  -0.833023       -0.863574      -0.821552   \n78283    0.185031     0.556194  -0.827457       -0.747979      -0.624860   \n\n       num__beta_bw  num__MAX  num__vol1m  num__vol6m  num__vol12m  \\\n39        -0.591416 -0.560881    0.497645   -0.175013    -0.312837   \n40        -0.709727 -0.369716   -0.133699   -0.133880    -0.258084   \n41        -0.504172  0.612468    1.194725   -0.004759    -0.119211   \n66        -2.445455  3.087190    3.635682    3.184424     2.267580   \n67        -2.053542  1.291341    2.582623    3.415948     2.403138   \n...             ...       ...         ...         ...          ...   \n78249      1.350629  1.849704    1.650750    0.220484     0.329703   \n78250      1.291279  2.190789    1.428214    0.529646     0.494496   \n78281     -0.798543 -0.778034   -0.829631   -0.846416    -0.826171   \n78282     -0.726471 -0.225214   -0.488456   -0.841954    -0.794622   \n78283     -0.648096 -0.477569   -0.377189   -0.776884    -0.764491   \n\n       num__BAspr  num__size  num__lbm  num__lop  num__lgp  num__linv  \\\n39       0.062075  -0.515229 -0.408215 -0.033124  0.109300  -0.026699   \n40      -0.302480  -0.460535 -0.408215 -0.033124  0.109300  -0.026699   \n41      -0.183760  -0.436810 -0.408215 -0.033124  0.109300  -0.026699   \n66       1.472282  -2.342709 -0.382877 -1.061952  1.948956  -0.689050   \n67       8.340880  -2.504108 -0.382877 -1.061952  1.948956  -0.689050   \n...           ...        ...       ...       ...       ...        ...   \n78249   -0.368781   0.547134  0.556766  0.333763 -0.907684  -0.328660   \n78250   -0.367257   0.494757  0.556766  0.333763 -0.907684  -0.328660   \n78281   -0.392569   0.813101 -1.434570  0.337093 -0.616757  -1.166201   \n78282   -0.390061   0.796316 -1.434570  0.337093 -0.616757  -1.166201   \n78283   -0.402058   0.804534 -1.434570  0.337093 -0.616757  -1.166201   \n\n       num__llme  num__l1amhd  num__l1MAX  num__l1BAspr  num__l3amhd  \\\n39     -0.554833     0.507669   -0.285266      0.270540     0.462800   \n40     -0.536835     0.502633   -0.564232      0.061044     0.481386   \n41     -0.589087     0.501912   -0.372573     -0.302765     0.496068   \n66     -1.673135     2.063489    4.003177      3.057275     2.051957   \n67     -1.700324     2.063489    3.093286      1.468365     2.051957   \n...          ...          ...         ...           ...          ...   \n78249   1.049053    -0.897648   -0.237758     -0.315237    -0.929665   \n78250   0.981460    -0.854238    1.852596     -0.368931    -0.931328   \n78281   0.785096    -0.844010   -0.593442     -0.376332    -0.864901   \n78282   0.763320    -0.848221   -0.781948     -0.392669    -0.856127   \n78283   0.735749    -0.838657   -0.227696     -0.390167    -0.855671   \n\n       num__l3MAX  num__l3BAspr  num__l6amhd  num__l6MAX  num__l6BAspr  \\\n39      -0.523765      0.021676     0.383204   -0.278687      0.402250   \n40      -0.744781      0.390686     0.405810   -0.398489      0.036208   \n41      -0.288589      0.269276     0.425136    0.416838      0.008422   \n66       0.123184      1.832875     2.035117    0.544967      0.485602   \n67       0.755039      2.181432     2.035117   -0.375175      1.554498   \n...           ...           ...          ...         ...           ...   \n78249   -0.735822     -0.386994    -0.989261   -0.094609     -0.393469   \n78250   -0.718356     -0.384852    -0.971228   -0.567803     -0.392234   \n78281   -0.587266     -0.403315    -0.893632   -0.918859     -0.405024   \n78282   -0.690745     -0.395040    -0.893655   -0.631482     -0.405024   \n78283   -0.599330     -0.377511    -0.887702   -0.539070     -0.405024   \n\n       num__l12amhd  num__l12MAX  num__l12BAspr  num__l12mom122  \\\n39         0.123209    -0.285266       0.089480       -1.868365   \n40         0.140100    -0.564232      -0.168442       -1.636608   \n41         0.199132    -0.372573      -0.298296       -1.508436   \n66         1.996417     4.003177       0.931388       -1.302168   \n67         1.996417     3.093286       2.697698       -1.576470   \n...             ...          ...            ...             ...   \n78249     -1.092463    -0.237758      -0.405480        0.168724   \n78250     -1.109453     1.852596      -0.402771        0.366459   \n78281     -0.865775    -0.593442      -0.405480        0.175709   \n78282     -0.881532    -0.781948      -0.405480        0.136469   \n78283     -0.885397    -0.227696      -0.405325       -0.037573   \n\n       num__l12ivol_capm  num__l12ivol_ff5  num__l12beta_bw  num__l12vol6m  \\\n39             -0.023381          0.075125        -0.135822      -0.198262   \n40             -0.900703         -0.812385        -0.243596      -0.272191   \n41             -0.009298         -0.138327        -0.299628      -0.377692   \n66              1.504758          1.765495        -1.753375       0.752070   \n67              0.892243          0.948094        -1.628943       0.748329   \n...                  ...               ...              ...            ...   \n78249          -0.825924         -0.749620        -0.298382      -1.154880   \n78250          -0.648510         -0.785161        -0.242835      -1.094196   \n78281          -0.605582         -0.573409        -0.221885      -1.057383   \n78282          -0.960917         -0.938984        -0.281091      -1.166432   \n78283          -0.816942         -0.699459        -0.227173      -1.160779   \n\n       num__l12vol12m  num__amhd_miss  num__BAspr_miss  cat__ind_1.0  \\\n39          -0.118275       -0.150249        -0.037746           0.0   \n40          -0.142440       -0.150249        -0.037746           0.0   \n41          -0.411109       -0.150249        -0.037746           0.0   \n66          -0.216356       -0.150249        -0.037746           0.0   \n67          -0.216356       -0.150249        -0.037746           0.0   \n...               ...             ...              ...           ...   \n78249       -1.009336       -0.150249        -0.037746           0.0   \n78250       -0.995190       -0.150249        -0.037746           0.0   \n78281       -1.143209       -0.150249        -0.037746           0.0   \n78282       -1.169511       -0.150249        -0.037746           0.0   \n78283       -1.171930       -0.150249        -0.037746           0.0   \n\n       cat__ind_2.0  cat__ind_3.0  cat__ind_4.0  cat__ind_5.0  cat__ind_6.0  \\\n39              0.0           0.0           0.0           0.0           0.0   \n40              0.0           0.0           0.0           0.0           0.0   \n41              0.0           0.0           0.0           0.0           0.0   \n66              0.0           0.0           0.0           0.0           0.0   \n67              0.0           0.0           0.0           0.0           0.0   \n...             ...           ...           ...           ...           ...   \n78249           0.0           0.0           0.0           0.0           0.0   \n78250           0.0           0.0           0.0           0.0           0.0   \n78281           0.0           0.0           0.0           0.0           0.0   \n78282           0.0           0.0           0.0           0.0           0.0   \n78283           0.0           0.0           0.0           0.0           0.0   \n\n       cat__ind_7.0  cat__ind_8.0  cat__ind_9.0  cat__ind_10.0  cat__ind_11.0  \\\n39              0.0           0.0           0.0            0.0            0.0   \n40              0.0           0.0           0.0            0.0            0.0   \n41              0.0           0.0           0.0            0.0            0.0   \n66              0.0           0.0           0.0            0.0            0.0   \n67              0.0           0.0           0.0            0.0            0.0   \n...             ...           ...           ...            ...            ...   \n78249           0.0           0.0           0.0            0.0            0.0   \n78250           0.0           0.0           0.0            0.0            0.0   \n78281           1.0           0.0           0.0            0.0            0.0   \n78282           1.0           0.0           0.0            0.0            0.0   \n78283           1.0           0.0           0.0            0.0            0.0   \n\n       cat__ind_12.0  cat__ind_13.0  cat__ind_14.0  cat__ind_15.0  \\\n39               0.0            0.0            0.0            1.0   \n40               0.0            0.0            0.0            1.0   \n41               0.0            0.0            0.0            1.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_16.0  cat__ind_17.0  cat__ind_18.0  cat__ind_19.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_20.0  cat__ind_21.0  cat__ind_22.0  cat__ind_23.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_24.0  cat__ind_25.0  cat__ind_26.0  cat__ind_27.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_28.0  cat__ind_29.0  cat__ind_30.0  cat__ind_31.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            1.0            0.0   \n78250            0.0            0.0            1.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_32.0  cat__ind_33.0  cat__ind_34.0  cat__ind_35.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_36.0  cat__ind_37.0  cat__ind_38.0  cat__ind_39.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_40.0  cat__ind_41.0  cat__ind_42.0  cat__ind_43.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            1.0            0.0   \n67               0.0            0.0            1.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_44.0  cat__ind_45.0  cat__ind_46.0  cat__ind_47.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_48.0  cat__ind_49.0  \n39               0.0            0.0  \n40               0.0            0.0  \n41               0.0            0.0  \n66               0.0            0.0  \n67               0.0            0.0  \n...              ...            ...  \n78249            0.0            0.0  \n78250            0.0            0.0  \n78281            0.0            0.0  \n78282            0.0            0.0  \n78283            0.0            0.0  \n\n[4706 rows x 92 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num__mom482</th>\n      <th>num__mom242</th>\n      <th>num__bm</th>\n      <th>num__op</th>\n      <th>num__gp</th>\n      <th>num__inv</th>\n      <th>num__mom11</th>\n      <th>num__mom122</th>\n      <th>num__amhd</th>\n      <th>num__ivol_capm</th>\n      <th>num__ivol_ff5</th>\n      <th>num__beta_bw</th>\n      <th>num__MAX</th>\n      <th>num__vol1m</th>\n      <th>num__vol6m</th>\n      <th>num__vol12m</th>\n      <th>num__BAspr</th>\n      <th>num__size</th>\n      <th>num__lbm</th>\n      <th>num__lop</th>\n      <th>num__lgp</th>\n      <th>num__linv</th>\n      <th>num__llme</th>\n      <th>num__l1amhd</th>\n      <th>num__l1MAX</th>\n      <th>num__l1BAspr</th>\n      <th>num__l3amhd</th>\n      <th>num__l3MAX</th>\n      <th>num__l3BAspr</th>\n      <th>num__l6amhd</th>\n      <th>num__l6MAX</th>\n      <th>num__l6BAspr</th>\n      <th>num__l12amhd</th>\n      <th>num__l12MAX</th>\n      <th>num__l12BAspr</th>\n      <th>num__l12mom122</th>\n      <th>num__l12ivol_capm</th>\n      <th>num__l12ivol_ff5</th>\n      <th>num__l12beta_bw</th>\n      <th>num__l12vol6m</th>\n      <th>num__l12vol12m</th>\n      <th>num__amhd_miss</th>\n      <th>num__BAspr_miss</th>\n      <th>cat__ind_1.0</th>\n      <th>cat__ind_2.0</th>\n      <th>cat__ind_3.0</th>\n      <th>cat__ind_4.0</th>\n      <th>cat__ind_5.0</th>\n      <th>cat__ind_6.0</th>\n      <th>cat__ind_7.0</th>\n      <th>cat__ind_8.0</th>\n      <th>cat__ind_9.0</th>\n      <th>cat__ind_10.0</th>\n      <th>cat__ind_11.0</th>\n      <th>cat__ind_12.0</th>\n      <th>cat__ind_13.0</th>\n      <th>cat__ind_14.0</th>\n      <th>cat__ind_15.0</th>\n      <th>cat__ind_16.0</th>\n      <th>cat__ind_17.0</th>\n      <th>cat__ind_18.0</th>\n      <th>cat__ind_19.0</th>\n      <th>cat__ind_20.0</th>\n      <th>cat__ind_21.0</th>\n      <th>cat__ind_22.0</th>\n      <th>cat__ind_23.0</th>\n      <th>cat__ind_24.0</th>\n      <th>cat__ind_25.0</th>\n      <th>cat__ind_26.0</th>\n      <th>cat__ind_27.0</th>\n      <th>cat__ind_28.0</th>\n      <th>cat__ind_29.0</th>\n      <th>cat__ind_30.0</th>\n      <th>cat__ind_31.0</th>\n      <th>cat__ind_32.0</th>\n      <th>cat__ind_33.0</th>\n      <th>cat__ind_34.0</th>\n      <th>cat__ind_35.0</th>\n      <th>cat__ind_36.0</th>\n      <th>cat__ind_37.0</th>\n      <th>cat__ind_38.0</th>\n      <th>cat__ind_39.0</th>\n      <th>cat__ind_40.0</th>\n      <th>cat__ind_41.0</th>\n      <th>cat__ind_42.0</th>\n      <th>cat__ind_43.0</th>\n      <th>cat__ind_44.0</th>\n      <th>cat__ind_45.0</th>\n      <th>cat__ind_46.0</th>\n      <th>cat__ind_47.0</th>\n      <th>cat__ind_48.0</th>\n      <th>cat__ind_49.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39</th>\n      <td>0.114148</td>\n      <td>-1.221555</td>\n      <td>-0.780439</td>\n      <td>-0.481518</td>\n      <td>-0.095930</td>\n      <td>-0.717797</td>\n      <td>-1.353610</td>\n      <td>0.558254</td>\n      <td>0.508204</td>\n      <td>0.601670</td>\n      <td>0.549860</td>\n      <td>-0.591416</td>\n      <td>-0.560881</td>\n      <td>0.497645</td>\n      <td>-0.175013</td>\n      <td>-0.312837</td>\n      <td>0.062075</td>\n      <td>-0.515229</td>\n      <td>-0.408215</td>\n      <td>-0.033124</td>\n      <td>0.109300</td>\n      <td>-0.026699</td>\n      <td>-0.554833</td>\n      <td>0.507669</td>\n      <td>-0.285266</td>\n      <td>0.270540</td>\n      <td>0.462800</td>\n      <td>-0.523765</td>\n      <td>0.021676</td>\n      <td>0.383204</td>\n      <td>-0.278687</td>\n      <td>0.402250</td>\n      <td>0.123209</td>\n      <td>-0.285266</td>\n      <td>0.089480</td>\n      <td>-1.868365</td>\n      <td>-0.023381</td>\n      <td>0.075125</td>\n      <td>-0.135822</td>\n      <td>-0.198262</td>\n      <td>-0.118275</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.708016</td>\n      <td>-1.025009</td>\n      <td>-0.780439</td>\n      <td>-0.481518</td>\n      <td>-0.095930</td>\n      <td>-0.717797</td>\n      <td>1.152138</td>\n      <td>-0.015554</td>\n      <td>0.507482</td>\n      <td>-0.108999</td>\n      <td>-0.048967</td>\n      <td>-0.709727</td>\n      <td>-0.369716</td>\n      <td>-0.133699</td>\n      <td>-0.133880</td>\n      <td>-0.258084</td>\n      <td>-0.302480</td>\n      <td>-0.460535</td>\n      <td>-0.408215</td>\n      <td>-0.033124</td>\n      <td>0.109300</td>\n      <td>-0.026699</td>\n      <td>-0.536835</td>\n      <td>0.502633</td>\n      <td>-0.564232</td>\n      <td>0.061044</td>\n      <td>0.481386</td>\n      <td>-0.744781</td>\n      <td>0.390686</td>\n      <td>0.405810</td>\n      <td>-0.398489</td>\n      <td>0.036208</td>\n      <td>0.140100</td>\n      <td>-0.564232</td>\n      <td>-0.168442</td>\n      <td>-1.636608</td>\n      <td>-0.900703</td>\n      <td>-0.812385</td>\n      <td>-0.243596</td>\n      <td>-0.272191</td>\n      <td>-0.142440</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.588727</td>\n      <td>-0.674185</td>\n      <td>-0.780439</td>\n      <td>-0.481518</td>\n      <td>-0.095930</td>\n      <td>-0.717797</td>\n      <td>0.418507</td>\n      <td>0.782500</td>\n      <td>0.494919</td>\n      <td>0.960556</td>\n      <td>0.585115</td>\n      <td>-0.504172</td>\n      <td>0.612468</td>\n      <td>1.194725</td>\n      <td>-0.004759</td>\n      <td>-0.119211</td>\n      <td>-0.183760</td>\n      <td>-0.436810</td>\n      <td>-0.408215</td>\n      <td>-0.033124</td>\n      <td>0.109300</td>\n      <td>-0.026699</td>\n      <td>-0.589087</td>\n      <td>0.501912</td>\n      <td>-0.372573</td>\n      <td>-0.302765</td>\n      <td>0.496068</td>\n      <td>-0.288589</td>\n      <td>0.269276</td>\n      <td>0.425136</td>\n      <td>0.416838</td>\n      <td>0.008422</td>\n      <td>0.199132</td>\n      <td>-0.372573</td>\n      <td>-0.298296</td>\n      <td>-1.508436</td>\n      <td>-0.009298</td>\n      <td>-0.138327</td>\n      <td>-0.299628</td>\n      <td>-0.377692</td>\n      <td>-0.411109</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>-0.152043</td>\n      <td>-0.096694</td>\n      <td>-0.278284</td>\n      <td>-1.027436</td>\n      <td>1.432911</td>\n      <td>-1.591683</td>\n      <td>-1.606161</td>\n      <td>-2.066496</td>\n      <td>2.068987</td>\n      <td>3.950431</td>\n      <td>4.096534</td>\n      <td>-2.445455</td>\n      <td>3.087190</td>\n      <td>3.635682</td>\n      <td>3.184424</td>\n      <td>2.267580</td>\n      <td>1.472282</td>\n      <td>-2.342709</td>\n      <td>-0.382877</td>\n      <td>-1.061952</td>\n      <td>1.948956</td>\n      <td>-0.689050</td>\n      <td>-1.673135</td>\n      <td>2.063489</td>\n      <td>4.003177</td>\n      <td>3.057275</td>\n      <td>2.051957</td>\n      <td>0.123184</td>\n      <td>1.832875</td>\n      <td>2.035117</td>\n      <td>0.544967</td>\n      <td>0.485602</td>\n      <td>1.996417</td>\n      <td>4.003177</td>\n      <td>0.931388</td>\n      <td>-1.302168</td>\n      <td>1.504758</td>\n      <td>1.765495</td>\n      <td>-1.753375</td>\n      <td>0.752070</td>\n      <td>-0.216356</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>-0.152043</td>\n      <td>-0.096694</td>\n      <td>-0.278284</td>\n      <td>-1.027436</td>\n      <td>1.432911</td>\n      <td>-1.591683</td>\n      <td>-2.351983</td>\n      <td>-2.066496</td>\n      <td>2.068987</td>\n      <td>2.766578</td>\n      <td>3.128399</td>\n      <td>-2.053542</td>\n      <td>1.291341</td>\n      <td>2.582623</td>\n      <td>3.415948</td>\n      <td>2.403138</td>\n      <td>8.340880</td>\n      <td>-2.504108</td>\n      <td>-0.382877</td>\n      <td>-1.061952</td>\n      <td>1.948956</td>\n      <td>-0.689050</td>\n      <td>-1.700324</td>\n      <td>2.063489</td>\n      <td>3.093286</td>\n      <td>1.468365</td>\n      <td>2.051957</td>\n      <td>0.755039</td>\n      <td>2.181432</td>\n      <td>2.035117</td>\n      <td>-0.375175</td>\n      <td>1.554498</td>\n      <td>1.996417</td>\n      <td>3.093286</td>\n      <td>2.697698</td>\n      <td>-1.576470</td>\n      <td>0.892243</td>\n      <td>0.948094</td>\n      <td>-1.628943</td>\n      <td>0.748329</td>\n      <td>-0.216356</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78249</th>\n      <td>-1.292315</td>\n      <td>-1.429734</td>\n      <td>1.132903</td>\n      <td>-0.671171</td>\n      <td>-1.397125</td>\n      <td>-0.509075</td>\n      <td>0.018750</td>\n      <td>-2.037527</td>\n      <td>-0.848603</td>\n      <td>1.191216</td>\n      <td>0.654402</td>\n      <td>1.350629</td>\n      <td>1.849704</td>\n      <td>1.650750</td>\n      <td>0.220484</td>\n      <td>0.329703</td>\n      <td>-0.368781</td>\n      <td>0.547134</td>\n      <td>0.556766</td>\n      <td>0.333763</td>\n      <td>-0.907684</td>\n      <td>-0.328660</td>\n      <td>1.049053</td>\n      <td>-0.897648</td>\n      <td>-0.237758</td>\n      <td>-0.315237</td>\n      <td>-0.929665</td>\n      <td>-0.735822</td>\n      <td>-0.386994</td>\n      <td>-0.989261</td>\n      <td>-0.094609</td>\n      <td>-0.393469</td>\n      <td>-1.092463</td>\n      <td>-0.237758</td>\n      <td>-0.405480</td>\n      <td>0.168724</td>\n      <td>-0.825924</td>\n      <td>-0.749620</td>\n      <td>-0.298382</td>\n      <td>-1.154880</td>\n      <td>-1.009336</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78250</th>\n      <td>-1.424066</td>\n      <td>-1.635540</td>\n      <td>1.132903</td>\n      <td>-0.671171</td>\n      <td>-1.397125</td>\n      <td>-0.509075</td>\n      <td>-1.187960</td>\n      <td>-1.857585</td>\n      <td>-0.816400</td>\n      <td>1.288830</td>\n      <td>0.587613</td>\n      <td>1.291279</td>\n      <td>2.190789</td>\n      <td>1.428214</td>\n      <td>0.529646</td>\n      <td>0.494496</td>\n      <td>-0.367257</td>\n      <td>0.494757</td>\n      <td>0.556766</td>\n      <td>0.333763</td>\n      <td>-0.907684</td>\n      <td>-0.328660</td>\n      <td>0.981460</td>\n      <td>-0.854238</td>\n      <td>1.852596</td>\n      <td>-0.368931</td>\n      <td>-0.931328</td>\n      <td>-0.718356</td>\n      <td>-0.384852</td>\n      <td>-0.971228</td>\n      <td>-0.567803</td>\n      <td>-0.392234</td>\n      <td>-1.109453</td>\n      <td>1.852596</td>\n      <td>-0.402771</td>\n      <td>0.366459</td>\n      <td>-0.648510</td>\n      <td>-0.785161</td>\n      <td>-0.242835</td>\n      <td>-1.094196</td>\n      <td>-0.995190</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78281</th>\n      <td>1.492163</td>\n      <td>0.296948</td>\n      <td>-1.789752</td>\n      <td>0.085412</td>\n      <td>-0.507287</td>\n      <td>-0.598994</td>\n      <td>0.288522</td>\n      <td>0.224005</td>\n      <td>-0.842586</td>\n      <td>-0.704322</td>\n      <td>-0.733165</td>\n      <td>-0.798543</td>\n      <td>-0.778034</td>\n      <td>-0.829631</td>\n      <td>-0.846416</td>\n      <td>-0.826171</td>\n      <td>-0.392569</td>\n      <td>0.813101</td>\n      <td>-1.434570</td>\n      <td>0.337093</td>\n      <td>-0.616757</td>\n      <td>-1.166201</td>\n      <td>0.785096</td>\n      <td>-0.844010</td>\n      <td>-0.593442</td>\n      <td>-0.376332</td>\n      <td>-0.864901</td>\n      <td>-0.587266</td>\n      <td>-0.403315</td>\n      <td>-0.893632</td>\n      <td>-0.918859</td>\n      <td>-0.405024</td>\n      <td>-0.865775</td>\n      <td>-0.593442</td>\n      <td>-0.405480</td>\n      <td>0.175709</td>\n      <td>-0.605582</td>\n      <td>-0.573409</td>\n      <td>-0.221885</td>\n      <td>-1.057383</td>\n      <td>-1.143209</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78282</th>\n      <td>1.772541</td>\n      <td>0.142887</td>\n      <td>-1.789752</td>\n      <td>0.085412</td>\n      <td>-0.507287</td>\n      <td>-0.598994</td>\n      <td>-0.469609</td>\n      <td>0.474893</td>\n      <td>-0.833023</td>\n      <td>-0.863574</td>\n      <td>-0.821552</td>\n      <td>-0.726471</td>\n      <td>-0.225214</td>\n      <td>-0.488456</td>\n      <td>-0.841954</td>\n      <td>-0.794622</td>\n      <td>-0.390061</td>\n      <td>0.796316</td>\n      <td>-1.434570</td>\n      <td>0.337093</td>\n      <td>-0.616757</td>\n      <td>-1.166201</td>\n      <td>0.763320</td>\n      <td>-0.848221</td>\n      <td>-0.781948</td>\n      <td>-0.392669</td>\n      <td>-0.856127</td>\n      <td>-0.690745</td>\n      <td>-0.395040</td>\n      <td>-0.893655</td>\n      <td>-0.631482</td>\n      <td>-0.405024</td>\n      <td>-0.881532</td>\n      <td>-0.781948</td>\n      <td>-0.405480</td>\n      <td>0.136469</td>\n      <td>-0.960917</td>\n      <td>-0.938984</td>\n      <td>-0.281091</td>\n      <td>-1.166432</td>\n      <td>-1.169511</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78283</th>\n      <td>1.554300</td>\n      <td>-0.010265</td>\n      <td>-1.789752</td>\n      <td>0.085412</td>\n      <td>-0.507287</td>\n      <td>-0.598994</td>\n      <td>0.185031</td>\n      <td>0.556194</td>\n      <td>-0.827457</td>\n      <td>-0.747979</td>\n      <td>-0.624860</td>\n      <td>-0.648096</td>\n      <td>-0.477569</td>\n      <td>-0.377189</td>\n      <td>-0.776884</td>\n      <td>-0.764491</td>\n      <td>-0.402058</td>\n      <td>0.804534</td>\n      <td>-1.434570</td>\n      <td>0.337093</td>\n      <td>-0.616757</td>\n      <td>-1.166201</td>\n      <td>0.735749</td>\n      <td>-0.838657</td>\n      <td>-0.227696</td>\n      <td>-0.390167</td>\n      <td>-0.855671</td>\n      <td>-0.599330</td>\n      <td>-0.377511</td>\n      <td>-0.887702</td>\n      <td>-0.539070</td>\n      <td>-0.405024</td>\n      <td>-0.885397</td>\n      <td>-0.227696</td>\n      <td>-0.405325</td>\n      <td>-0.037573</td>\n      <td>-0.816942</td>\n      <td>-0.699459</td>\n      <td>-0.227173</td>\n      <td>-1.160779</td>\n      <td>-1.171930</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4706 rows  92 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neurons_base = 16\ndropout_rate = 0.05\n# n_b=8 was ok with small overfit.\n# n_b=32 starts clearly overfitting. \n# 128 fits clearly slower than 64 and becomes somewhat unstable. regularization could make it work, but i see no reason to go wider.\n# 64 seems to have nice balance of flexibility and runtime, but its variance may be too large. dropout makes variance vene worse.\n# 6 hidden layers is probably most this architecture can hold\n\n# in this framework the optimal model seems to have width of 16 or 32, somehow regularized. try l1/l2?\n# w32 can take at most 0.03 dropout.\n# w16 looks good w/o dropout.\n\n# more general point:\n# main drawback of dropout is in incresing variance\n# for textbook problems with high s/n ratio (e.g., mnist) this may be ok.\n# for application like this with very low s/n ratio dropout may be a bad idea.\n\nmodel_snn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*32, activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=X_train.shape[1:]),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*16, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*8, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    Dense(1)])\n\nprint(model_snn.count_params())","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:46.383978Z","iopub.execute_input":"2022-09-07T01:00:46.385256Z","iopub.status.idle":"2022-09-07T01:00:54.402327Z","shell.execute_reply.started":"2022-09-07T01:00:46.385222Z","shell.execute_reply":"2022-09-07T01:00:54.401303Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"2022-09-07 01:00:46.425597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:46.426970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:46.427667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:46.428536: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-09-07 01:00:46.428865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:46.429575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:46.430291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:53.960843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:53.961863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:53.962649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node r","output_type":"stream"},{"name":"stdout","text":"222721\n","output_type":"stream"},{"name":"stderr","text":"ead from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:53.963302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14637 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"neurons_base = 16\nl2_reg_rate = 0.4\n\nmodel_snn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*8, activation=\"selu\", kernel_initializer=\"lecun_normal\", \n                          input_shape=X_train.shape[1:],\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    Dense(1)])\n\nprint(model_snn.count_params())\n\n# similar problem as before: model seems ok in terms of flexibility and variance, but adding dropout breaks it before i can fix overfitting.\n# the solution is to either use smaller models or to use laternative regularizers (which do not increase variance.)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T02:52:08.286173Z","iopub.execute_input":"2022-09-07T02:52:08.286892Z","iopub.status.idle":"2022-09-07T02:52:08.341099Z","shell.execute_reply.started":"2022-09-07T02:52:08.286855Z","shell.execute_reply":"2022-09-07T02:52:08.340052Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"26049\n","output_type":"stream"}]},{"cell_type":"code","source":"neurons_base = 6\nl2_reg_rate = 0.2\n\nmodel_snn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\", \n                          kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate), input_shape=X_train.shape[1:]),\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base/2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base/2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    Dense(1)])\n\nprint(model_snn.count_params())","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:54.459515Z","iopub.execute_input":"2022-09-07T01:00:54.459895Z","iopub.status.idle":"2022-09-07T01:00:54.521256Z","shell.execute_reply.started":"2022-09-07T01:00:54.459858Z","shell.execute_reply":"2022-09-07T01:00:54.520241Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"3247\n","output_type":"stream"}]},{"cell_type":"code","source":"neurons_base = 8\nl2_reg_rate = 0.5\n\nmodel_snn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\", \n                          kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate), input_shape=X_train.shape[1:]),\n    tf.keras.layers.Dense(units=neurons_base*3, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n\n    Dense(1)])\n\nprint(model_snn.count_params())","metadata":{"execution":{"iopub.status.busy":"2022-09-07T02:45:37.177683Z","iopub.execute_input":"2022-09-07T02:45:37.178063Z","iopub.status.idle":"2022-09-07T02:45:37.238284Z","shell.execute_reply.started":"2022-09-07T02:45:37.178027Z","shell.execute_reply":"2022-09-07T02:45:37.237225Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"4433\n","output_type":"stream"}]},{"cell_type":"code","source":"neurons_base = 8\nl2_reg_rate = 0.5\n\nmodel_snn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\", \n                          kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate), input_shape=X_train.shape[1:]),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base/2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    Dense(1)])\n\nprint(model_snn.count_params())\n\n# snn: 32-16-8-4 with 30%l2 reg seems to converge to 5.1% test r2.","metadata":{"execution":{"iopub.status.busy":"2022-09-07T02:40:45.791711Z","iopub.execute_input":"2022-09-07T02:40:45.792706Z","iopub.status.idle":"2022-09-07T02:40:45.838903Z","shell.execute_reply.started":"2022-09-07T02:40:45.792667Z","shell.execute_reply":"2022-09-07T02:40:45.837695Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"3457\n","output_type":"stream"}]},{"cell_type":"code","source":"early_stopping50 = EarlyStopping(patience=50, restore_best_weights=True)\ntime1 = time.time()\noptimizer_adam = tf.keras.optimizers.Adam()\nmodel_snn.compile(loss= \"mean_squared_error\" , optimizer=optimizer_adam, metrics=[\"mean_squared_error\"])\nhistory = model_snn.fit(X_train, y_train, validation_data=(X_val, y_val), \n                         batch_size=2048, epochs=1000, verbose=2, callbacks=[early_stopping50])\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))\n\nprint([r2_score(y_train, model_snn.predict(X_train)), \n       r2_score(y_val, model_snn.predict(X_val)),\n       r2_score(y_test, model_snn.predict(X_test))])\nprint(time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T02:52:15.739120Z","iopub.execute_input":"2022-09-07T02:52:15.739721Z","iopub.status.idle":"2022-09-07T02:52:40.470267Z","shell.execute_reply.started":"2022-09-07T02:52:15.739686Z","shell.execute_reply":"2022-09-07T02:52:40.469366Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Epoch 1/1000\n39/39 - 1s - loss: 232.5919 - mean_squared_error: 133.3574 - val_loss: 199.5337 - val_mean_squared_error: 121.5351\nEpoch 2/1000\n39/39 - 0s - loss: 194.3529 - mean_squared_error: 130.9302 - val_loss: 172.0664 - val_mean_squared_error: 121.6215\nEpoch 3/1000\n39/39 - 0s - loss: 170.6353 - mean_squared_error: 128.6529 - val_loss: 156.1316 - val_mean_squared_error: 121.9355\nEpoch 4/1000\n39/39 - 0s - loss: 157.0099 - mean_squared_error: 128.1639 - val_loss: 143.6440 - val_mean_squared_error: 119.6882\nEpoch 5/1000\n39/39 - 0s - loss: 148.2828 - mean_squared_error: 127.5942 - val_loss: 138.6927 - val_mean_squared_error: 121.0958\nEpoch 6/1000\n39/39 - 0s - loss: 143.0166 - mean_squared_error: 127.6291 - val_loss: 133.3485 - val_mean_squared_error: 119.9878\nEpoch 7/1000\n39/39 - 0s - loss: 139.3758 - mean_squared_error: 127.3787 - val_loss: 130.5997 - val_mean_squared_error: 120.0000\nEpoch 8/1000\n39/39 - 0s - loss: 136.9719 - mean_squared_error: 127.3262 - val_loss: 129.5414 - val_mean_squared_error: 120.8504\nEpoch 9/1000\n39/39 - 0s - loss: 135.3307 - mean_squared_error: 127.2712 - val_loss: 126.0722 - val_mean_squared_error: 118.6282\nEpoch 10/1000\n39/39 - 0s - loss: 134.3410 - mean_squared_error: 127.4120 - val_loss: 126.5668 - val_mean_squared_error: 120.0160\nEpoch 11/1000\n39/39 - 0s - loss: 133.4444 - mean_squared_error: 127.2692 - val_loss: 126.5328 - val_mean_squared_error: 120.7082\nEpoch 12/1000\n39/39 - 0s - loss: 133.0131 - mean_squared_error: 127.4563 - val_loss: 125.5915 - val_mean_squared_error: 120.2773\nEpoch 13/1000\n39/39 - 0s - loss: 132.5704 - mean_squared_error: 127.4406 - val_loss: 126.1160 - val_mean_squared_error: 121.1542\nEpoch 14/1000\n39/39 - 0s - loss: 131.7283 - mean_squared_error: 126.8940 - val_loss: 124.3007 - val_mean_squared_error: 119.6289\nEpoch 15/1000\n39/39 - 0s - loss: 131.5646 - mean_squared_error: 127.0408 - val_loss: 124.1208 - val_mean_squared_error: 119.7781\nEpoch 16/1000\n39/39 - 0s - loss: 131.2522 - mean_squared_error: 126.9935 - val_loss: 125.7062 - val_mean_squared_error: 121.4752\nEpoch 17/1000\n39/39 - 0s - loss: 131.0992 - mean_squared_error: 126.9899 - val_loss: 124.0110 - val_mean_squared_error: 120.0782\nEpoch 18/1000\n39/39 - 0s - loss: 130.9574 - mean_squared_error: 127.0431 - val_loss: 123.1800 - val_mean_squared_error: 119.3340\nEpoch 19/1000\n39/39 - 0s - loss: 130.6541 - mean_squared_error: 126.8615 - val_loss: 123.9031 - val_mean_squared_error: 120.2149\nEpoch 20/1000\n39/39 - 0s - loss: 130.6434 - mean_squared_error: 126.9861 - val_loss: 124.4480 - val_mean_squared_error: 120.8914\nEpoch 21/1000\n39/39 - 0s - loss: 130.5218 - mean_squared_error: 126.9814 - val_loss: 123.2752 - val_mean_squared_error: 119.7196\nEpoch 22/1000\n39/39 - 0s - loss: 130.2483 - mean_squared_error: 126.7567 - val_loss: 123.1763 - val_mean_squared_error: 119.8605\nEpoch 23/1000\n39/39 - 0s - loss: 130.4313 - mean_squared_error: 127.0823 - val_loss: 122.8311 - val_mean_squared_error: 119.4650\nEpoch 24/1000\n39/39 - 0s - loss: 130.0286 - mean_squared_error: 126.7156 - val_loss: 124.1257 - val_mean_squared_error: 120.8364\nEpoch 25/1000\n39/39 - 0s - loss: 129.9997 - mean_squared_error: 126.7748 - val_loss: 122.3581 - val_mean_squared_error: 119.1602\nEpoch 26/1000\n39/39 - 0s - loss: 130.0930 - mean_squared_error: 126.9153 - val_loss: 125.7376 - val_mean_squared_error: 122.5537\nEpoch 27/1000\n39/39 - 0s - loss: 129.9048 - mean_squared_error: 126.8036 - val_loss: 125.0768 - val_mean_squared_error: 121.9574\nEpoch 28/1000\n39/39 - 0s - loss: 129.6591 - mean_squared_error: 126.6117 - val_loss: 125.4659 - val_mean_squared_error: 122.3983\nEpoch 29/1000\n39/39 - 0s - loss: 129.6173 - mean_squared_error: 126.6029 - val_loss: 122.8559 - val_mean_squared_error: 119.8880\nEpoch 30/1000\n39/39 - 0s - loss: 129.5504 - mean_squared_error: 126.6174 - val_loss: 122.8601 - val_mean_squared_error: 119.9022\nEpoch 31/1000\n39/39 - 0s - loss: 130.1342 - mean_squared_error: 127.2777 - val_loss: 123.5290 - val_mean_squared_error: 120.6397\nEpoch 32/1000\n39/39 - 0s - loss: 129.7013 - mean_squared_error: 126.8149 - val_loss: 124.2670 - val_mean_squared_error: 121.4685\nEpoch 33/1000\n39/39 - 0s - loss: 129.4554 - mean_squared_error: 126.6046 - val_loss: 125.1071 - val_mean_squared_error: 122.2832\nEpoch 34/1000\n39/39 - 0s - loss: 129.5390 - mean_squared_error: 126.7565 - val_loss: 121.9775 - val_mean_squared_error: 119.1994\nEpoch 35/1000\n39/39 - 0s - loss: 129.2457 - mean_squared_error: 126.4859 - val_loss: 122.6499 - val_mean_squared_error: 119.9500\nEpoch 36/1000\n39/39 - 0s - loss: 129.5188 - mean_squared_error: 126.8192 - val_loss: 121.5710 - val_mean_squared_error: 118.8914\nEpoch 37/1000\n39/39 - 0s - loss: 129.3770 - mean_squared_error: 126.6895 - val_loss: 121.0484 - val_mean_squared_error: 118.4446\nEpoch 38/1000\n39/39 - 0s - loss: 129.3672 - mean_squared_error: 126.6984 - val_loss: 121.4488 - val_mean_squared_error: 118.8473\nEpoch 39/1000\n39/39 - 0s - loss: 129.2836 - mean_squared_error: 126.6579 - val_loss: 124.2660 - val_mean_squared_error: 121.6769\nEpoch 40/1000\n39/39 - 0s - loss: 129.1678 - mean_squared_error: 126.5414 - val_loss: 123.7156 - val_mean_squared_error: 121.2013\nEpoch 41/1000\n39/39 - 0s - loss: 129.0931 - mean_squared_error: 126.5168 - val_loss: 121.5291 - val_mean_squared_error: 118.9691\nEpoch 42/1000\n39/39 - 0s - loss: 129.1303 - mean_squared_error: 126.5761 - val_loss: 121.8686 - val_mean_squared_error: 119.2805\nEpoch 43/1000\n39/39 - 0s - loss: 129.1108 - mean_squared_error: 126.5500 - val_loss: 121.6219 - val_mean_squared_error: 119.1180\nEpoch 44/1000\n39/39 - 0s - loss: 128.9225 - mean_squared_error: 126.3837 - val_loss: 121.8916 - val_mean_squared_error: 119.4455\nEpoch 45/1000\n39/39 - 0s - loss: 128.9728 - mean_squared_error: 126.4895 - val_loss: 123.9639 - val_mean_squared_error: 121.3568\nEpoch 46/1000\n39/39 - 0s - loss: 128.9390 - mean_squared_error: 126.4221 - val_loss: 121.3733 - val_mean_squared_error: 118.9595\nEpoch 47/1000\n39/39 - 0s - loss: 128.9541 - mean_squared_error: 126.4895 - val_loss: 122.2968 - val_mean_squared_error: 119.9082\nEpoch 48/1000\n39/39 - 0s - loss: 128.8562 - mean_squared_error: 126.4103 - val_loss: 121.5354 - val_mean_squared_error: 119.1249\nEpoch 49/1000\n39/39 - 0s - loss: 129.0274 - mean_squared_error: 126.5974 - val_loss: 122.1770 - val_mean_squared_error: 119.7691\nEpoch 50/1000\n39/39 - 0s - loss: 128.9572 - mean_squared_error: 126.5502 - val_loss: 121.8492 - val_mean_squared_error: 119.4771\nEpoch 51/1000\n39/39 - 0s - loss: 128.8376 - mean_squared_error: 126.4446 - val_loss: 120.9389 - val_mean_squared_error: 118.5319\nEpoch 52/1000\n39/39 - 0s - loss: 128.8797 - mean_squared_error: 126.4916 - val_loss: 122.2536 - val_mean_squared_error: 119.8375\nEpoch 53/1000\n39/39 - 0s - loss: 128.7174 - mean_squared_error: 126.3216 - val_loss: 120.9922 - val_mean_squared_error: 118.6425\nEpoch 54/1000\n39/39 - 0s - loss: 128.5973 - mean_squared_error: 126.2425 - val_loss: 122.5783 - val_mean_squared_error: 120.2135\nEpoch 55/1000\n39/39 - 0s - loss: 128.7638 - mean_squared_error: 126.4212 - val_loss: 122.9702 - val_mean_squared_error: 120.6720\nEpoch 56/1000\n39/39 - 0s - loss: 128.6866 - mean_squared_error: 126.3440 - val_loss: 122.3651 - val_mean_squared_error: 120.0552\nEpoch 57/1000\n39/39 - 0s - loss: 128.6429 - mean_squared_error: 126.3205 - val_loss: 122.6321 - val_mean_squared_error: 120.3597\nEpoch 58/1000\n39/39 - 0s - loss: 128.8852 - mean_squared_error: 126.5741 - val_loss: 120.2685 - val_mean_squared_error: 117.9886\nEpoch 59/1000\n39/39 - 0s - loss: 128.6797 - mean_squared_error: 126.3866 - val_loss: 121.8454 - val_mean_squared_error: 119.6130\nEpoch 60/1000\n39/39 - 0s - loss: 128.8261 - mean_squared_error: 126.5441 - val_loss: 121.1308 - val_mean_squared_error: 118.8288\nEpoch 61/1000\n39/39 - 0s - loss: 128.6709 - mean_squared_error: 126.3768 - val_loss: 123.6869 - val_mean_squared_error: 121.3324\nEpoch 62/1000\n39/39 - 0s - loss: 128.6959 - mean_squared_error: 126.4244 - val_loss: 122.0081 - val_mean_squared_error: 119.8255\nEpoch 63/1000\n39/39 - 0s - loss: 128.7622 - mean_squared_error: 126.5260 - val_loss: 123.5293 - val_mean_squared_error: 121.2709\nEpoch 64/1000\n39/39 - 0s - loss: 128.4829 - mean_squared_error: 126.2294 - val_loss: 121.4218 - val_mean_squared_error: 119.1483\nEpoch 65/1000\n39/39 - 0s - loss: 128.4079 - mean_squared_error: 126.1715 - val_loss: 122.3768 - val_mean_squared_error: 120.2093\nEpoch 66/1000\n39/39 - 0s - loss: 128.4476 - mean_squared_error: 126.2243 - val_loss: 120.8506 - val_mean_squared_error: 118.6299\nEpoch 67/1000\n39/39 - 0s - loss: 128.4138 - mean_squared_error: 126.2164 - val_loss: 124.3636 - val_mean_squared_error: 122.1033\nEpoch 68/1000\n39/39 - 0s - loss: 128.6892 - mean_squared_error: 126.4748 - val_loss: 125.4713 - val_mean_squared_error: 123.2547\nEpoch 69/1000\n39/39 - 0s - loss: 128.3378 - mean_squared_error: 126.1367 - val_loss: 124.0222 - val_mean_squared_error: 121.7417\nEpoch 70/1000\n39/39 - 0s - loss: 128.3859 - mean_squared_error: 126.1684 - val_loss: 122.1802 - val_mean_squared_error: 120.0292\nEpoch 71/1000\n39/39 - 0s - loss: 128.4752 - mean_squared_error: 126.2886 - val_loss: 125.2864 - val_mean_squared_error: 123.0282\nEpoch 72/1000\n39/39 - 0s - loss: 128.4109 - mean_squared_error: 126.2295 - val_loss: 122.7530 - val_mean_squared_error: 120.5694\nEpoch 73/1000\n39/39 - 0s - loss: 128.2596 - mean_squared_error: 126.0789 - val_loss: 124.5590 - val_mean_squared_error: 122.3636\nEpoch 74/1000\n39/39 - 0s - loss: 128.4275 - mean_squared_error: 126.2536 - val_loss: 121.5570 - val_mean_squared_error: 119.4167\nEpoch 75/1000\n39/39 - 0s - loss: 128.3341 - mean_squared_error: 126.1733 - val_loss: 121.9410 - val_mean_squared_error: 119.7786\nEpoch 76/1000\n39/39 - 0s - loss: 128.6384 - mean_squared_error: 126.5144 - val_loss: 122.7635 - val_mean_squared_error: 120.6585\nEpoch 77/1000\n39/39 - 0s - loss: 128.4636 - mean_squared_error: 126.3212 - val_loss: 122.0278 - val_mean_squared_error: 119.8538\nEpoch 78/1000\n39/39 - 0s - loss: 128.3042 - mean_squared_error: 126.1640 - val_loss: 121.8625 - val_mean_squared_error: 119.7559\nEpoch 79/1000\n39/39 - 0s - loss: 128.3477 - mean_squared_error: 126.2087 - val_loss: 124.4348 - val_mean_squared_error: 122.3155\nEpoch 80/1000\n39/39 - 0s - loss: 128.3148 - mean_squared_error: 126.2006 - val_loss: 122.0478 - val_mean_squared_error: 119.9336\nEpoch 81/1000\n39/39 - 0s - loss: 127.9851 - mean_squared_error: 125.8555 - val_loss: 125.2439 - val_mean_squared_error: 123.1313\nEpoch 82/1000\n39/39 - 0s - loss: 128.2656 - mean_squared_error: 126.1714 - val_loss: 122.8108 - val_mean_squared_error: 120.6887\nEpoch 83/1000\n39/39 - 0s - loss: 128.1405 - mean_squared_error: 126.0339 - val_loss: 121.6545 - val_mean_squared_error: 119.5589\nEpoch 84/1000\n39/39 - 0s - loss: 128.2299 - mean_squared_error: 126.1230 - val_loss: 121.7860 - val_mean_squared_error: 119.6577\nEpoch 85/1000\n39/39 - 0s - loss: 128.6003 - mean_squared_error: 126.4902 - val_loss: 123.0596 - val_mean_squared_error: 120.8948\nEpoch 86/1000\n39/39 - 0s - loss: 128.2950 - mean_squared_error: 126.1657 - val_loss: 121.1842 - val_mean_squared_error: 119.0335\nEpoch 87/1000\n39/39 - 0s - loss: 128.1338 - mean_squared_error: 126.0138 - val_loss: 122.3950 - val_mean_squared_error: 120.2695\nEpoch 88/1000\n39/39 - 0s - loss: 128.3373 - mean_squared_error: 126.2543 - val_loss: 124.4513 - val_mean_squared_error: 122.3232\nEpoch 89/1000\n39/39 - 0s - loss: 128.3458 - mean_squared_error: 126.2422 - val_loss: 123.4399 - val_mean_squared_error: 121.3564\nEpoch 90/1000\n39/39 - 0s - loss: 128.2175 - mean_squared_error: 126.1243 - val_loss: 123.1341 - val_mean_squared_error: 121.0276\nEpoch 91/1000\n39/39 - 0s - loss: 128.1003 - mean_squared_error: 125.9965 - val_loss: 120.6539 - val_mean_squared_error: 118.5695\nEpoch 92/1000\n39/39 - 0s - loss: 128.2301 - mean_squared_error: 126.1300 - val_loss: 124.0255 - val_mean_squared_error: 121.9357\nEpoch 93/1000\n39/39 - 0s - loss: 127.9630 - mean_squared_error: 125.8828 - val_loss: 122.1395 - val_mean_squared_error: 120.0690\nEpoch 94/1000\n39/39 - 0s - loss: 128.1517 - mean_squared_error: 126.1015 - val_loss: 122.8693 - val_mean_squared_error: 120.8729\nEpoch 95/1000\n39/39 - 0s - loss: 128.1631 - mean_squared_error: 126.1294 - val_loss: 124.6009 - val_mean_squared_error: 122.5059\nEpoch 96/1000\n39/39 - 0s - loss: 128.0829 - mean_squared_error: 126.0188 - val_loss: 121.8669 - val_mean_squared_error: 119.8689\nEpoch 97/1000\n39/39 - 0s - loss: 127.9905 - mean_squared_error: 125.9538 - val_loss: 122.5026 - val_mean_squared_error: 120.4700\nEpoch 98/1000\n39/39 - 0s - loss: 128.1267 - mean_squared_error: 126.0731 - val_loss: 122.6683 - val_mean_squared_error: 120.7079\nEpoch 99/1000\n39/39 - 0s - loss: 128.0146 - mean_squared_error: 125.9898 - val_loss: 123.6476 - val_mean_squared_error: 121.5824\nEpoch 100/1000\n39/39 - 0s - loss: 128.1222 - mean_squared_error: 126.0809 - val_loss: 125.0355 - val_mean_squared_error: 123.0121\nEpoch 101/1000\n39/39 - 0s - loss: 127.9300 - mean_squared_error: 125.9132 - val_loss: 122.5383 - val_mean_squared_error: 120.5243\nEpoch 102/1000\n39/39 - 0s - loss: 128.1468 - mean_squared_error: 126.1212 - val_loss: 123.0154 - val_mean_squared_error: 121.0446\nEpoch 103/1000\n39/39 - 0s - loss: 128.0666 - mean_squared_error: 126.0465 - val_loss: 122.1475 - val_mean_squared_error: 120.1350\nEpoch 104/1000\n39/39 - 0s - loss: 128.2260 - mean_squared_error: 126.1700 - val_loss: 121.4951 - val_mean_squared_error: 119.4195\nEpoch 105/1000\n39/39 - 0s - loss: 128.1763 - mean_squared_error: 126.1436 - val_loss: 122.9443 - val_mean_squared_error: 120.9726\nEpoch 106/1000\n39/39 - 0s - loss: 128.0928 - mean_squared_error: 126.0629 - val_loss: 121.5273 - val_mean_squared_error: 119.5092\nEpoch 107/1000\n39/39 - 0s - loss: 128.0738 - mean_squared_error: 126.0571 - val_loss: 120.7992 - val_mean_squared_error: 118.7886\nEpoch 108/1000\n39/39 - 0s - loss: 128.0235 - mean_squared_error: 126.0066 - val_loss: 122.7458 - val_mean_squared_error: 120.7904\nMinimum Validation Loss: 120.2685\n[0.0733187954299852, -0.0003727383599947398, 0.017438054475999887]\n24.631619215011597\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"X_train.skew()","metadata":{"execution":{"iopub.status.busy":"2022-09-06T01:58:14.615470Z","iopub.execute_input":"2022-09-06T01:58:14.616043Z","iopub.status.idle":"2022-09-06T01:58:14.787794Z","shell.execute_reply.started":"2022-09-06T01:58:14.615998Z","shell.execute_reply":"2022-09-06T01:58:14.786906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val","metadata":{"execution":{"iopub.status.busy":"2022-09-06T00:36:53.150674Z","iopub.status.idle":"2022-09-06T00:36:53.151429Z","shell.execute_reply.started":"2022-09-06T00:36:53.151166Z","shell.execute_reply":"2022-09-06T00:36:53.151191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on nns:\n# - try classic regularizers (l1, l2 etc)\n# - try different architecture (not snnn)\n# classic architecture:\n# He initialization, elu activation, batch norm, l2 reg, adam.\n\n# - try exotic architecture, e.g., wide'n'deep\n# \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classic architecture:\n\nneurons_base = 16\nl2_reg_rate = 0.3\nhe_init = tf.keras.initializers.HeNormal()\n\nmodel_nn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*8, activation=\"elu\", kernel_initializer=he_init, \n                          kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate), input_shape=X_train.shape[1:]),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"elu\", kernel_initializer=he_init,\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.BatchNormalization(),    \n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"elu\", kernel_initializer=he_init,\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.BatchNormalization(),    \n    tf.keras.layers.Dense(units=neurons_base, activation=\"elu\", kernel_initializer=he_init,\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(1)])\n\nprint(model_nn.count_params())\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T02:55:32.562128Z","iopub.execute_input":"2022-09-07T02:55:32.563292Z","iopub.status.idle":"2022-09-07T02:55:32.643152Z","shell.execute_reply.started":"2022-09-07T02:55:32.563251Z","shell.execute_reply":"2022-09-07T02:55:32.642042Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"22785\n","output_type":"stream"}]},{"cell_type":"code","source":"early_stopping50 = EarlyStopping(patience=50, restore_best_weights=True)\ntime1 = time.time()\noptimizer_adam = tf.keras.optimizers.Adam()\nmodel_nn.compile(loss= \"mean_squared_error\" , optimizer=optimizer_adam, metrics=[\"mean_squared_error\"])\nhistory = model_nn.fit(X_train, y_train, validation_data=(X_val, y_val), \n                         batch_size=2048, epochs=1000, verbose=2, callbacks=[early_stopping50])\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))\n\nprint([r2_score(y_train, model_nn.predict(X_train)), \n       r2_score(y_val, model_nn.predict(X_val)),\n       r2_score(y_test, model_nn.predict(X_test))])\nprint(time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T02:55:32.811205Z","iopub.execute_input":"2022-09-07T02:55:32.811953Z","iopub.status.idle":"2022-09-07T02:56:03.909068Z","shell.execute_reply.started":"2022-09-07T02:55:32.811915Z","shell.execute_reply":"2022-09-07T02:56:03.908059Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Epoch 1/1000\n39/39 - 1s - loss: 258.8375 - mean_squared_error: 133.4472 - val_loss: 226.8497 - val_mean_squared_error: 121.1553\nEpoch 2/1000\n39/39 - 0s - loss: 221.6393 - mean_squared_error: 130.8071 - val_loss: 196.0983 - val_mean_squared_error: 119.2516\nEpoch 3/1000\n39/39 - 0s - loss: 195.3092 - mean_squared_error: 128.4861 - val_loss: 175.8640 - val_mean_squared_error: 118.5182\nEpoch 4/1000\n39/39 - 0s - loss: 177.6655 - mean_squared_error: 127.2538 - val_loss: 161.4191 - val_mean_squared_error: 117.5804\nEpoch 5/1000\n39/39 - 0s - loss: 165.8575 - mean_squared_error: 126.8642 - val_loss: 153.1823 - val_mean_squared_error: 118.7891\nEpoch 6/1000\n39/39 - 0s - loss: 157.9041 - mean_squared_error: 126.9165 - val_loss: 146.4233 - val_mean_squared_error: 118.6809\nEpoch 7/1000\n39/39 - 0s - loss: 152.0497 - mean_squared_error: 126.7609 - val_loss: 141.0490 - val_mean_squared_error: 118.1770\nEpoch 8/1000\n39/39 - 0s - loss: 147.5006 - mean_squared_error: 126.5266 - val_loss: 138.1116 - val_mean_squared_error: 118.9951\nEpoch 9/1000\n39/39 - 0s - loss: 144.1432 - mean_squared_error: 126.4617 - val_loss: 133.4016 - val_mean_squared_error: 117.1374\nEpoch 10/1000\n39/39 - 0s - loss: 141.4128 - mean_squared_error: 126.2714 - val_loss: 131.2945 - val_mean_squared_error: 117.2653\nEpoch 11/1000\n39/39 - 0s - loss: 139.5819 - mean_squared_error: 126.4154 - val_loss: 131.0267 - val_mean_squared_error: 118.7375\nEpoch 12/1000\n39/39 - 0s - loss: 137.8754 - mean_squared_error: 126.3062 - val_loss: 128.6797 - val_mean_squared_error: 117.8291\nEpoch 13/1000\n39/39 - 0s - loss: 136.1935 - mean_squared_error: 125.9535 - val_loss: 127.9086 - val_mean_squared_error: 118.3100\nEpoch 14/1000\n39/39 - 0s - loss: 135.4242 - mean_squared_error: 126.3120 - val_loss: 128.9751 - val_mean_squared_error: 120.3201\nEpoch 15/1000\n39/39 - 0s - loss: 134.3423 - mean_squared_error: 126.0742 - val_loss: 125.6258 - val_mean_squared_error: 117.7879\nEpoch 16/1000\n39/39 - 0s - loss: 133.5489 - mean_squared_error: 126.0578 - val_loss: 124.8217 - val_mean_squared_error: 117.6832\nEpoch 17/1000\n39/39 - 0s - loss: 133.0155 - mean_squared_error: 126.1592 - val_loss: 125.6390 - val_mean_squared_error: 119.0752\nEpoch 18/1000\n39/39 - 0s - loss: 132.3689 - mean_squared_error: 126.0383 - val_loss: 124.1999 - val_mean_squared_error: 118.1134\nEpoch 19/1000\n39/39 - 0s - loss: 131.6480 - mean_squared_error: 125.8021 - val_loss: 122.7211 - val_mean_squared_error: 117.1191\nEpoch 20/1000\n39/39 - 0s - loss: 131.4373 - mean_squared_error: 126.0092 - val_loss: 124.9883 - val_mean_squared_error: 119.7548\nEpoch 21/1000\n39/39 - 0s - loss: 131.3481 - mean_squared_error: 126.2718 - val_loss: 123.7369 - val_mean_squared_error: 118.8052\nEpoch 22/1000\n39/39 - 0s - loss: 130.6666 - mean_squared_error: 125.8699 - val_loss: 123.2757 - val_mean_squared_error: 118.6368\nEpoch 23/1000\n39/39 - 0s - loss: 130.1784 - mean_squared_error: 125.6967 - val_loss: 122.7582 - val_mean_squared_error: 118.4377\nEpoch 24/1000\n39/39 - 0s - loss: 129.8428 - mean_squared_error: 125.6397 - val_loss: 121.0040 - val_mean_squared_error: 116.9320\nEpoch 25/1000\n39/39 - 0s - loss: 129.8050 - mean_squared_error: 125.8315 - val_loss: 119.8868 - val_mean_squared_error: 116.0121\nEpoch 26/1000\n39/39 - 0s - loss: 129.5399 - mean_squared_error: 125.7441 - val_loss: 122.4122 - val_mean_squared_error: 118.7198\nEpoch 27/1000\n39/39 - 0s - loss: 129.3458 - mean_squared_error: 125.7442 - val_loss: 123.6561 - val_mean_squared_error: 120.1442\nEpoch 28/1000\n39/39 - 0s - loss: 129.2022 - mean_squared_error: 125.7462 - val_loss: 121.1380 - val_mean_squared_error: 117.7739\nEpoch 29/1000\n39/39 - 0s - loss: 129.0505 - mean_squared_error: 125.7562 - val_loss: 121.6755 - val_mean_squared_error: 118.4508\nEpoch 30/1000\n39/39 - 0s - loss: 128.7955 - mean_squared_error: 125.6233 - val_loss: 122.7714 - val_mean_squared_error: 119.6656\nEpoch 31/1000\n39/39 - 0s - loss: 128.6821 - mean_squared_error: 125.6276 - val_loss: 122.0852 - val_mean_squared_error: 119.0911\nEpoch 32/1000\n39/39 - 0s - loss: 128.6267 - mean_squared_error: 125.6886 - val_loss: 120.3064 - val_mean_squared_error: 117.4246\nEpoch 33/1000\n39/39 - 0s - loss: 128.5632 - mean_squared_error: 125.7223 - val_loss: 121.9891 - val_mean_squared_error: 119.1954\nEpoch 34/1000\n39/39 - 0s - loss: 128.3614 - mean_squared_error: 125.6154 - val_loss: 121.5637 - val_mean_squared_error: 118.8720\nEpoch 35/1000\n39/39 - 0s - loss: 128.2007 - mean_squared_error: 125.5532 - val_loss: 122.0849 - val_mean_squared_error: 119.4736\nEpoch 36/1000\n39/39 - 0s - loss: 128.4104 - mean_squared_error: 125.8341 - val_loss: 120.5487 - val_mean_squared_error: 118.0057\nEpoch 37/1000\n39/39 - 0s - loss: 127.9567 - mean_squared_error: 125.4370 - val_loss: 122.2044 - val_mean_squared_error: 119.7156\nEpoch 38/1000\n39/39 - 0s - loss: 128.1842 - mean_squared_error: 125.7237 - val_loss: 122.0817 - val_mean_squared_error: 119.6482\nEpoch 39/1000\n39/39 - 0s - loss: 127.9299 - mean_squared_error: 125.5259 - val_loss: 121.1876 - val_mean_squared_error: 118.8135\nEpoch 40/1000\n39/39 - 0s - loss: 127.6796 - mean_squared_error: 125.3357 - val_loss: 119.2158 - val_mean_squared_error: 116.9111\nEpoch 41/1000\n39/39 - 0s - loss: 127.8923 - mean_squared_error: 125.6104 - val_loss: 125.3943 - val_mean_squared_error: 123.1254\nEpoch 42/1000\n39/39 - 0s - loss: 127.7441 - mean_squared_error: 125.4820 - val_loss: 120.7134 - val_mean_squared_error: 118.4848\nEpoch 43/1000\n39/39 - 0s - loss: 127.5623 - mean_squared_error: 125.3577 - val_loss: 121.8583 - val_mean_squared_error: 119.6806\nEpoch 44/1000\n39/39 - 0s - loss: 127.6450 - mean_squared_error: 125.4804 - val_loss: 120.9829 - val_mean_squared_error: 118.8427\nEpoch 45/1000\n39/39 - 0s - loss: 127.5715 - mean_squared_error: 125.4486 - val_loss: 124.4058 - val_mean_squared_error: 122.2998\nEpoch 46/1000\n39/39 - 0s - loss: 127.5254 - mean_squared_error: 125.4263 - val_loss: 120.4666 - val_mean_squared_error: 118.3883\nEpoch 47/1000\n39/39 - 0s - loss: 127.7070 - mean_squared_error: 125.6283 - val_loss: 119.1786 - val_mean_squared_error: 117.1036\nEpoch 48/1000\n39/39 - 0s - loss: 127.7290 - mean_squared_error: 125.6597 - val_loss: 124.2815 - val_mean_squared_error: 122.2138\nEpoch 49/1000\n39/39 - 0s - loss: 127.3666 - mean_squared_error: 125.3181 - val_loss: 121.8192 - val_mean_squared_error: 119.8132\nEpoch 50/1000\n39/39 - 0s - loss: 127.6625 - mean_squared_error: 125.6684 - val_loss: 119.2523 - val_mean_squared_error: 117.2737\nEpoch 51/1000\n39/39 - 0s - loss: 127.4800 - mean_squared_error: 125.5043 - val_loss: 125.4707 - val_mean_squared_error: 123.5038\nEpoch 52/1000\n39/39 - 0s - loss: 127.3246 - mean_squared_error: 125.3817 - val_loss: 124.8117 - val_mean_squared_error: 122.8864\nEpoch 53/1000\n39/39 - 0s - loss: 127.4181 - mean_squared_error: 125.4968 - val_loss: 118.6599 - val_mean_squared_error: 116.7571\nEpoch 54/1000\n39/39 - 0s - loss: 127.1849 - mean_squared_error: 125.2998 - val_loss: 119.2945 - val_mean_squared_error: 117.4350\nEpoch 55/1000\n39/39 - 0s - loss: 127.1841 - mean_squared_error: 125.3248 - val_loss: 121.2479 - val_mean_squared_error: 119.4026\nEpoch 56/1000\n39/39 - 0s - loss: 127.2243 - mean_squared_error: 125.3843 - val_loss: 122.0049 - val_mean_squared_error: 120.1764\nEpoch 57/1000\n39/39 - 0s - loss: 127.1210 - mean_squared_error: 125.3073 - val_loss: 121.6459 - val_mean_squared_error: 119.8475\nEpoch 58/1000\n39/39 - 0s - loss: 127.1688 - mean_squared_error: 125.3643 - val_loss: 121.7512 - val_mean_squared_error: 119.9549\nEpoch 59/1000\n39/39 - 0s - loss: 126.9805 - mean_squared_error: 125.1952 - val_loss: 119.7157 - val_mean_squared_error: 117.9510\nEpoch 60/1000\n39/39 - 0s - loss: 126.9790 - mean_squared_error: 125.2179 - val_loss: 120.4363 - val_mean_squared_error: 118.6843\nEpoch 61/1000\n39/39 - 0s - loss: 126.8152 - mean_squared_error: 125.0761 - val_loss: 123.0566 - val_mean_squared_error: 121.3331\nEpoch 62/1000\n39/39 - 0s - loss: 127.3521 - mean_squared_error: 125.6229 - val_loss: 125.5139 - val_mean_squared_error: 123.7808\nEpoch 63/1000\n39/39 - 0s - loss: 127.0053 - mean_squared_error: 125.2735 - val_loss: 123.9493 - val_mean_squared_error: 122.2313\nEpoch 64/1000\n39/39 - 0s - loss: 126.8574 - mean_squared_error: 125.1470 - val_loss: 121.0898 - val_mean_squared_error: 119.3880\nEpoch 65/1000\n39/39 - 0s - loss: 126.9357 - mean_squared_error: 125.2411 - val_loss: 120.3945 - val_mean_squared_error: 118.7097\nEpoch 66/1000\n39/39 - 0s - loss: 126.8515 - mean_squared_error: 125.1730 - val_loss: 120.2849 - val_mean_squared_error: 118.6116\nEpoch 67/1000\n39/39 - 0s - loss: 126.8490 - mean_squared_error: 125.1802 - val_loss: 118.5135 - val_mean_squared_error: 116.8541\nEpoch 68/1000\n39/39 - 0s - loss: 126.9794 - mean_squared_error: 125.3138 - val_loss: 121.2930 - val_mean_squared_error: 119.6279\nEpoch 69/1000\n39/39 - 0s - loss: 126.9816 - mean_squared_error: 125.3229 - val_loss: 122.2862 - val_mean_squared_error: 120.6300\nEpoch 70/1000\n39/39 - 0s - loss: 127.0998 - mean_squared_error: 125.4478 - val_loss: 121.5112 - val_mean_squared_error: 119.8599\nEpoch 71/1000\n39/39 - 0s - loss: 126.8581 - mean_squared_error: 125.2033 - val_loss: 120.7262 - val_mean_squared_error: 119.0905\nEpoch 72/1000\n39/39 - 0s - loss: 126.6749 - mean_squared_error: 125.0485 - val_loss: 119.3828 - val_mean_squared_error: 117.7677\nEpoch 73/1000\n39/39 - 0s - loss: 126.7386 - mean_squared_error: 125.1252 - val_loss: 118.8532 - val_mean_squared_error: 117.2408\nEpoch 74/1000\n39/39 - 0s - loss: 126.7024 - mean_squared_error: 125.0812 - val_loss: 118.5636 - val_mean_squared_error: 116.9473\nEpoch 75/1000\n39/39 - 0s - loss: 126.6303 - mean_squared_error: 125.0223 - val_loss: 119.8933 - val_mean_squared_error: 118.2993\nEpoch 76/1000\n39/39 - 0s - loss: 126.7884 - mean_squared_error: 125.1897 - val_loss: 124.0949 - val_mean_squared_error: 122.4910\nEpoch 77/1000\n39/39 - 0s - loss: 126.7912 - mean_squared_error: 125.1799 - val_loss: 122.5198 - val_mean_squared_error: 120.9062\nEpoch 78/1000\n39/39 - 0s - loss: 126.8139 - mean_squared_error: 125.2040 - val_loss: 119.5506 - val_mean_squared_error: 117.9497\nEpoch 79/1000\n39/39 - 0s - loss: 126.7255 - mean_squared_error: 125.1206 - val_loss: 124.4297 - val_mean_squared_error: 122.8231\nEpoch 80/1000\n39/39 - 0s - loss: 126.8784 - mean_squared_error: 125.2620 - val_loss: 121.0571 - val_mean_squared_error: 119.4429\nEpoch 81/1000\n39/39 - 0s - loss: 126.7583 - mean_squared_error: 125.1411 - val_loss: 117.3376 - val_mean_squared_error: 115.7277\nEpoch 82/1000\n39/39 - 0s - loss: 126.6389 - mean_squared_error: 125.0328 - val_loss: 124.7299 - val_mean_squared_error: 123.1202\nEpoch 83/1000\n39/39 - 0s - loss: 126.6862 - mean_squared_error: 125.0692 - val_loss: 120.8423 - val_mean_squared_error: 119.2414\nEpoch 84/1000\n39/39 - 0s - loss: 126.7268 - mean_squared_error: 125.1292 - val_loss: 120.2730 - val_mean_squared_error: 118.6844\nEpoch 85/1000\n39/39 - 0s - loss: 126.7480 - mean_squared_error: 125.1504 - val_loss: 122.6872 - val_mean_squared_error: 121.0753\nEpoch 86/1000\n39/39 - 0s - loss: 126.8151 - mean_squared_error: 125.1950 - val_loss: 121.0634 - val_mean_squared_error: 119.4519\nEpoch 87/1000\n39/39 - 0s - loss: 126.4305 - mean_squared_error: 124.8238 - val_loss: 122.6780 - val_mean_squared_error: 121.0862\nEpoch 88/1000\n39/39 - 0s - loss: 126.3542 - mean_squared_error: 124.7727 - val_loss: 120.2364 - val_mean_squared_error: 118.6636\nEpoch 89/1000\n39/39 - 0s - loss: 126.6688 - mean_squared_error: 125.0873 - val_loss: 120.1716 - val_mean_squared_error: 118.5854\nEpoch 90/1000\n39/39 - 0s - loss: 126.4486 - mean_squared_error: 124.8478 - val_loss: 120.1722 - val_mean_squared_error: 118.5737\nEpoch 91/1000\n39/39 - 0s - loss: 126.5291 - mean_squared_error: 124.9372 - val_loss: 127.4312 - val_mean_squared_error: 125.8470\nEpoch 92/1000\n39/39 - 0s - loss: 126.7790 - mean_squared_error: 125.1721 - val_loss: 123.5801 - val_mean_squared_error: 121.9619\nEpoch 93/1000\n39/39 - 0s - loss: 126.4603 - mean_squared_error: 124.8432 - val_loss: 122.7796 - val_mean_squared_error: 121.1700\nEpoch 94/1000\n39/39 - 0s - loss: 126.7145 - mean_squared_error: 125.0912 - val_loss: 124.1283 - val_mean_squared_error: 122.5017\nEpoch 95/1000\n39/39 - 0s - loss: 126.4400 - mean_squared_error: 124.8202 - val_loss: 122.2259 - val_mean_squared_error: 120.6238\nEpoch 96/1000\n39/39 - 0s - loss: 126.4149 - mean_squared_error: 124.8108 - val_loss: 127.2021 - val_mean_squared_error: 125.5789\nEpoch 97/1000\n39/39 - 0s - loss: 126.6138 - mean_squared_error: 124.9787 - val_loss: 121.5582 - val_mean_squared_error: 119.9341\nEpoch 98/1000\n39/39 - 0s - loss: 126.4645 - mean_squared_error: 124.8543 - val_loss: 121.2204 - val_mean_squared_error: 119.6167\nEpoch 99/1000\n39/39 - 0s - loss: 126.2298 - mean_squared_error: 124.6265 - val_loss: 120.9560 - val_mean_squared_error: 119.3596\nEpoch 100/1000\n39/39 - 0s - loss: 126.4414 - mean_squared_error: 124.8319 - val_loss: 121.5070 - val_mean_squared_error: 119.8951\nEpoch 101/1000\n39/39 - 0s - loss: 126.5368 - mean_squared_error: 124.9277 - val_loss: 122.2441 - val_mean_squared_error: 120.6371\nEpoch 102/1000\n39/39 - 0s - loss: 126.3861 - mean_squared_error: 124.7760 - val_loss: 121.6739 - val_mean_squared_error: 120.0630\nEpoch 103/1000\n39/39 - 0s - loss: 126.4229 - mean_squared_error: 124.8094 - val_loss: 122.2423 - val_mean_squared_error: 120.6334\nEpoch 104/1000\n39/39 - 0s - loss: 126.3929 - mean_squared_error: 124.7848 - val_loss: 118.6475 - val_mean_squared_error: 117.0387\nEpoch 105/1000\n39/39 - 0s - loss: 126.3198 - mean_squared_error: 124.6842 - val_loss: 123.0086 - val_mean_squared_error: 121.3475\nEpoch 106/1000\n39/39 - 0s - loss: 126.4936 - mean_squared_error: 124.8332 - val_loss: 121.7876 - val_mean_squared_error: 120.1427\nEpoch 107/1000\n39/39 - 0s - loss: 126.5118 - mean_squared_error: 124.8750 - val_loss: 120.4508 - val_mean_squared_error: 118.8217\nEpoch 108/1000\n39/39 - 0s - loss: 126.2335 - mean_squared_error: 124.6061 - val_loss: 125.1664 - val_mean_squared_error: 123.5485\nEpoch 109/1000\n39/39 - 0s - loss: 126.3780 - mean_squared_error: 124.7568 - val_loss: 119.8112 - val_mean_squared_error: 118.1940\nEpoch 110/1000\n39/39 - 0s - loss: 126.2965 - mean_squared_error: 124.6647 - val_loss: 122.4285 - val_mean_squared_error: 120.7926\nEpoch 111/1000\n39/39 - 0s - loss: 126.3622 - mean_squared_error: 124.7174 - val_loss: 123.4605 - val_mean_squared_error: 121.8155\nEpoch 112/1000\n39/39 - 0s - loss: 126.3418 - mean_squared_error: 124.6932 - val_loss: 121.2935 - val_mean_squared_error: 119.6288\nEpoch 113/1000\n39/39 - 0s - loss: 126.4447 - mean_squared_error: 124.7766 - val_loss: 122.2005 - val_mean_squared_error: 120.5441\nEpoch 114/1000\n39/39 - 0s - loss: 126.0798 - mean_squared_error: 124.4299 - val_loss: 119.2087 - val_mean_squared_error: 117.5639\nEpoch 115/1000\n39/39 - 0s - loss: 126.3331 - mean_squared_error: 124.6805 - val_loss: 121.6600 - val_mean_squared_error: 120.0150\nEpoch 116/1000\n39/39 - 0s - loss: 126.1698 - mean_squared_error: 124.5258 - val_loss: 125.5639 - val_mean_squared_error: 123.9159\nEpoch 117/1000\n39/39 - 0s - loss: 126.1158 - mean_squared_error: 124.4629 - val_loss: 121.5981 - val_mean_squared_error: 119.9390\nEpoch 118/1000\n39/39 - 0s - loss: 126.1506 - mean_squared_error: 124.4854 - val_loss: 122.3081 - val_mean_squared_error: 120.6382\nEpoch 119/1000\n39/39 - 0s - loss: 126.2396 - mean_squared_error: 124.5712 - val_loss: 121.0719 - val_mean_squared_error: 119.4152\nEpoch 120/1000\n39/39 - 0s - loss: 126.0558 - mean_squared_error: 124.3923 - val_loss: 119.7840 - val_mean_squared_error: 118.1197\nEpoch 121/1000\n39/39 - 0s - loss: 126.1452 - mean_squared_error: 124.4769 - val_loss: 121.8354 - val_mean_squared_error: 120.1652\nEpoch 122/1000\n39/39 - 0s - loss: 126.0414 - mean_squared_error: 124.3573 - val_loss: 121.6066 - val_mean_squared_error: 119.9172\nEpoch 123/1000\n39/39 - 0s - loss: 126.1154 - mean_squared_error: 124.4199 - val_loss: 120.2061 - val_mean_squared_error: 118.5190\nEpoch 124/1000\n39/39 - 0s - loss: 126.0766 - mean_squared_error: 124.3848 - val_loss: 120.3462 - val_mean_squared_error: 118.6538\nEpoch 125/1000\n39/39 - 0s - loss: 125.9156 - mean_squared_error: 124.2103 - val_loss: 120.9317 - val_mean_squared_error: 119.2319\nEpoch 126/1000\n39/39 - 0s - loss: 126.0012 - mean_squared_error: 124.3001 - val_loss: 123.5106 - val_mean_squared_error: 121.8058\nEpoch 127/1000\n39/39 - 0s - loss: 125.8722 - mean_squared_error: 124.1562 - val_loss: 122.2996 - val_mean_squared_error: 120.5848\nEpoch 128/1000\n39/39 - 0s - loss: 125.9534 - mean_squared_error: 124.2385 - val_loss: 122.4523 - val_mean_squared_error: 120.7399\nEpoch 129/1000\n39/39 - 0s - loss: 125.9854 - mean_squared_error: 124.2699 - val_loss: 124.2748 - val_mean_squared_error: 122.5516\nEpoch 130/1000\n39/39 - 0s - loss: 125.9278 - mean_squared_error: 124.2006 - val_loss: 122.2620 - val_mean_squared_error: 120.5376\nEpoch 131/1000\n39/39 - 0s - loss: 125.8434 - mean_squared_error: 124.1089 - val_loss: 122.1225 - val_mean_squared_error: 120.3867\nMinimum Validation Loss: 117.3376\n[0.08114895363760255, 0.018796987075215044, 0.009426881468717063]\n30.98833155632019\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"# usually self-norm seems better: it overfits less and runs faster\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
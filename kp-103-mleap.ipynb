{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This is a new version of MLEAP scripts, started in late Aug 2022.\nIt will combine IProject_MLEAP_ANN and IP_MLEAP script, while improving them.","metadata":{}},{"cell_type":"markdown","source":"#### Outline\n\n1. Load libraries and data.\n2. pEDA. Look at feature distribution, fix them if they do not look right.\n3. Train-test split. Most likely couple years into test set. 2015-2018?. Impute missing values.\n4. Transform numerical features, add ohe for inds.\n5. Fit xgb as a baseline, then xgb optuna.\n6. Fit DL.\n\n","metadata":{}},{"cell_type":"code","source":"# 0. Import libraries #\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport os, time, math, re, warnings, random, gc, dill, optuna, pickle, shap\nimport statsmodels.api as sm\nfrom random import sample\n\nfrom sklearn.model_selection import train_test_split, KFold, PredefinedSplit\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNetCV\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn.inspection import permutation_importance\nfrom category_encoders import MEstimateEncoder\nfrom xgboost import XGBRegressor\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import regularizers\n\nplt.style.use('seaborn-white')\nwarnings.simplefilter(action='ignore')\npd.set_option('display.max_columns', 110)\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T00:56:36.806062Z","iopub.execute_input":"2022-09-07T00:56:36.806905Z","iopub.status.idle":"2022-09-07T00:56:47.325280Z","shell.execute_reply.started":"2022-09-07T00:56:36.806861Z","shell.execute_reply":"2022-09-07T00:56:47.324063Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"### target encoding ###\n# source: https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices/notebook\n\nclass CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=4)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded","metadata":{"execution":{"iopub.status.busy":"2022-09-07T00:56:47.327847Z","iopub.execute_input":"2022-09-07T00:56:47.328770Z","iopub.status.idle":"2022-09-07T00:56:47.343128Z","shell.execute_reply.started":"2022-09-07T00:56:47.328709Z","shell.execute_reply":"2022-09-07T00:56:47.340791Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T00:56:47.345040Z","iopub.execute_input":"2022-09-07T00:56:47.346021Z","iopub.status.idle":"2022-09-07T00:56:47.375276Z","shell.execute_reply.started":"2022-09-07T00:56:47.345974Z","shell.execute_reply":"2022-09-07T00:56:47.374070Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"REPLICAS:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"#min_prd_list = range(100, 676, 25)\nmin_prd_list = [150, 650]\n# min_prd_list = [150, 250, 350, 450, 550, 650]\n#min_prd = min_prd_list[0]\nwindows_width = 3*12\ncv_regularizer=0.2\noptuna_trials = 20\ntime0 = time.time()\n\nresults = pd.DataFrame(columns = ['min_prd', 'xgbf_train', 'xgbf_val', 'xgbf_test', \n                                  'xgbgs_train', 'xgbgs_val', 'xgbgs_test', \n                                  'xgbo_train', 'xgbo_val', 'xgbo_test'])\nresults.min_prd = min_prd_list\n\nfor min_prd in min_prd_list:\n\n    with open('../input/mleap-46-preprocessed/MLEAP_46_v7.pkl', 'rb') as pickled_one:\n        df = pickle.load(pickled_one)\n    df = df[df.prd.isin(range(min_prd-1, min_prd+windows_width+10))]\n    df_cnt = df.count()\n    empty_cols = list(df_cnt[df_cnt<int(df.shape[0]/2)].index)\n    df.drop(columns=empty_cols, inplace=True)\n    #display(df.shape, df.head(), df.year.describe(), df.count())\n\n    features_miss_dummies = ['amhd', 'BAspr']\n    for col in features_miss_dummies:\n        if col in df.columns:\n            df[col+'_miss'] = df[col].isnull().astype(int)\n\n    temp_cols = ['PERMNO', 'year', 'prd']\n    df.reset_index(inplace=True, drop=True)\n    X = df.copy()\n    y = X.pop('RET')\n\n    train_indx = X.prd<(min_prd+windows_width-1)\n    val_indx = X['prd'].isin(range(min_prd+windows_width-1, min_prd+windows_width+2))\n    val_indx_extra = X['prd'].isin(range(min_prd+windows_width+5, min_prd+windows_width+8))\n    test_indx = X['prd'].isin(range(min_prd+windows_width+2, min_prd+windows_width+5))\n\n    X_train = X[train_indx]\n    X_val = X[val_indx]\n    X_val_extra = X[val_indx_extra]\n    X_test = X[test_indx]\n    y_train = y[train_indx]\n    y_val = y[val_indx]\n    y_val_extra = y[val_indx_extra]\n    y_test = y[test_indx]\n\n    #display(X_train.head(3), X_train.tail(3), y_train.head(3), y_train.tail(3))\n    display(X_train.shape, X_val.shape, X_test.shape, X_train.prd.describe(), X_val.prd.describe(), X_test.prd.describe())\n\n    X_train.drop(columns=temp_cols, inplace=True)\n    X_val.drop(columns=temp_cols, inplace=True)\n    X_val_extra.drop(columns=temp_cols, inplace=True)\n    X_test.drop(columns=temp_cols, inplace=True)\n\n    #display(X_train.tail())\n    col_cat = ['ind']\n    col_num = [x for x in X_train.columns if x not in col_cat]\n    for col in col_num:\n        X_train[col] = X_train[col].fillna(X_train[col].median())\n        X_val[col] = X_val[col].fillna(X_train[col].median())\n        X_val_extra[col] = X_val_extra[col].fillna(X_train[col].median())\n        X_test[col] = X_test[col].fillna(X_train[col].median())\n    for col in col_cat:\n        X_train[col] = X_train[col].fillna(value=-1000)\n        X_val[col] = X_val[col].fillna(value=-1000)\n        X_val_extra[col] = X_val_extra[col].fillna(value=-1000)\n        X_test[col] = X_test[col].fillna(value=-1000)\n\n    #display(X_train.tail())\n    feature_transformer = ColumnTransformer([('num', StandardScaler(), col_num),\n                                            (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\", drop='if_binary'), col_cat)], \n                                            remainder=\"passthrough\")\n\n    print('Number of features before transformation: ', X_train.shape)\n    train_index, val_index, val_index_extra, test_index = X_train.index, X_val.index, X_val_extra.index, X_test.index\n    X_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\n    X_val = pd.DataFrame(feature_transformer.transform(X_val), columns=feature_transformer.get_feature_names_out())\n    X_val_extra = pd.DataFrame(feature_transformer.transform(X_val_extra), columns=feature_transformer.get_feature_names_out())\n    X_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\n    print('time to do feature proprocessing: ')\n    print('Number of features after transformation: ', X_train.shape, X_val.shape, X_val_extra.shape, X_test.shape)\n    X_train.index = train_index\n    X_val.index = val_index\n    X_val_extra.index = val_index_extra\n    X_test.index = test_index\n    #display(X_train.tail())\n\n    X = pd.concat([X_train, X_val])\n    y = pd.concat([y_train, y_val])\n    #display(X,y)\n\n    X_ = pd.concat([X_train, X_val, X_val_extra])\n    y_ = pd.concat([y_train, y_val, y_val_extra])\n    #display(X,y, X_,y_)\n\n    print('mae of a constant model', mean_absolute_error(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\n    print('R2 of a constant model', r2_score(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\n\n    xgb1 = XGBRegressor(tree_method = 'gpu_hist', n_estimators=400, max_depth=4, eta=0.02, colsample_bytree=0.4, subsample=0.6)\n    xgb1.fit(X_train, y_train)\n    print('fixed XGB train:', mean_absolute_error(y_train, xgb1.predict(X_train)), r2_score(y_train, xgb1.predict(X_train)))\n    print('XGB val:', mean_absolute_error(y_val, xgb1.predict(X_val)), r2_score(y_val, xgb1.predict(X_val)))\n    print('XGB val extra:', mean_absolute_error(y_val_extra, xgb1.predict(X_val_extra)), r2_score(y_val_extra, xgb1.predict(X_val_extra)))\n    print('XGB test:', mean_absolute_error(y_test, xgb1.predict(X_test)), r2_score(y_test, xgb1.predict(X_test)))\n\n    results.loc[results.min_prd==min_prd,'xgbf_train':'xgbf_test'] = \\\n    [r2_score(y_train, xgb1.predict(X_train)), \n    r2_score(y_val, xgb1.predict(X_val)),\n    r2_score(y_test, xgb1.predict(X_test))]\n\n    time1 = time.time()\n\n    # Create a list where train data indices are -1 and validation data indices are 0\n    split_index = [-1 if x in X_train.index else 0 for x in X.index]\n    pds = PredefinedSplit(test_fold = split_index)\n\n    xgb = XGBRegressor(tree_method = 'gpu_hist')\n    param_grid = {'n_estimators':[400, 600, 800], 'max_depth':[2,3,4,5], 'eta':[0.006, 0.012, 0.02], \n                  'subsample':[0.6], 'colsample_bytree':[0.6]}\n    xgbgs = GridSearchCV(estimator = xgb, cv=pds, param_grid=param_grid)\n\n    # Fit with all data\n    xgbgs.fit(X_, y_)\n\n    print('gs XGB', xgbgs.best_params_, xgbgs.best_score_, time.time()-time1)\n    print('XGB train:', mean_absolute_error(y_train, xgbgs.predict(X_train)), r2_score(y_train, xgbgs.predict(X_train)))\n    print('XGB validation:', mean_absolute_error(y_val, xgbgs.predict(X_val)), r2_score(y_val, xgbgs.predict(X_val)))\n    print('XGB validation extra:', mean_absolute_error(y_val_extra, xgbgs.predict(X_val_extra)), r2_score(y_val_extra, xgbgs.predict(X_val_extra)))\n    print('XGB test:', mean_absolute_error(y_test, xgbgs.predict(X_test)), r2_score(y_test, xgbgs.predict(X_test)))\n\n    results.loc[results.min_prd==min_prd,'xgbgs_train':'xgbgs_test'] = \\\n    [r2_score(y_train, xgbgs.predict(X_train)), \n    r2_score(y_val, xgbgs.predict(X_val)),\n    r2_score(y_test, xgbgs.predict(X_test))]\n\n    time1 = time.time()\n    def objective(trial, cv_runs=1, n_splits=2, n_jobs=-1):\n\n        params = {\n        \"tree_method\": 'gpu_hist',\n        \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 800, 1500),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 6),\n        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.0005, 0.03),\n        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.05, 0.95),\n        \"subsample\": trial.suggest_uniform(\"subsample\", 0.1, 0.95),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 0.1, 50.0),\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 0.1, 500.0),\n        \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-10, 100.0),\n        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 0.1, 50)    }\n\n        model = XGBRegressor(**params, njobs=-1)\n        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose = False)\n\n        score_train = r2_score(y_train, model.predict(X_train))\n        score_val = r2_score(y_val, model.predict(X_val))\n        score_val_extra = r2_score(y_val_extra, model.predict(X_val_extra)) \n        score_val = (score_val+score_val_extra)/2\n        overfit = np.abs(score_train-score_val)\n\n        return score_val-cv_regularizer*overfit\n\n\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=optuna_trials)\n    print('Total time for hypermarameter optimization ', time.time()-time1)\n    hp = study.best_params\n    for key, value in hp.items():\n        print(f\"{key:>20s} : {value}\")\n    print(f\"{'best objective value':>20s} : {study.best_value}\")\n    optuna_hyperpars = study.best_params\n    optuna_hyperpars['tree_method']='gpu_hist'\n    optuna_xgb = XGBRegressor(**optuna_hyperpars)\n    optuna_xgb.fit(X, y)\n    print('Optuna XGB train: \\n', \n          mean_absolute_error(y_train, optuna_xgb.predict(X_train)), r2_score(y_train, optuna_xgb.predict(X_train)), '\\nvalidation \\n',\n          mean_absolute_error(y_val, optuna_xgb.predict(X_val)), r2_score(y_val, optuna_xgb.predict(X_val)),\n          mean_absolute_error(y_val_extra, optuna_xgb.predict(X_val_extra)), r2_score(y_val_extra, optuna_xgb.predict(X_val_extra)), '\\ntest \\n',\n          mean_absolute_error(y_test, optuna_xgb.predict(X_test)), r2_score(y_test, optuna_xgb.predict(X_test)))\n\n    results.loc[results.min_prd==min_prd,'xgbo_train':'xgbo_test'] = \\\n    [r2_score(y_train, optuna_xgb.predict(X_train)), \n    r2_score(y_val, optuna_xgb.predict(X_val)),\n    r2_score(y_test, optuna_xgb.predict(X_test))]\n\n    display(results)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T00:56:47.378454Z","iopub.execute_input":"2022-09-07T00:56:47.379386Z","iopub.status.idle":"2022-09-07T01:00:44.704597Z","shell.execute_reply.started":"2022-09-07T00:56:47.379350Z","shell.execute_reply":"2022-09-07T01:00:44.703567Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"(46500, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(4444, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(4403, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    46500.000000\nmean       167.403097\nstd         10.350122\nmin        149.000000\n25%        159.000000\n50%        168.000000\n75%        176.000000\nmax        184.000000\nName: prd, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    4444.000000\nmean      185.997525\nstd         0.816079\nmin       185.000000\n25%       185.000000\n50%       186.000000\n75%       187.000000\nmax       187.000000\nName: prd, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    4403.000000\nmean      188.997956\nstd         0.818208\nmin       188.000000\n25%       188.000000\n50%       189.000000\n75%       190.000000\nmax       190.000000\nName: prd, dtype: float64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (46500, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (46500, 84) (4444, 84) (4381, 84) (4403, 84)\nmae of a constant model 7.989002798117338\nR2 of a constant model 0.0\nfixed XGB train: 7.2936517680386475 0.08209972933431675\nXGB val: 9.333257547436476 0.021046069322619876\nXGB val extra: 7.449474573984752 0.005638548266455157\nXGB test: 10.509277917328513 0.026280919917970325\ngs XGB {'colsample_bytree': 0.6, 'eta': 0.012, 'max_depth': 5, 'n_estimators': 600, 'subsample': 0.6} 0.025436589972033352 52.95054602622986\nXGB train: 7.241671823627634 0.09783003114377553\nXGB validation: 8.837739464119451 0.1338705926983017\nXGB validation extra: 6.983415793741495 0.1367766827196445\nXGB test: 10.455126096822962 0.03312929656455288\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-07 00:57:51,154]\u001b[0m A new study created in memory with name: no-name-3cb446f1-e5f3-469a-a894-c2321b6e4a8f\u001b[0m\n\u001b[32m[I 2022-09-07 00:57:55,484]\u001b[0m Trial 0 finished with value: 0.0010487315872245162 and parameters: {'n_estimators': 853, 'max_depth': 5, 'learning_rate': 0.005554481208627272, 'colsample_bytree': 0.8356093575921506, 'subsample': 0.5432061652329488, 'alpha': 0.11533951508784888, 'lambda': 0.27538060266325076, 'gamma': 0.029340729898137585, 'min_child_weight': 12.736503737730905}. Best is trial 0 with value: 0.0010487315872245162.\u001b[0m\n\u001b[32m[I 2022-09-07 00:57:58,201]\u001b[0m Trial 1 finished with value: 0.008413727532025784 and parameters: {'n_estimators': 1073, 'max_depth': 3, 'learning_rate': 0.007602155679306577, 'colsample_bytree': 0.3615664373117418, 'subsample': 0.7898778548776517, 'alpha': 0.10416280011392451, 'lambda': 367.9752670653509, 'gamma': 2.50851441150189, 'min_child_weight': 3.814335181119885}. Best is trial 1 with value: 0.008413727532025784.\u001b[0m\n\u001b[32m[I 2022-09-07 00:57:59,642]\u001b[0m Trial 2 finished with value: 0.003496426315793987 and parameters: {'n_estimators': 1328, 'max_depth': 3, 'learning_rate': 0.027764607530150014, 'colsample_bytree': 0.7525931428346061, 'subsample': 0.934498535716841, 'alpha': 5.178192777444259, 'lambda': 50.613556542554655, 'gamma': 4.614682070168678e-09, 'min_child_weight': 0.12283370850261424}. Best is trial 1 with value: 0.008413727532025784.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:01,564]\u001b[0m Trial 3 finished with value: 0.0006315750340744053 and parameters: {'n_estimators': 1364, 'max_depth': 6, 'learning_rate': 0.01590923255238317, 'colsample_bytree': 0.4675725775224492, 'subsample': 0.11189115319024258, 'alpha': 0.6586818840006575, 'lambda': 12.261489960419091, 'gamma': 2.146662687506288e-05, 'min_child_weight': 0.4209195838740825}. Best is trial 1 with value: 0.008413727532025784.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:03,192]\u001b[0m Trial 4 finished with value: 0.007155217262674296 and parameters: {'n_estimators': 1071, 'max_depth': 3, 'learning_rate': 0.015319702921059325, 'colsample_bytree': 0.7939533057952717, 'subsample': 0.30502387420350874, 'alpha': 25.747196258726703, 'lambda': 11.432585302590983, 'gamma': 0.34952168744741174, 'min_child_weight': 4.033865450710429}. Best is trial 1 with value: 0.008413727532025784.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:05,602]\u001b[0m Trial 5 finished with value: 0.006198976295951608 and parameters: {'n_estimators': 1152, 'max_depth': 5, 'learning_rate': 0.010058982429138531, 'colsample_bytree': 0.6138138657157906, 'subsample': 0.23737674561039798, 'alpha': 3.9131430224883186, 'lambda': 185.20807391993114, 'gamma': 19.779373547898004, 'min_child_weight': 1.2354800683998637}. Best is trial 1 with value: 0.008413727532025784.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:10,062]\u001b[0m Trial 6 finished with value: -0.0028537303466981585 and parameters: {'n_estimators': 909, 'max_depth': 6, 'learning_rate': 0.02190900847440538, 'colsample_bytree': 0.08662101740998635, 'subsample': 0.8486100344592236, 'alpha': 0.19719845348400494, 'lambda': 17.342623266659228, 'gamma': 0.731946542294778, 'min_child_weight': 0.9523140434090451}. Best is trial 1 with value: 0.008413727532025784.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:12,229]\u001b[0m Trial 7 finished with value: 0.011414419398879706 and parameters: {'n_estimators': 1347, 'max_depth': 2, 'learning_rate': 0.007417143220430349, 'colsample_bytree': 0.6640269634794023, 'subsample': 0.40476828849483937, 'alpha': 3.8115493711892254, 'lambda': 0.5235575943930181, 'gamma': 80.88216965468553, 'min_child_weight': 5.988043264914834}. Best is trial 7 with value: 0.011414419398879706.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:13,147]\u001b[0m Trial 8 finished with value: 0.009407580563050622 and parameters: {'n_estimators': 1398, 'max_depth': 3, 'learning_rate': 0.022942107242752786, 'colsample_bytree': 0.5603434407772575, 'subsample': 0.26303494662506577, 'alpha': 0.8488938079637044, 'lambda': 88.57827498702349, 'gamma': 7.74932209670729e-05, 'min_child_weight': 17.15880518393503}. Best is trial 7 with value: 0.011414419398879706.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:14,954]\u001b[0m Trial 9 finished with value: -0.0030605687595454574 and parameters: {'n_estimators': 993, 'max_depth': 6, 'learning_rate': 0.028210228476687967, 'colsample_bytree': 0.39746087434051613, 'subsample': 0.5001745448772156, 'alpha': 0.3735285981162804, 'lambda': 4.666179407150965, 'gamma': 90.27523977223973, 'min_child_weight': 23.78286067821747}. Best is trial 7 with value: 0.011414419398879706.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:17,687]\u001b[0m Trial 10 finished with value: 0.007425595381170336 and parameters: {'n_estimators': 1234, 'max_depth': 2, 'learning_rate': 0.0011067346082465849, 'colsample_bytree': 0.9315189675392732, 'subsample': 0.5483568184806564, 'alpha': 17.198955425629865, 'lambda': 0.10637626356240769, 'gamma': 1.185870945166455e-08, 'min_child_weight': 7.405547167088014}. Best is trial 7 with value: 0.011414419398879706.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:18,574]\u001b[0m Trial 11 finished with value: 0.01008183545845045 and parameters: {'n_estimators': 1500, 'max_depth': 2, 'learning_rate': 0.021163561175251158, 'colsample_bytree': 0.6121858031914775, 'subsample': 0.34437000815549706, 'alpha': 1.2823217604129595, 'lambda': 0.6886530001042449, 'gamma': 1.0126416204101678e-05, 'min_child_weight': 40.507594823066086}. Best is trial 7 with value: 0.011414419398879706.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:19,374]\u001b[0m Trial 12 finished with value: 0.010053551050618337 and parameters: {'n_estimators': 1482, 'max_depth': 2, 'learning_rate': 0.021003733917823602, 'colsample_bytree': 0.6420091150658681, 'subsample': 0.4053107419006209, 'alpha': 1.9449505208213242, 'lambda': 1.2124957928763336, 'gamma': 5.371703018896343e-07, 'min_child_weight': 49.07140876369456}. Best is trial 7 with value: 0.011414419398879706.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:20,633]\u001b[0m Trial 13 finished with value: 0.011639576305152933 and parameters: {'n_estimators': 1487, 'max_depth': 2, 'learning_rate': 0.010046999641840417, 'colsample_bytree': 0.17503617707261887, 'subsample': 0.6872624925355114, 'alpha': 8.233538788883006, 'lambda': 1.268225759361033, 'gamma': 0.0035106177414781147, 'min_child_weight': 46.558553672654234}. Best is trial 13 with value: 0.011639576305152933.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:23,478]\u001b[0m Trial 14 finished with value: 0.009179717479665306 and parameters: {'n_estimators': 1235, 'max_depth': 4, 'learning_rate': 0.00949061148888648, 'colsample_bytree': 0.1760636458419465, 'subsample': 0.6648459617368178, 'alpha': 8.943079057243436, 'lambda': 2.0096574282482, 'gamma': 0.010595971162733517, 'min_child_weight': 8.192773722165759}. Best is trial 13 with value: 0.011639576305152933.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:26,435]\u001b[0m Trial 15 finished with value: 0.011531828338886597 and parameters: {'n_estimators': 1285, 'max_depth': 2, 'learning_rate': 0.0029253866752842307, 'colsample_bytree': 0.2718964505668128, 'subsample': 0.6974253145640075, 'alpha': 47.36780300204347, 'lambda': 0.44290164595846804, 'gamma': 0.0022208654179520027, 'min_child_weight': 2.954023681716052}. Best is trial 13 with value: 0.011639576305152933.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:30,786]\u001b[0m Trial 16 finished with value: 0.008165751103504681 and parameters: {'n_estimators': 1253, 'max_depth': 4, 'learning_rate': 0.0009935375231354944, 'colsample_bytree': 0.24424266989143228, 'subsample': 0.7232767439363138, 'alpha': 37.16272866153656, 'lambda': 3.7001009271710803, 'gamma': 0.002068626220418703, 'min_child_weight': 0.261258780684948}. Best is trial 13 with value: 0.011639576305152933.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:32,197]\u001b[0m Trial 17 finished with value: 0.011349277091923815 and parameters: {'n_estimators': 1442, 'max_depth': 2, 'learning_rate': 0.012265795542169368, 'colsample_bytree': 0.2814370436977207, 'subsample': 0.6434372564492332, 'alpha': 12.617757703366392, 'lambda': 0.1244587841923982, 'gamma': 0.0014480993725987993, 'min_child_weight': 1.049696973935287}. Best is trial 13 with value: 0.011639576305152933.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:36,348]\u001b[0m Trial 18 finished with value: 0.01471613193622825 and parameters: {'n_estimators': 1312, 'max_depth': 3, 'learning_rate': 0.004580563303691158, 'colsample_bytree': 0.054642666794509576, 'subsample': 0.7989220485693367, 'alpha': 44.506602896391556, 'lambda': 0.30392764109947135, 'gamma': 9.950541908700065e-08, 'min_child_weight': 1.7908938124382492}. Best is trial 18 with value: 0.01471613193622825.\u001b[0m\n\u001b[32m[I 2022-09-07 00:58:39,163]\u001b[0m Trial 19 finished with value: 0.015650065512771795 and parameters: {'n_estimators': 1421, 'max_depth': 3, 'learning_rate': 0.01268081997781313, 'colsample_bytree': 0.05541138494360648, 'subsample': 0.9462953760536352, 'alpha': 8.034813552010322, 'lambda': 1.9184398294778817, 'gamma': 1.132840789369327e-10, 'min_child_weight': 2.174942112625565}. Best is trial 19 with value: 0.015650065512771795.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  48.010602712631226\n        n_estimators : 1421\n           max_depth : 3\n       learning_rate : 0.01268081997781313\n    colsample_bytree : 0.05541138494360648\n           subsample : 0.9462953760536352\n               alpha : 8.034813552010322\n              lambda : 1.9184398294778817\n               gamma : 1.132840789369327e-10\n    min_child_weight : 2.174942112625565\nbest objective value : 0.015650065512771795\nOptuna XGB train: \n 7.381897176222274 0.05315860154502827 \nvalidation \n 9.101018980041395 0.07279894790320474 7.3289798045213175 0.02752500726740692 \ntest \n 10.489568024623782 0.022449379332751596\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   min_prd xgbf_train  xgbf_val xgbf_test xgbgs_train xgbgs_val xgbgs_test  \\\n0      150     0.0821  0.021046  0.026281     0.09783  0.133871   0.033129   \n1      650        NaN       NaN       NaN         NaN       NaN        NaN   \n\n  xgbo_train  xgbo_val xgbo_test  \n0   0.053159  0.072799  0.022449  \n1        NaN       NaN       NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>min_prd</th>\n      <th>xgbf_train</th>\n      <th>xgbf_val</th>\n      <th>xgbf_test</th>\n      <th>xgbgs_train</th>\n      <th>xgbgs_val</th>\n      <th>xgbgs_test</th>\n      <th>xgbo_train</th>\n      <th>xgbo_val</th>\n      <th>xgbo_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>150</td>\n      <td>0.0821</td>\n      <td>0.021046</td>\n      <td>0.026281</td>\n      <td>0.09783</td>\n      <td>0.133871</td>\n      <td>0.033129</td>\n      <td>0.053159</td>\n      <td>0.072799</td>\n      <td>0.022449</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>650</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(61151, 47)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(4761, 47)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(4706, 47)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    61151.000000\nmean       666.117741\nstd         10.398283\nmin        649.000000\n25%        657.000000\n50%        666.000000\n75%        675.000000\nmax        684.000000\nName: prd, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    4761.000000\nmean      685.998110\nstd         0.817223\nmin       685.000000\n25%       685.000000\n50%       686.000000\n75%       687.000000\nmax       687.000000\nName: prd, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    4706.000000\nmean      688.997025\nstd         0.816925\nmin       688.000000\n25%       688.000000\n50%       689.000000\n75%       690.000000\nmax       690.000000\nName: prd, dtype: float64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (61151, 44)\ntime to do feature proprocessing: \nNumber of features after transformation:  (61151, 92) (4761, 92) (4635, 92) (4706, 92)\nmae of a constant model 7.991024255095651\nR2 of a constant model 0.0\nfixed XGB train: 7.37186159053143 0.09370125511856164\nXGB val: 7.769372845620342 0.1202960492766123\nXGB val extra: 8.716766312159114 0.08044960563574766\nXGB test: 8.464771770272549 0.04196543276367293\ngs XGB {'colsample_bytree': 0.6, 'eta': 0.02, 'max_depth': 2, 'n_estimators': 600, 'subsample': 0.6} 0.13082812132204125 56.8817253112793\nXGB train: 7.487009718437392 0.05510111043575783\nXGB validation: 7.5185901740389 0.18438306180043718\nXGB validation extra: 8.477010479339 0.12992120563495957\nXGB test: 8.439680663549156 0.040450396213600026\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-07 00:59:45,575]\u001b[0m A new study created in memory with name: no-name-00b7c1bb-7a28-4aa7-bfce-3e30ef677db0\u001b[0m\n\u001b[32m[I 2022-09-07 00:59:47,274]\u001b[0m Trial 0 finished with value: 0.09552727433179534 and parameters: {'n_estimators': 1079, 'max_depth': 2, 'learning_rate': 0.022306589642374277, 'colsample_bytree': 0.2087114430326722, 'subsample': 0.22079721447293946, 'alpha': 2.1537998766884425, 'lambda': 0.7280692638370136, 'gamma': 23.968358783137713, 'min_child_weight': 23.734630833507307}. Best is trial 0 with value: 0.09552727433179534.\u001b[0m\n\u001b[32m[I 2022-09-07 00:59:48,850]\u001b[0m Trial 1 finished with value: 0.10065358924134826 and parameters: {'n_estimators': 1264, 'max_depth': 4, 'learning_rate': 0.0191275865237689, 'colsample_bytree': 0.8319032492890219, 'subsample': 0.4297256476710566, 'alpha': 0.12715188972160768, 'lambda': 1.0836208339092357, 'gamma': 0.0060436591170761195, 'min_child_weight': 6.909891770856923}. Best is trial 1 with value: 0.10065358924134826.\u001b[0m\n\u001b[32m[I 2022-09-07 00:59:50,881]\u001b[0m Trial 2 finished with value: 0.10392983759138345 and parameters: {'n_estimators': 1477, 'max_depth': 3, 'learning_rate': 0.019754948141593447, 'colsample_bytree': 0.41611119613442266, 'subsample': 0.7072906632446987, 'alpha': 0.1415753949568421, 'lambda': 8.888077381572515, 'gamma': 8.57776528027647e-09, 'min_child_weight': 1.7911947788279619}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 00:59:56,858]\u001b[0m Trial 3 finished with value: 0.09645619774432143 and parameters: {'n_estimators': 1149, 'max_depth': 5, 'learning_rate': 0.004661528984465844, 'colsample_bytree': 0.8697081646540037, 'subsample': 0.3743350883717773, 'alpha': 0.14408979334991634, 'lambda': 5.922405526624956, 'gamma': 2.1690728287350794e-08, 'min_child_weight': 19.453973000373686}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 00:59:59,224]\u001b[0m Trial 4 finished with value: 0.09822922438173969 and parameters: {'n_estimators': 1193, 'max_depth': 2, 'learning_rate': 0.016365283243105613, 'colsample_bytree': 0.15952862465137824, 'subsample': 0.3507851073195948, 'alpha': 1.0964104978644844, 'lambda': 7.098887280932728, 'gamma': 1.4114179244228966e-08, 'min_child_weight': 1.6204158238664734}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:01,818]\u001b[0m Trial 5 finished with value: 0.09827449548694367 and parameters: {'n_estimators': 1209, 'max_depth': 3, 'learning_rate': 0.009354710691065441, 'colsample_bytree': 0.5210200571586477, 'subsample': 0.6517881808811608, 'alpha': 1.8712554406865605, 'lambda': 3.557157196650253, 'gamma': 0.008241791332607969, 'min_child_weight': 1.0984177661511403}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:05,105]\u001b[0m Trial 6 finished with value: 0.09325301527149743 and parameters: {'n_estimators': 981, 'max_depth': 3, 'learning_rate': 0.007372963482353445, 'colsample_bytree': 0.4128638433198256, 'subsample': 0.3054660922367972, 'alpha': 49.874215762122304, 'lambda': 0.25430422034420014, 'gamma': 0.037049448776110654, 'min_child_weight': 4.676110073409408}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:08,276]\u001b[0m Trial 7 finished with value: 0.0757900537258616 and parameters: {'n_estimators': 1292, 'max_depth': 2, 'learning_rate': 0.0033343844628388962, 'colsample_bytree': 0.22157129907904882, 'subsample': 0.3826118273740452, 'alpha': 6.310863425825209, 'lambda': 2.415298219574812, 'gamma': 3.840144184733007e-06, 'min_child_weight': 1.5570879149348316}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:11,244]\u001b[0m Trial 8 finished with value: 0.09643336861059273 and parameters: {'n_estimators': 907, 'max_depth': 4, 'learning_rate': 0.01058126223497552, 'colsample_bytree': 0.7891087655139881, 'subsample': 0.23286171470287656, 'alpha': 0.3175194595742464, 'lambda': 1.6416952188257967, 'gamma': 0.2616208254646788, 'min_child_weight': 1.2622104186821872}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:15,413]\u001b[0m Trial 9 finished with value: 0.08428449383001621 and parameters: {'n_estimators': 998, 'max_depth': 4, 'learning_rate': 0.003679406570343791, 'colsample_bytree': 0.5742556691273492, 'subsample': 0.7863367713848941, 'alpha': 0.31440086317869514, 'lambda': 46.03676958474204, 'gamma': 7.334026874884639e-09, 'min_child_weight': 1.7635374937528514}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:18,193]\u001b[0m Trial 10 finished with value: 0.0975276834354379 and parameters: {'n_estimators': 1494, 'max_depth': 6, 'learning_rate': 0.02894515420477812, 'colsample_bytree': 0.3796740231312675, 'subsample': 0.8828703611966922, 'alpha': 8.204517635515336, 'lambda': 139.5888550291221, 'gamma': 7.600952879388585e-06, 'min_child_weight': 0.1540160145519311}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:20,140]\u001b[0m Trial 11 finished with value: 0.09927551114565207 and parameters: {'n_estimators': 1474, 'max_depth': 3, 'learning_rate': 0.01784698908440493, 'colsample_bytree': 0.7075898097105761, 'subsample': 0.5828180485508037, 'alpha': 0.10460568984097116, 'lambda': 25.94211227376054, 'gamma': 1.5924983058120544e-10, 'min_child_weight': 6.680713406196148}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:21,845]\u001b[0m Trial 12 finished with value: 0.07875169309436066 and parameters: {'n_estimators': 1352, 'max_depth': 5, 'learning_rate': 0.022642283416375822, 'colsample_bytree': 0.6678139290158798, 'subsample': 0.7220427904154001, 'alpha': 0.4708256665953328, 'lambda': 0.12234635957665461, 'gamma': 0.00044378453494819606, 'min_child_weight': 0.30087530776357474}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:23,837]\u001b[0m Trial 13 finished with value: 0.09687243789990707 and parameters: {'n_estimators': 1363, 'max_depth': 5, 'learning_rate': 0.022328335386136607, 'colsample_bytree': 0.33420896364456665, 'subsample': 0.501388371562282, 'alpha': 0.6148167555407296, 'lambda': 24.369456070665212, 'gamma': 2.4437447858698424e-06, 'min_child_weight': 7.823275674560434}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:25,945]\u001b[0m Trial 14 finished with value: 0.09382487020855483 and parameters: {'n_estimators': 1387, 'max_depth': 4, 'learning_rate': 0.013428990692313174, 'colsample_bytree': 0.9092524965525524, 'subsample': 0.5173203993743573, 'alpha': 0.1709709232911909, 'lambda': 1.0445382751286303, 'gamma': 4.4874103614018175, 'min_child_weight': 0.4426190527410569}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:27,229]\u001b[0m Trial 15 finished with value: 0.09203012155692344 and parameters: {'n_estimators': 1275, 'max_depth': 3, 'learning_rate': 0.028093565921659597, 'colsample_bytree': 0.6134045271185176, 'subsample': 0.1254713384683861, 'alpha': 6.0171733488015375, 'lambda': 0.4314593294950433, 'gamma': 0.00046888215927734544, 'min_child_weight': 4.211240223755887}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:30,056]\u001b[0m Trial 16 finished with value: 0.09461804982464965 and parameters: {'n_estimators': 1407, 'max_depth': 6, 'learning_rate': 0.019306821132223692, 'colsample_bytree': 0.46175685719607645, 'subsample': 0.9140560298379995, 'alpha': 0.21949194649401776, 'lambda': 10.4741596500591, 'gamma': 1.6543732753308514e-10, 'min_child_weight': 44.52669745399915}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:32,615]\u001b[0m Trial 17 finished with value: 0.09152864909774741 and parameters: {'n_estimators': 1278, 'max_depth': 3, 'learning_rate': 0.013848778108711303, 'colsample_bytree': 0.28269189060701727, 'subsample': 0.45506405307585535, 'alpha': 0.8725095898073788, 'lambda': 177.73011353174303, 'gamma': 7.139141446994985e-05, 'min_child_weight': 12.470620653953247}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:37,007]\u001b[0m Trial 18 finished with value: 0.0930373916056686 and parameters: {'n_estimators': 1103, 'max_depth': 4, 'learning_rate': 0.026759702096032685, 'colsample_bytree': 0.0525533022464158, 'subsample': 0.6007814355117581, 'alpha': 0.33159450552317793, 'lambda': 359.1116266434958, 'gamma': 1.2351364089591895e-07, 'min_child_weight': 0.6455539501756786}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n\u001b[32m[I 2022-09-07 01:00:38,540]\u001b[0m Trial 19 finished with value: 0.1001078734758184 and parameters: {'n_estimators': 1446, 'max_depth': 4, 'learning_rate': 0.025452245988286562, 'colsample_bytree': 0.7964512267179498, 'subsample': 0.7834117765040322, 'alpha': 0.10329097092630693, 'lambda': 14.774087411288816, 'gamma': 0.0030203767756331297, 'min_child_weight': 3.5270853286212605}. Best is trial 2 with value: 0.10392983759138345.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  52.966289043426514\n        n_estimators : 1477\n           max_depth : 3\n       learning_rate : 0.019754948141593447\n    colsample_bytree : 0.41611119613442266\n           subsample : 0.7072906632446987\n               alpha : 0.1415753949568421\n              lambda : 8.888077381572515\n               gamma : 8.57776528027647e-09\n    min_child_weight : 1.7911947788279619\nbest objective value : 0.10392983759138345\nOptuna XGB train: \n 7.315122797851029 0.10856201100958718 \nvalidation \n 7.341674486916245 0.23359373160350327 8.583436137056328 0.10202295985186882 \ntest \n 8.452829179435007 0.037441996330436655\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   min_prd xgbf_train  xgbf_val xgbf_test xgbgs_train xgbgs_val xgbgs_test  \\\n0      150     0.0821  0.021046  0.026281     0.09783  0.133871   0.033129   \n1      650   0.093701  0.120296  0.041965    0.055101  0.184383    0.04045   \n\n  xgbo_train  xgbo_val xgbo_test  \n0   0.053159  0.072799  0.022449  \n1   0.108562  0.233594  0.037442  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>min_prd</th>\n      <th>xgbf_train</th>\n      <th>xgbf_val</th>\n      <th>xgbf_test</th>\n      <th>xgbgs_train</th>\n      <th>xgbgs_val</th>\n      <th>xgbgs_test</th>\n      <th>xgbo_train</th>\n      <th>xgbo_val</th>\n      <th>xgbo_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>150</td>\n      <td>0.0821</td>\n      <td>0.021046</td>\n      <td>0.026281</td>\n      <td>0.09783</td>\n      <td>0.133871</td>\n      <td>0.033129</td>\n      <td>0.053159</td>\n      <td>0.072799</td>\n      <td>0.022449</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>650</td>\n      <td>0.093701</td>\n      <td>0.120296</td>\n      <td>0.041965</td>\n      <td>0.055101</td>\n      <td>0.184383</td>\n      <td>0.04045</td>\n      <td>0.108562</td>\n      <td>0.233594</td>\n      <td>0.037442</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"display(results.iloc[:,1:].mean())\n# cv_regularizer = 0.5\n# optuna_trials = 80\nprint(time.time()-time0)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:44.706000Z","iopub.execute_input":"2022-09-07T01:00:44.706645Z","iopub.status.idle":"2022-09-07T01:00:44.720757Z","shell.execute_reply.started":"2022-09-07T01:00:44.706606Z","shell.execute_reply":"2022-09-07T01:00:44.719629Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"xgbf_train     0.087900\nxgbf_val       0.070671\nxgbf_test      0.034123\nxgbgs_train    0.076466\nxgbgs_val      0.159127\nxgbgs_test     0.036790\nxgbo_train     0.080860\nxgbo_val       0.153196\nxgbo_test      0.029946\ndtype: float64"},"metadata":{}},{"name":"stdout","text":"237.29979705810547\n","output_type":"stream"}]},{"cell_type":"code","source":"# general point:\n# compared to NN, xgb is harder to regularize\n# in NN, you can simply shrink coefficient towards constant prediction.\n# in xgb, you can not do that. the only way to regularize is via hyperparameters.\n# in other words, by tweaking hyperpars, in NN you can approach R^2=0.0 prediction from a constant model arbitrarily close\n# in xgb, you can not do that.\n# by setting eta as low as 0.1% you can bring r2 down to 0.1%, but lowering eta further actyally increases abs(r2).\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:44.722180Z","iopub.execute_input":"2022-09-07T01:00:44.722899Z","iopub.status.idle":"2022-09-07T01:00:44.732572Z","shell.execute_reply.started":"2022-09-07T01:00:44.722861Z","shell.execute_reply":"2022-09-07T01:00:44.731486Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"optuna_xgb","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:44.734056Z","iopub.execute_input":"2022-09-07T01:00:44.735151Z","iopub.status.idle":"2022-09-07T01:00:44.752332Z","shell.execute_reply.started":"2022-09-07T01:00:44.735109Z","shell.execute_reply":"2022-09-07T01:00:44.749700Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(alpha=0.1415753949568421, base_score=0.5, booster='gbtree',\n             callbacks=None, colsample_bylevel=1, colsample_bynode=1,\n             colsample_bytree=0.41611119613442266, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None,\n             gamma=8.57776528027647e-09, gpu_id=0, grow_policy='depthwise',\n             importance_type=None, interaction_constraints='',\n             lambda=8.888077381572515, learning_rate=0.019754948141593447,\n             max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=3,\n             max_leaves=0, min_child_weight=1.7911947788279619, missing=nan,\n             monotone_constraints='()', n_estimators=1477, n_jobs=0,\n             num_parallel_tree=1, predictor='auto', random_state=0, ...)"},"metadata":{}}]},{"cell_type":"code","source":"explainerxgbc = shap.TreeExplainer(optuna_xgb)\nshap_values_XGBoost_test = explainerxgbc.shap_values(X_test)\n\nvals = np.abs(shap_values_XGBoost_test).mean(0)\nfeature_names = X_test.columns\nfeature_importance = pd.DataFrame(list(zip(feature_names, vals)),\n                                 columns=['col_name','feature_importance_vals'])\nfeature_importance.sort_values(by=['feature_importance_vals'],\n                              ascending=False, inplace=True)\n\nshap.summary_plot(shap_values_XGBoost_test, X_test, \n                  plot_type=\"bar\", plot_size=(6,6), max_display=20)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:44.755048Z","iopub.execute_input":"2022-09-07T01:00:44.755844Z","iopub.status.idle":"2022-09-07T01:00:45.732648Z","shell.execute_reply.started":"2022-09-07T01:00:44.755804Z","shell.execute_reply":"2022-09-07T01:00:45.731680Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x432 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate performance of XGB models:\nr2_xgb1 = r2_score(y_test, xgb1.predict(X_test))\nr2_xgbgs = r2_score(y_test, xgbgs.predict(X_test))\nr2_xgbo = r2_score(y_test, optuna_xgb.predict(X_test))\n\nprint('Min_prd: ', min_prd)\nprint('Constant guess: ', mean_absolute_error(y_test, np.ones(len(y_test))*y_test.mean()), \n      r2_score(y_test, np.ones(len(y_test))*y_test.mean()))\nprint('XGB test:', mean_absolute_error(y_test, xgb1.predict(X_test)), r2_xgb1)\nprint('XGB GS test:', mean_absolute_error(y_test, xgbgs.predict(X_test)), r2_xgbgs)\nprint('Optuna XGB test:', mean_absolute_error(y_test, optuna_xgb.predict(X_test)), r2_xgbo)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:45.734083Z","iopub.execute_input":"2022-09-07T01:00:45.735110Z","iopub.status.idle":"2022-09-07T01:00:45.995382Z","shell.execute_reply.started":"2022-09-07T01:00:45.735071Z","shell.execute_reply":"2022-09-07T01:00:45.993473Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Min_prd:  650\nConstant guess:  8.70343870957194 0.0\nXGB test: 8.464771770272549 0.04196543276367293\nXGB GS test: 8.439680663549156 0.040450396213600026\nOptuna XGB test: 8.452829179435007 0.037441996330436655\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total time for a script: ', time.time()-time0)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:45.999930Z","iopub.execute_input":"2022-09-07T01:00:46.000463Z","iopub.status.idle":"2022-09-07T01:00:46.007960Z","shell.execute_reply.started":"2022-09-07T01:00:46.000415Z","shell.execute_reply":"2022-09-07T01:00:46.005868Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Total time for a script:  238.5843210220337\n","output_type":"stream"}]},{"cell_type":"code","source":"results.iloc[:,1:].mean()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:46.009902Z","iopub.execute_input":"2022-09-07T01:00:46.010796Z","iopub.status.idle":"2022-09-07T01:00:46.026075Z","shell.execute_reply.started":"2022-09-07T01:00:46.010740Z","shell.execute_reply":"2022-09-07T01:00:46.024960Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"xgbf_train     0.087900\nxgbf_val       0.070671\nxgbf_test      0.034123\nxgbgs_train    0.076466\nxgbgs_val      0.159127\nxgbgs_test     0.036790\nxgbo_train     0.080860\nxgbo_val       0.153196\nxgbo_test      0.029946\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# 3yr window, trials=20, cv_reg=0.03: 0.88%. runs 1 hr.\n# 3yr, t=40, cv_reg=0.04: 0.96%.\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:46.027950Z","iopub.execute_input":"2022-09-07T01:00:46.028441Z","iopub.status.idle":"2022-09-07T01:00:46.033781Z","shell.execute_reply.started":"2022-09-07T01:00:46.028405Z","shell.execute_reply":"2022-09-07T01:00:46.032572Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"display(X_train, X_val, X_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:46.035611Z","iopub.execute_input":"2022-09-07T01:00:46.036162Z","iopub.status.idle":"2022-09-07T01:00:46.382725Z","shell.execute_reply.started":"2022-09-07T01:00:46.036125Z","shell.execute_reply":"2022-09-07T01:00:46.381810Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"       num__mom482  num__mom242   num__bm   num__op   num__gp  num__inv  \\\n0        -0.500811     0.216499 -0.340384 -0.328582  0.045307 -0.588233   \n1         0.160589     0.161776 -0.340384 -0.328582  0.045307 -0.588233   \n2         0.575119     0.265471 -0.282249 -0.211330 -0.007926  0.443927   \n3         0.815074     0.890410 -0.282249 -0.211330 -0.007926  0.443927   \n4         0.933095     1.326763 -0.282249 -0.211330 -0.007926  0.443927   \n...            ...          ...       ...       ...       ...       ...   \n78273    -0.152043     0.211762 -1.380615  0.341591 -0.616479 -1.181068   \n78274    -0.152043     0.365979 -1.380615  0.341591 -0.616479 -1.181068   \n78275    -0.152043     0.172720 -1.380615  0.341591 -0.616479 -1.181068   \n78276    -0.152043     0.125273 -1.380615  0.341591 -0.616479 -1.181068   \n78277    -0.152043     0.199470 -1.380615  0.341591 -0.616479 -1.181068   \n\n       num__mom11  num__mom122  num__amhd  num__ivol_capm  num__ivol_ff5  \\\n0       -0.093832     0.000390   0.618694       -0.598732      -0.668599   \n1       -0.209729    -0.031615   0.581445       -0.907245      -0.887352   \n2        2.504443     0.095002   0.569546       -0.379325      -0.203368   \n3        0.677506     1.240795   0.551723       -0.785948      -0.791334   \n4        0.606145     1.563619   0.520774       -0.657968      -0.637011   \n...           ...          ...        ...             ...            ...   \n78273    0.105060    -0.067179  -0.833931       -0.678315      -0.620012   \n78274    0.504697     0.030860  -0.852461       -0.907245      -0.887352   \n78275   -0.155180     0.308838  -0.858578       -0.854257      -0.887352   \n78276    0.553158    -0.147552  -0.858601       -0.486667      -0.753886   \n78277    0.578670     0.098636  -0.852650       -0.513213      -0.549666   \n\n       num__beta_bw  num__MAX  num__vol1m  num__vol6m  num__vol12m  \\\n0         -0.045083 -0.636752   -0.547769   -0.197902    -0.146483   \n1         -0.147561 -0.930676   -1.012115   -0.545421    -0.204533   \n2         -0.209169  0.164629   -0.553321   -0.751682    -0.206327   \n3         -0.258246 -0.498815   -0.926922   -0.837305    -0.233204   \n4         -0.108027 -0.202545   -0.731773   -0.912226    -0.371910   \n...             ...       ...         ...         ...          ...   \n78273     -0.529956 -0.726330   -0.883644   -0.568782    -0.837818   \n78274     -0.654774 -0.851084   -0.969702   -0.566360    -0.841361   \n78275     -0.696841 -0.875052   -0.938885   -0.616002    -0.852235   \n78276     -0.786535 -0.586396   -0.573308   -0.583994    -0.883229   \n78277     -0.862609 -0.493572   -0.754182   -0.575445    -0.859598   \n\n       num__BAspr  num__size  num__lbm  num__lop  num__lgp  num__linv  \\\n0       -0.138587  -0.629521 -0.541304  0.771667  0.622910  -0.842829   \n1       -0.016439  -0.634032 -0.541304  0.771667  0.622910  -0.842829   \n2       -0.326794  -0.527200 -0.378242 -0.328445  0.040105  -0.591069   \n3       -0.016652  -0.491969 -0.378242 -0.328445  0.040105  -0.591069   \n4       -0.187430  -0.460080 -0.378242 -0.328445  0.040105  -0.591069   \n...           ...        ...       ...       ...       ...        ...   \n78273   -0.387942   0.744157 -0.680315  0.045389 -0.815751   0.263971   \n78274   -0.402058   0.771630 -0.680315  0.045389 -0.815751   0.263971   \n78275   -0.402058   0.769599 -0.680315  0.045389 -0.815751   0.263971   \n78276   -0.402058   0.791150 -0.680315  0.045389 -0.815751   0.263971   \n78277   -0.402058   0.830383 -0.680315  0.045389 -0.815751   0.263971   \n\n       num__llme  num__l1amhd  num__l1MAX  num__l1BAspr  num__l3amhd  \\\n0      -0.604599     0.619048   -0.539101     -0.162381     0.640642   \n1      -0.598933     0.613128   -0.640300     -0.139207     0.636029   \n2      -0.622427     0.575878   -0.934985     -0.017309     0.607452   \n3      -0.709632     0.563978    0.163157     -0.327029     0.601532   \n4      -0.707738     0.546154   -0.502006     -0.017522     0.564280   \n...          ...          ...         ...           ...          ...   \n78273   0.771868    -0.839093    1.905235     -0.402139    -0.835373   \n78274   0.766944    -0.839565   -0.730109     -0.388052    -0.839237   \n78275   0.754989    -0.858096   -0.855187     -0.402139    -0.850753   \n78276   0.813726    -0.864214   -0.879217     -0.402139    -0.851225   \n78277   0.805669    -0.864236   -0.589813     -0.402139    -0.869757   \n\n       num__l3MAX  num__l3BAspr  num__l6amhd  num__l6MAX  num__l6BAspr  \\\n0       -0.255652     -0.064216     0.663339    0.842260     -0.043732   \n1       -0.350676     -0.080901     0.654569    0.985874     -0.104737   \n2       -0.544536     -0.163588     0.647515    0.815119     -0.037338   \n3       -0.646577     -0.140418     0.623360   -0.296632     -0.073990   \n4       -0.943714     -0.018536     0.618745   -0.390212     -0.090278   \n...           ...           ...          ...         ...           ...   \n78273   -0.826126     -0.403315    -0.835424   -0.730009     -0.405024   \n78274   -0.739355     -0.403153    -0.834337   -0.709379     -0.392811   \n78275    1.920142     -0.403315    -0.837364   -0.640977     -0.405024   \n78276   -0.737134     -0.389230    -0.853118   -0.858436     -0.405024   \n78277   -0.863253     -0.403315    -0.856983   -0.772983     -0.404866   \n\n       num__l12amhd  num__l12MAX  num__l12BAspr  num__l12mom122  \\\n0          0.610264    -0.539101      -0.158755       -0.190705   \n1          0.628126    -0.640300      -0.037412        0.150876   \n2          0.630172    -0.934985      -0.219313        0.357740   \n3          0.633321     0.163157      -0.178803       -0.361082   \n4          0.639270    -0.502006       0.030898       -0.008430   \n...             ...          ...            ...             ...   \n78273     -0.910094     1.905235      -0.405480        0.324973   \n78274     -0.887051    -0.730109      -0.370414        0.346716   \n78275     -0.868129    -0.855187      -0.405480        0.220208   \n78276     -0.857690    -0.879217      -0.405480       -0.081957   \n78277     -0.859085    -0.589813      -0.405480        0.092781   \n\n       num__l12ivol_capm  num__l12ivol_ff5  num__l12beta_bw  num__l12vol6m  \\\n0              -0.419162         -0.318870         0.700359      -0.292789   \n1              -0.712379         -0.660494         0.536133      -0.415928   \n2              -0.192800         -0.119984         0.589740      -0.395724   \n3              -0.647774         -0.732243         0.731954      -0.485705   \n4              -0.037824          0.107947         0.014322      -0.279744   \n...                  ...               ...              ...            ...   \n78273          -0.770838         -0.669282        -0.879701      -0.948424   \n78274          -0.945976         -0.870085        -0.826236      -1.006173   \n78275          -0.674529         -0.743757        -0.829343      -1.013382   \n78276          -0.435216         -0.471655        -0.541129      -0.954561   \n78277          -0.950414         -0.849883        -0.555705      -0.986327   \n\n       num__l12vol12m  num__amhd_miss  num__BAspr_miss  cat__ind_1.0  \\\n0           -0.036506       -0.150249        -0.037746           0.0   \n1           -0.223150       -0.150249        -0.037746           0.0   \n2           -0.341288       -0.150249        -0.037746           0.0   \n3           -0.355413       -0.150249        -0.037746           0.0   \n4           -0.322183       -0.150249        -0.037746           0.0   \n...               ...             ...              ...           ...   \n78273       -1.041228       -0.150249        -0.037746           0.0   \n78274       -1.076735       -0.150249        -0.037746           0.0   \n78275       -1.057706       -0.150249        -0.037746           0.0   \n78276       -1.039620       -0.150249        -0.037746           0.0   \n78277       -1.032359       -0.150249        -0.037746           0.0   \n\n       cat__ind_2.0  cat__ind_3.0  cat__ind_4.0  cat__ind_5.0  cat__ind_6.0  \\\n0               0.0           0.0           0.0           0.0           0.0   \n1               0.0           0.0           0.0           0.0           0.0   \n2               0.0           0.0           0.0           0.0           0.0   \n3               0.0           0.0           0.0           0.0           0.0   \n4               0.0           0.0           0.0           0.0           0.0   \n...             ...           ...           ...           ...           ...   \n78273           0.0           0.0           0.0           0.0           0.0   \n78274           0.0           0.0           0.0           0.0           0.0   \n78275           0.0           0.0           0.0           0.0           0.0   \n78276           0.0           0.0           0.0           0.0           0.0   \n78277           0.0           0.0           0.0           0.0           0.0   \n\n       cat__ind_7.0  cat__ind_8.0  cat__ind_9.0  cat__ind_10.0  cat__ind_11.0  \\\n0               0.0           0.0           0.0            0.0            0.0   \n1               0.0           0.0           0.0            0.0            0.0   \n2               0.0           0.0           0.0            0.0            0.0   \n3               0.0           0.0           0.0            0.0            0.0   \n4               0.0           0.0           0.0            0.0            0.0   \n...             ...           ...           ...            ...            ...   \n78273           1.0           0.0           0.0            0.0            0.0   \n78274           1.0           0.0           0.0            0.0            0.0   \n78275           1.0           0.0           0.0            0.0            0.0   \n78276           1.0           0.0           0.0            0.0            0.0   \n78277           1.0           0.0           0.0            0.0            0.0   \n\n       cat__ind_12.0  cat__ind_13.0  cat__ind_14.0  cat__ind_15.0  \\\n0                0.0            0.0            0.0            1.0   \n1                0.0            0.0            0.0            1.0   \n2                0.0            0.0            0.0            1.0   \n3                0.0            0.0            0.0            1.0   \n4                0.0            0.0            0.0            1.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_16.0  cat__ind_17.0  cat__ind_18.0  cat__ind_19.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_20.0  cat__ind_21.0  cat__ind_22.0  cat__ind_23.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_24.0  cat__ind_25.0  cat__ind_26.0  cat__ind_27.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_28.0  cat__ind_29.0  cat__ind_30.0  cat__ind_31.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_32.0  cat__ind_33.0  cat__ind_34.0  cat__ind_35.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_36.0  cat__ind_37.0  cat__ind_38.0  cat__ind_39.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_40.0  cat__ind_41.0  cat__ind_42.0  cat__ind_43.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_44.0  cat__ind_45.0  cat__ind_46.0  cat__ind_47.0  \\\n0                0.0            0.0            0.0            0.0   \n1                0.0            0.0            0.0            0.0   \n2                0.0            0.0            0.0            0.0   \n3                0.0            0.0            0.0            0.0   \n4                0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78273            0.0            0.0            0.0            0.0   \n78274            0.0            0.0            0.0            0.0   \n78275            0.0            0.0            0.0            0.0   \n78276            0.0            0.0            0.0            0.0   \n78277            0.0            0.0            0.0            0.0   \n\n       cat__ind_48.0  cat__ind_49.0  \n0                0.0            0.0  \n1                0.0            0.0  \n2                0.0            0.0  \n3                0.0            0.0  \n4                0.0            0.0  \n...              ...            ...  \n78273            0.0            0.0  \n78274            0.0            0.0  \n78275            0.0            0.0  \n78276            0.0            0.0  \n78277            0.0            0.0  \n\n[61151 rows x 92 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num__mom482</th>\n      <th>num__mom242</th>\n      <th>num__bm</th>\n      <th>num__op</th>\n      <th>num__gp</th>\n      <th>num__inv</th>\n      <th>num__mom11</th>\n      <th>num__mom122</th>\n      <th>num__amhd</th>\n      <th>num__ivol_capm</th>\n      <th>num__ivol_ff5</th>\n      <th>num__beta_bw</th>\n      <th>num__MAX</th>\n      <th>num__vol1m</th>\n      <th>num__vol6m</th>\n      <th>num__vol12m</th>\n      <th>num__BAspr</th>\n      <th>num__size</th>\n      <th>num__lbm</th>\n      <th>num__lop</th>\n      <th>num__lgp</th>\n      <th>num__linv</th>\n      <th>num__llme</th>\n      <th>num__l1amhd</th>\n      <th>num__l1MAX</th>\n      <th>num__l1BAspr</th>\n      <th>num__l3amhd</th>\n      <th>num__l3MAX</th>\n      <th>num__l3BAspr</th>\n      <th>num__l6amhd</th>\n      <th>num__l6MAX</th>\n      <th>num__l6BAspr</th>\n      <th>num__l12amhd</th>\n      <th>num__l12MAX</th>\n      <th>num__l12BAspr</th>\n      <th>num__l12mom122</th>\n      <th>num__l12ivol_capm</th>\n      <th>num__l12ivol_ff5</th>\n      <th>num__l12beta_bw</th>\n      <th>num__l12vol6m</th>\n      <th>num__l12vol12m</th>\n      <th>num__amhd_miss</th>\n      <th>num__BAspr_miss</th>\n      <th>cat__ind_1.0</th>\n      <th>cat__ind_2.0</th>\n      <th>cat__ind_3.0</th>\n      <th>cat__ind_4.0</th>\n      <th>cat__ind_5.0</th>\n      <th>cat__ind_6.0</th>\n      <th>cat__ind_7.0</th>\n      <th>cat__ind_8.0</th>\n      <th>cat__ind_9.0</th>\n      <th>cat__ind_10.0</th>\n      <th>cat__ind_11.0</th>\n      <th>cat__ind_12.0</th>\n      <th>cat__ind_13.0</th>\n      <th>cat__ind_14.0</th>\n      <th>cat__ind_15.0</th>\n      <th>cat__ind_16.0</th>\n      <th>cat__ind_17.0</th>\n      <th>cat__ind_18.0</th>\n      <th>cat__ind_19.0</th>\n      <th>cat__ind_20.0</th>\n      <th>cat__ind_21.0</th>\n      <th>cat__ind_22.0</th>\n      <th>cat__ind_23.0</th>\n      <th>cat__ind_24.0</th>\n      <th>cat__ind_25.0</th>\n      <th>cat__ind_26.0</th>\n      <th>cat__ind_27.0</th>\n      <th>cat__ind_28.0</th>\n      <th>cat__ind_29.0</th>\n      <th>cat__ind_30.0</th>\n      <th>cat__ind_31.0</th>\n      <th>cat__ind_32.0</th>\n      <th>cat__ind_33.0</th>\n      <th>cat__ind_34.0</th>\n      <th>cat__ind_35.0</th>\n      <th>cat__ind_36.0</th>\n      <th>cat__ind_37.0</th>\n      <th>cat__ind_38.0</th>\n      <th>cat__ind_39.0</th>\n      <th>cat__ind_40.0</th>\n      <th>cat__ind_41.0</th>\n      <th>cat__ind_42.0</th>\n      <th>cat__ind_43.0</th>\n      <th>cat__ind_44.0</th>\n      <th>cat__ind_45.0</th>\n      <th>cat__ind_46.0</th>\n      <th>cat__ind_47.0</th>\n      <th>cat__ind_48.0</th>\n      <th>cat__ind_49.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.500811</td>\n      <td>0.216499</td>\n      <td>-0.340384</td>\n      <td>-0.328582</td>\n      <td>0.045307</td>\n      <td>-0.588233</td>\n      <td>-0.093832</td>\n      <td>0.000390</td>\n      <td>0.618694</td>\n      <td>-0.598732</td>\n      <td>-0.668599</td>\n      <td>-0.045083</td>\n      <td>-0.636752</td>\n      <td>-0.547769</td>\n      <td>-0.197902</td>\n      <td>-0.146483</td>\n      <td>-0.138587</td>\n      <td>-0.629521</td>\n      <td>-0.541304</td>\n      <td>0.771667</td>\n      <td>0.622910</td>\n      <td>-0.842829</td>\n      <td>-0.604599</td>\n      <td>0.619048</td>\n      <td>-0.539101</td>\n      <td>-0.162381</td>\n      <td>0.640642</td>\n      <td>-0.255652</td>\n      <td>-0.064216</td>\n      <td>0.663339</td>\n      <td>0.842260</td>\n      <td>-0.043732</td>\n      <td>0.610264</td>\n      <td>-0.539101</td>\n      <td>-0.158755</td>\n      <td>-0.190705</td>\n      <td>-0.419162</td>\n      <td>-0.318870</td>\n      <td>0.700359</td>\n      <td>-0.292789</td>\n      <td>-0.036506</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.160589</td>\n      <td>0.161776</td>\n      <td>-0.340384</td>\n      <td>-0.328582</td>\n      <td>0.045307</td>\n      <td>-0.588233</td>\n      <td>-0.209729</td>\n      <td>-0.031615</td>\n      <td>0.581445</td>\n      <td>-0.907245</td>\n      <td>-0.887352</td>\n      <td>-0.147561</td>\n      <td>-0.930676</td>\n      <td>-1.012115</td>\n      <td>-0.545421</td>\n      <td>-0.204533</td>\n      <td>-0.016439</td>\n      <td>-0.634032</td>\n      <td>-0.541304</td>\n      <td>0.771667</td>\n      <td>0.622910</td>\n      <td>-0.842829</td>\n      <td>-0.598933</td>\n      <td>0.613128</td>\n      <td>-0.640300</td>\n      <td>-0.139207</td>\n      <td>0.636029</td>\n      <td>-0.350676</td>\n      <td>-0.080901</td>\n      <td>0.654569</td>\n      <td>0.985874</td>\n      <td>-0.104737</td>\n      <td>0.628126</td>\n      <td>-0.640300</td>\n      <td>-0.037412</td>\n      <td>0.150876</td>\n      <td>-0.712379</td>\n      <td>-0.660494</td>\n      <td>0.536133</td>\n      <td>-0.415928</td>\n      <td>-0.223150</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.575119</td>\n      <td>0.265471</td>\n      <td>-0.282249</td>\n      <td>-0.211330</td>\n      <td>-0.007926</td>\n      <td>0.443927</td>\n      <td>2.504443</td>\n      <td>0.095002</td>\n      <td>0.569546</td>\n      <td>-0.379325</td>\n      <td>-0.203368</td>\n      <td>-0.209169</td>\n      <td>0.164629</td>\n      <td>-0.553321</td>\n      <td>-0.751682</td>\n      <td>-0.206327</td>\n      <td>-0.326794</td>\n      <td>-0.527200</td>\n      <td>-0.378242</td>\n      <td>-0.328445</td>\n      <td>0.040105</td>\n      <td>-0.591069</td>\n      <td>-0.622427</td>\n      <td>0.575878</td>\n      <td>-0.934985</td>\n      <td>-0.017309</td>\n      <td>0.607452</td>\n      <td>-0.544536</td>\n      <td>-0.163588</td>\n      <td>0.647515</td>\n      <td>0.815119</td>\n      <td>-0.037338</td>\n      <td>0.630172</td>\n      <td>-0.934985</td>\n      <td>-0.219313</td>\n      <td>0.357740</td>\n      <td>-0.192800</td>\n      <td>-0.119984</td>\n      <td>0.589740</td>\n      <td>-0.395724</td>\n      <td>-0.341288</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.815074</td>\n      <td>0.890410</td>\n      <td>-0.282249</td>\n      <td>-0.211330</td>\n      <td>-0.007926</td>\n      <td>0.443927</td>\n      <td>0.677506</td>\n      <td>1.240795</td>\n      <td>0.551723</td>\n      <td>-0.785948</td>\n      <td>-0.791334</td>\n      <td>-0.258246</td>\n      <td>-0.498815</td>\n      <td>-0.926922</td>\n      <td>-0.837305</td>\n      <td>-0.233204</td>\n      <td>-0.016652</td>\n      <td>-0.491969</td>\n      <td>-0.378242</td>\n      <td>-0.328445</td>\n      <td>0.040105</td>\n      <td>-0.591069</td>\n      <td>-0.709632</td>\n      <td>0.563978</td>\n      <td>0.163157</td>\n      <td>-0.327029</td>\n      <td>0.601532</td>\n      <td>-0.646577</td>\n      <td>-0.140418</td>\n      <td>0.623360</td>\n      <td>-0.296632</td>\n      <td>-0.073990</td>\n      <td>0.633321</td>\n      <td>0.163157</td>\n      <td>-0.178803</td>\n      <td>-0.361082</td>\n      <td>-0.647774</td>\n      <td>-0.732243</td>\n      <td>0.731954</td>\n      <td>-0.485705</td>\n      <td>-0.355413</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.933095</td>\n      <td>1.326763</td>\n      <td>-0.282249</td>\n      <td>-0.211330</td>\n      <td>-0.007926</td>\n      <td>0.443927</td>\n      <td>0.606145</td>\n      <td>1.563619</td>\n      <td>0.520774</td>\n      <td>-0.657968</td>\n      <td>-0.637011</td>\n      <td>-0.108027</td>\n      <td>-0.202545</td>\n      <td>-0.731773</td>\n      <td>-0.912226</td>\n      <td>-0.371910</td>\n      <td>-0.187430</td>\n      <td>-0.460080</td>\n      <td>-0.378242</td>\n      <td>-0.328445</td>\n      <td>0.040105</td>\n      <td>-0.591069</td>\n      <td>-0.707738</td>\n      <td>0.546154</td>\n      <td>-0.502006</td>\n      <td>-0.017522</td>\n      <td>0.564280</td>\n      <td>-0.943714</td>\n      <td>-0.018536</td>\n      <td>0.618745</td>\n      <td>-0.390212</td>\n      <td>-0.090278</td>\n      <td>0.639270</td>\n      <td>-0.502006</td>\n      <td>0.030898</td>\n      <td>-0.008430</td>\n      <td>-0.037824</td>\n      <td>0.107947</td>\n      <td>0.014322</td>\n      <td>-0.279744</td>\n      <td>-0.322183</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78273</th>\n      <td>-0.152043</td>\n      <td>0.211762</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>0.105060</td>\n      <td>-0.067179</td>\n      <td>-0.833931</td>\n      <td>-0.678315</td>\n      <td>-0.620012</td>\n      <td>-0.529956</td>\n      <td>-0.726330</td>\n      <td>-0.883644</td>\n      <td>-0.568782</td>\n      <td>-0.837818</td>\n      <td>-0.387942</td>\n      <td>0.744157</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.771868</td>\n      <td>-0.839093</td>\n      <td>1.905235</td>\n      <td>-0.402139</td>\n      <td>-0.835373</td>\n      <td>-0.826126</td>\n      <td>-0.403315</td>\n      <td>-0.835424</td>\n      <td>-0.730009</td>\n      <td>-0.405024</td>\n      <td>-0.910094</td>\n      <td>1.905235</td>\n      <td>-0.405480</td>\n      <td>0.324973</td>\n      <td>-0.770838</td>\n      <td>-0.669282</td>\n      <td>-0.879701</td>\n      <td>-0.948424</td>\n      <td>-1.041228</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78274</th>\n      <td>-0.152043</td>\n      <td>0.365979</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>0.504697</td>\n      <td>0.030860</td>\n      <td>-0.852461</td>\n      <td>-0.907245</td>\n      <td>-0.887352</td>\n      <td>-0.654774</td>\n      <td>-0.851084</td>\n      <td>-0.969702</td>\n      <td>-0.566360</td>\n      <td>-0.841361</td>\n      <td>-0.402058</td>\n      <td>0.771630</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.766944</td>\n      <td>-0.839565</td>\n      <td>-0.730109</td>\n      <td>-0.388052</td>\n      <td>-0.839237</td>\n      <td>-0.739355</td>\n      <td>-0.403153</td>\n      <td>-0.834337</td>\n      <td>-0.709379</td>\n      <td>-0.392811</td>\n      <td>-0.887051</td>\n      <td>-0.730109</td>\n      <td>-0.370414</td>\n      <td>0.346716</td>\n      <td>-0.945976</td>\n      <td>-0.870085</td>\n      <td>-0.826236</td>\n      <td>-1.006173</td>\n      <td>-1.076735</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78275</th>\n      <td>-0.152043</td>\n      <td>0.172720</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>-0.155180</td>\n      <td>0.308838</td>\n      <td>-0.858578</td>\n      <td>-0.854257</td>\n      <td>-0.887352</td>\n      <td>-0.696841</td>\n      <td>-0.875052</td>\n      <td>-0.938885</td>\n      <td>-0.616002</td>\n      <td>-0.852235</td>\n      <td>-0.402058</td>\n      <td>0.769599</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.754989</td>\n      <td>-0.858096</td>\n      <td>-0.855187</td>\n      <td>-0.402139</td>\n      <td>-0.850753</td>\n      <td>1.920142</td>\n      <td>-0.403315</td>\n      <td>-0.837364</td>\n      <td>-0.640977</td>\n      <td>-0.405024</td>\n      <td>-0.868129</td>\n      <td>-0.855187</td>\n      <td>-0.405480</td>\n      <td>0.220208</td>\n      <td>-0.674529</td>\n      <td>-0.743757</td>\n      <td>-0.829343</td>\n      <td>-1.013382</td>\n      <td>-1.057706</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78276</th>\n      <td>-0.152043</td>\n      <td>0.125273</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>0.553158</td>\n      <td>-0.147552</td>\n      <td>-0.858601</td>\n      <td>-0.486667</td>\n      <td>-0.753886</td>\n      <td>-0.786535</td>\n      <td>-0.586396</td>\n      <td>-0.573308</td>\n      <td>-0.583994</td>\n      <td>-0.883229</td>\n      <td>-0.402058</td>\n      <td>0.791150</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.813726</td>\n      <td>-0.864214</td>\n      <td>-0.879217</td>\n      <td>-0.402139</td>\n      <td>-0.851225</td>\n      <td>-0.737134</td>\n      <td>-0.389230</td>\n      <td>-0.853118</td>\n      <td>-0.858436</td>\n      <td>-0.405024</td>\n      <td>-0.857690</td>\n      <td>-0.879217</td>\n      <td>-0.405480</td>\n      <td>-0.081957</td>\n      <td>-0.435216</td>\n      <td>-0.471655</td>\n      <td>-0.541129</td>\n      <td>-0.954561</td>\n      <td>-1.039620</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78277</th>\n      <td>-0.152043</td>\n      <td>0.199470</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>0.578670</td>\n      <td>0.098636</td>\n      <td>-0.852650</td>\n      <td>-0.513213</td>\n      <td>-0.549666</td>\n      <td>-0.862609</td>\n      <td>-0.493572</td>\n      <td>-0.754182</td>\n      <td>-0.575445</td>\n      <td>-0.859598</td>\n      <td>-0.402058</td>\n      <td>0.830383</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.805669</td>\n      <td>-0.864236</td>\n      <td>-0.589813</td>\n      <td>-0.402139</td>\n      <td>-0.869757</td>\n      <td>-0.863253</td>\n      <td>-0.403315</td>\n      <td>-0.856983</td>\n      <td>-0.772983</td>\n      <td>-0.404866</td>\n      <td>-0.859085</td>\n      <td>-0.589813</td>\n      <td>-0.405480</td>\n      <td>0.092781</td>\n      <td>-0.950414</td>\n      <td>-0.849883</td>\n      <td>-0.555705</td>\n      <td>-0.986327</td>\n      <td>-1.032359</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>61151 rows × 92 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"       num__mom482  num__mom242   num__bm   num__op   num__gp  num__inv  \\\n36        0.017571    -1.255213 -0.369900 -0.031204  0.115022 -0.006492   \n37       -0.122740    -1.136954 -0.369900 -0.031204  0.115022 -0.006492   \n38        0.226189    -1.110995 -0.780439 -0.481518 -0.095930 -0.717797   \n64       -0.152043    -0.096694 -0.344948 -1.067199  1.968471 -0.689230   \n65       -0.152043    -0.096694 -0.278284 -1.027436  1.432911 -1.591683   \n...            ...          ...       ...       ...       ...       ...   \n78246    -0.152043    -1.123797  0.580376  0.338238 -0.909588 -0.317748   \n78247    -0.152043    -1.263248  1.132903 -0.671171 -1.397125 -0.509075   \n78278    -0.152043    -0.030471 -1.380615  0.341591 -0.616479 -1.181068   \n78279    -0.152043     0.283512 -1.380615  0.341591 -0.616479 -1.181068   \n78280     1.198636     0.016462 -1.789752  0.085412 -0.507287 -0.598994   \n\n       num__mom11  num__mom122  num__amhd  num__ivol_capm  num__ivol_ff5  \\\n36      -1.009764     1.071891   0.479974       -0.180693      -0.157000   \n37      -0.125082     1.144146   0.498559       -0.659567      -0.713933   \n38       0.923598     0.774266   0.513240       -0.270934      -0.273592   \n64      -2.351983    -1.349284   2.068987        3.883441       3.748632   \n65       1.057888    -2.066496   2.068987        4.081030       3.979960   \n...           ...          ...        ...             ...            ...   \n78246   -1.735374    -1.189147  -0.912364        0.030683       0.184636   \n78247   -0.281250    -1.616178  -0.914026       -0.757077      -0.819137   \n78278   -0.398589     0.319302  -0.847606       -0.457602      -0.391194   \n78279    0.391453     0.157390  -0.838832       -0.849395      -0.867005   \n78280   -0.932847     0.152863  -0.838376       -0.695451      -0.643683   \n\n       num__beta_bw  num__MAX  num__vol1m  num__vol6m  num__vol12m  \\\n36        -0.183768 -0.515268   -0.347572   -0.228553    -0.208170   \n37        -0.249618 -0.733894   -0.690161   -0.241237    -0.218720   \n38        -0.453558 -0.282635   -0.394608   -0.291224    -0.355168   \n64        -2.415869  0.749706    4.022481    2.049071     1.584084   \n65        -2.406530  3.994730    4.122402    2.794204     2.031846   \n...             ...       ...         ...         ...          ...   \n78246      1.408413 -0.725032    0.075438    0.340738     0.020141   \n78247      1.276622 -0.707755   -0.778868   -0.167411     0.020129   \n78278     -0.836977 -0.578082   -0.415400   -0.916476    -0.831464   \n78279     -0.789223 -0.680442   -0.852647   -0.910567    -0.827425   \n78280     -0.739484 -0.590016   -0.709366   -0.863951    -0.805263   \n\n       num__BAspr  num__size  num__lbm  num__lop  num__lgp  num__linv  \\\n36       0.023861  -0.498862 -0.729077  0.419892  0.520345  -0.288298   \n37       0.393677  -0.499506 -0.729077  0.419892  0.520345  -0.288298   \n38       0.272001  -0.454238 -0.408215 -0.033124  0.109300  -0.026699   \n64       2.188332  -2.319097 -1.115141 -0.143111  2.377806  -0.732182   \n65       3.064452  -2.268268 -0.382877 -1.061952  1.948956  -0.689050   \n...           ...        ...       ...       ...       ...        ...   \n78246   -0.385702   0.682241  0.537244 -0.079524 -1.149430   0.595084   \n78247   -0.383555   0.674351  0.556766  0.333763 -0.907684  -0.328660   \n78278   -0.402058   0.817380 -0.680315  0.045389 -0.815751   0.263971   \n78279   -0.393765   0.835050 -0.680315  0.045389 -0.815751   0.263971   \n78280   -0.376198   0.795630 -1.434570  0.337093 -0.616757  -1.166201   \n\n       num__llme  num__l1amhd  num__l1MAX  num__l1BAspr  num__l3amhd  \\\n36     -0.617712     0.454084    0.465902      0.021436     0.400562   \n37     -0.669699     0.474402   -0.518501      0.022908     0.423160   \n38     -0.627657     0.492988   -0.737694      0.391967     0.442480   \n64     -1.551684     2.063489    0.123108      1.834347     2.051957   \n65     -1.701090     2.063489    0.749748      2.182949     2.051957   \n...          ...          ...         ...           ...          ...   \n78246   0.998694    -0.935036   -0.290222     -0.391434    -0.971474   \n78247   1.034725    -0.918001   -0.728808     -0.385816    -0.953446   \n78278   0.807354    -0.858285   -0.496749     -0.402139    -0.875875   \n78279   0.811065    -0.853241   -0.581478     -0.402139    -0.875898   \n78280   0.834602    -0.844466   -0.684103     -0.393863    -0.869946   \n\n       num__l3MAX  num__l3BAspr  num__l6amhd  num__l6MAX  num__l6BAspr  \\\n36      -0.237429      0.423626     0.288105    0.777438     -0.126923   \n37      -0.359081      0.048667     0.334052   -0.811733      0.131124   \n38       0.468830      0.020204     0.363010    0.066329      0.163772   \n64      -0.335407      1.603946     2.024413    2.226897      0.104445   \n65       1.405445      2.491250     2.035117    0.059071      1.725945   \n...           ...           ...          ...         ...           ...   \n78246   -0.050510     -0.391478    -1.041212    0.000487     -0.392559   \n78247   -0.531008     -0.390212    -1.027701    0.270291     -0.390777   \n78278   -0.887482     -0.403315    -0.868502    1.846090     -0.405024   \n78279   -0.595670     -0.403315    -0.868975   -0.770796     -0.391274   \n78280   -0.501832     -0.403315    -0.887512   -0.894998     -0.405024   \n\n       num__l12amhd  num__l12MAX  num__l12BAspr  num__l12mom122  \\\n36        -0.008636     0.465902      -0.115740       -1.740134   \n37         0.015623    -0.518501      -0.056377       -1.882481   \n38         0.089343    -0.737694      -0.008474       -1.877967   \n64         1.995707     0.123108      -0.092068       -0.910604   \n65         1.993128     0.749748       1.335923       -1.223386   \n...             ...          ...            ...             ...   \n78246     -1.037594    -0.290222      -0.403731       -0.164819   \n78247     -1.047336    -0.728808      -0.405428        0.013950   \n78278     -0.856769    -0.496749      -0.405480        0.027287   \n78279     -0.863835    -0.581478      -0.405480       -0.077624   \n78280     -0.862748    -0.684103      -0.393512        0.159732   \n\n       num__l12ivol_capm  num__l12ivol_ff5  num__l12beta_bw  num__l12vol6m  \\\n36             -0.637351         -0.715329        -0.585179      -0.413230   \n37             -0.675613         -0.722268        -0.659664      -0.425989   \n38              0.774472          0.782417        -0.208721      -0.238738   \n64              1.110320          1.169139        -2.729320       0.660596   \n65              0.524419          0.467423        -1.695742       0.589892   \n...                  ...               ...              ...            ...   \n78246          -0.817938         -0.837669        -0.364856      -0.820085   \n78247          -0.820570         -0.819109        -0.305213      -0.852782   \n78278          -0.828575         -0.727009        -0.407072      -1.081661   \n78279          -0.855083         -0.773845        -0.459198      -1.086932   \n78280          -0.909681         -0.856119        -0.275987      -1.101124   \n\n       num__l12vol12m  num__amhd_miss  num__BAspr_miss  cat__ind_1.0  \\\n36          -0.080031       -0.150249        -0.037746           0.0   \n37          -0.088143       -0.150249        -0.037746           0.0   \n38          -0.195021       -0.150249        -0.037746           0.0   \n64          -0.216356       -0.150249        -0.037746           0.0   \n65          -0.216356       -0.150249        -0.037746           0.0   \n...               ...             ...              ...           ...   \n78246       -0.964781       -0.150249        -0.037746           0.0   \n78247       -0.980294       -0.150249        -0.037746           0.0   \n78278       -1.103256       -0.150249        -0.037746           0.0   \n78279       -1.117821       -0.150249        -0.037746           0.0   \n78280       -1.134378       -0.150249        -0.037746           0.0   \n\n       cat__ind_2.0  cat__ind_3.0  cat__ind_4.0  cat__ind_5.0  cat__ind_6.0  \\\n36              0.0           0.0           0.0           0.0           0.0   \n37              0.0           0.0           0.0           0.0           0.0   \n38              0.0           0.0           0.0           0.0           0.0   \n64              0.0           0.0           0.0           0.0           0.0   \n65              0.0           0.0           0.0           0.0           0.0   \n...             ...           ...           ...           ...           ...   \n78246           0.0           0.0           0.0           0.0           0.0   \n78247           0.0           0.0           0.0           0.0           0.0   \n78278           0.0           0.0           0.0           0.0           0.0   \n78279           0.0           0.0           0.0           0.0           0.0   \n78280           0.0           0.0           0.0           0.0           0.0   \n\n       cat__ind_7.0  cat__ind_8.0  cat__ind_9.0  cat__ind_10.0  cat__ind_11.0  \\\n36              0.0           0.0           0.0            0.0            0.0   \n37              0.0           0.0           0.0            0.0            0.0   \n38              0.0           0.0           0.0            0.0            0.0   \n64              0.0           0.0           0.0            0.0            0.0   \n65              0.0           0.0           0.0            0.0            0.0   \n...             ...           ...           ...            ...            ...   \n78246           0.0           0.0           0.0            0.0            0.0   \n78247           0.0           0.0           0.0            0.0            0.0   \n78278           1.0           0.0           0.0            0.0            0.0   \n78279           1.0           0.0           0.0            0.0            0.0   \n78280           1.0           0.0           0.0            0.0            0.0   \n\n       cat__ind_12.0  cat__ind_13.0  cat__ind_14.0  cat__ind_15.0  \\\n36               0.0            0.0            0.0            1.0   \n37               0.0            0.0            0.0            1.0   \n38               0.0            0.0            0.0            1.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_16.0  cat__ind_17.0  cat__ind_18.0  cat__ind_19.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_20.0  cat__ind_21.0  cat__ind_22.0  cat__ind_23.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_24.0  cat__ind_25.0  cat__ind_26.0  cat__ind_27.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_28.0  cat__ind_29.0  cat__ind_30.0  cat__ind_31.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            1.0            0.0   \n78247            0.0            0.0            1.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_32.0  cat__ind_33.0  cat__ind_34.0  cat__ind_35.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_36.0  cat__ind_37.0  cat__ind_38.0  cat__ind_39.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_40.0  cat__ind_41.0  cat__ind_42.0  cat__ind_43.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            1.0            0.0   \n65               0.0            0.0            1.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_44.0  cat__ind_45.0  cat__ind_46.0  cat__ind_47.0  \\\n36               0.0            0.0            0.0            0.0   \n37               0.0            0.0            0.0            0.0   \n38               0.0            0.0            0.0            0.0   \n64               0.0            0.0            0.0            0.0   \n65               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78246            0.0            0.0            0.0            0.0   \n78247            0.0            0.0            0.0            0.0   \n78278            0.0            0.0            0.0            0.0   \n78279            0.0            0.0            0.0            0.0   \n78280            0.0            0.0            0.0            0.0   \n\n       cat__ind_48.0  cat__ind_49.0  \n36               0.0            0.0  \n37               0.0            0.0  \n38               0.0            0.0  \n64               0.0            0.0  \n65               0.0            0.0  \n...              ...            ...  \n78246            0.0            0.0  \n78247            0.0            0.0  \n78278            0.0            0.0  \n78279            0.0            0.0  \n78280            0.0            0.0  \n\n[4761 rows x 92 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num__mom482</th>\n      <th>num__mom242</th>\n      <th>num__bm</th>\n      <th>num__op</th>\n      <th>num__gp</th>\n      <th>num__inv</th>\n      <th>num__mom11</th>\n      <th>num__mom122</th>\n      <th>num__amhd</th>\n      <th>num__ivol_capm</th>\n      <th>num__ivol_ff5</th>\n      <th>num__beta_bw</th>\n      <th>num__MAX</th>\n      <th>num__vol1m</th>\n      <th>num__vol6m</th>\n      <th>num__vol12m</th>\n      <th>num__BAspr</th>\n      <th>num__size</th>\n      <th>num__lbm</th>\n      <th>num__lop</th>\n      <th>num__lgp</th>\n      <th>num__linv</th>\n      <th>num__llme</th>\n      <th>num__l1amhd</th>\n      <th>num__l1MAX</th>\n      <th>num__l1BAspr</th>\n      <th>num__l3amhd</th>\n      <th>num__l3MAX</th>\n      <th>num__l3BAspr</th>\n      <th>num__l6amhd</th>\n      <th>num__l6MAX</th>\n      <th>num__l6BAspr</th>\n      <th>num__l12amhd</th>\n      <th>num__l12MAX</th>\n      <th>num__l12BAspr</th>\n      <th>num__l12mom122</th>\n      <th>num__l12ivol_capm</th>\n      <th>num__l12ivol_ff5</th>\n      <th>num__l12beta_bw</th>\n      <th>num__l12vol6m</th>\n      <th>num__l12vol12m</th>\n      <th>num__amhd_miss</th>\n      <th>num__BAspr_miss</th>\n      <th>cat__ind_1.0</th>\n      <th>cat__ind_2.0</th>\n      <th>cat__ind_3.0</th>\n      <th>cat__ind_4.0</th>\n      <th>cat__ind_5.0</th>\n      <th>cat__ind_6.0</th>\n      <th>cat__ind_7.0</th>\n      <th>cat__ind_8.0</th>\n      <th>cat__ind_9.0</th>\n      <th>cat__ind_10.0</th>\n      <th>cat__ind_11.0</th>\n      <th>cat__ind_12.0</th>\n      <th>cat__ind_13.0</th>\n      <th>cat__ind_14.0</th>\n      <th>cat__ind_15.0</th>\n      <th>cat__ind_16.0</th>\n      <th>cat__ind_17.0</th>\n      <th>cat__ind_18.0</th>\n      <th>cat__ind_19.0</th>\n      <th>cat__ind_20.0</th>\n      <th>cat__ind_21.0</th>\n      <th>cat__ind_22.0</th>\n      <th>cat__ind_23.0</th>\n      <th>cat__ind_24.0</th>\n      <th>cat__ind_25.0</th>\n      <th>cat__ind_26.0</th>\n      <th>cat__ind_27.0</th>\n      <th>cat__ind_28.0</th>\n      <th>cat__ind_29.0</th>\n      <th>cat__ind_30.0</th>\n      <th>cat__ind_31.0</th>\n      <th>cat__ind_32.0</th>\n      <th>cat__ind_33.0</th>\n      <th>cat__ind_34.0</th>\n      <th>cat__ind_35.0</th>\n      <th>cat__ind_36.0</th>\n      <th>cat__ind_37.0</th>\n      <th>cat__ind_38.0</th>\n      <th>cat__ind_39.0</th>\n      <th>cat__ind_40.0</th>\n      <th>cat__ind_41.0</th>\n      <th>cat__ind_42.0</th>\n      <th>cat__ind_43.0</th>\n      <th>cat__ind_44.0</th>\n      <th>cat__ind_45.0</th>\n      <th>cat__ind_46.0</th>\n      <th>cat__ind_47.0</th>\n      <th>cat__ind_48.0</th>\n      <th>cat__ind_49.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36</th>\n      <td>0.017571</td>\n      <td>-1.255213</td>\n      <td>-0.369900</td>\n      <td>-0.031204</td>\n      <td>0.115022</td>\n      <td>-0.006492</td>\n      <td>-1.009764</td>\n      <td>1.071891</td>\n      <td>0.479974</td>\n      <td>-0.180693</td>\n      <td>-0.157000</td>\n      <td>-0.183768</td>\n      <td>-0.515268</td>\n      <td>-0.347572</td>\n      <td>-0.228553</td>\n      <td>-0.208170</td>\n      <td>0.023861</td>\n      <td>-0.498862</td>\n      <td>-0.729077</td>\n      <td>0.419892</td>\n      <td>0.520345</td>\n      <td>-0.288298</td>\n      <td>-0.617712</td>\n      <td>0.454084</td>\n      <td>0.465902</td>\n      <td>0.021436</td>\n      <td>0.400562</td>\n      <td>-0.237429</td>\n      <td>0.423626</td>\n      <td>0.288105</td>\n      <td>0.777438</td>\n      <td>-0.126923</td>\n      <td>-0.008636</td>\n      <td>0.465902</td>\n      <td>-0.115740</td>\n      <td>-1.740134</td>\n      <td>-0.637351</td>\n      <td>-0.715329</td>\n      <td>-0.585179</td>\n      <td>-0.413230</td>\n      <td>-0.080031</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>-0.122740</td>\n      <td>-1.136954</td>\n      <td>-0.369900</td>\n      <td>-0.031204</td>\n      <td>0.115022</td>\n      <td>-0.006492</td>\n      <td>-0.125082</td>\n      <td>1.144146</td>\n      <td>0.498559</td>\n      <td>-0.659567</td>\n      <td>-0.713933</td>\n      <td>-0.249618</td>\n      <td>-0.733894</td>\n      <td>-0.690161</td>\n      <td>-0.241237</td>\n      <td>-0.218720</td>\n      <td>0.393677</td>\n      <td>-0.499506</td>\n      <td>-0.729077</td>\n      <td>0.419892</td>\n      <td>0.520345</td>\n      <td>-0.288298</td>\n      <td>-0.669699</td>\n      <td>0.474402</td>\n      <td>-0.518501</td>\n      <td>0.022908</td>\n      <td>0.423160</td>\n      <td>-0.359081</td>\n      <td>0.048667</td>\n      <td>0.334052</td>\n      <td>-0.811733</td>\n      <td>0.131124</td>\n      <td>0.015623</td>\n      <td>-0.518501</td>\n      <td>-0.056377</td>\n      <td>-1.882481</td>\n      <td>-0.675613</td>\n      <td>-0.722268</td>\n      <td>-0.659664</td>\n      <td>-0.425989</td>\n      <td>-0.088143</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0.226189</td>\n      <td>-1.110995</td>\n      <td>-0.780439</td>\n      <td>-0.481518</td>\n      <td>-0.095930</td>\n      <td>-0.717797</td>\n      <td>0.923598</td>\n      <td>0.774266</td>\n      <td>0.513240</td>\n      <td>-0.270934</td>\n      <td>-0.273592</td>\n      <td>-0.453558</td>\n      <td>-0.282635</td>\n      <td>-0.394608</td>\n      <td>-0.291224</td>\n      <td>-0.355168</td>\n      <td>0.272001</td>\n      <td>-0.454238</td>\n      <td>-0.408215</td>\n      <td>-0.033124</td>\n      <td>0.109300</td>\n      <td>-0.026699</td>\n      <td>-0.627657</td>\n      <td>0.492988</td>\n      <td>-0.737694</td>\n      <td>0.391967</td>\n      <td>0.442480</td>\n      <td>0.468830</td>\n      <td>0.020204</td>\n      <td>0.363010</td>\n      <td>0.066329</td>\n      <td>0.163772</td>\n      <td>0.089343</td>\n      <td>-0.737694</td>\n      <td>-0.008474</td>\n      <td>-1.877967</td>\n      <td>0.774472</td>\n      <td>0.782417</td>\n      <td>-0.208721</td>\n      <td>-0.238738</td>\n      <td>-0.195021</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>-0.152043</td>\n      <td>-0.096694</td>\n      <td>-0.344948</td>\n      <td>-1.067199</td>\n      <td>1.968471</td>\n      <td>-0.689230</td>\n      <td>-2.351983</td>\n      <td>-1.349284</td>\n      <td>2.068987</td>\n      <td>3.883441</td>\n      <td>3.748632</td>\n      <td>-2.415869</td>\n      <td>0.749706</td>\n      <td>4.022481</td>\n      <td>2.049071</td>\n      <td>1.584084</td>\n      <td>2.188332</td>\n      <td>-2.319097</td>\n      <td>-1.115141</td>\n      <td>-0.143111</td>\n      <td>2.377806</td>\n      <td>-0.732182</td>\n      <td>-1.551684</td>\n      <td>2.063489</td>\n      <td>0.123108</td>\n      <td>1.834347</td>\n      <td>2.051957</td>\n      <td>-0.335407</td>\n      <td>1.603946</td>\n      <td>2.024413</td>\n      <td>2.226897</td>\n      <td>0.104445</td>\n      <td>1.995707</td>\n      <td>0.123108</td>\n      <td>-0.092068</td>\n      <td>-0.910604</td>\n      <td>1.110320</td>\n      <td>1.169139</td>\n      <td>-2.729320</td>\n      <td>0.660596</td>\n      <td>-0.216356</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>-0.152043</td>\n      <td>-0.096694</td>\n      <td>-0.278284</td>\n      <td>-1.027436</td>\n      <td>1.432911</td>\n      <td>-1.591683</td>\n      <td>1.057888</td>\n      <td>-2.066496</td>\n      <td>2.068987</td>\n      <td>4.081030</td>\n      <td>3.979960</td>\n      <td>-2.406530</td>\n      <td>3.994730</td>\n      <td>4.122402</td>\n      <td>2.794204</td>\n      <td>2.031846</td>\n      <td>3.064452</td>\n      <td>-2.268268</td>\n      <td>-0.382877</td>\n      <td>-1.061952</td>\n      <td>1.948956</td>\n      <td>-0.689050</td>\n      <td>-1.701090</td>\n      <td>2.063489</td>\n      <td>0.749748</td>\n      <td>2.182949</td>\n      <td>2.051957</td>\n      <td>1.405445</td>\n      <td>2.491250</td>\n      <td>2.035117</td>\n      <td>0.059071</td>\n      <td>1.725945</td>\n      <td>1.993128</td>\n      <td>0.749748</td>\n      <td>1.335923</td>\n      <td>-1.223386</td>\n      <td>0.524419</td>\n      <td>0.467423</td>\n      <td>-1.695742</td>\n      <td>0.589892</td>\n      <td>-0.216356</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78246</th>\n      <td>-0.152043</td>\n      <td>-1.123797</td>\n      <td>0.580376</td>\n      <td>0.338238</td>\n      <td>-0.909588</td>\n      <td>-0.317748</td>\n      <td>-1.735374</td>\n      <td>-1.189147</td>\n      <td>-0.912364</td>\n      <td>0.030683</td>\n      <td>0.184636</td>\n      <td>1.408413</td>\n      <td>-0.725032</td>\n      <td>0.075438</td>\n      <td>0.340738</td>\n      <td>0.020141</td>\n      <td>-0.385702</td>\n      <td>0.682241</td>\n      <td>0.537244</td>\n      <td>-0.079524</td>\n      <td>-1.149430</td>\n      <td>0.595084</td>\n      <td>0.998694</td>\n      <td>-0.935036</td>\n      <td>-0.290222</td>\n      <td>-0.391434</td>\n      <td>-0.971474</td>\n      <td>-0.050510</td>\n      <td>-0.391478</td>\n      <td>-1.041212</td>\n      <td>0.000487</td>\n      <td>-0.392559</td>\n      <td>-1.037594</td>\n      <td>-0.290222</td>\n      <td>-0.403731</td>\n      <td>-0.164819</td>\n      <td>-0.817938</td>\n      <td>-0.837669</td>\n      <td>-0.364856</td>\n      <td>-0.820085</td>\n      <td>-0.964781</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78247</th>\n      <td>-0.152043</td>\n      <td>-1.263248</td>\n      <td>1.132903</td>\n      <td>-0.671171</td>\n      <td>-1.397125</td>\n      <td>-0.509075</td>\n      <td>-0.281250</td>\n      <td>-1.616178</td>\n      <td>-0.914026</td>\n      <td>-0.757077</td>\n      <td>-0.819137</td>\n      <td>1.276622</td>\n      <td>-0.707755</td>\n      <td>-0.778868</td>\n      <td>-0.167411</td>\n      <td>0.020129</td>\n      <td>-0.383555</td>\n      <td>0.674351</td>\n      <td>0.556766</td>\n      <td>0.333763</td>\n      <td>-0.907684</td>\n      <td>-0.328660</td>\n      <td>1.034725</td>\n      <td>-0.918001</td>\n      <td>-0.728808</td>\n      <td>-0.385816</td>\n      <td>-0.953446</td>\n      <td>-0.531008</td>\n      <td>-0.390212</td>\n      <td>-1.027701</td>\n      <td>0.270291</td>\n      <td>-0.390777</td>\n      <td>-1.047336</td>\n      <td>-0.728808</td>\n      <td>-0.405428</td>\n      <td>0.013950</td>\n      <td>-0.820570</td>\n      <td>-0.819109</td>\n      <td>-0.305213</td>\n      <td>-0.852782</td>\n      <td>-0.980294</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78278</th>\n      <td>-0.152043</td>\n      <td>-0.030471</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>-0.398589</td>\n      <td>0.319302</td>\n      <td>-0.847606</td>\n      <td>-0.457602</td>\n      <td>-0.391194</td>\n      <td>-0.836977</td>\n      <td>-0.578082</td>\n      <td>-0.415400</td>\n      <td>-0.916476</td>\n      <td>-0.831464</td>\n      <td>-0.402058</td>\n      <td>0.817380</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.807354</td>\n      <td>-0.858285</td>\n      <td>-0.496749</td>\n      <td>-0.402139</td>\n      <td>-0.875875</td>\n      <td>-0.887482</td>\n      <td>-0.403315</td>\n      <td>-0.868502</td>\n      <td>1.846090</td>\n      <td>-0.405024</td>\n      <td>-0.856769</td>\n      <td>-0.496749</td>\n      <td>-0.405480</td>\n      <td>0.027287</td>\n      <td>-0.828575</td>\n      <td>-0.727009</td>\n      <td>-0.407072</td>\n      <td>-1.081661</td>\n      <td>-1.103256</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78279</th>\n      <td>-0.152043</td>\n      <td>0.283512</td>\n      <td>-1.380615</td>\n      <td>0.341591</td>\n      <td>-0.616479</td>\n      <td>-1.181068</td>\n      <td>0.391453</td>\n      <td>0.157390</td>\n      <td>-0.838832</td>\n      <td>-0.849395</td>\n      <td>-0.867005</td>\n      <td>-0.789223</td>\n      <td>-0.680442</td>\n      <td>-0.852647</td>\n      <td>-0.910567</td>\n      <td>-0.827425</td>\n      <td>-0.393765</td>\n      <td>0.835050</td>\n      <td>-0.680315</td>\n      <td>0.045389</td>\n      <td>-0.815751</td>\n      <td>0.263971</td>\n      <td>0.811065</td>\n      <td>-0.853241</td>\n      <td>-0.581478</td>\n      <td>-0.402139</td>\n      <td>-0.875898</td>\n      <td>-0.595670</td>\n      <td>-0.403315</td>\n      <td>-0.868975</td>\n      <td>-0.770796</td>\n      <td>-0.391274</td>\n      <td>-0.863835</td>\n      <td>-0.581478</td>\n      <td>-0.405480</td>\n      <td>-0.077624</td>\n      <td>-0.855083</td>\n      <td>-0.773845</td>\n      <td>-0.459198</td>\n      <td>-1.086932</td>\n      <td>-1.117821</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78280</th>\n      <td>1.198636</td>\n      <td>0.016462</td>\n      <td>-1.789752</td>\n      <td>0.085412</td>\n      <td>-0.507287</td>\n      <td>-0.598994</td>\n      <td>-0.932847</td>\n      <td>0.152863</td>\n      <td>-0.838376</td>\n      <td>-0.695451</td>\n      <td>-0.643683</td>\n      <td>-0.739484</td>\n      <td>-0.590016</td>\n      <td>-0.709366</td>\n      <td>-0.863951</td>\n      <td>-0.805263</td>\n      <td>-0.376198</td>\n      <td>0.795630</td>\n      <td>-1.434570</td>\n      <td>0.337093</td>\n      <td>-0.616757</td>\n      <td>-1.166201</td>\n      <td>0.834602</td>\n      <td>-0.844466</td>\n      <td>-0.684103</td>\n      <td>-0.393863</td>\n      <td>-0.869946</td>\n      <td>-0.501832</td>\n      <td>-0.403315</td>\n      <td>-0.887512</td>\n      <td>-0.894998</td>\n      <td>-0.405024</td>\n      <td>-0.862748</td>\n      <td>-0.684103</td>\n      <td>-0.393512</td>\n      <td>0.159732</td>\n      <td>-0.909681</td>\n      <td>-0.856119</td>\n      <td>-0.275987</td>\n      <td>-1.101124</td>\n      <td>-1.134378</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4761 rows × 92 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"       num__mom482  num__mom242   num__bm   num__op   num__gp  num__inv  \\\n39        0.114148    -1.221555 -0.780439 -0.481518 -0.095930 -0.717797   \n40        0.708016    -1.025009 -0.780439 -0.481518 -0.095930 -0.717797   \n41        0.588727    -0.674185 -0.780439 -0.481518 -0.095930 -0.717797   \n66       -0.152043    -0.096694 -0.278284 -1.027436  1.432911 -1.591683   \n67       -0.152043    -0.096694 -0.278284 -1.027436  1.432911 -1.591683   \n...            ...          ...       ...       ...       ...       ...   \n78249    -1.292315    -1.429734  1.132903 -0.671171 -1.397125 -0.509075   \n78250    -1.424066    -1.635540  1.132903 -0.671171 -1.397125 -0.509075   \n78281     1.492163     0.296948 -1.789752  0.085412 -0.507287 -0.598994   \n78282     1.772541     0.142887 -1.789752  0.085412 -0.507287 -0.598994   \n78283     1.554300    -0.010265 -1.789752  0.085412 -0.507287 -0.598994   \n\n       num__mom11  num__mom122  num__amhd  num__ivol_capm  num__ivol_ff5  \\\n39      -1.353610     0.558254   0.508204        0.601670       0.549860   \n40       1.152138    -0.015554   0.507482       -0.108999      -0.048967   \n41       0.418507     0.782500   0.494919        0.960556       0.585115   \n66      -1.606161    -2.066496   2.068987        3.950431       4.096534   \n67      -2.351983    -2.066496   2.068987        2.766578       3.128399   \n...           ...          ...        ...             ...            ...   \n78249    0.018750    -2.037527  -0.848603        1.191216       0.654402   \n78250   -1.187960    -1.857585  -0.816400        1.288830       0.587613   \n78281    0.288522     0.224005  -0.842586       -0.704322      -0.733165   \n78282   -0.469609     0.474893  -0.833023       -0.863574      -0.821552   \n78283    0.185031     0.556194  -0.827457       -0.747979      -0.624860   \n\n       num__beta_bw  num__MAX  num__vol1m  num__vol6m  num__vol12m  \\\n39        -0.591416 -0.560881    0.497645   -0.175013    -0.312837   \n40        -0.709727 -0.369716   -0.133699   -0.133880    -0.258084   \n41        -0.504172  0.612468    1.194725   -0.004759    -0.119211   \n66        -2.445455  3.087190    3.635682    3.184424     2.267580   \n67        -2.053542  1.291341    2.582623    3.415948     2.403138   \n...             ...       ...         ...         ...          ...   \n78249      1.350629  1.849704    1.650750    0.220484     0.329703   \n78250      1.291279  2.190789    1.428214    0.529646     0.494496   \n78281     -0.798543 -0.778034   -0.829631   -0.846416    -0.826171   \n78282     -0.726471 -0.225214   -0.488456   -0.841954    -0.794622   \n78283     -0.648096 -0.477569   -0.377189   -0.776884    -0.764491   \n\n       num__BAspr  num__size  num__lbm  num__lop  num__lgp  num__linv  \\\n39       0.062075  -0.515229 -0.408215 -0.033124  0.109300  -0.026699   \n40      -0.302480  -0.460535 -0.408215 -0.033124  0.109300  -0.026699   \n41      -0.183760  -0.436810 -0.408215 -0.033124  0.109300  -0.026699   \n66       1.472282  -2.342709 -0.382877 -1.061952  1.948956  -0.689050   \n67       8.340880  -2.504108 -0.382877 -1.061952  1.948956  -0.689050   \n...           ...        ...       ...       ...       ...        ...   \n78249   -0.368781   0.547134  0.556766  0.333763 -0.907684  -0.328660   \n78250   -0.367257   0.494757  0.556766  0.333763 -0.907684  -0.328660   \n78281   -0.392569   0.813101 -1.434570  0.337093 -0.616757  -1.166201   \n78282   -0.390061   0.796316 -1.434570  0.337093 -0.616757  -1.166201   \n78283   -0.402058   0.804534 -1.434570  0.337093 -0.616757  -1.166201   \n\n       num__llme  num__l1amhd  num__l1MAX  num__l1BAspr  num__l3amhd  \\\n39     -0.554833     0.507669   -0.285266      0.270540     0.462800   \n40     -0.536835     0.502633   -0.564232      0.061044     0.481386   \n41     -0.589087     0.501912   -0.372573     -0.302765     0.496068   \n66     -1.673135     2.063489    4.003177      3.057275     2.051957   \n67     -1.700324     2.063489    3.093286      1.468365     2.051957   \n...          ...          ...         ...           ...          ...   \n78249   1.049053    -0.897648   -0.237758     -0.315237    -0.929665   \n78250   0.981460    -0.854238    1.852596     -0.368931    -0.931328   \n78281   0.785096    -0.844010   -0.593442     -0.376332    -0.864901   \n78282   0.763320    -0.848221   -0.781948     -0.392669    -0.856127   \n78283   0.735749    -0.838657   -0.227696     -0.390167    -0.855671   \n\n       num__l3MAX  num__l3BAspr  num__l6amhd  num__l6MAX  num__l6BAspr  \\\n39      -0.523765      0.021676     0.383204   -0.278687      0.402250   \n40      -0.744781      0.390686     0.405810   -0.398489      0.036208   \n41      -0.288589      0.269276     0.425136    0.416838      0.008422   \n66       0.123184      1.832875     2.035117    0.544967      0.485602   \n67       0.755039      2.181432     2.035117   -0.375175      1.554498   \n...           ...           ...          ...         ...           ...   \n78249   -0.735822     -0.386994    -0.989261   -0.094609     -0.393469   \n78250   -0.718356     -0.384852    -0.971228   -0.567803     -0.392234   \n78281   -0.587266     -0.403315    -0.893632   -0.918859     -0.405024   \n78282   -0.690745     -0.395040    -0.893655   -0.631482     -0.405024   \n78283   -0.599330     -0.377511    -0.887702   -0.539070     -0.405024   \n\n       num__l12amhd  num__l12MAX  num__l12BAspr  num__l12mom122  \\\n39         0.123209    -0.285266       0.089480       -1.868365   \n40         0.140100    -0.564232      -0.168442       -1.636608   \n41         0.199132    -0.372573      -0.298296       -1.508436   \n66         1.996417     4.003177       0.931388       -1.302168   \n67         1.996417     3.093286       2.697698       -1.576470   \n...             ...          ...            ...             ...   \n78249     -1.092463    -0.237758      -0.405480        0.168724   \n78250     -1.109453     1.852596      -0.402771        0.366459   \n78281     -0.865775    -0.593442      -0.405480        0.175709   \n78282     -0.881532    -0.781948      -0.405480        0.136469   \n78283     -0.885397    -0.227696      -0.405325       -0.037573   \n\n       num__l12ivol_capm  num__l12ivol_ff5  num__l12beta_bw  num__l12vol6m  \\\n39             -0.023381          0.075125        -0.135822      -0.198262   \n40             -0.900703         -0.812385        -0.243596      -0.272191   \n41             -0.009298         -0.138327        -0.299628      -0.377692   \n66              1.504758          1.765495        -1.753375       0.752070   \n67              0.892243          0.948094        -1.628943       0.748329   \n...                  ...               ...              ...            ...   \n78249          -0.825924         -0.749620        -0.298382      -1.154880   \n78250          -0.648510         -0.785161        -0.242835      -1.094196   \n78281          -0.605582         -0.573409        -0.221885      -1.057383   \n78282          -0.960917         -0.938984        -0.281091      -1.166432   \n78283          -0.816942         -0.699459        -0.227173      -1.160779   \n\n       num__l12vol12m  num__amhd_miss  num__BAspr_miss  cat__ind_1.0  \\\n39          -0.118275       -0.150249        -0.037746           0.0   \n40          -0.142440       -0.150249        -0.037746           0.0   \n41          -0.411109       -0.150249        -0.037746           0.0   \n66          -0.216356       -0.150249        -0.037746           0.0   \n67          -0.216356       -0.150249        -0.037746           0.0   \n...               ...             ...              ...           ...   \n78249       -1.009336       -0.150249        -0.037746           0.0   \n78250       -0.995190       -0.150249        -0.037746           0.0   \n78281       -1.143209       -0.150249        -0.037746           0.0   \n78282       -1.169511       -0.150249        -0.037746           0.0   \n78283       -1.171930       -0.150249        -0.037746           0.0   \n\n       cat__ind_2.0  cat__ind_3.0  cat__ind_4.0  cat__ind_5.0  cat__ind_6.0  \\\n39              0.0           0.0           0.0           0.0           0.0   \n40              0.0           0.0           0.0           0.0           0.0   \n41              0.0           0.0           0.0           0.0           0.0   \n66              0.0           0.0           0.0           0.0           0.0   \n67              0.0           0.0           0.0           0.0           0.0   \n...             ...           ...           ...           ...           ...   \n78249           0.0           0.0           0.0           0.0           0.0   \n78250           0.0           0.0           0.0           0.0           0.0   \n78281           0.0           0.0           0.0           0.0           0.0   \n78282           0.0           0.0           0.0           0.0           0.0   \n78283           0.0           0.0           0.0           0.0           0.0   \n\n       cat__ind_7.0  cat__ind_8.0  cat__ind_9.0  cat__ind_10.0  cat__ind_11.0  \\\n39              0.0           0.0           0.0            0.0            0.0   \n40              0.0           0.0           0.0            0.0            0.0   \n41              0.0           0.0           0.0            0.0            0.0   \n66              0.0           0.0           0.0            0.0            0.0   \n67              0.0           0.0           0.0            0.0            0.0   \n...             ...           ...           ...            ...            ...   \n78249           0.0           0.0           0.0            0.0            0.0   \n78250           0.0           0.0           0.0            0.0            0.0   \n78281           1.0           0.0           0.0            0.0            0.0   \n78282           1.0           0.0           0.0            0.0            0.0   \n78283           1.0           0.0           0.0            0.0            0.0   \n\n       cat__ind_12.0  cat__ind_13.0  cat__ind_14.0  cat__ind_15.0  \\\n39               0.0            0.0            0.0            1.0   \n40               0.0            0.0            0.0            1.0   \n41               0.0            0.0            0.0            1.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_16.0  cat__ind_17.0  cat__ind_18.0  cat__ind_19.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_20.0  cat__ind_21.0  cat__ind_22.0  cat__ind_23.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_24.0  cat__ind_25.0  cat__ind_26.0  cat__ind_27.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_28.0  cat__ind_29.0  cat__ind_30.0  cat__ind_31.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            1.0            0.0   \n78250            0.0            0.0            1.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_32.0  cat__ind_33.0  cat__ind_34.0  cat__ind_35.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_36.0  cat__ind_37.0  cat__ind_38.0  cat__ind_39.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_40.0  cat__ind_41.0  cat__ind_42.0  cat__ind_43.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            1.0            0.0   \n67               0.0            0.0            1.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_44.0  cat__ind_45.0  cat__ind_46.0  cat__ind_47.0  \\\n39               0.0            0.0            0.0            0.0   \n40               0.0            0.0            0.0            0.0   \n41               0.0            0.0            0.0            0.0   \n66               0.0            0.0            0.0            0.0   \n67               0.0            0.0            0.0            0.0   \n...              ...            ...            ...            ...   \n78249            0.0            0.0            0.0            0.0   \n78250            0.0            0.0            0.0            0.0   \n78281            0.0            0.0            0.0            0.0   \n78282            0.0            0.0            0.0            0.0   \n78283            0.0            0.0            0.0            0.0   \n\n       cat__ind_48.0  cat__ind_49.0  \n39               0.0            0.0  \n40               0.0            0.0  \n41               0.0            0.0  \n66               0.0            0.0  \n67               0.0            0.0  \n...              ...            ...  \n78249            0.0            0.0  \n78250            0.0            0.0  \n78281            0.0            0.0  \n78282            0.0            0.0  \n78283            0.0            0.0  \n\n[4706 rows x 92 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num__mom482</th>\n      <th>num__mom242</th>\n      <th>num__bm</th>\n      <th>num__op</th>\n      <th>num__gp</th>\n      <th>num__inv</th>\n      <th>num__mom11</th>\n      <th>num__mom122</th>\n      <th>num__amhd</th>\n      <th>num__ivol_capm</th>\n      <th>num__ivol_ff5</th>\n      <th>num__beta_bw</th>\n      <th>num__MAX</th>\n      <th>num__vol1m</th>\n      <th>num__vol6m</th>\n      <th>num__vol12m</th>\n      <th>num__BAspr</th>\n      <th>num__size</th>\n      <th>num__lbm</th>\n      <th>num__lop</th>\n      <th>num__lgp</th>\n      <th>num__linv</th>\n      <th>num__llme</th>\n      <th>num__l1amhd</th>\n      <th>num__l1MAX</th>\n      <th>num__l1BAspr</th>\n      <th>num__l3amhd</th>\n      <th>num__l3MAX</th>\n      <th>num__l3BAspr</th>\n      <th>num__l6amhd</th>\n      <th>num__l6MAX</th>\n      <th>num__l6BAspr</th>\n      <th>num__l12amhd</th>\n      <th>num__l12MAX</th>\n      <th>num__l12BAspr</th>\n      <th>num__l12mom122</th>\n      <th>num__l12ivol_capm</th>\n      <th>num__l12ivol_ff5</th>\n      <th>num__l12beta_bw</th>\n      <th>num__l12vol6m</th>\n      <th>num__l12vol12m</th>\n      <th>num__amhd_miss</th>\n      <th>num__BAspr_miss</th>\n      <th>cat__ind_1.0</th>\n      <th>cat__ind_2.0</th>\n      <th>cat__ind_3.0</th>\n      <th>cat__ind_4.0</th>\n      <th>cat__ind_5.0</th>\n      <th>cat__ind_6.0</th>\n      <th>cat__ind_7.0</th>\n      <th>cat__ind_8.0</th>\n      <th>cat__ind_9.0</th>\n      <th>cat__ind_10.0</th>\n      <th>cat__ind_11.0</th>\n      <th>cat__ind_12.0</th>\n      <th>cat__ind_13.0</th>\n      <th>cat__ind_14.0</th>\n      <th>cat__ind_15.0</th>\n      <th>cat__ind_16.0</th>\n      <th>cat__ind_17.0</th>\n      <th>cat__ind_18.0</th>\n      <th>cat__ind_19.0</th>\n      <th>cat__ind_20.0</th>\n      <th>cat__ind_21.0</th>\n      <th>cat__ind_22.0</th>\n      <th>cat__ind_23.0</th>\n      <th>cat__ind_24.0</th>\n      <th>cat__ind_25.0</th>\n      <th>cat__ind_26.0</th>\n      <th>cat__ind_27.0</th>\n      <th>cat__ind_28.0</th>\n      <th>cat__ind_29.0</th>\n      <th>cat__ind_30.0</th>\n      <th>cat__ind_31.0</th>\n      <th>cat__ind_32.0</th>\n      <th>cat__ind_33.0</th>\n      <th>cat__ind_34.0</th>\n      <th>cat__ind_35.0</th>\n      <th>cat__ind_36.0</th>\n      <th>cat__ind_37.0</th>\n      <th>cat__ind_38.0</th>\n      <th>cat__ind_39.0</th>\n      <th>cat__ind_40.0</th>\n      <th>cat__ind_41.0</th>\n      <th>cat__ind_42.0</th>\n      <th>cat__ind_43.0</th>\n      <th>cat__ind_44.0</th>\n      <th>cat__ind_45.0</th>\n      <th>cat__ind_46.0</th>\n      <th>cat__ind_47.0</th>\n      <th>cat__ind_48.0</th>\n      <th>cat__ind_49.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39</th>\n      <td>0.114148</td>\n      <td>-1.221555</td>\n      <td>-0.780439</td>\n      <td>-0.481518</td>\n      <td>-0.095930</td>\n      <td>-0.717797</td>\n      <td>-1.353610</td>\n      <td>0.558254</td>\n      <td>0.508204</td>\n      <td>0.601670</td>\n      <td>0.549860</td>\n      <td>-0.591416</td>\n      <td>-0.560881</td>\n      <td>0.497645</td>\n      <td>-0.175013</td>\n      <td>-0.312837</td>\n      <td>0.062075</td>\n      <td>-0.515229</td>\n      <td>-0.408215</td>\n      <td>-0.033124</td>\n      <td>0.109300</td>\n      <td>-0.026699</td>\n      <td>-0.554833</td>\n      <td>0.507669</td>\n      <td>-0.285266</td>\n      <td>0.270540</td>\n      <td>0.462800</td>\n      <td>-0.523765</td>\n      <td>0.021676</td>\n      <td>0.383204</td>\n      <td>-0.278687</td>\n      <td>0.402250</td>\n      <td>0.123209</td>\n      <td>-0.285266</td>\n      <td>0.089480</td>\n      <td>-1.868365</td>\n      <td>-0.023381</td>\n      <td>0.075125</td>\n      <td>-0.135822</td>\n      <td>-0.198262</td>\n      <td>-0.118275</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.708016</td>\n      <td>-1.025009</td>\n      <td>-0.780439</td>\n      <td>-0.481518</td>\n      <td>-0.095930</td>\n      <td>-0.717797</td>\n      <td>1.152138</td>\n      <td>-0.015554</td>\n      <td>0.507482</td>\n      <td>-0.108999</td>\n      <td>-0.048967</td>\n      <td>-0.709727</td>\n      <td>-0.369716</td>\n      <td>-0.133699</td>\n      <td>-0.133880</td>\n      <td>-0.258084</td>\n      <td>-0.302480</td>\n      <td>-0.460535</td>\n      <td>-0.408215</td>\n      <td>-0.033124</td>\n      <td>0.109300</td>\n      <td>-0.026699</td>\n      <td>-0.536835</td>\n      <td>0.502633</td>\n      <td>-0.564232</td>\n      <td>0.061044</td>\n      <td>0.481386</td>\n      <td>-0.744781</td>\n      <td>0.390686</td>\n      <td>0.405810</td>\n      <td>-0.398489</td>\n      <td>0.036208</td>\n      <td>0.140100</td>\n      <td>-0.564232</td>\n      <td>-0.168442</td>\n      <td>-1.636608</td>\n      <td>-0.900703</td>\n      <td>-0.812385</td>\n      <td>-0.243596</td>\n      <td>-0.272191</td>\n      <td>-0.142440</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.588727</td>\n      <td>-0.674185</td>\n      <td>-0.780439</td>\n      <td>-0.481518</td>\n      <td>-0.095930</td>\n      <td>-0.717797</td>\n      <td>0.418507</td>\n      <td>0.782500</td>\n      <td>0.494919</td>\n      <td>0.960556</td>\n      <td>0.585115</td>\n      <td>-0.504172</td>\n      <td>0.612468</td>\n      <td>1.194725</td>\n      <td>-0.004759</td>\n      <td>-0.119211</td>\n      <td>-0.183760</td>\n      <td>-0.436810</td>\n      <td>-0.408215</td>\n      <td>-0.033124</td>\n      <td>0.109300</td>\n      <td>-0.026699</td>\n      <td>-0.589087</td>\n      <td>0.501912</td>\n      <td>-0.372573</td>\n      <td>-0.302765</td>\n      <td>0.496068</td>\n      <td>-0.288589</td>\n      <td>0.269276</td>\n      <td>0.425136</td>\n      <td>0.416838</td>\n      <td>0.008422</td>\n      <td>0.199132</td>\n      <td>-0.372573</td>\n      <td>-0.298296</td>\n      <td>-1.508436</td>\n      <td>-0.009298</td>\n      <td>-0.138327</td>\n      <td>-0.299628</td>\n      <td>-0.377692</td>\n      <td>-0.411109</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>-0.152043</td>\n      <td>-0.096694</td>\n      <td>-0.278284</td>\n      <td>-1.027436</td>\n      <td>1.432911</td>\n      <td>-1.591683</td>\n      <td>-1.606161</td>\n      <td>-2.066496</td>\n      <td>2.068987</td>\n      <td>3.950431</td>\n      <td>4.096534</td>\n      <td>-2.445455</td>\n      <td>3.087190</td>\n      <td>3.635682</td>\n      <td>3.184424</td>\n      <td>2.267580</td>\n      <td>1.472282</td>\n      <td>-2.342709</td>\n      <td>-0.382877</td>\n      <td>-1.061952</td>\n      <td>1.948956</td>\n      <td>-0.689050</td>\n      <td>-1.673135</td>\n      <td>2.063489</td>\n      <td>4.003177</td>\n      <td>3.057275</td>\n      <td>2.051957</td>\n      <td>0.123184</td>\n      <td>1.832875</td>\n      <td>2.035117</td>\n      <td>0.544967</td>\n      <td>0.485602</td>\n      <td>1.996417</td>\n      <td>4.003177</td>\n      <td>0.931388</td>\n      <td>-1.302168</td>\n      <td>1.504758</td>\n      <td>1.765495</td>\n      <td>-1.753375</td>\n      <td>0.752070</td>\n      <td>-0.216356</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>-0.152043</td>\n      <td>-0.096694</td>\n      <td>-0.278284</td>\n      <td>-1.027436</td>\n      <td>1.432911</td>\n      <td>-1.591683</td>\n      <td>-2.351983</td>\n      <td>-2.066496</td>\n      <td>2.068987</td>\n      <td>2.766578</td>\n      <td>3.128399</td>\n      <td>-2.053542</td>\n      <td>1.291341</td>\n      <td>2.582623</td>\n      <td>3.415948</td>\n      <td>2.403138</td>\n      <td>8.340880</td>\n      <td>-2.504108</td>\n      <td>-0.382877</td>\n      <td>-1.061952</td>\n      <td>1.948956</td>\n      <td>-0.689050</td>\n      <td>-1.700324</td>\n      <td>2.063489</td>\n      <td>3.093286</td>\n      <td>1.468365</td>\n      <td>2.051957</td>\n      <td>0.755039</td>\n      <td>2.181432</td>\n      <td>2.035117</td>\n      <td>-0.375175</td>\n      <td>1.554498</td>\n      <td>1.996417</td>\n      <td>3.093286</td>\n      <td>2.697698</td>\n      <td>-1.576470</td>\n      <td>0.892243</td>\n      <td>0.948094</td>\n      <td>-1.628943</td>\n      <td>0.748329</td>\n      <td>-0.216356</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78249</th>\n      <td>-1.292315</td>\n      <td>-1.429734</td>\n      <td>1.132903</td>\n      <td>-0.671171</td>\n      <td>-1.397125</td>\n      <td>-0.509075</td>\n      <td>0.018750</td>\n      <td>-2.037527</td>\n      <td>-0.848603</td>\n      <td>1.191216</td>\n      <td>0.654402</td>\n      <td>1.350629</td>\n      <td>1.849704</td>\n      <td>1.650750</td>\n      <td>0.220484</td>\n      <td>0.329703</td>\n      <td>-0.368781</td>\n      <td>0.547134</td>\n      <td>0.556766</td>\n      <td>0.333763</td>\n      <td>-0.907684</td>\n      <td>-0.328660</td>\n      <td>1.049053</td>\n      <td>-0.897648</td>\n      <td>-0.237758</td>\n      <td>-0.315237</td>\n      <td>-0.929665</td>\n      <td>-0.735822</td>\n      <td>-0.386994</td>\n      <td>-0.989261</td>\n      <td>-0.094609</td>\n      <td>-0.393469</td>\n      <td>-1.092463</td>\n      <td>-0.237758</td>\n      <td>-0.405480</td>\n      <td>0.168724</td>\n      <td>-0.825924</td>\n      <td>-0.749620</td>\n      <td>-0.298382</td>\n      <td>-1.154880</td>\n      <td>-1.009336</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78250</th>\n      <td>-1.424066</td>\n      <td>-1.635540</td>\n      <td>1.132903</td>\n      <td>-0.671171</td>\n      <td>-1.397125</td>\n      <td>-0.509075</td>\n      <td>-1.187960</td>\n      <td>-1.857585</td>\n      <td>-0.816400</td>\n      <td>1.288830</td>\n      <td>0.587613</td>\n      <td>1.291279</td>\n      <td>2.190789</td>\n      <td>1.428214</td>\n      <td>0.529646</td>\n      <td>0.494496</td>\n      <td>-0.367257</td>\n      <td>0.494757</td>\n      <td>0.556766</td>\n      <td>0.333763</td>\n      <td>-0.907684</td>\n      <td>-0.328660</td>\n      <td>0.981460</td>\n      <td>-0.854238</td>\n      <td>1.852596</td>\n      <td>-0.368931</td>\n      <td>-0.931328</td>\n      <td>-0.718356</td>\n      <td>-0.384852</td>\n      <td>-0.971228</td>\n      <td>-0.567803</td>\n      <td>-0.392234</td>\n      <td>-1.109453</td>\n      <td>1.852596</td>\n      <td>-0.402771</td>\n      <td>0.366459</td>\n      <td>-0.648510</td>\n      <td>-0.785161</td>\n      <td>-0.242835</td>\n      <td>-1.094196</td>\n      <td>-0.995190</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78281</th>\n      <td>1.492163</td>\n      <td>0.296948</td>\n      <td>-1.789752</td>\n      <td>0.085412</td>\n      <td>-0.507287</td>\n      <td>-0.598994</td>\n      <td>0.288522</td>\n      <td>0.224005</td>\n      <td>-0.842586</td>\n      <td>-0.704322</td>\n      <td>-0.733165</td>\n      <td>-0.798543</td>\n      <td>-0.778034</td>\n      <td>-0.829631</td>\n      <td>-0.846416</td>\n      <td>-0.826171</td>\n      <td>-0.392569</td>\n      <td>0.813101</td>\n      <td>-1.434570</td>\n      <td>0.337093</td>\n      <td>-0.616757</td>\n      <td>-1.166201</td>\n      <td>0.785096</td>\n      <td>-0.844010</td>\n      <td>-0.593442</td>\n      <td>-0.376332</td>\n      <td>-0.864901</td>\n      <td>-0.587266</td>\n      <td>-0.403315</td>\n      <td>-0.893632</td>\n      <td>-0.918859</td>\n      <td>-0.405024</td>\n      <td>-0.865775</td>\n      <td>-0.593442</td>\n      <td>-0.405480</td>\n      <td>0.175709</td>\n      <td>-0.605582</td>\n      <td>-0.573409</td>\n      <td>-0.221885</td>\n      <td>-1.057383</td>\n      <td>-1.143209</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78282</th>\n      <td>1.772541</td>\n      <td>0.142887</td>\n      <td>-1.789752</td>\n      <td>0.085412</td>\n      <td>-0.507287</td>\n      <td>-0.598994</td>\n      <td>-0.469609</td>\n      <td>0.474893</td>\n      <td>-0.833023</td>\n      <td>-0.863574</td>\n      <td>-0.821552</td>\n      <td>-0.726471</td>\n      <td>-0.225214</td>\n      <td>-0.488456</td>\n      <td>-0.841954</td>\n      <td>-0.794622</td>\n      <td>-0.390061</td>\n      <td>0.796316</td>\n      <td>-1.434570</td>\n      <td>0.337093</td>\n      <td>-0.616757</td>\n      <td>-1.166201</td>\n      <td>0.763320</td>\n      <td>-0.848221</td>\n      <td>-0.781948</td>\n      <td>-0.392669</td>\n      <td>-0.856127</td>\n      <td>-0.690745</td>\n      <td>-0.395040</td>\n      <td>-0.893655</td>\n      <td>-0.631482</td>\n      <td>-0.405024</td>\n      <td>-0.881532</td>\n      <td>-0.781948</td>\n      <td>-0.405480</td>\n      <td>0.136469</td>\n      <td>-0.960917</td>\n      <td>-0.938984</td>\n      <td>-0.281091</td>\n      <td>-1.166432</td>\n      <td>-1.169511</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>78283</th>\n      <td>1.554300</td>\n      <td>-0.010265</td>\n      <td>-1.789752</td>\n      <td>0.085412</td>\n      <td>-0.507287</td>\n      <td>-0.598994</td>\n      <td>0.185031</td>\n      <td>0.556194</td>\n      <td>-0.827457</td>\n      <td>-0.747979</td>\n      <td>-0.624860</td>\n      <td>-0.648096</td>\n      <td>-0.477569</td>\n      <td>-0.377189</td>\n      <td>-0.776884</td>\n      <td>-0.764491</td>\n      <td>-0.402058</td>\n      <td>0.804534</td>\n      <td>-1.434570</td>\n      <td>0.337093</td>\n      <td>-0.616757</td>\n      <td>-1.166201</td>\n      <td>0.735749</td>\n      <td>-0.838657</td>\n      <td>-0.227696</td>\n      <td>-0.390167</td>\n      <td>-0.855671</td>\n      <td>-0.599330</td>\n      <td>-0.377511</td>\n      <td>-0.887702</td>\n      <td>-0.539070</td>\n      <td>-0.405024</td>\n      <td>-0.885397</td>\n      <td>-0.227696</td>\n      <td>-0.405325</td>\n      <td>-0.037573</td>\n      <td>-0.816942</td>\n      <td>-0.699459</td>\n      <td>-0.227173</td>\n      <td>-1.160779</td>\n      <td>-1.171930</td>\n      <td>-0.150249</td>\n      <td>-0.037746</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4706 rows × 92 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neurons_base = 16\ndropout_rate = 0.05\n# n_b=8 was ok with small overfit.\n# n_b=32 starts clearly overfitting. \n# 128 fits clearly slower than 64 and becomes somewhat unstable. regularization could make it work, but i see no reason to go wider.\n# 64 seems to have nice balance of flexibility and runtime, but its variance may be too large. dropout makes variance vene worse.\n# 6 hidden layers is probably most this architecture can hold\n\n# in this framework the optimal model seems to have width of 16 or 32, somehow regularized. try l1/l2?\n# w32 can take at most 0.03 dropout.\n# w16 looks good w/o dropout.\n\n# more general point:\n# main drawback of dropout is in incresing variance\n# for textbook problems with high s/n ratio (e.g., mnist) this may be ok.\n# for application like this with very low s/n ratio dropout may be a bad idea.\n\nmodel_snn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*32, activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=X_train.shape[1:]),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*16, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*8, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    Dense(1)])\n\nprint(model_snn.count_params())","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:46.383978Z","iopub.execute_input":"2022-09-07T01:00:46.385256Z","iopub.status.idle":"2022-09-07T01:00:54.402327Z","shell.execute_reply.started":"2022-09-07T01:00:46.385222Z","shell.execute_reply":"2022-09-07T01:00:54.401303Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"2022-09-07 01:00:46.425597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:46.426970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:46.427667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:46.428536: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-09-07 01:00:46.428865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:46.429575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:46.430291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:53.960843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:53.961863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:53.962649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node r","output_type":"stream"},{"name":"stdout","text":"222721\n","output_type":"stream"},{"name":"stderr","text":"ead from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-07 01:00:53.963302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14637 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"neurons_base = 32\ndropout_rate = 0.25\n\nmodel_snn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*8, activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=X_train.shape[1:]),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    Dense(1)])\n\nprint(model_snn.count_params())\n\n# similar problem as before: model seems ok in terms of flexibility and variance, but adding dropout breaks it before i can fix overfitting.\n# the solution is to either use smaller models or to use laternative regularizers (which do not increase variance.)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:54.403808Z","iopub.execute_input":"2022-09-07T01:00:54.404694Z","iopub.status.idle":"2022-09-07T01:00:54.458008Z","shell.execute_reply.started":"2022-09-07T01:00:54.404636Z","shell.execute_reply":"2022-09-07T01:00:54.456985Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"67073\n","output_type":"stream"}]},{"cell_type":"code","source":"neurons_base = 6\nl2_reg_rate = 0.2\n\nmodel_snn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\", \n                          kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate), input_shape=X_train.shape[1:]),\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base/2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base/2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    Dense(1)])\n\nprint(model_snn.count_params())","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:54.459515Z","iopub.execute_input":"2022-09-07T01:00:54.459895Z","iopub.status.idle":"2022-09-07T01:00:54.521256Z","shell.execute_reply.started":"2022-09-07T01:00:54.459858Z","shell.execute_reply":"2022-09-07T01:00:54.520241Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"3247\n","output_type":"stream"}]},{"cell_type":"code","source":"neurons_base = 8\nl2_reg_rate = 0.2\n\nmodel_snn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\", \n                          kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate), input_shape=X_train.shape[1:]),\n    tf.keras.layers.Dense(units=neurons_base*3, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n\n    Dense(1)])\n\nprint(model_snn.count_params())","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:00:54.522608Z","iopub.execute_input":"2022-09-07T01:00:54.522943Z","iopub.status.idle":"2022-09-07T01:00:54.583417Z","shell.execute_reply.started":"2022-09-07T01:00:54.522909Z","shell.execute_reply":"2022-09-07T01:00:54.582418Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"4657\n","output_type":"stream"}]},{"cell_type":"code","source":"neurons_base = 8\nl2_reg_rate = 0.3\n\nmodel_snn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\", \n                          kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate), input_shape=X_train.shape[1:]),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base/2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    Dense(1)])\n\nprint(model_snn.count_params())\n\n# snn: 32-16-8-4 with 30%l2 reg seems to converge to 5.1% test r2.","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:34:43.298489Z","iopub.execute_input":"2022-09-07T01:34:43.298875Z","iopub.status.idle":"2022-09-07T01:34:43.345582Z","shell.execute_reply.started":"2022-09-07T01:34:43.298842Z","shell.execute_reply":"2022-09-07T01:34:43.344502Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"3681\n","output_type":"stream"}]},{"cell_type":"code","source":"early_stopping50 = EarlyStopping(patience=50, restore_best_weights=True)\ntime1 = time.time()\noptimizer_adam = tf.keras.optimizers.Adam()\nmodel_snn.compile(loss= \"mean_squared_error\" , optimizer=optimizer_adam, metrics=[\"mean_squared_error\"])\nhistory = model_snn.fit(X_train, y_train, validation_data=(X_val, y_val), \n                         batch_size=2048, epochs=1000, verbose=2, callbacks=[early_stopping50])\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))\n\nprint([r2_score(y_train, model_snn.predict(X_train)), \n       r2_score(y_val, model_snn.predict(X_val)),\n       r2_score(y_test, model_snn.predict(X_test))])\nprint(time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:34:43.496549Z","iopub.execute_input":"2022-09-07T01:34:43.496912Z","iopub.status.idle":"2022-09-07T01:35:10.866513Z","shell.execute_reply.started":"2022-09-07T01:34:43.496880Z","shell.execute_reply":"2022-09-07T01:35:10.865548Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"Epoch 1/1000\n30/30 - 1s - loss: 139.9440 - mean_squared_error: 123.9719 - val_loss: 150.7428 - val_mean_squared_error: 136.6830\nEpoch 2/1000\n30/30 - 0s - loss: 135.5417 - mean_squared_error: 123.0081 - val_loss: 147.0118 - val_mean_squared_error: 135.9563\nEpoch 3/1000\n30/30 - 0s - loss: 132.5221 - mean_squared_error: 122.5378 - val_loss: 144.0993 - val_mean_squared_error: 135.1556\nEpoch 4/1000\n30/30 - 0s - loss: 130.1232 - mean_squared_error: 121.9219 - val_loss: 141.9333 - val_mean_squared_error: 134.4223\nEpoch 5/1000\n30/30 - 0s - loss: 128.1767 - mean_squared_error: 121.1550 - val_loss: 138.5352 - val_mean_squared_error: 131.9656\nEpoch 6/1000\n30/30 - 0s - loss: 126.7361 - mean_squared_error: 120.5175 - val_loss: 138.7566 - val_mean_squared_error: 132.9056\nEpoch 7/1000\n30/30 - 0s - loss: 125.7207 - mean_squared_error: 120.1480 - val_loss: 136.9989 - val_mean_squared_error: 131.7204\nEpoch 8/1000\n30/30 - 0s - loss: 124.8485 - mean_squared_error: 119.8273 - val_loss: 137.1170 - val_mean_squared_error: 132.3429\nEpoch 9/1000\n30/30 - 0s - loss: 124.2544 - mean_squared_error: 119.6823 - val_loss: 134.2358 - val_mean_squared_error: 129.8565\nEpoch 10/1000\n30/30 - 0s - loss: 123.7740 - mean_squared_error: 119.5476 - val_loss: 133.5453 - val_mean_squared_error: 129.4803\nEpoch 11/1000\n30/30 - 0s - loss: 123.3348 - mean_squared_error: 119.3906 - val_loss: 133.0693 - val_mean_squared_error: 129.2537\nEpoch 12/1000\n30/30 - 0s - loss: 122.9513 - mean_squared_error: 119.2751 - val_loss: 133.9385 - val_mean_squared_error: 130.3644\nEpoch 13/1000\n30/30 - 0s - loss: 122.6459 - mean_squared_error: 119.1584 - val_loss: 133.3864 - val_mean_squared_error: 129.9920\nEpoch 14/1000\n30/30 - 0s - loss: 122.5893 - mean_squared_error: 119.2740 - val_loss: 130.5700 - val_mean_squared_error: 127.3646\nEpoch 15/1000\n30/30 - 0s - loss: 122.3735 - mean_squared_error: 119.2437 - val_loss: 131.7057 - val_mean_squared_error: 128.6240\nEpoch 16/1000\n30/30 - 0s - loss: 122.0210 - mean_squared_error: 118.9720 - val_loss: 133.1746 - val_mean_squared_error: 130.1639\nEpoch 17/1000\n30/30 - 0s - loss: 121.9230 - mean_squared_error: 118.9874 - val_loss: 133.5349 - val_mean_squared_error: 130.6546\nEpoch 18/1000\n30/30 - 0s - loss: 121.7290 - mean_squared_error: 118.8535 - val_loss: 131.5101 - val_mean_squared_error: 128.6760\nEpoch 19/1000\n30/30 - 0s - loss: 121.7052 - mean_squared_error: 118.8985 - val_loss: 130.9760 - val_mean_squared_error: 128.2363\nEpoch 20/1000\n30/30 - 0s - loss: 121.5203 - mean_squared_error: 118.8093 - val_loss: 131.3641 - val_mean_squared_error: 128.6941\nEpoch 21/1000\n30/30 - 0s - loss: 121.4190 - mean_squared_error: 118.7651 - val_loss: 130.4774 - val_mean_squared_error: 127.8328\nEpoch 22/1000\n30/30 - 0s - loss: 121.3220 - mean_squared_error: 118.6983 - val_loss: 130.4072 - val_mean_squared_error: 127.8122\nEpoch 23/1000\n30/30 - 0s - loss: 121.1493 - mean_squared_error: 118.5852 - val_loss: 130.3689 - val_mean_squared_error: 127.8028\nEpoch 24/1000\n30/30 - 0s - loss: 121.2074 - mean_squared_error: 118.6521 - val_loss: 130.6298 - val_mean_squared_error: 128.1102\nEpoch 25/1000\n30/30 - 0s - loss: 121.1880 - mean_squared_error: 118.6877 - val_loss: 130.9360 - val_mean_squared_error: 128.4678\nEpoch 26/1000\n30/30 - 0s - loss: 120.9490 - mean_squared_error: 118.4896 - val_loss: 130.4234 - val_mean_squared_error: 127.9481\nEpoch 27/1000\n30/30 - 0s - loss: 121.0237 - mean_squared_error: 118.5676 - val_loss: 129.8374 - val_mean_squared_error: 127.4226\nEpoch 28/1000\n30/30 - 0s - loss: 120.9542 - mean_squared_error: 118.5521 - val_loss: 131.2216 - val_mean_squared_error: 128.8278\nEpoch 29/1000\n30/30 - 0s - loss: 120.9815 - mean_squared_error: 118.6114 - val_loss: 129.7822 - val_mean_squared_error: 127.4157\nEpoch 30/1000\n30/30 - 0s - loss: 120.7810 - mean_squared_error: 118.4301 - val_loss: 130.6325 - val_mean_squared_error: 128.2471\nEpoch 31/1000\n30/30 - 0s - loss: 120.7174 - mean_squared_error: 118.3445 - val_loss: 131.1874 - val_mean_squared_error: 128.8587\nEpoch 32/1000\n30/30 - 0s - loss: 120.7132 - mean_squared_error: 118.3806 - val_loss: 129.1674 - val_mean_squared_error: 126.8296\nEpoch 33/1000\n30/30 - 0s - loss: 120.6630 - mean_squared_error: 118.3393 - val_loss: 130.0877 - val_mean_squared_error: 127.7462\nEpoch 34/1000\n30/30 - 0s - loss: 120.5662 - mean_squared_error: 118.2435 - val_loss: 128.7057 - val_mean_squared_error: 126.4130\nEpoch 35/1000\n30/30 - 0s - loss: 120.7789 - mean_squared_error: 118.5062 - val_loss: 129.6210 - val_mean_squared_error: 127.3613\nEpoch 36/1000\n30/30 - 0s - loss: 120.6088 - mean_squared_error: 118.3255 - val_loss: 129.5102 - val_mean_squared_error: 127.2640\nEpoch 37/1000\n30/30 - 0s - loss: 120.5622 - mean_squared_error: 118.3194 - val_loss: 128.7651 - val_mean_squared_error: 126.5025\nEpoch 38/1000\n30/30 - 0s - loss: 120.6542 - mean_squared_error: 118.3971 - val_loss: 131.1773 - val_mean_squared_error: 128.9789\nEpoch 39/1000\n30/30 - 0s - loss: 120.4071 - mean_squared_error: 118.2121 - val_loss: 129.8109 - val_mean_squared_error: 127.6059\nEpoch 40/1000\n30/30 - 0s - loss: 120.3763 - mean_squared_error: 118.1254 - val_loss: 130.7683 - val_mean_squared_error: 128.5372\nEpoch 41/1000\n30/30 - 0s - loss: 120.3993 - mean_squared_error: 118.1981 - val_loss: 127.9950 - val_mean_squared_error: 125.7827\nEpoch 42/1000\n30/30 - 0s - loss: 120.2864 - mean_squared_error: 118.0695 - val_loss: 128.3601 - val_mean_squared_error: 126.1363\nEpoch 43/1000\n30/30 - 0s - loss: 120.4212 - mean_squared_error: 118.2130 - val_loss: 128.7728 - val_mean_squared_error: 126.6121\nEpoch 44/1000\n30/30 - 0s - loss: 120.2646 - mean_squared_error: 118.0754 - val_loss: 128.1510 - val_mean_squared_error: 125.9653\nEpoch 45/1000\n30/30 - 0s - loss: 120.2273 - mean_squared_error: 118.0570 - val_loss: 130.0920 - val_mean_squared_error: 127.9054\nEpoch 46/1000\n30/30 - 0s - loss: 120.2114 - mean_squared_error: 118.0217 - val_loss: 127.2021 - val_mean_squared_error: 125.0128\nEpoch 47/1000\n30/30 - 0s - loss: 120.1750 - mean_squared_error: 117.9966 - val_loss: 130.1673 - val_mean_squared_error: 128.0092\nEpoch 48/1000\n30/30 - 0s - loss: 120.1649 - mean_squared_error: 117.9878 - val_loss: 128.0786 - val_mean_squared_error: 125.8978\nEpoch 49/1000\n30/30 - 0s - loss: 120.1760 - mean_squared_error: 118.0272 - val_loss: 127.1272 - val_mean_squared_error: 124.9721\nEpoch 50/1000\n30/30 - 0s - loss: 120.1572 - mean_squared_error: 118.0118 - val_loss: 128.2822 - val_mean_squared_error: 126.1623\nEpoch 51/1000\n30/30 - 0s - loss: 119.9968 - mean_squared_error: 117.8455 - val_loss: 127.1202 - val_mean_squared_error: 124.9668\nEpoch 52/1000\n30/30 - 0s - loss: 119.9604 - mean_squared_error: 117.8115 - val_loss: 128.2120 - val_mean_squared_error: 126.0536\nEpoch 53/1000\n30/30 - 0s - loss: 120.0050 - mean_squared_error: 117.8490 - val_loss: 129.5049 - val_mean_squared_error: 127.3627\nEpoch 54/1000\n30/30 - 0s - loss: 119.9577 - mean_squared_error: 117.8015 - val_loss: 128.0372 - val_mean_squared_error: 125.8901\nEpoch 55/1000\n30/30 - 0s - loss: 119.9688 - mean_squared_error: 117.8578 - val_loss: 128.7815 - val_mean_squared_error: 126.6639\nEpoch 56/1000\n30/30 - 0s - loss: 120.1928 - mean_squared_error: 118.0621 - val_loss: 128.1321 - val_mean_squared_error: 126.0500\nEpoch 57/1000\n30/30 - 0s - loss: 120.3338 - mean_squared_error: 118.2758 - val_loss: 128.2041 - val_mean_squared_error: 126.1478\nEpoch 58/1000\n30/30 - 0s - loss: 120.0742 - mean_squared_error: 117.9881 - val_loss: 134.6268 - val_mean_squared_error: 132.5604\nEpoch 59/1000\n30/30 - 0s - loss: 120.2546 - mean_squared_error: 118.2134 - val_loss: 128.8591 - val_mean_squared_error: 126.8268\nEpoch 60/1000\n30/30 - 0s - loss: 119.8323 - mean_squared_error: 117.7661 - val_loss: 126.4419 - val_mean_squared_error: 124.3716\nEpoch 61/1000\n30/30 - 0s - loss: 119.9422 - mean_squared_error: 117.8745 - val_loss: 129.8736 - val_mean_squared_error: 127.8110\nEpoch 62/1000\n30/30 - 0s - loss: 120.0695 - mean_squared_error: 118.0049 - val_loss: 129.5805 - val_mean_squared_error: 127.5370\nEpoch 63/1000\n30/30 - 0s - loss: 119.8528 - mean_squared_error: 117.7991 - val_loss: 127.7473 - val_mean_squared_error: 125.6866\nEpoch 64/1000\n30/30 - 0s - loss: 119.9167 - mean_squared_error: 117.8478 - val_loss: 127.6369 - val_mean_squared_error: 125.5811\nEpoch 65/1000\n30/30 - 0s - loss: 120.0252 - mean_squared_error: 118.0137 - val_loss: 127.9721 - val_mean_squared_error: 125.9397\nEpoch 66/1000\n30/30 - 0s - loss: 119.8528 - mean_squared_error: 117.8029 - val_loss: 127.2663 - val_mean_squared_error: 125.1990\nEpoch 67/1000\n30/30 - 0s - loss: 119.7537 - mean_squared_error: 117.6995 - val_loss: 127.7326 - val_mean_squared_error: 125.6906\nEpoch 68/1000\n30/30 - 0s - loss: 119.6458 - mean_squared_error: 117.5855 - val_loss: 124.6221 - val_mean_squared_error: 122.5490\nEpoch 69/1000\n30/30 - 0s - loss: 119.8034 - mean_squared_error: 117.7623 - val_loss: 128.1570 - val_mean_squared_error: 126.1064\nEpoch 70/1000\n30/30 - 0s - loss: 119.8653 - mean_squared_error: 117.8017 - val_loss: 132.2493 - val_mean_squared_error: 130.2610\nEpoch 71/1000\n30/30 - 0s - loss: 119.7525 - mean_squared_error: 117.7597 - val_loss: 127.7867 - val_mean_squared_error: 125.7828\nEpoch 72/1000\n30/30 - 0s - loss: 119.6724 - mean_squared_error: 117.6218 - val_loss: 127.3360 - val_mean_squared_error: 125.2800\nEpoch 73/1000\n30/30 - 0s - loss: 119.6029 - mean_squared_error: 117.5631 - val_loss: 130.4307 - val_mean_squared_error: 128.4100\nEpoch 74/1000\n30/30 - 0s - loss: 119.6227 - mean_squared_error: 117.5987 - val_loss: 127.5595 - val_mean_squared_error: 125.5012\nEpoch 75/1000\n30/30 - 0s - loss: 119.4711 - mean_squared_error: 117.4132 - val_loss: 128.1648 - val_mean_squared_error: 126.1208\nEpoch 76/1000\n30/30 - 0s - loss: 119.5985 - mean_squared_error: 117.5586 - val_loss: 125.7071 - val_mean_squared_error: 123.6611\nEpoch 77/1000\n30/30 - 0s - loss: 119.8888 - mean_squared_error: 117.8557 - val_loss: 128.2374 - val_mean_squared_error: 126.2393\nEpoch 78/1000\n30/30 - 0s - loss: 119.5209 - mean_squared_error: 117.4971 - val_loss: 128.0674 - val_mean_squared_error: 126.0465\nEpoch 79/1000\n30/30 - 0s - loss: 119.4588 - mean_squared_error: 117.4251 - val_loss: 127.0321 - val_mean_squared_error: 124.9814\nEpoch 80/1000\n30/30 - 0s - loss: 119.4420 - mean_squared_error: 117.4081 - val_loss: 126.7136 - val_mean_squared_error: 124.6810\nEpoch 81/1000\n30/30 - 0s - loss: 119.5087 - mean_squared_error: 117.4663 - val_loss: 127.9485 - val_mean_squared_error: 125.9110\nEpoch 82/1000\n30/30 - 0s - loss: 119.5572 - mean_squared_error: 117.5132 - val_loss: 126.5926 - val_mean_squared_error: 124.5703\nEpoch 83/1000\n30/30 - 0s - loss: 119.4336 - mean_squared_error: 117.4289 - val_loss: 132.0118 - val_mean_squared_error: 130.0104\nEpoch 84/1000\n30/30 - 0s - loss: 119.6464 - mean_squared_error: 117.6402 - val_loss: 126.5270 - val_mean_squared_error: 124.5035\nEpoch 85/1000\n30/30 - 0s - loss: 119.5755 - mean_squared_error: 117.5656 - val_loss: 127.7354 - val_mean_squared_error: 125.7213\nEpoch 86/1000\n30/30 - 0s - loss: 119.6430 - mean_squared_error: 117.6286 - val_loss: 127.0581 - val_mean_squared_error: 125.0688\nEpoch 87/1000\n30/30 - 0s - loss: 119.3901 - mean_squared_error: 117.3983 - val_loss: 127.6402 - val_mean_squared_error: 125.6194\nEpoch 88/1000\n30/30 - 0s - loss: 119.3888 - mean_squared_error: 117.3807 - val_loss: 127.3657 - val_mean_squared_error: 125.3554\nEpoch 89/1000\n30/30 - 0s - loss: 119.5801 - mean_squared_error: 117.5913 - val_loss: 127.9013 - val_mean_squared_error: 125.9200\nEpoch 90/1000\n30/30 - 0s - loss: 119.4239 - mean_squared_error: 117.4296 - val_loss: 128.4547 - val_mean_squared_error: 126.4687\nEpoch 91/1000\n30/30 - 0s - loss: 119.6404 - mean_squared_error: 117.6562 - val_loss: 125.8149 - val_mean_squared_error: 123.8315\nEpoch 92/1000\n30/30 - 0s - loss: 119.4640 - mean_squared_error: 117.4973 - val_loss: 127.3570 - val_mean_squared_error: 125.3740\nEpoch 93/1000\n30/30 - 0s - loss: 119.4997 - mean_squared_error: 117.4978 - val_loss: 129.5240 - val_mean_squared_error: 127.5626\nEpoch 94/1000\n30/30 - 0s - loss: 119.4886 - mean_squared_error: 117.5198 - val_loss: 127.6097 - val_mean_squared_error: 125.6432\nEpoch 95/1000\n30/30 - 0s - loss: 119.4186 - mean_squared_error: 117.4444 - val_loss: 124.2685 - val_mean_squared_error: 122.2947\nEpoch 96/1000\n30/30 - 0s - loss: 119.3149 - mean_squared_error: 117.3338 - val_loss: 129.4583 - val_mean_squared_error: 127.4737\nEpoch 97/1000\n30/30 - 0s - loss: 119.2505 - mean_squared_error: 117.2609 - val_loss: 129.2405 - val_mean_squared_error: 127.2507\nEpoch 98/1000\n30/30 - 0s - loss: 119.3103 - mean_squared_error: 117.3242 - val_loss: 127.0539 - val_mean_squared_error: 125.0600\nEpoch 99/1000\n30/30 - 0s - loss: 119.3444 - mean_squared_error: 117.3612 - val_loss: 129.2051 - val_mean_squared_error: 127.2227\nEpoch 100/1000\n30/30 - 0s - loss: 119.1966 - mean_squared_error: 117.2007 - val_loss: 129.5958 - val_mean_squared_error: 127.6069\nEpoch 101/1000\n30/30 - 0s - loss: 119.1835 - mean_squared_error: 117.1951 - val_loss: 128.9724 - val_mean_squared_error: 126.9803\nEpoch 102/1000\n30/30 - 0s - loss: 119.0869 - mean_squared_error: 117.0714 - val_loss: 130.5705 - val_mean_squared_error: 128.5727\nEpoch 103/1000\n30/30 - 0s - loss: 119.1151 - mean_squared_error: 117.1272 - val_loss: 126.3634 - val_mean_squared_error: 124.3611\nEpoch 104/1000\n30/30 - 0s - loss: 119.3192 - mean_squared_error: 117.3221 - val_loss: 130.4121 - val_mean_squared_error: 128.4353\nEpoch 105/1000\n30/30 - 0s - loss: 119.2153 - mean_squared_error: 117.2227 - val_loss: 125.4538 - val_mean_squared_error: 123.4414\nEpoch 106/1000\n30/30 - 0s - loss: 119.1096 - mean_squared_error: 117.1109 - val_loss: 128.3200 - val_mean_squared_error: 126.3439\nEpoch 107/1000\n30/30 - 0s - loss: 119.2584 - mean_squared_error: 117.2764 - val_loss: 125.0884 - val_mean_squared_error: 123.0976\nEpoch 108/1000\n30/30 - 0s - loss: 119.0489 - mean_squared_error: 117.0619 - val_loss: 128.5917 - val_mean_squared_error: 126.5900\nEpoch 109/1000\n30/30 - 0s - loss: 119.0679 - mean_squared_error: 117.0727 - val_loss: 127.2544 - val_mean_squared_error: 125.2799\nEpoch 110/1000\n30/30 - 0s - loss: 119.3402 - mean_squared_error: 117.3594 - val_loss: 132.4083 - val_mean_squared_error: 130.4664\nEpoch 111/1000\n30/30 - 0s - loss: 119.2440 - mean_squared_error: 117.2921 - val_loss: 128.6986 - val_mean_squared_error: 126.7293\nEpoch 112/1000\n30/30 - 0s - loss: 119.2352 - mean_squared_error: 117.2636 - val_loss: 126.5573 - val_mean_squared_error: 124.5810\nEpoch 113/1000\n30/30 - 0s - loss: 119.3395 - mean_squared_error: 117.3836 - val_loss: 132.6009 - val_mean_squared_error: 130.6889\nEpoch 114/1000\n30/30 - 0s - loss: 119.2947 - mean_squared_error: 117.3595 - val_loss: 126.6523 - val_mean_squared_error: 124.7112\nEpoch 115/1000\n30/30 - 0s - loss: 119.0264 - mean_squared_error: 117.0619 - val_loss: 126.5109 - val_mean_squared_error: 124.5507\nEpoch 116/1000\n30/30 - 0s - loss: 118.9156 - mean_squared_error: 116.9537 - val_loss: 128.4973 - val_mean_squared_error: 126.5339\nEpoch 117/1000\n30/30 - 0s - loss: 119.0470 - mean_squared_error: 117.0764 - val_loss: 128.9876 - val_mean_squared_error: 126.9980\nEpoch 118/1000\n30/30 - 0s - loss: 118.8304 - mean_squared_error: 116.8437 - val_loss: 126.1513 - val_mean_squared_error: 124.1580\nEpoch 119/1000\n30/30 - 0s - loss: 118.9138 - mean_squared_error: 116.9301 - val_loss: 128.9478 - val_mean_squared_error: 126.9720\nEpoch 120/1000\n30/30 - 0s - loss: 118.9598 - mean_squared_error: 116.9838 - val_loss: 126.9768 - val_mean_squared_error: 125.0150\nEpoch 121/1000\n30/30 - 0s - loss: 118.9146 - mean_squared_error: 116.9499 - val_loss: 127.7505 - val_mean_squared_error: 125.7779\nEpoch 122/1000\n30/30 - 0s - loss: 118.7733 - mean_squared_error: 116.7841 - val_loss: 128.8733 - val_mean_squared_error: 126.8827\nEpoch 123/1000\n30/30 - 0s - loss: 118.6919 - mean_squared_error: 116.6942 - val_loss: 127.0616 - val_mean_squared_error: 125.0662\nEpoch 124/1000\n30/30 - 0s - loss: 118.6703 - mean_squared_error: 116.6610 - val_loss: 126.3068 - val_mean_squared_error: 124.2959\nEpoch 125/1000\n30/30 - 0s - loss: 118.7199 - mean_squared_error: 116.7186 - val_loss: 129.5802 - val_mean_squared_error: 127.5779\nEpoch 126/1000\n30/30 - 0s - loss: 118.7436 - mean_squared_error: 116.7377 - val_loss: 129.1978 - val_mean_squared_error: 127.2056\nEpoch 127/1000\n30/30 - 0s - loss: 118.7758 - mean_squared_error: 116.7839 - val_loss: 126.6634 - val_mean_squared_error: 124.6701\nEpoch 128/1000\n30/30 - 0s - loss: 118.8897 - mean_squared_error: 116.8968 - val_loss: 128.2456 - val_mean_squared_error: 126.2635\nEpoch 129/1000\n30/30 - 0s - loss: 118.8213 - mean_squared_error: 116.8352 - val_loss: 125.7852 - val_mean_squared_error: 123.7944\nEpoch 130/1000\n30/30 - 0s - loss: 118.6538 - mean_squared_error: 116.6691 - val_loss: 130.1989 - val_mean_squared_error: 128.1999\nEpoch 131/1000\n30/30 - 0s - loss: 118.8441 - mean_squared_error: 116.8492 - val_loss: 128.4725 - val_mean_squared_error: 126.4839\nEpoch 132/1000\n30/30 - 0s - loss: 119.0184 - mean_squared_error: 117.0571 - val_loss: 128.8134 - val_mean_squared_error: 126.8737\nEpoch 133/1000\n30/30 - 0s - loss: 118.7492 - mean_squared_error: 116.7840 - val_loss: 127.6743 - val_mean_squared_error: 125.7090\nEpoch 134/1000\n30/30 - 0s - loss: 118.7487 - mean_squared_error: 116.7744 - val_loss: 129.6451 - val_mean_squared_error: 127.6729\nEpoch 135/1000\n30/30 - 0s - loss: 118.7067 - mean_squared_error: 116.7213 - val_loss: 125.7205 - val_mean_squared_error: 123.7352\nEpoch 136/1000\n30/30 - 0s - loss: 118.9707 - mean_squared_error: 117.0095 - val_loss: 124.2797 - val_mean_squared_error: 122.3217\nEpoch 137/1000\n30/30 - 0s - loss: 118.7713 - mean_squared_error: 116.8000 - val_loss: 128.5697 - val_mean_squared_error: 126.6061\nEpoch 138/1000\n30/30 - 0s - loss: 119.3331 - mean_squared_error: 117.3754 - val_loss: 129.1410 - val_mean_squared_error: 127.2013\nEpoch 139/1000\n30/30 - 0s - loss: 119.2080 - mean_squared_error: 117.2714 - val_loss: 126.2698 - val_mean_squared_error: 124.3632\nEpoch 140/1000\n30/30 - 0s - loss: 118.9054 - mean_squared_error: 116.9749 - val_loss: 127.0101 - val_mean_squared_error: 125.0556\nEpoch 141/1000\n30/30 - 0s - loss: 118.6582 - mean_squared_error: 116.7018 - val_loss: 127.3099 - val_mean_squared_error: 125.3626\nEpoch 142/1000\n30/30 - 0s - loss: 118.5904 - mean_squared_error: 116.6259 - val_loss: 123.6688 - val_mean_squared_error: 121.7013\nEpoch 143/1000\n30/30 - 0s - loss: 118.7207 - mean_squared_error: 116.7583 - val_loss: 128.7420 - val_mean_squared_error: 126.7853\nEpoch 144/1000\n30/30 - 0s - loss: 118.6954 - mean_squared_error: 116.7273 - val_loss: 126.6384 - val_mean_squared_error: 124.6701\nEpoch 145/1000\n30/30 - 0s - loss: 118.7982 - mean_squared_error: 116.8411 - val_loss: 127.6378 - val_mean_squared_error: 125.6806\nEpoch 146/1000\n30/30 - 0s - loss: 118.5469 - mean_squared_error: 116.5835 - val_loss: 126.9731 - val_mean_squared_error: 124.9995\nEpoch 147/1000\n30/30 - 0s - loss: 118.8751 - mean_squared_error: 116.9366 - val_loss: 129.2340 - val_mean_squared_error: 127.2852\nEpoch 148/1000\n30/30 - 0s - loss: 118.5655 - mean_squared_error: 116.5906 - val_loss: 128.4716 - val_mean_squared_error: 126.5113\nEpoch 149/1000\n30/30 - 0s - loss: 118.6058 - mean_squared_error: 116.6479 - val_loss: 131.0404 - val_mean_squared_error: 129.1018\nEpoch 150/1000\n30/30 - 0s - loss: 118.5217 - mean_squared_error: 116.5592 - val_loss: 126.2495 - val_mean_squared_error: 124.2841\nEpoch 151/1000\n30/30 - 0s - loss: 118.6874 - mean_squared_error: 116.7275 - val_loss: 129.7435 - val_mean_squared_error: 127.7925\nEpoch 152/1000\n30/30 - 0s - loss: 118.4706 - mean_squared_error: 116.5197 - val_loss: 124.4892 - val_mean_squared_error: 122.5194\nEpoch 153/1000\n30/30 - 0s - loss: 118.3243 - mean_squared_error: 116.3570 - val_loss: 124.6354 - val_mean_squared_error: 122.6649\nEpoch 154/1000\n30/30 - 0s - loss: 118.7654 - mean_squared_error: 116.7922 - val_loss: 129.0722 - val_mean_squared_error: 127.1212\nEpoch 155/1000\n30/30 - 0s - loss: 118.4740 - mean_squared_error: 116.5219 - val_loss: 127.2215 - val_mean_squared_error: 125.2501\nEpoch 156/1000\n30/30 - 0s - loss: 118.5432 - mean_squared_error: 116.5704 - val_loss: 127.4012 - val_mean_squared_error: 125.4360\nEpoch 157/1000\n30/30 - 0s - loss: 118.5357 - mean_squared_error: 116.5645 - val_loss: 127.1386 - val_mean_squared_error: 125.1605\nEpoch 158/1000\n30/30 - 0s - loss: 118.5000 - mean_squared_error: 116.5237 - val_loss: 127.2299 - val_mean_squared_error: 125.2613\nEpoch 159/1000\n30/30 - 0s - loss: 118.6592 - mean_squared_error: 116.7013 - val_loss: 125.8720 - val_mean_squared_error: 123.9207\nEpoch 160/1000\n30/30 - 0s - loss: 118.9279 - mean_squared_error: 116.9936 - val_loss: 127.4589 - val_mean_squared_error: 125.5380\nEpoch 161/1000\n30/30 - 0s - loss: 118.5369 - mean_squared_error: 116.5977 - val_loss: 129.3280 - val_mean_squared_error: 127.3577\nEpoch 162/1000\n30/30 - 0s - loss: 118.4496 - mean_squared_error: 116.4964 - val_loss: 130.0051 - val_mean_squared_error: 128.0495\nEpoch 163/1000\n30/30 - 0s - loss: 118.4345 - mean_squared_error: 116.4758 - val_loss: 127.5007 - val_mean_squared_error: 125.5406\nEpoch 164/1000\n30/30 - 0s - loss: 118.5532 - mean_squared_error: 116.5975 - val_loss: 126.8306 - val_mean_squared_error: 124.8817\nEpoch 165/1000\n30/30 - 0s - loss: 118.5453 - mean_squared_error: 116.5900 - val_loss: 125.9241 - val_mean_squared_error: 123.9767\nEpoch 166/1000\n30/30 - 0s - loss: 118.5317 - mean_squared_error: 116.5859 - val_loss: 126.7559 - val_mean_squared_error: 124.8197\nEpoch 167/1000\n30/30 - 0s - loss: 118.4757 - mean_squared_error: 116.5331 - val_loss: 125.2268 - val_mean_squared_error: 123.2683\nEpoch 168/1000\n30/30 - 0s - loss: 118.3401 - mean_squared_error: 116.3772 - val_loss: 128.4910 - val_mean_squared_error: 126.5362\nEpoch 169/1000\n30/30 - 0s - loss: 118.4145 - mean_squared_error: 116.4625 - val_loss: 125.5498 - val_mean_squared_error: 123.6016\nEpoch 170/1000\n30/30 - 0s - loss: 118.4551 - mean_squared_error: 116.4915 - val_loss: 129.8870 - val_mean_squared_error: 127.9302\nEpoch 171/1000\n30/30 - 0s - loss: 118.4257 - mean_squared_error: 116.4697 - val_loss: 130.5122 - val_mean_squared_error: 128.5620\nEpoch 172/1000\n30/30 - 0s - loss: 118.5148 - mean_squared_error: 116.5664 - val_loss: 127.0347 - val_mean_squared_error: 125.0900\nEpoch 173/1000\n30/30 - 0s - loss: 118.3105 - mean_squared_error: 116.3610 - val_loss: 127.0867 - val_mean_squared_error: 125.1348\nEpoch 174/1000\n30/30 - 0s - loss: 118.2740 - mean_squared_error: 116.3151 - val_loss: 130.7202 - val_mean_squared_error: 128.7749\nEpoch 175/1000\n30/30 - 0s - loss: 118.3299 - mean_squared_error: 116.3684 - val_loss: 129.9021 - val_mean_squared_error: 127.9350\nEpoch 176/1000\n30/30 - 0s - loss: 118.2978 - mean_squared_error: 116.3361 - val_loss: 127.4804 - val_mean_squared_error: 125.5190\nEpoch 177/1000\n30/30 - 0s - loss: 118.4533 - mean_squared_error: 116.4902 - val_loss: 131.1974 - val_mean_squared_error: 129.2642\nEpoch 178/1000\n30/30 - 0s - loss: 118.7804 - mean_squared_error: 116.8636 - val_loss: 127.0970 - val_mean_squared_error: 125.1594\nEpoch 179/1000\n30/30 - 0s - loss: 118.3150 - mean_squared_error: 116.3780 - val_loss: 125.1145 - val_mean_squared_error: 123.1636\nEpoch 180/1000\n30/30 - 0s - loss: 118.6463 - mean_squared_error: 116.7112 - val_loss: 127.9106 - val_mean_squared_error: 125.9846\nEpoch 181/1000\n30/30 - 0s - loss: 118.2416 - mean_squared_error: 116.3036 - val_loss: 125.7454 - val_mean_squared_error: 123.7918\nEpoch 182/1000\n30/30 - 0s - loss: 118.4038 - mean_squared_error: 116.4586 - val_loss: 127.7040 - val_mean_squared_error: 125.7547\nEpoch 183/1000\n30/30 - 0s - loss: 118.1466 - mean_squared_error: 116.1918 - val_loss: 125.3151 - val_mean_squared_error: 123.3625\nEpoch 184/1000\n30/30 - 0s - loss: 118.2013 - mean_squared_error: 116.2456 - val_loss: 126.5612 - val_mean_squared_error: 124.6047\nEpoch 185/1000\n30/30 - 0s - loss: 118.4822 - mean_squared_error: 116.5271 - val_loss: 125.9262 - val_mean_squared_error: 123.9722\nEpoch 186/1000\n30/30 - 0s - loss: 118.3032 - mean_squared_error: 116.3584 - val_loss: 125.4169 - val_mean_squared_error: 123.4681\nEpoch 187/1000\n30/30 - 0s - loss: 118.3159 - mean_squared_error: 116.3754 - val_loss: 126.2312 - val_mean_squared_error: 124.2771\nEpoch 188/1000\n30/30 - 0s - loss: 118.5040 - mean_squared_error: 116.5523 - val_loss: 130.4433 - val_mean_squared_error: 128.5262\nEpoch 189/1000\n30/30 - 0s - loss: 118.2085 - mean_squared_error: 116.2738 - val_loss: 123.8348 - val_mean_squared_error: 121.8850\nEpoch 190/1000\n30/30 - 0s - loss: 118.2461 - mean_squared_error: 116.2870 - val_loss: 126.8202 - val_mean_squared_error: 124.8566\nEpoch 191/1000\n30/30 - 0s - loss: 118.6252 - mean_squared_error: 116.6922 - val_loss: 130.1834 - val_mean_squared_error: 128.2545\nEpoch 192/1000\n30/30 - 0s - loss: 118.7780 - mean_squared_error: 116.8635 - val_loss: 130.4764 - val_mean_squared_error: 128.5667\nMinimum Validation Loss: 123.6688\n[0.060193137654131146, 0.15660315785269696, 0.051736818663456696]\n27.25041961669922\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAXwAAAD1CAYAAABTL05uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABVJElEQVR4nO2deXxU1fn/37Nksk32PRD2HSSgoOICCqIWCCBKW5Vaqbb9osWFfq2i/bYurYjtj/LV+qVYam2rtYsgKSCi7IgooCCCsi9JIJns+zLJzPz+OHPmzmSdJEMmk5z365XXZO7M3HnunXs/5znPec5zdA6Hw4FCoVAoejx6fxugUCgUiq5BCb5CoVD0EpTgKxQKRS9BCb5CoVD0EpTgKxQKRS/B6I8vra2t5ejRoyQkJGAwGPxhgkKhUAQcNpuNgoICxowZQ0hISLs/7xfBP3r0KPfee68/vlqhUCgCnrfffpsJEya0+3N+EfyEhARAGJ2cnOwPExQKhSLgyMvL495773VpaHvxi+DLME5ycjJ9+/b1hwkKhUIRsHQ0FK4GbRUKhaKXoARfoVAoeglK8BUKhaKXoARfoVAoeglK8BUKhaKXoARfoVAoegmBJ/jbfwX/WexvKxQKRYAyfvx4f5vgN/ySh98pis5A3hF/W6FQKBQBR5se/tKlS5k0aRKzZs1ybXv11Ve58cYbmTNnDnPmzGHXrl2u11avXs306dO57bbb2LNnj+8tDo2BmhLf71ehUPQqHA4Hy5cvZ9asWWRkZPD+++8DkJ+fz7333sucOXOYNWsWBw8exGaz8dRTT7ne++abb/rX+A7Spoc/b948FixYwJNPPumx/f777+eBBx7w2Hb69Gk2bdrEpk2bsFgsLFy4kC1btvi2QJoUfLsd9IEXkVIoFIK1n+fwr4PZPt3ntyekcedV3s3e//DDDzl+/DiZmZmUlJRw1113MWHCBDZu3MgNN9zAokWLsNls1NTU8M0332CxWNi4cSMA5eXlPrW7q2hTMSdOnEhUVJRXO9u2bRszZ87EZDKRlpZG//79OXLEx+GX0Bhw2MFa4dv9KhSKXsXnn3/OzJkzMRgMxMfHM3HiRL766iuuuOIK1q1bx6uvvsrJkycxm82kpaWRnZ3NCy+8wO7duzGbzf42v0N0OIb/9ttvs379esaMGcNTTz1FVFQUFouF9PR013uSkpKwWCw+MdRFaIx4rCmBEO8aIoVC0f2486q+XnvjXcnEiRN566232LVrF0899RQLFy5k7ty5ZGZm8vHHH/OPf/yDzZs3s2zZMn+b2m46FBO5++67+eijj8jMzCQxMZGXXnrJ13a1jLvgKxQKRQeZMGECmzdvxmazUVxczMGDBxk7diwXL14kPj6eb3/728yfP59jx45RXFyMw+Hgtttu47HHHuPrr7/2t/kdokMefnx8vOv/+fPn81//9V+A8Ojz8vJcr1ksFpKSkjppYiOU4CsUCh8wffp0Dh06xJw5c9DpdDzxxBMkJCTw3nvv8ac//Qmj0UhYWBjLly8nPz+fpUuXYrfbAViyZImfre8YHRL8/Px8EhMTAdi6dStDhw4FYOrUqfz0pz9l4cKFWCwWzp8/z9ixY31nLSjBVygUneLQoUMA6HQ6nnzyySYJKXfccQd33HFHk8+99957XWLf5aRNwV+yZAn79++npKSEyZMns3jxYvbv38/x48cB6NOnD88//zwAQ4cO5Vvf+hYzZszAYDDwi1/8wvdLGCrBVygUig7RpuCvWLGiybb58+e3+P5FixaxaNGizlnVGqHR4lEJvkKhULSLwEtkNwZDUDjUlPrbEoVCoQgoAk/wQc22VSgUig6gBF+hUCh6CYEp+GFK8BUKhaK9BKbgKw9foVAo2o0SfIVCoWiF1urn5+TkeFQS7u4EtuA7HP62RKFQKAKGwFsABYTg26xQXw2mcH9bo1AoOsLhd+DQW77d5/gFMO7uVt/y29/+lpSUFO69915ArO9hMBj47LPPKC8vp6GhgUcffZRbbrmlXV9dV1fHs88+y9GjRzEYDDz11FNce+21nDp1iqVLl1JfX4/dbufVV18lMTGRxx57jLy8POx2Ow899BAzZszo8GF7S+AKPggvXwm+QqFoBzNmzODFF190Cf7mzZv505/+xH333YfZbKa4uJjvfOc7TJs2DZ1O5/V+3377bQA2bNjAmTNneOCBB9iyZQv/+Mc/uO+++5g9ezZWqxW73c6uXbtITEzk9ddfB6CiomvKvQe+4Ed1v/KqCoXCC8bd3aY3fjkYNWoURUVFWCwWSkpKiIyMJD4+nmXLlnHgwAH0ej0Wi4XCwkISEhK83u/nn3/OggULABg8eDCpqamcO3eOcePG8Yc//IG8vDxuvfVWBgwYwLBhw1i+fDm/+c1vuPnmm5kwYcLlOlwPAjeGD2rgVqFQdIjbb7+dLVu28P777zNjxgw2bNhAcXEx69atIzMzk/j4eOrq6nzyXRkZGaxatYqQkBB+9KMfsW/fPgYOHMi6desYNmwYK1eu5Pe//71PvqstlOArFIpex4wZM3j//ffZsmULt99+OxUVFcTFxREUFMSnn37KxYsX273PCRMmsGHDBgDOnTtHbm4ugwYNIjs7m7S0NO677z6mTZvGiRMnsFgshIaGMmfOHB544IEuq68f2CGd6iL/2qFQKAKSoUOHUlVVRWJiIomJiWRkZLBo0SIyMjIYM2YMgwYNavc+77nnHp599lkyMjIwGAwsW7YMk8nE5s2byczMxGg0Eh8fz49//GO++uorXn75ZfR6PUajkWeffdb3B9kMOoej63Mbc3JymDZtGtu2baNv3w7E4G318EI83PwMTPmZ7w1UKBSKbkhntTMwQzqGIOHlV/p4vVyFQqHowQRmSAcgPBEq8/1thUKh6AWcOHGCn/3MM5pgMpn497//7SeLOkbgCr45EaoK/G2FQqHoBQwfPpzMzEx/m9FpAjOkAxCeoDx8hUKhaAeBK/jKw1coFIp2EbiCH54AdeVQX+tvSxQKhSIgCFzBNyeKxyoV1lEoFApvaFPwly5dyqRJk5qt+fzGG28wfPhwiouLAfjss8+46qqrmDNnDnPmzLm804XDnYJfqcI6CoVC4Q1tZunMmzePBQsW8OSTT3psz83NZe/evaSmpnpsnzBhAqtXr/atlc1hdhY1Urn4CoVC4RVtevgTJ04kKiqqyfZly5bxxBNPtKt8qE8xJ4lHFdJRKBQKr+hQDH/r1q0kJiYyYsSIJq8dPnyY2bNn8+CDD3Lq1KlOG9gi4dLDVyEdhUKh8IZ2T7yqqalh9erVvPHGG01eGz16NNu3byc8PJxdu3bx8MMP8+GHH/rE0CYYgyEkSnn4CoVC4SXt9vCzsrLIyclhzpw5TJ06lby8PObNm0dBQQFms5nwcLEC1ZQpU2hoaHAN6F4WVHkFhUKh8Jp2e/jDhw9n3759rudTp07l3XffJTY2loKCAuLj49HpdBw5cgS73U5MTIxPDfZATb5SKBQKr2lT8JcsWcL+/fspKSlh8uTJLF68mPnz5zf73i1btvDOO+9gMBgICQlhxYoVl3dQNzwBLMcu3/4VCoWiB9Gm4K9YsaLV17dv3+76f8GCBa41HbsEcyKc2dF136dQKBQBTODOtAWISIa6MrBW+dsShUKh6PYEtuBH9ROPpdn+tUOhUCgCgMAW/Og08VimBF+hUCjaIrAFP8op+KVZ/rVDoVAoAoDAFvyIZNAblYevUCgUXhDYgq83QFRfFcNXKBQKLwhswQcR1lEevkKhULRJ4At+dD/l4SsUCoUXBL7gR6VBRS40WP1tiUKhUHRrAl/wo9MAB5Rf9LclCoVC0a0JfMGPUrn4CoVC4Q2BL/hy8pWK4ysUCkWrBL7gR/YFdGrylUKhULRB4Au+0STKJFfk+tsShUKh6NYEvuADhMVBzWVcWUuhUCh6AD1H8KuV4CsUCkVr9BDBj4XqIn9boVAoFN2aHiL4cUrwFQqFog16iODHipCOw+FvSxQKhaLb0kMEPw4cNqgt87clCoVC0W3pOYIPKqyjUCgUreCV4C9dupRJkyYxa9asJq+98cYbDB8+nOJikSXjcDj41a9+xfTp08nIyODYsWO+tbg5XIKvMnUUCoWiJbwS/Hnz5rFmzZom23Nzc9m7dy+pqamubbt37+b8+fN8+OGHvPDCCzz77LM+M7ZFQmPFo/LwFQqFokW8EvyJEycSFRXVZPuyZct44okn0Ol0rm3btm1j7ty56HQ6xo0bR3l5Ofn5+b6zuDnCnIKvJl8pFApFi3Q4hr9161YSExMZMWKEx3aLxUJycrLreXJyMhaLpeMWNuLoxTIOnm8k7CqGr1AoFG3SIcGvqalh9erVPProo762p01+v/00z25oNC4QHAH6ICX4CoVC0QrGjnwoKyuLnJwc5syZA0BeXh7z5s3j3//+N0lJSeTl5bnem5eXR1JSkm+sBUJNBkqr6z036nRqtq1CoVC0QYcEf/jw4ezbt8/1fOrUqbz77rvExsYydepU3nrrLWbOnMmXX35JREQEiYmJPjM4IsRIRW1D0xdUPR2FQqFoFa8Ef8mSJezfv5+SkhImT57M4sWLmT9/frPvnTJlCrt27WL69OmEhoby4osv+tRgIfj1OBwOj8FiJfgKhULROl4J/ooVK1p9ffv27a7/dTodv/zlLztnVStEhgRhd0CV1YY52M38sFjIP37ZvlehUCgCnYCbaRsREgRARW2jOL4qoKZQKBStEoCCL7z6JnH80FiRh19+CSrymvmkQqFQ9G4CVvDLa5rx8B12eOVKWPugHyxTKBSK7k3ACX5kqAzpNPLww+PFY0Mt5H2lSiUrFApFIwJP8KWH3ziGP+w2+NbLMPUZqC1VGTsKhULRiIATfDloW97Yww+Jgmt+DMnp4nnR6S62TKFQKLo3ASf4kS1l6UjiBotHJfgKhULhQcAJfkiQHqNe1/xsW4Do/qA3QtGprjVMoVAoujkBJ/g6nc4127ZZDEaIGag8fIVCoWhEwAk+iDh+eU0LHj5A/FAoOtN1BikUCkUAEJCCHxnaiocPIo5fdAbs9q4zSqFQKLo5ASn4EcFBLcfwAeKGgK0Ozu2C3C+7zjCFQqHoxgSm4IcYm+bhuxM3RDz+bS68maEmYSkUCgUBKviRoW14+CnjYMgt0Hci1JVBXUWX2aZQKBTdlYAU/BYXQZEEm2HBWpjorKlTVdA1hikUCkU3JkAFP4jKugZs9jZCNeEJ4rEy//IbpVAoFN2cgBR8WU+nsjUvH8DsXFqx0nKZLVIoFIruT4AKvqyn08rALYDZuXi6CukoFApFYAp+i4ugNCYsDnR6FdJRKBQKAlbwvfTw9QYh+iqko1AoFIEq+F56+CDCOiqko1AoFIEp+HLVqybLHDZHeIIK6SgUCgVgbOsNS5cuZefOncTFxbFx40YAVq5cybZt29Dr9cTFxbFs2TKSkpL47LPPeOihh+jbty8A06dP5yc/+YnPjY4JE4JfUm1t+83mRFVITaFQKPDCw583bx5r1qzx2Pbggw+yYcMGMjMzuemmm3jttddcr02YMIHMzEwyMzMvi9iDyNIx6nUUVXkp+FX5qryCQqHo9bQp+BMnTiQqKspjm9lsdv1fU1ODTqfzvWWtoNfriA03UVRZ1/abwxPFwuaqvIJCoejltBnSaYnf/e53rF+/noiICP7617+6th8+fJjZs2eTmJjIk08+ydChQ31iaGPizcEUVXrp4YMYuA2JvCy2KBQKRSDQ4UHbxx9/nF27dpGRkcFbb70FwOjRo9m+fTv/+c9/+N73vsfDDz/sM0MbE2c2UeiNh69m23ac8lyoLfe3FQqFwkd0OksnIyODDz/8EBChnvDwcACmTJlCQ0MDxcXFnf2KZok3B1PojYcfLgVfZeq0m7fmwfYX/G2FQqHwER0S/PPnz7v+37ZtG4MGDQKgoKAAh3Nw9MiRI9jtdmJiYjpvZTPEm00UVdW5vq9F3EM6ivZRkSf+FApFj6DNGP6SJUvYv38/JSUlTJ48mcWLF7N7927OnTuHTqejT58+PPfccwBs2bKFd955B4PBQEhICCtWrLhsA7px5mBq6+1UW22EB7dyGLK8QvnFy2JHj6a+BqxV/rZCoVD4iDYFf8WKFU22zZ8/v9n3LliwgAULFnTeKi+ICzcBUFhZ17rg6w3Q92o4vgmm/RJkA9RQB8bgLrA0QLHboaEG6qv9bYlCofARATnTFiA+Qoi1V3H88fdC4UnIOSCeF52BZWlw/P3LaGGA01AjHq2V/rVDoVD4jMAV/HAh+F7l4o++A4LC4JDIJuLrTLHI+c5lakJWS1idnr0K6SgUPYaAFfw4swjpeDXbNjgCRs2Fo+ugrhJObAaDCfKOwOltTd9fXQxbnhGPvRUZyrGqkI5C0VMIeMEvrPDCwwexvq21Arb+UoR2rnsEIvvAx7/zfJ/DAZk/gX2/b74x6C3UKw9foehpdHimrb8JNhqICDF65+ED9L0KRs2BA866QKPmiJILB9YIkZeDuQf/BCc2if9Lz/vc7oDBJfiVnudHoVAELAHr4YOcfOWlhw8iS0cfBJF9IfkKiEh21tlxm0267zXoN0mUVS654HujAwVXKMchzpFCoQh4AtbDB+fkK2+ydCRxgyFjpRjA1ek8Z+GGRIn4fvE5SL8b7A1Q2osFv75G+99aBUGh/rNFoVD4hID28OPC2+nhA4xfAGPmif8b19kpOA44IGk0RPfv3R6+e/69iuMrFD2CwBZ8s8n7GH5zmJPEoxR8y1HxmDQaYvpDWQ7YvFhGsSeiBP/yUnYRVo4VPUqFoosIaMFPiAimuMqKtcHesR24BN9ZZ8dyDEwRENUPYgaAw9Z7SzIowfcdDgesfxgufKJtKzwhQoYFx/1nl6LXEdCCnxIVAkB+RQcHFUNjQG908/CPQdIo0OtFSAeg5HznDQ1E3PPv630g+B+vhL2vdH4/gYi1Cg6/Bac+dNum0l4VXU9AC35ylBhIzCvroODr9WLgttK5BKLlGCSOEq/FOAW/tw7cNh607SzH3oOv13d+P+6c3wu1Zb7d5+VAlqeoKdG2yR6UqlWk6EICWvClh5/bUcEHMXBbaYHyS1BbKuL3IFI3dYbeO3Dr7tX7QvBry3y7mIq1Gv6SAV/8zXf7vFzUNSP48pwqD1/RhQR0WmayU/A77OGDiONX5ArvHiBpjHg0GCGqr/LwwXeCbwjq/H4kdeVijMVdRLsrVud6ys15+ErwFV1IQHv4EcFGwk0GH3j4+XDpEKDTPHwQYZ3e6uFbq8UANnRelByOy+DhSw85AKp5Sg+/2t3DVyEdRdcT0IKv0+lIjgohr7ym7Te3hDlRrIaV9YkQe/eFzuOHi1TNqiLRKBz5V+eNDhTqqyE8XvzfWcG3VgpvvKEGbPWdt03u0/2xO9NsDF+FdBRdT0ALPkBKVGgnPfwkIUbn90LaNZ6vTXxQhDb2vQrv/gDW/VAL/XjD2Z1isNKd7AMiB9sbSrPEnz+orxZVRg3Bnc/SqSnV/veVly+95kAQTBXDDxzsNuHY2W3+tuSyEPCCnxwV0skYvnO2rb0e+l3r+VriCBg9V6QUnt8jtp3c4v2+d7wIm5/SnldY4M2ZYrs3ZD4Ma3/o/ff5kvpqMIWLv86KknsmTZ2PsmoCSTBlDL++Sqy0Br0npHNmO+R/428rvOfCXuHYnf/Y35ZcFgJe8FOiQsivqKPB1snJV9DUwweY/IR4HHorJI/1zKV25/A78Ne5mgDZ7ZB3FCrzoKpQbPv0NbHwSvFZ72wrPg+5h/0z29daLernmMw+EPxSt/995OFLEa0LgJCOu42yt9NbQjrrH4Y9TZdJ7bZUOSdhVhf5147LRMALfnJUCDa7w7ulDptDCn5EKkT3a/p60mj48S6Y/yYM/xZkf9Z0YZTT24Q3fnYH7P+j2FZ8Vrup874S3fkDb4jn3mT+2O1QcUlUqiw8CV+9C+t+1KFD7BD1NaLInCnMxx6+rwQ/gAZt3W2UYZ3eMPHK1iAcnu48V+LAGs/JlfL36c42d4KAF3wtF7+DA7cypNPvmpZrvqeki9DGsNvAYYfTW7XXsg/Av74PiSNhwI2w93+hrgLyvtTeYzkGX/xVeKUjZomc/4Y2ir5VFYiKnSBW5jqwRsQWu8rbr69yCr6PQzo9IYZ/dB18s8H799c1I/i9YeJVVYG4X+oq/G2JoDRLhFUldRWw6aew6zfatq4QfF8lLnQArwR/6dKlTJo0iVmzZrm2rVy5koyMDObMmcMPfvADLBZxIh0OB7/61a+YPn06GRkZHDvWjkHODpAc2cnZtiYzpN8DV97X9ntTxoM5GTY8Cn+7AzY/KR7D4+Hef8Mtz0FNMXz6B+HV640QFi8yfb7+D6SOhxEzAQeUZrf+XRWXtP/PfwzZ+8Xnqgs7dpztpb7GGdIJ77wouQ/aunv4/3mk46uK+TOGv+NF+ORV8f+FT8QYT2tY3QSvxtk7DKQxiI4ir+HuIPi2BnjjW7D5CW2b7Kmf2KQ5UvJadQ9DdoSPfwfbXmh++8uD/fa7eyX48+bNY82aNR7bHnzwQTZs2EBmZiY33XQTr732GgC7d+/m/PnzfPjhh7zwwgs8++yzPjfanU7PttXp4I5VMHhq2+/V62HBuzD+eyJN8/M3IToNFr4PkaliVa0h0+GzPwjPP2EkpI6Dc7vh4kEYPlMUZYO2V9Mqd94sQeHCs3c4swYqLS1/RmK3eZ8J1BL1NULsg8I7HzZpzsNvqIMv/gIn3u/YPv2VltngHIORx/HlO7Dr5dY/U1cpsp2gqYffVWsGn/yw7V6lr6nIE4++CuN1hhOboDxHu69Aa3xrSsRgrfwfOu/hn9wCpxoleBx6G7Y+KyIFpvDO7b+DeCX4EydOJCoqymOb2Wx2/V9TU4POGQ7Ztm0bc+fORafTMW7cOMrLy8nPz/ehyZ5EhwURbNR3PKTTXpKvgBkvw6K98HQuLPpEiL3kusXCC7/wMaSMFTN3ZcXNETPcirJdEBeAjPk3Rl6Yg28WA72SyhbO5cktsP3X4v+j6+CV8WL+QEdwOLRFT3wS0ikVDQdoN5IcyG7peNrC6hbSsXdwwL4jFJ0Rja88jppSEf5qLY3PWilmbYNbDN95Tn1RmK4tis/B3+d3/TySilzx6GsPv/hc+39zeZ+5j7+5///Nf8Sj/H3ce6UdobbMc7Y6wIfPiNX05rzWuX13gk7F8H/3u98xZcoUNmzYwKOPPgqAxWIhOTnZ9Z7k5GRXuOdyoNPp6BsTSnZxFwm+O3p907j/wMmiUQCR1SNLNUT3F4XZIlLAYBIDRTt+DXv+X/P7Lr8oQkKy55EwUjxKr6kxh/4mwgwOBxSddmYDnenYcdnqhai5YvhuXujXmU0HrduitgzC4sT+pLcnsyE6LPhSKB1iQldXIcsZS8GXXf/Wehp1leJ31xmaCn5XdO1lxklXl2J29/AdDt/s89Ih4cy0p2eY/41IqzaGal49aL9F/HD4ZqNoRHzl4TcW/IY6se8h08Bo6ty+O0GnBP/xxx9n165dZGRk8NZbb/nKpnbTLzaMrOJuMvil08F1ovGj7wRIdgr+iFniNb1eZAOd/ECIekWuVo/fnfJLInOoz1Xi+bh7xGNLIZ2S80L4rJWamHZ00pb0OhsP2pZfgn/dJ8Yt2pMOWVMKoVEQHNnUw6/qoOC7e41dGQ8tOCEe66tEwyiPp7XzYa0Qk9hCY5qGdBpqL/8kH9koFZ2+vN/TmHKnh29vEMd5ZrvINusMn/8FcLTvWGRO/RV3imtRnm/5W4yZJ7KJKi75WPDdNEk6SWFxndtvJ/FJlk5GRgYffijy05OSksjL07zQvLw8kpKSWvqoT+gfF05WcTUOX3kRneWKu+Chz4TgJ4yAW56FSQ9rr0f3F6mWkrwj4kb4ww3wye+FgJVfEqGilHT47t/hmh9DcFTzHrHDIXL2QbwuRbStWv41Jc2LpfRMTFLwK8V3yIYk97CYeewttWUQEi3KVvjcw6fjIYNLh73LmLDbxAS6szs9veTacq3r35oNdZUQbNYE324TAihrFXV2UNxugw9/DoWnmn9djjc09/q7D4jB88uBDOmAOD/7XoOdL3V8f9YqOLq26b7bQjZ48cMBh/abSXGXvfDyXDfBL+24nbYGcc+4e/iylxWogn/+/HnX/9u2bWPQoEEATJ06lfXr1+NwODh8+DAREREkJiZ22tDWSIsNo7KugeLOLHfoS3Q6MUtX/n/D4xDVR3tdDtzKeH7eETj4Z+E9fvgMbHlGeP+RqeLzI2aCMRgikpr38KuLtEyQqgKtx9CWh/+XDHj/Z023yxCO9PBxCIGSF+2AG8WAlLehndpSsUh8cKQmPjLbyFrZMQ/dPYTSkc+X58Ifb4bDf9e25R2F318Np7Z6vvfT/4PPVomsLA/BL/UupGOtFNlgYbFCUKTA+6pWUfE5Ec779/3ND8zKRrbkPDQ0ukey9omMssuBe/ixrkJcL5051q8zxbEYTO0U/DIRzolIEc9lWKe6WFyTcu2L8hzfePjyfLv33rqJ4HtVHnnJkiXs37+fkpISJk+ezOLFi9m9ezfnzp1Dp9PRp08fnnvuOQCmTJnCrl27mD59OqGhobz4opdlBDpB/9gwALKKq4kzB1/27+s08gIbfYcYYD2/V9x41z8qhP7oOhGDHz7D83PmFgTf3ZOvtHgX0qkpFTd6cwJR7yb4crDVWqUJ/OCpIiZafE6IWFtID7++2i2k4xbGqsyH2IFt78cda5W4WevKOyYixWdFjrgM0YCYL1F4Qgxwzv49jL8XCk6K9LqIFE3sE0ZCwTfiHMoGrLVMFHcPv/yS1qCGJ0DJuc4LvhQTy1HYuUz0KN2RNjps4lpJGCae19cKe4w+vmf2/1FMUqzIFWHJikvi/NQUdy6r6uhaiBkoMuPK2yP45aJ3GRYjnlcXAUOFuIdGQ6TTGSs6DTarGDurLRO92pbm5rT6faXa//U14rcPJMFfsaLp1Oj58+c3+16dTscvf/nLzlnVTvrHaYI/vl9Ml353h4h33nDDbhcX2fGN4vnQ6UIUj/xTPI/s4/k5c6KzjHMj3BfCrsz3TvBznRPDik5rOfcSl+CHaulj1kpN8PtOdH7vWZGK2ha1ZcLDt1Zq8w9kDB+Eve0W/EpxPjoq+GVOO0rczp3sJUX3F+GH8ffC538WN/0PtsDrU4RIpF0tBL8sG3CGEVuK4dsaxNiKyRnDt3ytiZ6c9Nc4pGO3ga6ZhICWkL2lpDHC7pt/LtZzkLh7q0WnNMGX9jeXkXJ8kwhjPbRPCJa3VFjg/f+Gi58LgR84xSn4FaI8tAwPymM7ug7iBovQZVsUnIT+kwCdlkbpDfL6C3U6J/I6rikWv0loDBhDtMKI0f2cM+VrRFizvbif724m+AE/0xZESAfgQlE3Gbhti6G3wYPbxMWbPFZsC46CvlfDwJvEZC3wTPcEp4ffTMzbJVo6cRPXlQsvpSy75fQ12XA47E2zN+obh3QQXqm8aFPHi+/yJgvIVi9u8tDopjF8vXNBFG/mFjSmrlIri2HtQAxfNjzujaUU7QHXuzUI5yF2kOiVycl5suaSe4PaUgxf2uYew28tpGOrh9VTYKvTafrir1q6rSTvK89wifxdht4qPFT33hNoYRAQcXw51iV7htKblTgc4jvLstq/AFBZjniUg7PSuakuFoXzHHbPBu79/2574hqInmhZtvgtIlNE78Hb1My6ciH4Umzd8+9DY0XjE5EiGmPQQq4dDet4CL7zWGUjE+pfh7RHCH5IkIGkyODuk6nTFnq9GNAFLYVz8M3CKzMYRdYANOPhJwnxlMK0+zfw2evixo1IERe0vGiTxoibvyUxvXRIxDVBfObgG2LsALSQgylM8+5klzwkSmyL6ity0ttChhMax/CrCiFhuPi/IwO31io3we+Ih+8U65LzmthZK4VnHT9MHG9tmWgYZI2lG38Ks1aK1FvwFMOWQhXytzI5Bd9aoQlCeEJT+7/4K1i+0uLqR9eK30Zit4mxl23Pa9tkb0lmhLnP0gZxziOSxfdlfQqvXiVmg0vBd9g8G6wz2yDf6e22dP2U54prr3GihGwo7c7BcCn4Ho2j85zIhXG8KSZYcgFwCMGPSBWZP97OOq8tE9deWCMPv7pYE+DIPqL3AyJsBB0fuG3s4YNolEOifLvqWwfoEYIPztTMQPHw3ek7QQjv6Du0bdf8F4y503P1LdAErtICZ3fB9l+JmXu5R4RXYk7UuqUynbMlD+3SIRFCMoaKQeOdy2Hf74WIy4s0KEwb6KrIFRet9JJiB3l3o8qbJiRaXPByEZSqQpHBBO0XfFu9GOOIcM736IjgSw+/ocYtX9w5uCoFvjRbNAxRac5jiIIJC0VvBTxXQ2scw6+vhQ+e1gQw2KwJjvzu8EYhHWsV7Fou/pfnpDJfCJsU5PxvhGfqPvZQXSR+q1iRONFkrkZduehBxg2Fk5tFz+z4Rs+xH3dx2/u/mjPQXMowiIZo8xPa8Umkhy/HfuKHOo+5mcaxvkYId/HZtvP05bUmPXzwnDXbGrVOD99kFr1K2SOqKdF+k8hU0fsAH3v4zmvT/d7xIz1I8MMDx8N3x5wIPzsj6u5L4gbDXW80jR/KmG/pBVHPJzxBXFCWr4RXEp6geXeyB9FcHL+6WOyj7wRR9O3Ld0QeMohyEe55+DKsVH5JfM5D8L3x8EvFo/TwQdyAVQXixg2La38uvisGnuT5vCUcDvjPYvjyH9q2smxhE2ghMWuFEAUp8Plfi5s3Os1zfyaz6Am0FtK59IUoh334bednIrT9FjrFunFI58g/RWOeNMZN8J0etmxcsvaJR/dzX10kwoARLQhhbZkIp0nxjRsiYuzuaZoyO8XWIEqBtDXvQx5v45pQZTni/IxxOjCyF1fSjODLRrKuvO1yxO6CH+G8JlvL1Pl4JfxxmvhfHr9OJ663mmIRDqotdfPw3cKnPhV8Nw9fCb7v6BcbRl55LbX1AbhSjbd1NaRHu/lJIVJ3/kkbQI0d6Fnbv7GH/9W7sFVkUrni96njRS+itkwI0tBb4dBbWgZEUKjwzIPCnIJfpA18xQ0WItFWaqYcEJQxfHCWfa4RIhXuXFPYbtO8vMJTra86JAUyNEaMVbQ1CezcbhEqkRUuHQ4hTANuFM9lHF9m00hhlgODUY0EX6cTjUXjMMW5PbBitGjQ5HmRk37c9yu9c9mAy+PJ/0Y0isO/Jbz6erdUWOmNZ30qHt3PfVWh8FTDE8Rs3oo8YcPeV8Q5lB7upJ/AnP+Dm58WvYpzu7RG2DWfwCnCcUPEQGZLjbEU7cYORVm2CPfd9DRkvCKE1GDy9PDl7+VeObWt8GDxWefAa4zm4bcm+LmHxXVut2sxfBDnqbpYiL3Drl3P7oIvEwg6Wl5BCf7lZ0B8gA3cdgQp6IUnRdhn0BS42lkjP2agJiAgxCU8Ubsh978uuurWKsg5COhEZoQMG43MgGsXCe9n10tC5IMjhLhFpop00ZoSNw9/sHh0H/RsDnnxu3v40lsLT9AWkf/bXPjPT8T2PSvEqkNrbmm+qqgUjGCzdwu07PmteJTealWByJHuN0kIpLRH5suHJ4hiZxc+EdvlfAl3ZHgKxDmpqxAF8spzhOjJgUEp1Caz1lOQK0A1DumUnBeDw+Yk52C620pR7oIvxUvaXV0kegt6g/hsRa4IuXz0P2JyWZ0zhp0wTGQepTlXdmuo1bJjZE9MCn5IlNYYN4d8X2PBL78oBD+qD1z1fbEtOKJ5D99dGNsKDxafFde4Tifs0ulbT82sLhJjE5V54jjltRfqFHzZo2ns4RuCtZ6SrwdtleD7jqGJYtbi8bxuUJnvchEaKy7IpDGiFDPA6HmiGNPIWdogoMkswkEJw8UNX18rvB2HTTxmfSL2ERIlUgzRiS78wJvg5mdgxm/h4c+0AaaIFM3DlzFPGS8uPiM85vefEDHrxkjhC43RPHzpzUnBz/1SeOEyVbQ8R3xn/tewd6W2r+pisfaAFAdTRNuCn71f7NsYqsW2ZSMSO0iIU0kjD1+vF9vlbOjGIR3QRFenFyEGa6UW764qbBqiCDZr5RWkeDcO6ZRc0MZiQEwEk5ScF3aX58AV8z3PY3WhJiYyg0X2IiouaSENSVQfrbchBd9VFtitgTa3Jvgtefg5TZMNgiM8CwDKcFBdOwVfXnMGoxD9xoPT7sjCgbIEg7uHX+Mm+GGNPPywWO29shEsv+QZDmyL2jLAmXbq4eF7MWflMtNjBH9Iopkgg47jed2g9vblQq+He/4hau8HibLQGIwwfoEIv0ihkMI/aIoYkD29VWTsgPBas/c785kRoZ//PgUDbxT7n/IzuPqHnqt/RfZxDuZWaxdtzABAJyZgffw70YP47A8iD7vsIpz6SLyvWnpSbjdSgVsM25ykiYH02MpzRUPU/3oRJpGc3gpfr4ejzpQ/15q7FeJ9za2duvu34rvHLxCC73BoGTrRac6xCBnDr9TKHUiRN4Zo59MdeSwhUULQ6iq0HkR1YdNQl/Qwo9Jw5e4HR4j9y4qfpVLwnT05mamjNwrBz/5MPE+/WzQ0Usyqi7VU3ogUcf5kqm25Mwc+2E3wQUstTR0vHqW4NRb8ximeEldIx81zr68R728cAguOaP6zMqSj07c+HmSrFw2LFHwQDVtbHj40L/jNevh9tOeGIDHoLM/FF3+D934sPudwaIkRLVFb5hmus1Y7Q5jKw/cZJqOewQlmvsntwR4+iFmujfPzJfIik4+DnYNWMvMjPNE5KFsN/a9z+1wzguZOZKqWAicv2qAQGHKLiI1vew76XSd6EEf+Kers/OMeZ/XBYuGFG00iLhyeoAl2eLwmpkHh4jsa6oQwR6SKRqjwhLZK0cXPxaMMtQSbxV9dpSgrsH6R2P7x7+Cf3xPhj1NbYNJDYszBXu8csHZ6+FFpIl7r8vArtDRUWc44qm/zE6Bcgh+tCb6Md1cViePWGbT3m5z7lQ2pPsgpLGHi96i0iNBDzADtnEjBT0kXgn9yi/i+lHHC9uIzovdmrYRw5+8SIT18p+AXnhLhIWmvRP7+KemiQWni4Uc6PfyWBm3dPPzSbPjjVK1xludOIhsbeQ5kj0aGheKHte7hl2aJa8td8CNSW47hOxya4Bc2EvxQp4cvX5cx/PAEcR5kAxASpTWC8ntKs0RvcdV1oufcErVl2nhbfU23mXQFPUjwAUamRHI8twd7+G0R3sjDT0kXF3TeERH/HHqrVpu/33XN76M53BsYeYMA3PMvuPddUSvonn9Cnwmiccn+VPQoakuduc7Oz5jCYdovtaUbw+JF7nhwpBBlEAJlrRA3zABnvvt5p5DkHBSP8gY0mcU+LcdEY3HpkEhX3blc1Df/y2yx74k/1G7AyjwRYw+O0qbV15SIG1PG8AGinMLc3DrH4CYg0c5Gp0ILf1QXip5N/DBnKqBRK18g9yczsGQ1UhnmcffwLc6QTt+rhSd94n0x1mIwigas6ExTMYlIFuddniMp/CGNPPzx34P7MkXmTki0m4ffKIZfXdT84LmcUFZ+UfS6Ln6uTRZrIvhOD196/o0HbVPGQdFZ0fOUjbk77hk6kshU0dA0V/yutkybByA9fNnohMWJ60+GoqTA6w2isZTPQ6O1RlD+rmXZWi+ytR5JbZk2DqAE//IxMiWCvPJaSrpLEbWupnFIR28QE7pAdOHTrhb/xw4Whdi8xT0m637R6vUil/+WZ4WgjLvbOXnJ6dlWFQpvStYwARh3rwgjBEcJ0RtyCzx5Hvo5BxIvfeH8TmelUFOEEPwGq2i4dG6XrMk5aCtTSsFZQKxGTJKy1YnB7dBosTQlCCEsuaCFbOTxVBdrMXzQXm8cnpCERDsfnSEda6UmDPK4w+PFTGqTWeslyP3JPPXGgh89QNgQFO7MLokWg602q/gOOSkvdrAQQlfPq7nZ2TpN8BuHdIwmGHST+N9d3BqHdBx2bWLX9l/DOmeSQF2F2L+9QYtv5zsn/bUk+OHxYixFNhZ15eL3TL5CxPP/NB3enAXH3oOcz7UMJzmWEjdE2+eQW8R+Tn5AE9zHT5oL6bhvl3MqAGauENeNfL88F7KXU5qt/U6tzQGoLRO/hz5I9N6U4F8eRqaIi7rHh3VaIixeCKm7JyTDOmlXa3Hb/u3w7sFTRFq7aMfcBf1vgMlPiOcylu3eK9Dr4Ttvw3ffcttm0BoVGbaJSBGebP/rRKjA8pUQvWG3a58zhWseeVA4jJojhHborTDtF/Dol3DTUuf+pOBbhAjKGaBy4LQyTzQQpkbeaHMDtuAZ0jGZRS/BVYWxSBuku+JOYY+ksYcvQzqlFwCd9n2u8FySlhceFq/1euIGC8GU4yHuHr4kdbwWg2/s4XscS3TTKpHBkZoNVfmw7/9g98twwimwdZWaXZajYnEfSeOQoxT8sDgtBCe/KzhCSxyY+EMxN+Tf98OaqfDXOSL+XXBcfNY99DjkFnGNfPHXpsfjLvhSoOXxy2sx54D4DfVuYbdht0KfK7Vz4hJ8Nw/fW8EPiXL+tjXdphY+9DDBH5HsFPyePHDbGgYjPPypqJ0vGZkBVy0UYhg/TNxUExa2b78eHn4rmQah0bBwk8gYAiE2NcVNPxPVRytPIJFdYHfBB+GFFp8Rg68AE36gfca91k+fK4U3rzfC9Y+JbTEDRAMDmhAWnRbiKgVK3oQybVB6+PHDxIBqyrjmj9Vj0DZSGxQHp+A7G7qJD8KdbstYSkEPaiakE9lHC/24j8dIYR01WyuKluhcAU16uLLhkpOSgsK0XhNoPZLmCI32TMs0RQghlCHCM9thy9POFcvKtHrv7jPBp/xMOBrhiU2rb7oEP9aZVeUW0gl2Zoo9kwczfwsL1or5AhN+IHoP+V9D/nFtxTeJTFY4vVWb3SuRgq8zaGtBy99Lnv/isyIttyXC44Rn73C4efhZ2niPDI02Rp6bkCiRSFFfpTz8y0VCRDDx5uDe6+GD8K7cb7iQSMhY6czT1oubSk7K8pawOK3QmTfFn2R4oaqgqYffEtIjkrWApEBfdb8I7Zx4X3i7g24WQmxypk9Kwe87QfQGnsoSxc8aExQqvuPcLvFcCqa8CWW2iewxRCTBE2eEJ9mSvaDF8CUGk7OhK2m+cZQ9B1MzIR0p7NDIwx8oeiw3PK693u868Vt8nel5HHJSUvwwT0+7cUjH41iiPUM68tikDZ+ucjakj4rn1YVigFmWxkAnqmLO+h1Mf77p/qXghzoFX3r47hOiZNZZcATc9mu4YYl4nntY9GLkjF13xi8QgvzlO+L52V1ioF6GoOKcc0V0eu13TRoNP94DPz0pxp1aImaAEPqKPC2LrDSrbQ/ffR5DUKjTwy8U56jxwLkf6FGCDzA6NZIvs0v9bUbPQq8XQuJt8ScpPhUWZzzTC8GXE7wcNiFOUkRNYWLFL3OSEHSDUcwhcAmm831yxnFrs5bNydos48aC39jDl/+3VKK4cZaOJH6YsyCbrfmGLjTGOX/Azf7SC8KT9RD8JO1RpxOxZfcBZKNJ9NrsDcKTlR58cKTYZ+JIT8FvLaQTGuOZltlY8CtyRVhKTraTA57hznIOyVeI33jQTWIcpzHuA6bBjTz8luyK6ivsOvmh6FUkjmz6npgBoqE/sVlkhK37keiJSI9afiY40vN3TBnb9hiWLKCWc8C5jyjxGzXUigakzOnhX9gnMqUk7qVEZEinqsDpNLmFj/xEjxP8awfFcSq/koKKZhb2UHScyD7eeeogxCgk2jkw5vD+czKMIx8lUX3hoU/FoiQgCsvJxd3D44Xg9Zngxf6TxSCkMUQT15BoQOfm4Ue08OFGuId0TG6NROIoIQrQfBde55zhLMX72kXaAKH7mgDhbiGdlpATsMJitdCVTifqME1+QgvvQOsefmi0M7PF7jlJy2TWQk9j52u9Oyn4JjNM/bnofbRGSyEdOQO4OeR5Or1VPG/OwwfREF38QoS2KvNE+KeqQAwOyxnSrTV2LSGvDzn3oe9VWnZZSrr4rqIz8OfbRdVaifugd1CoGJ+pKmz9d+xCjP42wNdcP0TcZJ+cKWTOuD5tvFvhNWPubF9Vy/B4LbvC2xmGcqzAfeBR4r4PmcIJIusn7Wrvso7kfhOGa96WwSgErzkPvzWkBx6RotWaB09PtKXjXvCulsnUdwL85KAQrIFT3PbvFtJpiX7XCVFvLGjDbhOPeuftrQ/yXOCmMSHRoiGUpZtlz0CnExlf1cVisFyG26TgB5s9q7y2hHtIJ9jsVoe/HBJbEePksWIdYWgaw5cMnQ47fg0fPCWe11eJXlxYnHYOOxJKaSz4fSaIsQwQEwIvHRKLxAB88ReY8qRwdJoIfo0IYckxFj/T4zz80alRRIQY2Xemjep7ivZx9Q9h6jPevz88wS31zVvBd3r2LU0saw5TmHerJYGb4DcSj7A4rcyvyUvBjxsMD24XQugKP0V4pnG2dNxBoUIcJMZgEZ5xTxF0hXRamRSn18O3lnvG9t2RPaWQyJZDU6B9b02pZ0gHxKD/9Y8Im2V6retcedkbShgpeiyJIxoN2rbi4YP2u4bGtiyYyenOmlEXtF5RzgEx6CrTk4M7IPhhccJWOcFKVp9Fpw2Gy2J8VQVi3gdos7bDE7TxmaoCzTY/0+ME36DXce2gOD5Rgu9fwuPdQhteDPSCFoJozsP3BTIXv3E8OCxOy7LxtnIpiG6+Xq95sOZEbcYrdK52yqCbhNfY/4bW3zdqNqR/t/nXjCZnqm4bIQ0Z/68tbSrCt/1aZOBA05BO45IJLRE/BJ44JcJYctDW4RC5/K2FW6TgJ45sucGSc0EArvuJeLRZnZVYnYLfEQ9fpxNevr1e9OCSxojtUX3d4vv7xaS4mAFwYI3YdnyTCCXFD9U8/KrC5stz+IEeJ/gA1w+OI6u4muxArI/fUwhz88i89vCl4LfDw28PsiFxzxkHz1i7tyLmjuwVmBMbHbeXDV2z+wwTZYxl9kpHiWwm5NMY6eFXF3tmzjQmOMpzHYD2rHXr2ofTw7dWioHt1sQ4drA4h3JVuJYY+x3Rs0q/W+theYR0OhDDBy2sY04SvSV9kNjm3gPtO1GkOmftEwPMZ3eKXpFOJ8Y/aopFqKyt8iVdRI8U/OuGiJtuz6lCP1vSi3H3aLz1dOWEsfYuaO4tg6fCdYtFjR533O3zNqTjjruHLxsPnb713PeuIv27YvylNVyZSuear7sj0TuPqbSd4S93TGbAoY0Htdb70OvF2s83N1OF1Z1BU+Dxo+L8y95beLwWRuloOqRL8BOFLX2uEgIfGqOtCNbnSjGvJTwR1j4gegSj5ojXgkK1jKFu4uG3OWi7dOlSdu7cSVxcHBs3bgRg+fLl7Nixg6CgIPr168eyZcuIjIwkJyeHGTNmMHCguGHT09N5/vlm8nIvM0MTzfSJDmX7cQv3XNNCLRTF5cVV3sHYdkhBkjQKfrTL+5h8ewmNhlt/1XS79Mrda960B1fpgEQt1hwao2XO+JNJD7f9nthB4tiznAOUrXnEYbFu9Wk60BuSvQI5Waot71vm0ntL4kg49aGwMyxOXHvtGRNyx93DB3hgiwhFyRTi4jNC8E3hMPm/YfPPRE9AZoy5D5QHSgx/3rx5rFmzxmPb9ddfz8aNG9mwYQMDBgxg9erVrtf69etHZmYmmZmZfhF7AJ1Oxy0jE/n4dGFgroDVE5Cx7NDY1gcMG5M6rn3v9wXSw3WvedMeDEEinDDsdtFgmCK8D2N1B4zBED9cK1zWmkfsHqbqkIfvbCTkxKWODKi2hmsGdbzIwFq0F67+ceufaQl3D1/iqonUR5wLGc+/6n5R6yf9u1pDL1Naodt4+G0K/sSJE4mK8vxRbrjhBoxG0TkYN24ceXl5zX3Ur0wbmURtvZ29p1VYxy/IC7wbLPrQJlLwO+KxSu74Awx1zsoNjwuM43YnabS2TkCrgu88LkOwZ6aRt0gPX5Ym6Gh8vSVSrwR0Wlgwul/Hx0Eae/juXLNILEIkGwBjMDy8X1SDlbgLfk+J4a9du5bJk7W6KDk5OcydO5cFCxZw8ODBzu6+w1wzKJZwk4Gt37Qjd1zhO6TgB4Kn6+7h+4KUcSKHPJBIHqP9742H35EBW9CyoKSH7+tyAwnD4LGvPOc0dJSYAWLd4wE3Nn1txAxtCUeJ3uDZQ+yGHn6nJl6tWrUKg8HA7NmzAUhMTGTHjh3ExMRw9OhRHn74YTZt2oTZ7KMbqR0EGw1MHpbA1m8sPG8bTZChG8RTexMyLh4Inq7Lw/fRdfrtv/hmP12JeyG01sIsUvA72jg2Cen42MOHliucthdDENy/seOflzF8U0TrE9+6kA6r4Lp169i5cye//e1v0TlbNZPJREyMuCDGjBlDv379OHfunG8s7QDzruxLQUUdHxztfiGnHk9YLKDrXGpiVyEbJV95+IFIklvqY2tetzxXHQ1/yUa1pYVZehJS5LtJOAc6KPi7d+9mzZo1rFq1itBQreUqLi7GZhODpNnZ2Zw/f560NB+1th1g2ohEBsSF8aeP/dfo9Fr0BrjiLq3mTXfG1x5+IBKR5DZRqY1Ca9BxwZeNask5UYnUPezR05DH1k3COeBFSGfJkiXs37+fkpISJk+ezOLFi3n99dexWq0sXCjqqsv0ywMHDvDKK69gNBrR6/U899xzREdHX+5jaBG9XsfC6wfyy/8c4/MLJVzVPwC8zZ7EnWvafk93ICRK1LbxtlRATyVptCgv3FpqamdDOhEpcN0jIvV29Lyuz8jqSqSHH0iCv2LFiibb5s+f3+x7b7vtNm677bbOW+VD7rqqLys+Oskr207xlx9c7W9zFN0RnU6sBtbWjM6ezohZopJoa3R20Favh1tf6NhnAw05QN2NBL/Hj2SGBxt5+ObB7DpZoFI0FS3zg82eVTh7I1f/sPVFQUCNd7QHVwy/e0y6gl4g+AD3TRpAn+hQlm3+Brvd4W9zFIrAxeXh9+DBVl/RDWP4vULwQ4IMPHHbcI5eLOfdz3Pa/oBCoWiezoZ0ehMxA0Tp6hGz/G2Ji14h+ABzxqUyoX8ML31wnLLqen+bo1AEJsGRYpWr0fP8bUn3R2+AW57V1nnoBvQawdfpdDw/Zwyl1VZe3nLc3+YoFIGJTieWT0wc0fZ7Fd2OXiP4AKNSI1l4/UDe/iyLj1XpZIVC0cvoVYIP8MRtwxmcEM4T736pQjsKhaJX0esEPyTIwIpvj6Ogoo6H/v459Ta7v01SKBSKLqHXCT5Aelo0L905lr2ni/ivv31O5uGLVNU1+NsshUKhuKx0qlpmIHPXVaKw2ivbTrHteD5DEs2suW8CA+LbsYi1QqFQBBC90sOXLLppMF89eyt/XjiRwso65v7fXi4UVfnbLIVCobgs9GrBBzAa9Nw8PJH3Hroeu93BT/5+iLoGtSyiQqHoefR6wZcMjA/nN/PT+epiGQ+8eZCtX1tUGQaFQtGjUILvxm2jk/mfWaP4JrecB/96kAf+coDCyjp/m6VQKBQ+odcO2rbEAzcM5L5J/Xn70wu8+P5xJvxqK5EhRu6+ph9Lpg8j2Gjwt4kKhULRIZTgN0OQQc/91w9k0uB4Pvo6j2/yKli96yw7jufz/esGMGtsKlGhQf42U6FQKNqFEvxWGJ4cwfBksQrSHeMsvLzlOM+8d5TnN3zN7WOS+en04fSL68FLtCkUih6FEnwvuWVUEtNGJvLVxTL+fTCHdV/k8OExC5OHxXPSUolOB0MTzfz6jiuIN7eyRJxCoVD4CSX47UCn0zG2bzRj+0az6KbB/CLzGEcvlnNFnyj0eth+PJ+7Vn3CraOTOXapjDGpUfSNCaWspp6M9FT6x6lJXQqFwn8owe8gqdGhrPn+BI9tn18o4YG/HODPe88xOMHMG3vPUW8TqZ2rd53luTmjuXV0Mubgpqe9vLaeiyU1jExRKwkpFIrLgxJ8H3JV/xg+XTqNBrsDc7CRamsDlbUN1DXY+ck7h1jyry8x6I8QHRpESJCBoUlmrh4YS3rfaJau+4qs4mrmX9WXH08ZRGRoEB99bSE5MoRpI5P8fWgKhaIHoATfx4QEaWmbYSYjYSZxit/9r0l8eraIA+eKKa62UlnbwDe5Fbz8wQkAEiKC+d61/fn7/iz+3WgZxufnjOa+SQOafFe9zY5ep8Og112+A1IoFD2GNgV/6dKl7Ny5k7i4ODZu3AjA8uXL2bFjB0FBQfTr149ly5YRGSlCEatXr+bdd99Fr9fz85//nBtvvPHyHkGAEGTQc+PQBG4c6rmgcVZRNZ+cKeTmEYkkRYbw4I0DOXi+hPyKOm4YEs//bjvFLzKP8fIHJzAHGymptpKeFs2E/jH8fX8WwUY9T88YydQRiUSEdD5V1OFwsOtkAcculfOjyYMIMuiprbd5NGQKhSIw0TkcjlbrBxw4cICwsDCefPJJl+B//PHHXHvttRiNRn7zm98A8MQTT3D69GmWLFnCu+++i8ViYeHChWzZsgWDwVMscnJymDZtGtu2baNv376X6dB6BvU2O/88kM3p/Eqq6howhxj56GsLOSU13Dw8gYLKOo5eLAcgIsRIVGgQKVEh9IkOJSzYiMPhoK7BTkSwkVGpkdx5ZV+MhuYnWOdX1PL4Pw+z93QRALeNTiIqNIh1X1zkzYVXc8PQ+C47boVC0ZTOamebHv7EiRPJyfEMMdxwww2u/8eNG8cHH3wAwLZt25g5cyYmk4m0tDT69+/PkSNHGD9+fLsNUwiCDHoWXNvfY9vPZ46iqLKOxMgQbHYHO0/kc9JSiaW8lrKaei6W1vB5Vgk1Vhs6nQ6TQU9FbT1/2XeBv+67wOz0VCJDgzhbUElIkIHBCWbqbXZWbj1FcZWVZzNG0WB38KtN36DXQXSYiWfWf8UHj07ms3NFrNlzjnOFVbx6z3iu7BfD6fwK3tmfTZjJwKKbBrvCWAqFonvR6Ttz7dq1fOtb3wLAYrGQnp7uei0pKQmLxdLZr1A0wqDXkRgZ4vp/2sikNgd2HQ4Hm4/msWzzNyzbLBZxNxn12OwObM4icUmRwfzrx5O4om8UAIMSwok3B1NZ28A9az7j+uXbKa6ykhQZjFGv57uvf0pyZAhZxdWYDHqsNjvrD1/koZuGkJGeijnYSFlNPesPXeTA+WIiQ4NYcE1/RqW2nom0cutJjl4s5//uvRKTUZV7Uih8RacEf9WqVRgMBmbPnu0rexSXCZ1Ox4wrUphxRQplNfWU19STGh1Kvc1OdnE1RoOelKgQj1j91BFaI3L/dQP4IquEZ2aMJCM9laq6Bp7bcIxqq42F1w9gdnoqZwqq+EXmUZau+4oXNn7NbaOT2XOqkMLKOlKiQiiptvL3z7IYFB/OlOEJTBmWQERIEHodjEuLRqfT8fruM6zcegqA//fRCZZ+a2Srx1VQUce+s0Wk942i2mojq7iam4cnejQUDocDnU5Hbb2N3ScLmDI8QdVEUvRKOiz469atY+fOnbz55pvodCJLJCkpiby8PNd7LBYLSUkqpbC7ERUa5KoFZNAbGJoU0eZnnp092uO5yWhi5Xc9Q3Vx5mA2P3ojX2SV8o/9WWw8ksuIlAj+9P0JpKdFU1ptZf2hi+w4UcDfP8viz3vPuz57zcBYQk0Gdp4oYOYVKUSEGHl991kAJvSPJTY8iNyyWg5llXIoqwSjQc+ssSn8fvtp8is8K5rePDyBVQuuot5m53/WH2XXyQIW3TSYjUdyOZJTxvCkCO69th/55XXodRAfEcykQXEMSTS7rmWFoifSIcHfvXs3a9as4a233iI0NNS1ferUqfz0pz9l4cKFWCwWzp8/z9ixY31mrKL7o9PpuKp/DFf1j2H5nWPRu6WMRoeZuP/6gdx//UBqrDY+v1BCg93OhaJqVm49iU6n44nbhvPgjQOx2R1cKqtlzZ5zrN511rWPYKOesX2jsJTX8ovMY6TFhvKXH1xNVnE1oUEGymrq+dWmr7n+pe3U2+xUWW2MSonkxfePE24y8N+3DuNvn17gF5nH0OvAfcmDQQnhfGdCGpOHJRBk0HM4u5QLRVWYDHruu25AswXzzhdWcTyvnCnDEgk1iV5Dg82Ozi1d1mZ38MbH50iKCuHWUUkEG/V8kVXC9uP5JEeGcP2QeAYlmC/TL9IxCivrWH/oIrPTU13hQ0Xg02aWzpIlS9i/fz8lJSXExcWxePFiXn/9daxWK9HR0QCkp6fz/PPPAyLMs3btWgwGA08//TRTpkxpsk+VpaNoTL3NDohBancq6xo4ZamgtKaeuHATI1MiCTKIsYe9pwtJ7xtNVJinEG85lseWY3kYdDq+e3UaV/aLYfepQtJiQhmUYKbGaqOoqo6UqFD0OsgpqWH3qQLWfp7DF1mlHvsy6HXYHQ6iQ4O4dlAccWYTt49OYWiSmT2nCvmf9UepqbcREWLkjvF9GJoUwWvbTxMTbmL1gqvoGxPKU+uO8K+DIvFBrxNjJ7X1dtd3hATp+fP9VzNpcNxlOLMd46m1R/jHgWxMRj2P3TKUh24a4m+TFHReO9sU/MuBEnxFdyWnpJr954ppsDu4sl8M/ePCOGmp4HcfneJCURW5ZbVU1jW43j9xQAyLbhrMfw5f4v2jeVgb7IzpE0lWUTV2B5iDjeSV1/LI1CFcOziOfWeKqLbaGJpoZlZ6KoUVdfzwrwe5WFrD0zNGMjIlkj/vPcfQxAgWTx2CXq+jpMrK2cJK4s3BpMWEefSa2ku1tYE1e84xaXAcEwfEerxWXGUlt6yGeHMwNy7fwa2jk7DZxWD/i3dcwT3X9Ovw93YWm92hJhiiBF+h6FJq623sOJ5PYWUdfWJCuXFogqtXIoV5fFoM2SXV/O+2U+jQcWX/aO65ul+L4wP5FbX88K+f82V2KSA8/tp6O1cPiKWoqo4zBVWu98abTTx88xDuvrpfs5PhrA12LpbWsO6LHPacKmR0aiRzxvXh6oGxHMoqYcm/vuRcYVWTXsWl0hq++/qnZBVXMzIlkhN55ez875tJjQ7hgb8c5OPThbzy3fHMHJvS5DvrGmx8famc9L7R1NTbeH7D18wd38erHkuDzd7ivBDJH3ad4bUdp/nbA9cwLi26zX36ggabnboGO+HN1L3qDA6Hgyqrrdl6Wt6gBF+h6AE4HA4+v1DCSUsls9JTWPt5Dq9sO8Wo1EgmD01gSKKZwso6Mg9f4pMzRZiDjVw3OI4+MaFU19k4nlfOxdJa15KcOh2M7RvNaUsFVVYbNwyJZ9/ZIpIigvn5rFGs+Ogkp/Mr0esgJsyEA6hvsDN5WAKbvspldnoqr9wtBuUr6xq4/439fJFVwpO3j2DayCQ2HrnEjhMFRIUG8VVOKSXV9dx1VV9qrDY2fZVLRLCRtQ9dR1JECKEmA0a9jnWHLlJjbWDBtf3R6XRUWxuY9crHDE0y89o9VzYRfrvdwerdZ1n+wXH0OrHu9KZHbrzss75r623c/cdPKaq0suWxydgcDk7nV3a6sfkmt5xf/ucYh7NLOfyL6R2ar6IEX6HoRTgcDvadLWLDl7nsO1NIQUUdwUEGRqZE0C82jKTIEJIjQ5g0OI7+ceHU1tt4ZdspXt99loz0VJ6dPZqo0CAKKur454EsauvtFFTUUVhZx+JpQxmXFs3+c8WMSIkg0q1UR7W1gUVvfcGukwWubVf1j6GuwUb/uHASzMG8+cl5AH40eRDvHbpIcZUVm91BRIiR1KhQTlgqAJg1NoXld47l/3ae5rUdZwAxq9scHER+RS3BRj3JUSF8k1vB5xdKmHlFCndd1ZeFbx7g1lFJ3H/dANJiRajtrU8vUFpTT5jJQGiQkT7RIYzrF81to5MJM4mZ5kVVVgoq6kiICOZEXgWHs0uZd2UfUqK0hBP38/vkWm3M5dFpQ/n0bBGfnSvm7w9ew3VDms42L6228k1uBdcOinX14j45XYgDuN75/vOFVcx4ZQ8hQQae+tYIvj0hrUO/vxJ8hULRJnUNtk7PPXA4HBzPq+CLrBLGpUUzOjXK4/W/f5ZFblkNS6YP44Slgn8dyCEpMpgzBZUcvVjO/dcNoKjKystbjhNvDqasup5ZY1NIiw3jf7edIiYsiP5x4dQ12LlUWkOQQc+Ttw/nziv7otfrWLn1JH/YdcZjwDslKoTBCWZq6m1iHkZRFVVWG/HmYK4ZFMtnZ4tdvR534sJN/CJjFKNSIskuqSanpIa48GD+cSCLPacKWTx1CCctFWw5JiaOxoQFYQ4x8v1JA1j3xUWemzOaiQNiKa228p3Vn3LCUsHto5OZO74Pe04V8PZnWRj1Ov50/0SuHxzHt1fv43R+JR88NpnU6KYNjbcowVcoFAHFF1kl/Grj11woqmbzYzeSYA7mYmkNqVGhHgPScsKcO1V1DXx6toiiKiuRIUamjUzyyOyy2R0cOF/MK9tOcSq/kusGx5HeN5rEyGAKK+pIigwhLTaMR/9xyGNsRBIRYmTJ9GF8f9IAsoqrmfnKHu6+uh+3jEriu69/CkCYM/32R5MHseWYhTP5ldx9dRrv7M/G6sw2+8H1A/n0bBHnCqtIiAgmq7ia//3uOOaM69Opc6cEX6FQBBwOh4MGu6NJGm5XUVtv4+jFMnJKakiOCmFAXDgFFXWkxYYSHWZyva/a2uCKta/9PIfwYANX9o9hwZrPOGmppE90KM/OHs30UUlYymspqrQSZzaRFBlCfnkt/5N5FB06rh8Sx/eaKXHeXi578TSFQqHwNTqdjiCD/9IsQ4IMTBgQy4QB2rbkqKYTzNwHVu+8ShPY9x+5kbKaeuLc1q9OigwhyW2SWmJkCKu/57kqnr9RlakUCoWinRgNeg+xDxSU4CsUCkUvQQm+QqFQ9BKU4CsUCkUvQQm+QqFQ9BKU4CsUCkUvQQm+QqFQ9BL8kodvs9kAPFbHUigUCkXrSM2UGtpe/CL4BQWiANO9997rj69XKBSKgKagoID+/fu3+3N+Ka1QW1vL0aNHSUhIwGBQi0krFAqFN9hsNgoKChgzZgwhIe1fetIvgq9QKBSKrkcN2ioUCkUvIeCKp+3evZtf//rX2O125s+fz49+9CO/2ZKbm8vPfvYzioqK0Ol0fPvb3+b73/8+r776Kv/617+IjRVrhi5ZsqTZxdy7gqlTpxIeHo5er8dgMLBu3TpKS0t5/PHHuXjxIn369GHlypVERUW1vTMfc/bsWR5//HHX8+zsbB555BEqKir8dv6WLl3Kzp07iYuLY+PGjQAtni+Hw8Gvf/1rdu3aRUhICC+99BKjR4/ucvuWL1/Ojh07CAoKol+/fixbtozIyEhycnKYMWMGAwcOBCA9PZ3nn3++y+1r7X5YvXo17777Lnq9np///OfceOONXWrbY489xrlz5wCoqKggIiKCzMxMv5y7lvTEp9efI4BoaGhwTJs2zZGVleWoq6tzZGRkOE6dOuU3eywWi+Po0aMOh8PhqKiocNx6662OU6dOOV555RXHmjVr/GaXOzfffLOjqKjIY9vy5csdq1evdjgcDsfq1asdL7/8sj9M86ChocFx3XXXOXJycvx6/vbv3+84evSoY+bMma5tLZ2vnTt3Oh544AGH3W53HDp0yHHXXXf5xb49e/Y46uvrHQ6Hw/Hyyy+77MvOzvZ4X1fQnH0t/Z6nTp1yZGRkOOrq6hxZWVmOadOmORoaGrrUNneWLVvmePXVVx0Oh3/OXUt64svrL6BCOkeOHKF///6kpaVhMpmYOXMm27Zt85s9iYmJrhbVbDYzaNAgLBaL3+zxlm3btjF37lwA5s6dy9atW/1rELBv3z7S0tLo06dzC0R0lokTJzbp7bR0vuR2nU7HuHHjKC8vJz8/v8vtu+GGGzAaRWd93Lhxfk13bs6+lti2bRszZ87EZDKRlpZG//79OXLkiF9sczgcbN68mVmzZl2272+LlvTEl9dfQAm+xWIhOTnZ9TwpKanbCGxOTg7ffPMN6enpALz99ttkZGSwdOlSysrK/GrbAw88wLx58/jnP/8JQFFREYmJiQAkJCRQVFTkT/MA2LRpk8fN1p3OX0vnq/H1mJyc7Pfrce3atUyePNn1PCcnh7lz57JgwQIOHjzoN7ua+z270/188OBB4uLiGDBggGubP8+du5748voLKMHvrlRVVfHII4/w9NNPYzabufvuu/noo4/IzMwkMTGRl156yW+2vfPOO7z33nv88Y9/5O233+bAgQMer+t0uibLyHU1VquV7du3c/vttwN0q/PXmO5wvlpi1apVGAwGZs+eDQiPcceOHaxfv56nnnqKn/70p1RWVna5Xd3595Rs3LjRw+Hw57lrrCfudPb6CyjBT0pK8uiuWiwWkpKS/GgR1NfX88gjj5CRkcGtt94KQHx8PAaDAb1ez/z58/nqq6/8Zp88P3FxcUyfPp0jR44QFxfn6vrl5+e7BtP8xe7duxk9ejTx8fFA9zp/QIvnq/H1mJeX57frcd26dezcuZPf/va3LkEwmUzExMQAMGbMGPr16+caoOxKWvo9u8v93NDQwEcffcSMGTNc2/x17prTE19efwEl+FdccQXnz58nOzsbq9XKpk2bmDp1qt/scTgcPPPMMwwaNIiFCxe6trvH0bZu3crQoUP9YR7V1dUur6S6upq9e/cydOhQpk6dyvr16wFYv34906ZN84t9kk2bNjFz5kzX8+5y/iQtnS+53eFwcPjwYSIiIlxd765k9+7drFmzhlWrVhEaGuraXlxc7JqCn52dzfnz50lLS+ty+1r6PadOncqmTZuwWq0u+8aOHdvl9n3yyScMGjTIIzzij3PXkp748voLuIlXu3bt4sUXX8Rms3HnnXeyaNEiv9ly8OBB7r33XoYNG4ZeL9rOJUuWsHHjRo4fPw5Anz59eP755/0iBNnZ2Tz88MOAmKE3a9YsFi1aRElJCY899hi5ubmkpqaycuVKoqOju9w+EA3RzTffzNatW4mIiADgiSee8Nv5W7JkCfv376ekpIS4uDgWL17MLbfc0uz5cjgcPP/88+zZs4fQ0FBefPFFrrjiii637/XXX8dqtbp+Q5lCuGXLFl555RWMRiN6vZ7FixdfdgepOfv279/f4u+5atUq1q5di8Fg4Omnn76s6bfN2TZ//nyeeuop0tPTufvuu13v9ce5a0lPxo4d67PrL+AEX6FQKBQdI6BCOgqFQqHoOErwFQqFopegBF+hUCh6CUrwFQqFopegBF+hUCh6CUrwFQqFopegBF+hUCh6CUrwFQqFopfw/wEWMo0evfyOgAAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"code","source":"X_train.skew()","metadata":{"execution":{"iopub.status.busy":"2022-09-06T01:58:14.615470Z","iopub.execute_input":"2022-09-06T01:58:14.616043Z","iopub.status.idle":"2022-09-06T01:58:14.787794Z","shell.execute_reply.started":"2022-09-06T01:58:14.615998Z","shell.execute_reply":"2022-09-06T01:58:14.786906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val","metadata":{"execution":{"iopub.status.busy":"2022-09-06T00:36:53.150674Z","iopub.status.idle":"2022-09-06T00:36:53.151429Z","shell.execute_reply.started":"2022-09-06T00:36:53.151166Z","shell.execute_reply":"2022-09-06T00:36:53.151191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on nns:\n# - try classic regularizers (l1, l2 etc)\n# - try different architecture (not snnn)\n# classic architecture:\n# He initialization, elu activation, batch norm, l2 reg, adam.\n\n# - try exotic architecture, e.g., wide'n'deep\n# \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classic architecture:\n\nneurons_base = 16\nl2_reg_rate = 0.4\nhe_init = tf.keras.initializers.HeNormal()\n\nmodel_nn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*8, activation=\"elu\", kernel_initializer=he_init, \n                          kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate), input_shape=X_train.shape[1:]),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"elu\", kernel_initializer=he_init,\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.BatchNormalization(),    \n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"elu\", kernel_initializer=he_init,\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.BatchNormalization(),    \n    tf.keras.layers.Dense(units=neurons_base, activation=\"elu\", kernel_initializer=he_init,\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(1)])\n\nprint(model_nn.count_params())\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:24:02.983873Z","iopub.execute_input":"2022-09-07T01:24:02.984760Z","iopub.status.idle":"2022-09-07T01:24:03.111698Z","shell.execute_reply.started":"2022-09-07T01:24:02.984698Z","shell.execute_reply":"2022-09-07T01:24:03.110719Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"23681\n","output_type":"stream"}]},{"cell_type":"code","source":"early_stopping50 = EarlyStopping(patience=50, restore_best_weights=True)\ntime1 = time.time()\noptimizer_adam = tf.keras.optimizers.Adam()\nmodel_nn.compile(loss= \"mean_squared_error\" , optimizer=optimizer_adam, metrics=[\"mean_squared_error\"])\nhistory = model_nn.fit(X_train, y_train, validation_data=(X_val, y_val), \n                         batch_size=2048, epochs=1000, verbose=2, callbacks=[early_stopping50])\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))\n\nprint([r2_score(y_train, model_nn.predict(X_train)), \n       r2_score(y_val, model_nn.predict(X_val)),\n       r2_score(y_test, model_nn.predict(X_test))])\nprint(time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T01:24:03.319789Z","iopub.execute_input":"2022-09-07T01:24:03.320391Z","iopub.status.idle":"2022-09-07T01:24:30.338572Z","shell.execute_reply.started":"2022-09-07T01:24:03.320356Z","shell.execute_reply":"2022-09-07T01:24:30.337643Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Epoch 1/1000\n30/30 - 2s - loss: 292.9427 - mean_squared_error: 123.7774 - val_loss: 280.9637 - val_mean_squared_error: 135.7735\nEpoch 2/1000\n30/30 - 0s - loss: 248.7766 - mean_squared_error: 122.1955 - val_loss: 244.3598 - val_mean_squared_error: 135.9327\nEpoch 3/1000\n30/30 - 0s - loss: 215.8054 - mean_squared_error: 120.9648 - val_loss: 218.1856 - val_mean_squared_error: 136.4254\nEpoch 4/1000\n30/30 - 0s - loss: 191.6477 - mean_squared_error: 119.5777 - val_loss: 199.5424 - val_mean_squared_error: 136.8327\nEpoch 5/1000\n30/30 - 0s - loss: 174.6854 - mean_squared_error: 118.9356 - val_loss: 184.2599 - val_mean_squared_error: 135.2799\nEpoch 6/1000\n30/30 - 0s - loss: 162.2748 - mean_squared_error: 118.3630 - val_loss: 175.2728 - val_mean_squared_error: 136.3410\nEpoch 7/1000\n30/30 - 0s - loss: 152.9210 - mean_squared_error: 117.8156 - val_loss: 168.7839 - val_mean_squared_error: 137.4088\nEpoch 8/1000\n30/30 - 0s - loss: 146.7896 - mean_squared_error: 118.1870 - val_loss: 160.7534 - val_mean_squared_error: 134.8652\nEpoch 9/1000\n30/30 - 0s - loss: 141.3315 - mean_squared_error: 117.6038 - val_loss: 154.9283 - val_mean_squared_error: 133.3375\nEpoch 10/1000\n30/30 - 0s - loss: 137.2978 - mean_squared_error: 117.3611 - val_loss: 153.0102 - val_mean_squared_error: 134.7478\nEpoch 11/1000\n30/30 - 0s - loss: 134.4307 - mean_squared_error: 117.4634 - val_loss: 150.3110 - val_mean_squared_error: 134.6189\nEpoch 12/1000\n30/30 - 0s - loss: 131.9117 - mean_squared_error: 117.2282 - val_loss: 149.7482 - val_mean_squared_error: 136.1177\nEpoch 13/1000\n30/30 - 0s - loss: 129.9907 - mean_squared_error: 117.1949 - val_loss: 147.3863 - val_mean_squared_error: 135.4152\nEpoch 14/1000\n30/30 - 0s - loss: 128.6957 - mean_squared_error: 117.3905 - val_loss: 147.3794 - val_mean_squared_error: 136.7273\nEpoch 15/1000\n30/30 - 0s - loss: 127.8081 - mean_squared_error: 117.6382 - val_loss: 140.3336 - val_mean_squared_error: 130.6747\nEpoch 16/1000\n30/30 - 0s - loss: 126.4936 - mean_squared_error: 117.2741 - val_loss: 143.3982 - val_mean_squared_error: 134.6465\nEpoch 17/1000\n30/30 - 0s - loss: 125.7008 - mean_squared_error: 117.3413 - val_loss: 141.2219 - val_mean_squared_error: 133.2564\nEpoch 18/1000\n30/30 - 0s - loss: 124.6276 - mean_squared_error: 116.9755 - val_loss: 141.2829 - val_mean_squared_error: 133.9419\nEpoch 19/1000\n30/30 - 0s - loss: 124.3650 - mean_squared_error: 117.2810 - val_loss: 143.9086 - val_mean_squared_error: 137.1311\nEpoch 20/1000\n30/30 - 0s - loss: 123.5131 - mean_squared_error: 116.9854 - val_loss: 140.4838 - val_mean_squared_error: 134.2154\nEpoch 21/1000\n30/30 - 0s - loss: 122.7947 - mean_squared_error: 116.7219 - val_loss: 136.9626 - val_mean_squared_error: 131.1106\nEpoch 22/1000\n30/30 - 0s - loss: 122.8210 - mean_squared_error: 117.1102 - val_loss: 144.9969 - val_mean_squared_error: 139.4718\nEpoch 23/1000\n30/30 - 0s - loss: 122.2422 - mean_squared_error: 116.8611 - val_loss: 143.4781 - val_mean_squared_error: 138.2415\nEpoch 24/1000\n30/30 - 0s - loss: 121.7269 - mean_squared_error: 116.6388 - val_loss: 141.0953 - val_mean_squared_error: 136.1655\nEpoch 25/1000\n30/30 - 0s - loss: 121.5661 - mean_squared_error: 116.7455 - val_loss: 141.8167 - val_mean_squared_error: 137.1008\nEpoch 26/1000\n30/30 - 0s - loss: 121.2566 - mean_squared_error: 116.6286 - val_loss: 135.8104 - val_mean_squared_error: 131.3083\nEpoch 27/1000\n30/30 - 0s - loss: 121.0110 - mean_squared_error: 116.5999 - val_loss: 139.7214 - val_mean_squared_error: 135.4104\nEpoch 28/1000\n30/30 - 0s - loss: 121.1585 - mean_squared_error: 116.9167 - val_loss: 139.5778 - val_mean_squared_error: 135.4220\nEpoch 29/1000\n30/30 - 0s - loss: 120.4517 - mean_squared_error: 116.3629 - val_loss: 134.2414 - val_mean_squared_error: 130.2499\nEpoch 30/1000\n30/30 - 0s - loss: 120.3904 - mean_squared_error: 116.4558 - val_loss: 135.2681 - val_mean_squared_error: 131.4092\nEpoch 31/1000\n30/30 - 0s - loss: 120.3719 - mean_squared_error: 116.5697 - val_loss: 135.8568 - val_mean_squared_error: 132.1054\nEpoch 32/1000\n30/30 - 0s - loss: 120.1695 - mean_squared_error: 116.4849 - val_loss: 141.4118 - val_mean_squared_error: 137.7876\nEpoch 33/1000\n30/30 - 0s - loss: 119.9131 - mean_squared_error: 116.3238 - val_loss: 135.4840 - val_mean_squared_error: 131.9511\nEpoch 34/1000\n30/30 - 0s - loss: 119.7338 - mean_squared_error: 116.2529 - val_loss: 135.7056 - val_mean_squared_error: 132.2834\nEpoch 35/1000\n30/30 - 0s - loss: 119.6611 - mean_squared_error: 116.2852 - val_loss: 135.6792 - val_mean_squared_error: 132.3340\nEpoch 36/1000\n30/30 - 0s - loss: 119.9920 - mean_squared_error: 116.6561 - val_loss: 127.6423 - val_mean_squared_error: 124.3213\nEpoch 37/1000\n30/30 - 0s - loss: 119.5122 - mean_squared_error: 116.2347 - val_loss: 134.9472 - val_mean_squared_error: 131.7146\nEpoch 38/1000\n30/30 - 0s - loss: 119.3385 - mean_squared_error: 116.1207 - val_loss: 133.3211 - val_mean_squared_error: 130.1396\nEpoch 39/1000\n30/30 - 0s - loss: 119.0140 - mean_squared_error: 115.8671 - val_loss: 133.9182 - val_mean_squared_error: 130.8165\nEpoch 40/1000\n30/30 - 0s - loss: 119.2659 - mean_squared_error: 116.1940 - val_loss: 132.4731 - val_mean_squared_error: 129.4152\nEpoch 41/1000\n30/30 - 0s - loss: 119.3050 - mean_squared_error: 116.2569 - val_loss: 132.7551 - val_mean_squared_error: 129.7323\nEpoch 42/1000\n30/30 - 0s - loss: 119.4373 - mean_squared_error: 116.4160 - val_loss: 140.8622 - val_mean_squared_error: 137.8587\nEpoch 43/1000\n30/30 - 0s - loss: 119.1699 - mean_squared_error: 116.1745 - val_loss: 128.7328 - val_mean_squared_error: 125.7627\nEpoch 44/1000\n30/30 - 0s - loss: 118.9143 - mean_squared_error: 115.9599 - val_loss: 131.5555 - val_mean_squared_error: 128.6375\nEpoch 45/1000\n30/30 - 0s - loss: 119.1339 - mean_squared_error: 116.2179 - val_loss: 130.9346 - val_mean_squared_error: 128.0332\nEpoch 46/1000\n30/30 - 0s - loss: 118.6381 - mean_squared_error: 115.7593 - val_loss: 125.8889 - val_mean_squared_error: 123.0439\nEpoch 47/1000\n30/30 - 0s - loss: 119.0142 - mean_squared_error: 116.1678 - val_loss: 136.6203 - val_mean_squared_error: 133.7915\nEpoch 48/1000\n30/30 - 0s - loss: 118.6950 - mean_squared_error: 115.8662 - val_loss: 137.1548 - val_mean_squared_error: 134.3440\nEpoch 49/1000\n30/30 - 0s - loss: 118.5053 - mean_squared_error: 115.7086 - val_loss: 135.7884 - val_mean_squared_error: 133.0245\nEpoch 50/1000\n30/30 - 0s - loss: 118.5710 - mean_squared_error: 115.8169 - val_loss: 132.6677 - val_mean_squared_error: 129.9332\nEpoch 51/1000\n30/30 - 0s - loss: 118.5964 - mean_squared_error: 115.8742 - val_loss: 132.5875 - val_mean_squared_error: 129.8786\nEpoch 52/1000\n30/30 - 0s - loss: 118.2631 - mean_squared_error: 115.5729 - val_loss: 125.9582 - val_mean_squared_error: 123.2861\nEpoch 53/1000\n30/30 - 0s - loss: 118.4737 - mean_squared_error: 115.8114 - val_loss: 129.0526 - val_mean_squared_error: 126.4040\nEpoch 54/1000\n30/30 - 0s - loss: 118.7721 - mean_squared_error: 116.1045 - val_loss: 138.8320 - val_mean_squared_error: 136.1561\nEpoch 55/1000\n30/30 - 0s - loss: 118.8617 - mean_squared_error: 116.1875 - val_loss: 126.7636 - val_mean_squared_error: 124.0885\nEpoch 56/1000\n30/30 - 0s - loss: 118.6439 - mean_squared_error: 115.9660 - val_loss: 138.3126 - val_mean_squared_error: 135.6500\nEpoch 57/1000\n30/30 - 0s - loss: 118.2139 - mean_squared_error: 115.5663 - val_loss: 134.2193 - val_mean_squared_error: 131.5935\nEpoch 58/1000\n30/30 - 0s - loss: 118.1733 - mean_squared_error: 115.5617 - val_loss: 134.0523 - val_mean_squared_error: 131.4703\nEpoch 59/1000\n30/30 - 0s - loss: 117.9698 - mean_squared_error: 115.3953 - val_loss: 136.8249 - val_mean_squared_error: 134.2699\nEpoch 60/1000\n30/30 - 0s - loss: 118.0615 - mean_squared_error: 115.4937 - val_loss: 127.1128 - val_mean_squared_error: 124.5472\nEpoch 61/1000\n30/30 - 0s - loss: 118.4513 - mean_squared_error: 115.8699 - val_loss: 129.3816 - val_mean_squared_error: 126.7941\nEpoch 62/1000\n30/30 - 0s - loss: 118.2759 - mean_squared_error: 115.7048 - val_loss: 133.4664 - val_mean_squared_error: 130.9034\nEpoch 63/1000\n30/30 - 0s - loss: 118.4146 - mean_squared_error: 115.8538 - val_loss: 129.4889 - val_mean_squared_error: 126.9255\nEpoch 64/1000\n30/30 - 0s - loss: 118.4051 - mean_squared_error: 115.8313 - val_loss: 134.7390 - val_mean_squared_error: 132.1630\nEpoch 65/1000\n30/30 - 0s - loss: 118.1771 - mean_squared_error: 115.6054 - val_loss: 142.2352 - val_mean_squared_error: 139.6840\nEpoch 66/1000\n30/30 - 0s - loss: 118.1191 - mean_squared_error: 115.5516 - val_loss: 137.5064 - val_mean_squared_error: 134.9530\nEpoch 67/1000\n30/30 - 0s - loss: 118.3167 - mean_squared_error: 115.7634 - val_loss: 129.7255 - val_mean_squared_error: 127.1777\nEpoch 68/1000\n30/30 - 0s - loss: 117.7376 - mean_squared_error: 115.1880 - val_loss: 133.4111 - val_mean_squared_error: 130.8784\nEpoch 69/1000\n30/30 - 0s - loss: 117.8179 - mean_squared_error: 115.2970 - val_loss: 130.4764 - val_mean_squared_error: 127.9645\nEpoch 70/1000\n30/30 - 0s - loss: 118.2887 - mean_squared_error: 115.7544 - val_loss: 126.1101 - val_mean_squared_error: 123.5635\nEpoch 71/1000\n30/30 - 0s - loss: 117.6895 - mean_squared_error: 115.1545 - val_loss: 127.7591 - val_mean_squared_error: 125.2418\nEpoch 72/1000\n30/30 - 0s - loss: 117.9221 - mean_squared_error: 115.4004 - val_loss: 131.3727 - val_mean_squared_error: 128.8392\nEpoch 73/1000\n30/30 - 0s - loss: 117.5733 - mean_squared_error: 115.0530 - val_loss: 135.7155 - val_mean_squared_error: 133.2014\nEpoch 74/1000\n30/30 - 0s - loss: 117.7235 - mean_squared_error: 115.2083 - val_loss: 133.6760 - val_mean_squared_error: 131.1697\nEpoch 75/1000\n30/30 - 0s - loss: 117.7978 - mean_squared_error: 115.2812 - val_loss: 132.9630 - val_mean_squared_error: 130.4483\nEpoch 76/1000\n30/30 - 0s - loss: 117.8669 - mean_squared_error: 115.3386 - val_loss: 127.9682 - val_mean_squared_error: 125.4337\nEpoch 77/1000\n30/30 - 0s - loss: 117.7301 - mean_squared_error: 115.1878 - val_loss: 134.4519 - val_mean_squared_error: 131.9096\nEpoch 78/1000\n30/30 - 0s - loss: 117.8842 - mean_squared_error: 115.3414 - val_loss: 127.9560 - val_mean_squared_error: 125.4127\nEpoch 79/1000\n30/30 - 0s - loss: 117.4006 - mean_squared_error: 114.8561 - val_loss: 138.6335 - val_mean_squared_error: 136.0983\nEpoch 80/1000\n30/30 - 0s - loss: 117.3017 - mean_squared_error: 114.7560 - val_loss: 132.0601 - val_mean_squared_error: 129.5229\nEpoch 81/1000\n30/30 - 0s - loss: 117.4299 - mean_squared_error: 114.8916 - val_loss: 135.3107 - val_mean_squared_error: 132.7834\nEpoch 82/1000\n30/30 - 0s - loss: 117.8946 - mean_squared_error: 115.3711 - val_loss: 140.1149 - val_mean_squared_error: 137.5705\nEpoch 83/1000\n30/30 - 0s - loss: 117.8768 - mean_squared_error: 115.3030 - val_loss: 132.4440 - val_mean_squared_error: 129.8593\nEpoch 84/1000\n30/30 - 0s - loss: 117.2415 - mean_squared_error: 114.6654 - val_loss: 130.1796 - val_mean_squared_error: 127.6249\nEpoch 85/1000\n30/30 - 0s - loss: 117.3518 - mean_squared_error: 114.8052 - val_loss: 125.6401 - val_mean_squared_error: 123.1024\nEpoch 86/1000\n30/30 - 0s - loss: 117.4808 - mean_squared_error: 114.9255 - val_loss: 136.1547 - val_mean_squared_error: 133.5915\nEpoch 87/1000\n30/30 - 0s - loss: 117.2760 - mean_squared_error: 114.7154 - val_loss: 137.9217 - val_mean_squared_error: 135.3617\nEpoch 88/1000\n30/30 - 0s - loss: 117.5825 - mean_squared_error: 115.0166 - val_loss: 132.0631 - val_mean_squared_error: 129.4941\nEpoch 89/1000\n30/30 - 0s - loss: 117.5139 - mean_squared_error: 114.9268 - val_loss: 131.8709 - val_mean_squared_error: 129.2707\nEpoch 90/1000\n30/30 - 0s - loss: 117.0688 - mean_squared_error: 114.4820 - val_loss: 129.6665 - val_mean_squared_error: 127.0977\nEpoch 91/1000\n30/30 - 0s - loss: 117.2599 - mean_squared_error: 114.6981 - val_loss: 132.9979 - val_mean_squared_error: 130.4419\nEpoch 92/1000\n30/30 - 0s - loss: 117.0398 - mean_squared_error: 114.4820 - val_loss: 130.7324 - val_mean_squared_error: 128.1824\nEpoch 93/1000\n30/30 - 0s - loss: 117.1435 - mean_squared_error: 114.5831 - val_loss: 129.8303 - val_mean_squared_error: 127.2634\nEpoch 94/1000\n30/30 - 0s - loss: 117.0534 - mean_squared_error: 114.4813 - val_loss: 132.0715 - val_mean_squared_error: 129.5088\nEpoch 95/1000\n30/30 - 0s - loss: 117.2670 - mean_squared_error: 114.7020 - val_loss: 145.9980 - val_mean_squared_error: 143.4228\nEpoch 96/1000\n30/30 - 0s - loss: 117.0136 - mean_squared_error: 114.4302 - val_loss: 133.2427 - val_mean_squared_error: 130.6579\nEpoch 97/1000\n30/30 - 0s - loss: 117.2800 - mean_squared_error: 114.6956 - val_loss: 130.8734 - val_mean_squared_error: 128.2946\nEpoch 98/1000\n30/30 - 0s - loss: 117.0500 - mean_squared_error: 114.4720 - val_loss: 140.1617 - val_mean_squared_error: 137.5823\nEpoch 99/1000\n30/30 - 0s - loss: 116.9706 - mean_squared_error: 114.3827 - val_loss: 139.0555 - val_mean_squared_error: 136.4624\nEpoch 100/1000\n30/30 - 0s - loss: 116.9654 - mean_squared_error: 114.3609 - val_loss: 136.5023 - val_mean_squared_error: 133.9066\nEpoch 101/1000\n30/30 - 0s - loss: 116.5539 - mean_squared_error: 113.9636 - val_loss: 132.4658 - val_mean_squared_error: 129.8774\nEpoch 102/1000\n30/30 - 0s - loss: 117.0581 - mean_squared_error: 114.4682 - val_loss: 136.2229 - val_mean_squared_error: 133.6224\nEpoch 103/1000\n30/30 - 0s - loss: 116.8463 - mean_squared_error: 114.2463 - val_loss: 131.7230 - val_mean_squared_error: 129.1301\nEpoch 104/1000\n30/30 - 0s - loss: 116.9456 - mean_squared_error: 114.3320 - val_loss: 143.7850 - val_mean_squared_error: 141.1619\nEpoch 105/1000\n30/30 - 0s - loss: 116.4824 - mean_squared_error: 113.8613 - val_loss: 133.0256 - val_mean_squared_error: 130.4109\nEpoch 106/1000\n30/30 - 0s - loss: 116.8573 - mean_squared_error: 114.2422 - val_loss: 140.0483 - val_mean_squared_error: 137.4343\nEpoch 107/1000\n30/30 - 0s - loss: 116.5626 - mean_squared_error: 113.9448 - val_loss: 133.3853 - val_mean_squared_error: 130.7714\nEpoch 108/1000\n30/30 - 0s - loss: 116.7834 - mean_squared_error: 114.1596 - val_loss: 134.2236 - val_mean_squared_error: 131.5915\nEpoch 109/1000\n30/30 - 0s - loss: 116.7563 - mean_squared_error: 114.1018 - val_loss: 131.5421 - val_mean_squared_error: 128.8819\nEpoch 110/1000\n30/30 - 0s - loss: 116.7074 - mean_squared_error: 114.0477 - val_loss: 132.9286 - val_mean_squared_error: 130.2803\nEpoch 111/1000\n30/30 - 0s - loss: 116.7853 - mean_squared_error: 114.1317 - val_loss: 136.4955 - val_mean_squared_error: 133.8361\nEpoch 112/1000\n30/30 - 0s - loss: 116.6657 - mean_squared_error: 113.9992 - val_loss: 134.4249 - val_mean_squared_error: 131.7566\nEpoch 113/1000\n30/30 - 0s - loss: 116.5251 - mean_squared_error: 113.8511 - val_loss: 135.9553 - val_mean_squared_error: 133.2877\nEpoch 114/1000\n30/30 - 0s - loss: 116.9981 - mean_squared_error: 114.3067 - val_loss: 135.8779 - val_mean_squared_error: 133.1824\nEpoch 115/1000\n30/30 - 0s - loss: 116.5283 - mean_squared_error: 113.8254 - val_loss: 138.2080 - val_mean_squared_error: 135.5077\nEpoch 116/1000\n30/30 - 0s - loss: 116.6106 - mean_squared_error: 113.9057 - val_loss: 140.7254 - val_mean_squared_error: 138.0245\nEpoch 117/1000\n30/30 - 0s - loss: 116.3983 - mean_squared_error: 113.6963 - val_loss: 137.3780 - val_mean_squared_error: 134.6762\nEpoch 118/1000\n30/30 - 0s - loss: 116.5107 - mean_squared_error: 113.8053 - val_loss: 144.0148 - val_mean_squared_error: 141.3142\nEpoch 119/1000\n30/30 - 0s - loss: 116.5895 - mean_squared_error: 113.8764 - val_loss: 130.3043 - val_mean_squared_error: 127.5736\nEpoch 120/1000\n30/30 - 0s - loss: 116.2906 - mean_squared_error: 113.5497 - val_loss: 129.7829 - val_mean_squared_error: 127.0457\nEpoch 121/1000\n30/30 - 0s - loss: 116.4917 - mean_squared_error: 113.7541 - val_loss: 135.9710 - val_mean_squared_error: 133.2321\nEpoch 122/1000\n30/30 - 0s - loss: 116.2833 - mean_squared_error: 113.5225 - val_loss: 131.4919 - val_mean_squared_error: 128.7111\nEpoch 123/1000\n30/30 - 0s - loss: 116.2315 - mean_squared_error: 113.4609 - val_loss: 133.8258 - val_mean_squared_error: 131.0700\nEpoch 124/1000\n30/30 - 0s - loss: 116.4168 - mean_squared_error: 113.6722 - val_loss: 155.3365 - val_mean_squared_error: 152.5939\nEpoch 125/1000\n30/30 - 0s - loss: 116.4964 - mean_squared_error: 113.7475 - val_loss: 137.6980 - val_mean_squared_error: 134.9362\nEpoch 126/1000\n30/30 - 0s - loss: 116.0660 - mean_squared_error: 113.2927 - val_loss: 136.3328 - val_mean_squared_error: 133.5563\nEpoch 127/1000\n30/30 - 0s - loss: 116.2945 - mean_squared_error: 113.5105 - val_loss: 134.8104 - val_mean_squared_error: 132.0136\nEpoch 128/1000\n30/30 - 0s - loss: 116.0815 - mean_squared_error: 113.2818 - val_loss: 135.3596 - val_mean_squared_error: 132.5616\nEpoch 129/1000\n30/30 - 0s - loss: 116.4652 - mean_squared_error: 113.6542 - val_loss: 150.5179 - val_mean_squared_error: 147.6929\nEpoch 130/1000\n30/30 - 0s - loss: 116.5753 - mean_squared_error: 113.7216 - val_loss: 132.2971 - val_mean_squared_error: 129.4232\nEpoch 131/1000\n30/30 - 0s - loss: 116.6805 - mean_squared_error: 113.8054 - val_loss: 139.2059 - val_mean_squared_error: 136.3442\nEpoch 132/1000\n30/30 - 0s - loss: 116.3065 - mean_squared_error: 113.4420 - val_loss: 139.8611 - val_mean_squared_error: 137.0078\nEpoch 133/1000\n30/30 - 0s - loss: 116.1710 - mean_squared_error: 113.3191 - val_loss: 134.1969 - val_mean_squared_error: 131.3443\nEpoch 134/1000\n30/30 - 0s - loss: 115.9540 - mean_squared_error: 113.0973 - val_loss: 136.4714 - val_mean_squared_error: 133.6223\nEpoch 135/1000\n30/30 - 0s - loss: 115.9652 - mean_squared_error: 113.1149 - val_loss: 136.4519 - val_mean_squared_error: 133.6059\nMinimum Validation Loss: 125.6401\n[0.04285526974826459, 0.14689324930459913, 0.024477873090611113]\n26.899967908859253\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAXsAAAD3CAYAAAD8O/QcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABFXElEQVR4nO3deVzUdf7A8dcczHAMNwx4gIpnaaKFZavpqgmGkndb2WXt1rqtZuyvVnN/bVnbte3mWrul2fXbbDtNNs0sbzs90jxS05QEg0EBuWGYme/vjw8DoiCgwDDwfj4ePga+c73nK/P+fj7vz+f7+eo0TdMQQgjRruk9HYAQQoiWJ8leCCE6AEn2QgjRAUiyF0KIDkCSvRBCdACS7IUQogMwNvSAiooKZsyYgd1ux+l0kpSUxJw5c8jIyCA1NZXTp0/Tv39/nnnmGUwmE3a7nQcffJD9+/cTEhLCc889R9euXVvjswghhKiHrqF59pqmUVpaSkBAAJWVldx8880sWLCA1157jcTERMaPH8/DDz9Mv379uPnmm1m+fDmHDh1i4cKFrF69ms8++4xFixbVes3y8nL27dtHZGQkBoOhJT+fEEK0G06nk5MnTzJgwAB8fX2b9NwGW/Y6nY6AgAAAHA4HDocDnU7H119/zd/+9jcAJk+ezAsvvMDNN9/Mhg0b+P3vfw9AUlISCxcuRNM0dDpd9Wvu27ePGTNmNClQIYQQyvLly0lISGjScxpM9qCOJlOmTOH48ePcfPPNxMTEEBQUhNGonh4dHY3NZgPAZrPRqVMn9eJGI4GBgeTn5xMWFlb9epGRkdUBR0dHNylgIYToqLKzs5kxY0Z1Dm2KRiV7g8FAWloahYWF3HvvvRw9erTJb3T264E6SEg9XwghmuZCyt9Nmo0TFBTEVVddxe7duyksLMThcADqaBMVFQVAVFQUWVlZgCr7FBUVERoa2uTAhBBCNJ8Gk31eXh6FhYWAGlj98ssv6dmzJ1dddRVr164F4MMPP2T06NEAjB49mg8//BCAtWvXMnTo0Fr1eiGEEK2vwTJOTk4O8+bNw+l0omka48aNY9SoUfTq1Yv777+fRYsWcckllzB9+nQApk2bxgMPPMDYsWMJDg7mueeea/EPIYQQ4vwaTPb9+vVj5cqV52yPiYnh/fffP2e72Wxm8eLFzRKcEEKI5iFn0AohRAcgyV4IIToAr0v2z649xPwVezwdhhDCSw0ePNjTIXhEo+bZtyVHcoo5eqrY02EIIYRX8bpk7282UFLh9HQYQggvp2kazzzzDFu3bkWn0zFr1iySk5PJycnh/vvvp7i4GKfTySOPPMLgwYNZsGAB+/btQ6fTMXXqVO644w5Pf4Qm8bpkH2AyUlYpyV4Ib/fBzkze3ZHRrK95Q0IMU69o3Fn5n376KQcPHiQtLY38/HymTZtGQkICq1atYvjw4cyaNQun00lZWRkHDhzAZrOxatUqgOpzj7yJ19Xs/U0GSiocng5DCOHldu7cyfjx4zEYDERERDBkyBD27t3LZZddxooVK3j++ef54YcfsFgsxMTEkJGRwWOPPcaWLVuwWCyeDr/JvK5l728yUuFw4XC6MBq87lglhKgy9YqujW6Ft6YhQ4bw5ptvsnnzZubNm8fMmTOZNGkSaWlpfP7557z99tusWbOGJ5980tOhNonXZcsAs1oAqFRKOUKIi5CQkMCaNWtwOp3k5eWxY8cOBg4cyIkTJ4iIiOCGG25g+vTp7N+/n7y8PDRNIykpiblz5/L99997Ovwm88qWPUBphZMgXx8PRyOE8FZjx45l165dTJw4EZ1OxwMPPEBkZCQffvghr7zyCkajEX9/f55++mlycnKYP38+LpcLgNTUVA9H33Rel+yrW/Z2qdsLIZpu165dgLow0x//+Ef++Mc/1rp/8uTJTJ48+ZznuRd49FZeV8bx83EneynjCCFEY3ldsg8wq86IzMgRQojG87pk72+Slr0QQjSV1yV7d8tekr0QQjSe1yX7kOyvuFa/kxIZoBVCiEbzvmS/9zX+YHyPUqnZCyFEo3ldsjf4WrBQRomUcYQQotG8Ltnr/YKx6Mpknr0QolWcb/37zMxMJkyY0IrRXLgGT6rKysriwQcfJDc3F51Oxw033MDtt9/O3LlzOXbsGABFRUUEBgaSlpZGZmYmycnJ9OjRA4D4+HgWLlzYbAHrzIEq2UsZRwghGq3BZG8wGJg3bx79+/enuLiYqVOnMmzYMBYtWlT9mKeeeqrWKnCxsbGkpaW1SMCYA/HBib28rGVeXwjROnb/B3a92byvOfgWGHTTeR/y7LPP0qlTJ2bMmAHA888/j8Fg4JtvvqGwsBCHw8F9993Htdde26S3rqio4JFHHmHfvn3VeXPo0KEcPnyY+fPnU1lZicvl4vnnn8dqtTJ37lyys7NxuVz87ne/Izk5+YI/dmM0mOytVitWqxUAi8VCXFwcNpuNXr16AeoCAGvWrOGNN95o0UCrmQMBcJUXtM77CSHaleTkZJ544onqZL9mzRpeeeUVbrvtNiwWC3l5efzqV79izJgx6HS6Rr/u8uXLAfjoo4/48ccfueuuu1i7di1vv/02t912G9dffz12ux2Xy8XmzZuxWq0sXboUUNWRltaktXEyMzM5cOAA8fHx1dt27NhBeHg43bt3r/W4SZMmYbFYmDt3LgkJCc0WML7B6rai5XeOEKIFDbqpwVZ4S7j00kvJzc3FZrORn59PUFAQERERPPnkk2zfvh29Xo/NZuPUqVNERkY2+nV37tzJLbfcAkDPnj3p3Lkzx44dY9CgQbz00ktkZ2eTmJhI9+7d6dOnD08//TR//etfGTVqVPPmyHo0eoC2pKSEOXPm8NBDD9Uq2axatarWAIXVamXjxo2sXLmSefPm8Yc//IHi4ma8ZmxVy55y77tSjBCibRg3bhxr167l448/Jjk5mY8++oi8vDxWrFhBWloaERERVFRUNMt7paSk8OKLL+Lr68vdd9/NV199RY8ePVixYgV9+vRh0aJFvPDCC83yXufTqGRfWVnJnDlzSElJITExsXq7w+Hgs88+q1VrMplMhIaGAjBgwABiY2OrB3KbRVWyN1TKRceFEBcmOTmZjz/+mLVr1zJu3DiKiooIDw/Hx8eHr7/+mhMnTjT5NRMSEvjoo48AOHbsGFlZWcTFxZGRkUFMTAy33XYbY8aM4dChQ9hsNvz8/Jg4cSJ33XVXq6yP32AZR9M0FixYQFxcHDNnzqx135dffklcXBzR0dHV2/Ly8ggODsZgMJCRkUF6ejoxMTHNF3FVstfbpYwjhLgwvXv3pqSkpHpMMiUlhVmzZpGSksKAAQOIi4tr8mvefPPNPPLII6SkpGAwGHjyyScxmUysWbOGtLQ0jEYjERER3HPPPezdu5dnnnkGvV6P0WjkkUceaf4PeRadpmna+R6wY8cOZsyYQZ8+fdDrVUcgNTWVkSNHMm/ePOLj47npppq629q1a1m8eDFGoxG9Xs/s2bMZPXp0rdfMzMxkzJgxrF+/nq5dm3hZsryjsHgwjxln879/erxpzxVCCC92MbmzwZZ9QkIChw4dqvO+p5566pxtSUlJJCUlNSmIJjGrAVqjQ8o4QgjRWF53pSrManDY7CzxcCBCiI7i0KFDPPjgg7W2mUwm3nvvPQ9F1HTel+yNZhw6E/5aGXaHC5PR61Z8EEJ4mb59+7bciaKtxCszZaUxgEBKZX0cIYRoJK9M9g4ftT6OrHwphBCN45XJ3mlSyxzLYmhCCNE4XpnsNVPVypfSshdCiEbx2mQfSJlcmlAIIRrJK5O9zjdIDdBWSMteCCEaw2uTvRqglZa9EEI0hvfNsweMfkGYKaNMBmiFEKJRvLJlb/QPxkfnpLy81NOhCCGEV/DKZO/jr9bHcZae9mwgQgjhJbwy2Rv8VLJ3lMkyx0II0Rhemezda9prFXIdWiGEaAyvTvaUS8teCCEaw6uTvU6uViWEEI3ipck+CABdhSR7IYRoDK9O9oZKSfZCCNEYXprs1dWqfBxytSohhGiMBpN9VlYWt956K8nJyYwfP5433ngDgOeff55rrrmGiRMnMnHiRDZv3lz9nCVLljB27FiSkpLYunVr80dtNFOp85FkL4QQjdTgcgkGg4F58+bRv39/iouLmTp1KsOGDQPgjjvu4K677qr1+CNHjrB69WpWr16NzWZj5syZrF27FoPB0KyBlxssmJxy0XEhhGiMBlv2VquV/v37A2CxWIiLi8Nms9X7+PXr1zN+/HhMJhMxMTF069aNPXv2NF/EVeyGAHzlouNCCNEoTarZZ2ZmcuDAAeLj4wFYvnw5KSkpzJ8/n4ICdYKTzWYjOjq6+jlRUVHnPThcKIfRgq+rFE3Tmv21hRCivWl0si8pKWHOnDk89NBDWCwWbrrpJj777DPS0tKwWq089dRTLRnnORw+Fiy6MiocrlZ9XyGE8EaNSvaVlZXMmTOHlJQUEhMTAYiIiMBgMKDX65k+fTp79+4FVEs+Ozu7+rk2m42oqKhmD9xVdbWqwvLKZn9tIYRobxpM9pqmsWDBAuLi4pg5c2b19pycnOqf161bR+/evQEYPXo0q1evxm63k5GRQXp6OgMHDmz+yM2BBFJKUbmsaS+EEA1pcDbOzp07SUtLo0+fPkycOBGA1NRUVq1axcGDBwHo0qULCxcuBKB3795cd911JCcnYzAYePjhh5t9Jg6oq1UF6MpIL5OWvRBCNKTBZJ+QkMChQ4fO2T5y5Mh6nzNr1ixmzZp1cZE1wOAXhIUyiiTZCyFEg7zzDFrAxy8IH52T4hJZMkEIIRrivcneEg5ARVG+hyMRQoi2z2uTvW9wBACVxSc9HIkQQrR9XpvsTYGRAGgluR6ORAgh2j6vTfa6ANWyR5K9EEI0yGuTPf6qZq8vz/NwIEII0fZ5b7L3CwXAKMleCCEa5L3J3uBDic6CyX7a05EIIUSb573JHigxBuPnOO3pMIQQos3z6mRfbgwmwFHg6TCEEKLN8+pkX2EKweIq9HQYQgjR5nl1sq80hxFMEZVOWdNeCCHOx6uTvcsvjDCKZJljIYRogFcne/zD8NdVUFwkdXshhDgfr072+qqzaEtPn/JwJEII0bZ5dbI3WlSyLy/MaeCRQgjRsXl1sjcFqcXQ7IWy8qUQQpyPVyd7vxArAM5iWQxNCCHOx6uTvX9VstdKpWYvhBDn0+A1aLOysnjwwQfJzc1Fp9Nxww03cPvtt/P000+zceNGfHx8iI2N5cknnyQoKIjMzEySk5Pp0aMHAPHx8dUXI29uAUERuDQdulJZDE0IIc6nwWRvMBiYN28e/fv3p7i4mKlTpzJs2DCGDRvGH/7wB4xGI3/9619ZsmQJDzzwAACxsbGkpaW1ePB6o5HTugAMFXJpQiGEOJ8GyzhWq5X+/fsDYLFYiIuLw2azMXz4cIxGdawYNGgQ2dnZLRtpPQp1QfhIshdCiPNqUs0+MzOTAwcOEB8fX2v7Bx98wIgRI2o9btKkSdxyyy3s2LGjeSKtR7E+GLMscyyEEOfVYBnHraSkhDlz5vDQQw9hsViqt7/44osYDAauv/56QPUENm7cSGhoKPv27ePee+9l9erVtZ7TnEqMwUQ6ZJ69EEKcT6Na9pWVlcyZM4eUlBQSExOrt69YsYJNmzbx7LPPotPpADCZTISGqqtIDRgwgNjYWI4dO9YCoSsVphACnLJcghBCnE+DyV7TNBYsWEBcXBwzZ86s3r5lyxaWLVvGiy++iJ+fX/X2vLw8nE4nABkZGaSnpxMTE9MCoSt2UyhBWiFoWou9hxBCeLsGyzg7d+4kLS2NPn36MHHiRABSU1N5/PHHsdvt1QcA9xTL7du3s3jxYoxGI3q9nkcffZSQkJAW+wBO3zDMVIK9BMwtUyoSQghv12CyT0hI4NChQ+dsHzlyZJ2PT0pKIikp6eIjaySXX5i6LclFL8leCCHq5NVn0ALo/FWyLymQQVohhKiP1yd7g3vly9OS7IUQoj5en+x9gqIAqCjI8nAkQgjRdnl9sjeFdgHAVfCzhyMRQoi2y+uTvcUSSJ5mgUJJ9kIIUR+vT/Yh/j5ka+EYiqSMI4QQ9fH6ZB8eYCZLC8NUKsleCCHq4/XJ3s9kIFcfhl+5zMYRQoj6eH2yByg0WbE48sFR4elQhBCiTWoXyb7UV02/ROr2QghRp3aR7Cv9O6kfZEaOEELUqV0ke1egJHshhDifdpHsDSFdAdAKTng4EiGEaJvaRbIPCg6lUPPDnp/p6VCEEKJNahfJPizARLYWhkOSvRBC1KldJPtwi5lsLQytUMo4QghRl/aR7ANMZGnhGItl6qUQQtSlfSR7i4lswjCXnwRnpafDEUKINqddJPuwABNZWhg6NCi2eTocIYRocxpM9llZWdx6660kJyczfvx43njjDQBOnz7NzJkzSUxMZObMmRQUFACgaRqPP/44Y8eOJSUlhf3797fsJwDMRgMFxkj1i8y1F0KIczSY7A0GA/PmzePjjz/mnXfe4a233uLIkSMsXbqUq6++mk8//ZSrr76apUuXArBlyxbS09P59NNPeeyxx3jkkUda+jMAUO5ftWSCDNIKIcQ5Gkz2VquV/v37A2CxWIiLi8Nms7F+/XomTZoEwKRJk1i3bh1A9XadTsegQYMoLCwkJ6flV6R0BshZtEIIUZ8m1ewzMzM5cOAA8fHx5ObmYrVaAYiMjCQ3NxcAm81GdHR09XOio6Ox2Vq+jm4ODKcckyR7IYSoQ6OTfUlJCXPmzOGhhx7CYrHUuk+n06HT6Zo9uKYIt5jJJgJOH/doHEII0RY1KtlXVlYyZ84cUlJSSExMBCA8PLy6PJOTk0NYWBgAUVFRZGdnVz83OzubqKio5o77HOEWE8dcVrT89BZ/LyGE8DYNJntN01iwYAFxcXHMnDmzevvo0aNZuXIlACtXrmTMmDG1tmuaxu7duwkMDKwu97SksAAzP7mskHcMNK3F308IIbyJsaEH7Ny5k7S0NPr06cPEiRMBSE1N5e6772bu3Lm8//77dO7cmUWLFgEwcuRINm/ezNixY/Hz8+OJJ55o0Q/gFmExsUezorMXQVk++Ie1yvsKIYQ3aDDZJyQkcOjQoTrvc8+5P5NOp+PPf/7zxUfWRGEBJo5rVT2I/HRJ9kIIcYZ2cQYtQHiAuXayF0IIUa39JHuLiQxJ9kIIUad2k+xD/U2U4kuJT5gkeyGEOEu7SfYmo55gPx9yfTpJshdCiLO0m2QPEBVkJksfLcleCCHO0q6SfZcQP446IqAgU9a1F0KIM7SrZN85xI8D5eGgOVXCF0IIAbSzZN8l1I9DFeHqFynlCCFEtfaV7EP8ZK69EELUoV0l+66hfmQTikvvA/nHPB2OEEK0Ge0q2XcO8UNDT5FfF2nZCyHEGdpVsrcG+mLU6zjl00mtfimEEAJoZ8neoNfRKcSX47qucOoHmX4phBBV2lWyB+gc7Me3rt7gKIfsPZ4ORwgh2oR2l+y7hPqxuay7+iVjm0djEUKItqLdJfuuIX7sK7KgBXeFjG88HY4QQrQJ7S7Zdwn1w6VBaVSCtOyFEKJKu0v2nUP8AMgJjofCE7JsghBC0A6TfZeqZH/Ut7/aIK17IYRo+Bq08+fPZ9OmTYSHh7Nq1SoA5s6dy7Fjah57UVERgYGBpKWlkZmZSXJyMj169AAgPj6ehQsXtmD453K37A+6Yhnj46+S/YAprRqDEEK0NQ0m+ylTpnDLLbfwxz/+sXrbokWLqn9+6qmnsFgs1b/HxsaSlpbWvFE2ga+PgQiLmYzCSuhyhQzSCiEEjSjjDBkyhODg4Drv0zSNNWvWMGHChGYP7GJ0CfHlxOkyiLlSzbW3l3o6JCGE8KiLqtnv2LGD8PBwunfvXr0tMzOTSZMmccstt7Bjx46Lje+CdAn140R+GXT7BbgckP65R+IQQoi2osEyzvmsWrWqVqvearWyceNGQkND2bdvH/feey+rV6+uVeZpDT0iAvh0v43KmFH4mALh4EfQJ7FVYxBCiLbkglv2DoeDzz77jOTk5OptJpOJ0NBQAAYMGEBsbGz1QG5r6m0NxOHS+KnAAb3HwqE14HK2ehxCCNFWXHCy//LLL4mLiyM6Orp6W15eHk6nSqoZGRmkp6cTExNz8VE2US+r6kkcthVDv/FQchIyt7d6HEII0VY0WMZJTU1l27Zt5OfnM2LECGbPns306dP5+OOPGT9+fK3Hbt++ncWLF2M0GtHr9Tz66KOEhIS0VOz16hlpQaeDwznFXDdsLOh94OAqiB3a6rEIIURb0GCy//vf/17n9qeeeuqcbUlJSSQlJV18VBfJz2Sga6gfh3OKwbc3xI2EA6tg7GOg03k6PCGEaHXt7gxat97WQA7bitQv/caryxTmHPBsUEII4SHtONlbOHqqBIfTBX2rBpF/+MSzQQkhhIe022Tfy2rB7nCRkV8GgdEQ2Q/St3o6LCGE8Ih2m+x7RwUC1JRyul8Dx7+WSxUKITqkdpvsq6df5hSrDT2ugcpSOPGtB6MSQgjPaLfJ3mI20jnYlyPuZN9tuLpN3+K5oIQQwkPabbIH6BUVyOGcqjJOQDhEDYBjUrcXQnQ87TrZ97ZaOJJTjMulqQ3dh6v17R0Vng1MCCFaWbtP9uWVLjLyq5Y47n4NOMrgxE7PBiaEEK2sXSf7AV3UOvzfZRaoDd2HATop5QghOpx2nez7RQfi66Nn1/F8tcEvFDrFw+FPPRuYEEK0snad7I0GPQO7hLA743TNxv6T4MQOyGv9pZeFEMJT2nWyBxgcG8L+E4VUOKrWsx8wVd3u+8BzQQkhRCtr98l+UEwIdqeL738uVBtCYiFmqCR7IUSH0u6T/eBYdeWsWqWcy6ZBzvdg2++ZoIQQopW1+2QfHexLp2Bfdh0/XbOx/2TQGWDv+x6LSwjRxrhc8PNuT0fRYtp9sgdVyqnVsg+IgJ6j4Lu3ofikx+ISQrQhP3wCS0fCyR88HUmL6BDJfnBsCMfzSjlVfMaZsyMegLJ8eG0cFGR6LjghRNtw+id1m/ejZ+NoIR0i2Q+KUXX7WqWc2KFw64dQnAOvjoOCE54JTgjRNhTb1G07bfw1mOznz5/P1VdfzYQJE6q3Pf/881xzzTVMnDiRiRMnsnnz5ur7lixZwtixY0lKSmLr1rZxpurArsH4+RjY8sNZJZtuV8PtH6kW/vt3ylr3QnRkRR082U+ZMoVly5ads/2OO+4gLS2NtLQ0Ro4cCcCRI0dYvXo1q1evZtmyZTz66KM4nc7mj7qJfH0MjOoXyZp92Tjdi6K5dR4EKf+AjK9hw+MeiU8I0Qa4W/aF7bOX32CyHzJkCMHBwY16sfXr1zN+/HhMJhMxMTF069aNPXv2XHSQzSH5sk6cKq5ge3reuXdeNg2uuAO+WARrF8CxLeCwt3aIQghPKs5Rt41p2Wsa/HsK7FvRsjE1owuu2S9fvpyUlBTmz59PQYFaaMxmsxEdHV39mKioKGw228VH2QxG97Pi66Pn471ZdT9g3FPQbwJ88xK8kQLLRkN5YesGKYTwnOqafSNa9mX58ON6+HFDy8bUjC4o2d9000189tlnpKWlYbVaeeqpp5o7rmbnbzIyqq+17lIOgI8f3Lgc/pgOE/8Ftu/h/ZngdLR6rEKIVuZ0QMlJ0OlVGcfVQPk5v2ptrcKfWz62ZnJByT4iIgKDwYBer2f69Ons3bsXUC357Ozs6sfZbDaioqKaJ9JmkHxZJ04WVbCjrlKOmzkQBs+ACX+HI+vgg7vgq3/Bjlehsqz1ghVCtJ7SU4AG1ktBc9a08uuTn65uvai+f0HJPicnp/rndevW0bt3bwBGjx7N6tWrsdvtZGRkkJ6ezsCBA5sn0mYwup8Vs1HP6vpKOWe64g41F//7lbB2Pqy6H777T0uHKITwBHdy73K5um2obu9eNdeLpmwbG3pAamoq27ZtIz8/nxEjRjB79my2bdvGwYMHAejSpQsLFy4EoHfv3lx33XUkJydjMBh4+OGHMRgMLfsJmiDAbGTMJVZW7cniT+MvxWRs4Fg3+k8w7D7VpVtyDRz+DBLubJ1ghWgtJbnw9k0w6UUI7+npaDzDPTjb+XL49v9Uso+5sv7Hu1v29iI1tucb1OIhXqwGk/3f//73c7ZNnz693sfPmjWLWbNmXVxULWjaFV35eG82mw7lkNg/uuEnmAPVbe9E2P2Wun6t0Xxhb65p8PED6gIqg28Bne7CXkeI5pTxjfr344YOnOzdLfsr1G1DLXt3sgdVyvGCZN8hzqA904jekURYzHzwbRNPnOidCJWl8NMXDT/24MeQsf3c7ScPwvaX4b+/hxW/gYqipsUgREtwLw9wqhnXhDl5yLNrzHz+HGQ24VrTRVVjjRG9wRTYcC0+Px1CuqmfvaRu3+GSvdGgZ/Lgzmw4mENeSRPm0ne/BgxmVcoB+OQheCURSs8a7P1xA7x9M/znRig7Xfu+9M/V7ZX3qPX0Xx8PFcUX/FmEaBa5LZDsV86CtN813+s1Rf5PsO4R2Plq459TnAPmYDUrL7jr+Vv2Dru6v/tw9buX1O07XLIHmHpFVyqdGv/d3YT/JJM/9LhGXb/28Dr4+p+q67t8ek3CPp0B798Fod2gNBc2P137NY5tgeBYSH4GbnwLsvfCB79WYwIul/rSaXVMCxXNq/BnVU6zl3g6krYh94i6ba6WuMulpi5n7/XM1OVDa9RtbhMWNCu2gcWqfg7ucv5kX5ABaGp9LXTSsm/L+kUH0b9zEO/tzERrSnLtnai+GB/eDZH9YNpr8PMu+L/r1WydN6eq9XVmfKBm83yzBHLUQDYul2rZu1sDfa+D656BH9bAvyfDogHw/OVwcNWFfajTGfDu7ef2NJqD09G+EuOuN2HbUjUGIyDvqLot+rl5TiQ8nQ6OMnCU1xxIWtOhj9VtU967OAcsVdPEG2rZu+fYh/dWz5Fk37bddGUs+38u5PMjpxr/pF7XqtuyfHXi1YApMPkllWi//y847TB1GUT0gtH/C2YLrHlQtdZzvoeyPNU7cLvyNzD0XjUOEH0Z+EfAnncu7ANtf1lNE22JC7JseAxeGt78r+spP25Ut9uWqoNwW1KY1boLcdlLVbLqNEj9fupw7fsddrW/mtJCdzdwALLPWC6lKS3tptjyLPxzqPpelp1W3ydzsDpJ6uxSan3ObNkHdVXz7us7r8Y97TK0e1UvQJJ9mzY9oSudg3157rMfGt+6D++pWvejHoKuVaP2A2+ABw7Dgz/Cfbuh7zi1PSAcRv0Jjm1WrfX0qhVAu19T+zWT/gLzT8DN76iLoR/+rGbgduvfYfHl8PIYVe6pLK87LpcT9ryrfm6Ja+v+8Ilq/ZU04cDYVlUUQeY2CO+latRHN3o6ohqaBsunwX9uar33dLfq+yar21OHat//7Rvw70nwr6Fw4KPGlRlPHlC3ep+aZJ+xTfVcD33SLGFX279SNUZOHlALGR5ZBy4HJMxU9zd2bfpiW+2WPdR/dmx+Ohh9ITAagjrXPM7pgB2vqZ7649FwdNMFfqiW0WGTvdlo4HejevHt8dNsOdyEJDbjPXWyVWMk3KnOyFv7kEriod0hJKb2Y3Q68PFVP/efrLq+hz5RrYVNT6kBI6Mv7H2v/hLPsc1QlKXmCGd8rXoazaU4R80iAsg50HyvW5+Th+CVpNrlqIITNcvPXqz0z1UyuO5pCLCqUltrO7ETPl907vafvgDbPpUgi3POvb8luJNhr2tVcj55VrI//jX4haq/03duUX+TDck5qFrHUf1V3R5q/nYP/Lf5Ys/epwaCu16pvmvbX1GLGQZEQvyN6jGN6U1UFIO9GALPSvb19bDy09V3WadTn7PwhDoIfvUCrJqr7jeY1Fn3bUiHTfYANyTE0CXEr2mt+6YwGFVSOX1cLZrUvYFSSMxVENgZ9q+ALc+A5oKb/qPW3A+JhV3/rvt5372juq2T/qV+3/9h830G9wwiqEn6LenAR+qAlXnG1NV3b1Oty+Youfy4AXz8VQ8r4U44vLblygv1+WYJrPuzmjVypm1LQV916suxLQ2/zt73VSuysaWKurjr2pF9VM/17DJO5nboMQJmfQXxN8Hmp9TU4vM5eQCs/aDTQMjaoxKhexbbD580vO5MYxTZVA/INxh+9W+49hFVhsneC33GQVicWuemMXX7kqoDa3XLvou6te2v+/HuZO9+rL0YKgrh4GpVDpv9LQy6STXaLub/ppl16GRvMur5/ehe7M44zX+/a6EFjXqMgEsnqZ+7jzj/Y/V61bo//JkaREyYqZK8Xg+DboGjm9WB40wVxaq1NGAyWC9RrfvmLOWkfw4mC5iDGteydzpg28vw1q/gqW7w9oyaOcyN8fMudet+L6dDfYFzvocDabUfq2mqXut+TmP8uBG6DVMnxiXcqRLC3vca//zmkFVV2jh0RtIsyIQDq+Cq36oEdr7ykqbBlr+qdZt+3ADfp9X/2IbkHlVJzhwIEX1ql3GKc9Sl+roOUQ2XCYug82BYcXf9M3dcTnXAsF4C0QPVOFXGNvX/1yVBzVLL2NZwXIU/Q3lB3ffZS+CtG1Rd/ca3VDnFNxiSnlD3XzpJ/f+GxDYu2bt7UdWzcWIg8hLVI/9kvhrXcNO0qmTfQ/0e1FndZu1RB8Y+41SLf+AN4Kyo6cnYSyD9C/jpy9ZvXFTp0MkeYPoVXbmiWyh/WrmPzPzShp9wIcY9CZffXlPPP5/+k8FVqbrU1/xPzfZBVXXc3Wesz1OQqaZ3VpaqVheoun/WblXL3Ps+7HwDdi2v3UJvivTPIfZqNfuoMS379K3w8f+ox/a6VtVQ/3mVarE3xolv1a37vfKOqi8NOtj8TO3W/dcvqnptY0sxpzMg97C62DyobnuneHUQvRCaBkfWN22mUmVZzXz2g6trtu94TfXkrrxbNRCObq6/Pv7FIlWfHvgr1YLddxGD8rlHIKzqrNmIPmrw0X0th8wd6rbrEHXr4wu/ehOMJvjv7Jr4jn8Niy6DU0dUInSUq2QZfZm6//Oqs/Cve1r9XR9qoGdQlq8mBCwZUTP4mfWdOsisuAfeuF6Vuqa9VrOWDajrUsz+FnpXTaQI73Vusq8sh9X/U/sMWHdjxN2yN/jAr9fBkF/D1/9SFyG3fa/uK81VLXl3yz6oquTz7RuABn2S1O+dL1fvv+ddddB6JRFeT4bXroMXhnhkdluHT/ZGg55FvxqEpkHqO9/VvfzxxQrqDNcvVq2PhnRNUOWcEX+oqSGCaqXEjYTdb6qW/7Kx8Fx/+HKxKknEXKUe13+yaq2+d7tq+X00R53c8kaKWgPFbf9KVTs+nyKbaul1H6665Y1J9lnfqdvfbIRpr8BvP4ewHur8g7NLBGcrzFLT/6CmZZ9T1ZX+xe9V6/Bg1UHj513w2cPq54Y+h5u7tdxzdM22HiNVi+xCvnwHPoI3p6hzLRr7/Jzv1aqKEX1VK680TyWDna+r6bih3SDul2out3vw9Jz3XaUS8OQlMGAaHNvatN7TmfJ+rFkiIbKvis1dx8/crspKneJrHh/cFX45X5Xajm5UCf+TearH+eXimv83az9Vs0enSjch3dRSBN2H18yDr8/mv6r9UpKr/m6/+Acsu1a9zvGv1GdNWVx34+nM5R7Ce5177soPn6iZa2eOPRSfVcYBNZNu/LNw60pVinl5lDo3460b1P1hZ7Xsv09TY0DuWU06HVx2g2r8/HuK+u5M/Cfclga/3QqmgPPvgxbQ4ZM9QEyYPwsn9mdbeh6L1zeQkFqaTgd3fVr3IPCgW9SXavk09Qd/7aPwu29UTd+9zk5wF5i5Rl1M/d5tcP9+1dXVXPBTVeu+LF+t1f9KohrU0jQ12PXD2tr1VPfju1+jWmqluVB81nV8z5a9V3WD/cPU7xG94aZ3VKvwv7PPX3f/uapV3yVBDRS6XKpuqjOoBBPeC9bMUy28d29T3e6h96qDSH1d/jMd/FiNiUT2q9kWN1L1pH76quHnn0nT1Cn5/uEqAS2/oe6EX14AiwfXzEJxl3BGPqgS6+HPVCu9NBdGVPXk4qp6HnXN5nA61D7pemVVQpkGaOrg3VTlBWp6YvgZLXuoGaTN3K5a5z5+tZ93+W2qRbvxSTU+9PMuVdb47u2asYaIvqo0FBanfu+dqOLtm6x6V4fWqBLJxidrJ+NTR2DbEvUet65Qs2Q+e1j1dmZ/C3P3QOp+uPzWhj9feC/VCj9zuWJ3yWvvezW9hmKb+hvzDz/3NXqOUg2W2KGqPKm5YMSDqpEAqoSk06tp170TVcnVbWDVGmIndqip2oNvUQfyqP4Nx94CJNlXmTy4C1Mv78o/1h/m0/0X2EpqaZekqD+YCYtg9k4YPle1oM5eUC12qGq9RvZVLbHeieAToFqAoJKI5lJ11dWp8Nee8NIw1Wr5v4k1sxCObVXrhHSKV+8DNdPq6pO9p6b77hYYBUlPqqS4/dzrGVc78a360g28QZ2UczpddZ/De6qWUMo/VEvq+FegAVNfgV5jAA1+3l37tYqyYemomvpwUbY6+3ngDbX3V8xQNXPi2Cb1+8HVapqro+L8n/PYFnVwGv2/MOVlOP6l6ml9dJ86cLr98KlqobsH17P3qMH0/pPBEq1ardteVuUb9yJcYXHqgFlXss89rPaNu7Ud2ReiLqu/lONyqv/HugZF3bXj8F7qNkItVU7O9+rxJ76tKeGcyWiGa1LVFNaP5oK1P9z0tiq37XhF9ULNFvVY999C70R1626N/+dGVYbb/JRaZRJU0v/0T2D0UyvOxlwJd6yC61+Am9+DgIi6P2N93Acxdymnskw1aHpdq/7+ty1RrfYDH6lZcvp6VugNjFIt8gXZcPcmGL2gZgadwaemR+Au4biFxcHw+1UvJP5XTYu9BTS46mVHodPp+MvkARzJKeL+d3az8t5h9I4K9HRYtfn4qq5gUxl81AHAXbc/sl4lnF9vUNPFsveog4PLAWv/pGrsRl81ANY7UQ3ORV6inptzULWy6mIvUa3s/lPOvW/QzWrgeM0DaiaKOQhu+D+IvarmMT9/q6aqdh5c8145+2u6xt2Hw2/W135d9xTNEztVK93t80Xq9T79E9y5Vp0tqzlh8FktQpO/aiUf3azm4H90n2rtBnaCxMfq36efP6e+5PE3qf+XwE6w8zVVo/0+DVIPqBaxu+x0ZL0a6MveqxKg3qDKNjtfU72N0X+qeW2dTn2WA6vOXT7XXSbrdMZ1Ii6bqtaCObhandUZ3rMmcW39G2z8Cwz5DST/tfaBzl0mctfsTQFq8PrL51XZpbKk7mQPaj9+/pwqN127TDUG+iarerz7bwXU5/jpy5qZaCGxMGqBim/QDPjwt6o8EtxVTVX8YQ2MXVgzWNp5cM3fQ1O5D2K5R9T7H1mvPtPVv1d/fzteUwe0vKNwSyMmNbgT/NmCuqhzUNxjQWe69pELi70FSMv+DL4+Bl669Qr8TEbueG07x061oyUCug9XrfLik2oGR9xINdB2TSpMf111mxPuVPXEfhOg33j1h3pd1fo+gdHqAHHygGohrbhbLQZ3bGvN2ZW27wHt3JY9qCQz5WWV1IbcpbrX352xXIGmqS9el8E1ZZYTO9VA2vm6vf5hqgXlLgGBasXvfE19CTO+UV/yXW9C7C/U2c1nixupkvC6R1Si7zFSJbz0elY4/Xm3qlcP/V1NAug+TJ09PeM9VSbbt0INBh5ep0oajjI48pkqwbj3z4Cqg2LyM+cukTvoFnXweffWmgFTUGUgo59K6m4Dpqra+ts3wz+HqEFAe4lKYlueVT2I7S+rxO9mL1XXW/bxr6k/gxr09A+HtHvV710T6t4HRhNMeA6GzYXeY9W2q3+vbt29QIArZkLq9+qg6jbyQbjmD+pvasrL6v/wzSmqpJX4OFw9u+73bKqgrmrxQnfL/vuV4BemypK/mK2mS6Zvheufr91QaKp+49V3x9zGGodnkWR/lk7Bfrw+cwhllU6mv/QVB7PbyUXH3a3x7cvUSSC9xtT9uPCeMGWJGlAefn9NzVWnU1/inIOqtbznHZVA3pgAK36tHuM+W/LMVueZAsLVWETi46orfWhNTQ0/7yiUn1azGHyD1Bd1/wp1n/XS83+2zpfXzOIBVRpxVqpxi+BYNUCd96M6oNW5b0YCmto3/aeoMY7Q7qrVefYy1JqmDgq+ITVnaZ6p2zBV+97xqjrZrbIExj6qBue/WKxmTrn3T48R8D9HVHnunNe5Gia+oEo5ab+r2U9Z36mDn+GMTnlILMzZDbf9V+3bzO3wzq2qxWzwgd9sUDN3NjwGq1LVtMn3blcH08lLatfkA6Pg5ndV4vIPr5liWJfeY9Vnc/cWuv1CldqG/LrmMTqdiqE+lkg1w2fAVLhni0rC+mZKS3q9+nvO+k71AA99ApdMUPuuy+Xq4JT8bM1Mtwt1Tao6YLdxkuzrMKBLMO/eMxSjXsf0l77ine3HW+akq9bUaZCqv3/1gvq9Zz3J/nwi+6lEsn2Z+qI8eFSVB/avVC3w7D0qCQbHNPBCqC5/sa1mjrz71l23tvarKTNENZDsu1yhDmBF2WoG0Y5X1RmUkX1h5APqfcxBcOnEep5/uTqXQO8DYx5W9ebJL0HB8XPHGI6sU636X86re3aVTqdaeSd2qKmi5iC1r/uMU9tAzT93s0TW/7kG3Qxj/qwGE/e8rRJ+9p7as2PcQmJU6/QXs1XC/XG9inXUQ2rQ/voXVCv72/9Trf/Dn8L4v8Gl15/7WlGXwu3/Va3uplxgR6dTCwCGxDb+OaB6D9Nerd0jaC6d4tX4yjNx6qpSZ/4NJP1FrU/VQUiyr0cvayDv/fZqLu0UxB8/2MtNL3/NjvQ87036BqNqLdqLVVnh7GUbGsN6iZq5Ej2wKikGqta/Tqfm87vr0Y1JEL3HqsHYQ1VzzY9uUuME1qp6r7uU4xMAId3P/1ruA8Txr9VFYVwOVSYAVVOPGgBX3F67lHAmg496fNJfakoasUPVrJivX6xZk8jpgLULVI074a7644m/UZVaTuxQn9NoUqUxUIPBkX3P/3nONPx+NQD65QtqtcWKwvp7Tm6X36ZarAOmqmsngIohZRHcvw9GzlMlmPNdYrPz4Pp7f94k5R9wywp1edHLb6+ZRdMByQDtecSE+fOf3wzl3R0ZPLnmINNe+oqBXYO5/9o+jOpn9XR4Tdd9uGrRXeiXuOdoVTKZsrTm0ozBXaB3kqqJVxTW7sKfj3+Y6vYfWqNavbveVLV8d5ffnfSt/Rru1kdfpg4cH81R0wknvVQzE8Pgo6bONXQAuib13G3D56rZSXveVi3W7S+r8w5ufEslz/r4hapEu/tNVc8Ftc+NvirRn6+scTadDq6+V5VyvlysttXVsj/blb+pu9UaGA2j5jf+/b2d0az2fXs4cF2kBlv28+fP5+qrr2bChAnV255++mnGjRtHSkoK9957L4WFqq6dmZnJwIEDmThxIhMnTuThhx9uuchbiV6v48YrY/lq/mgemzSAonIHM1/fzpz/7CK3uIHpeW1N7yRVqrikjq57Y0T2hbs31kzRc0uYqdYXcZTXPThbn77JaprfezPVbIwzZy64Z3Q0VK8H1WKPulQl+jF/PrcGe6HX+u0xUpW/vvgHbHpanTzUc0zNCpHnc00qDLxRHchAzXQZtUAN6jbVZdPUzJ+dr6uB2MbsEyHO0mCynzJlCsuW1a5bDhs2jFWrVvHRRx/RvXt3liypOV09NjaWtLQ00tLSWLhwYfNH7CH+JiO3Du3G2rkjuP/aPqzZl8XwpzfyP+99x86fWuCCIS3B2g/mZ6pyTnPqdW1NnT66gRLDmfpep24LM1V3+8zZDNZ+auZEfdM8zzY8VZ1kNvz+xr9/Q3Q61brPOwqbnlDJ+8a3GnfwcA90n3mm5LA5NasxNoXRXNNKj7zkwi94Lzq0Bss4Q4YMITOz9lKfw4fXrN44aNAgPvmkmdeobsNMRj33Xdub8QOjeeXzY/x398+8vzOT4b0ieCCpL/ExIZ4O8fzqmyt8MfQGVWr4YvG5rf7zCeuhSkPhvc/tZpsC4IEfG98qd09jbG6XXK9msnS+HK6658J7CRcr4S51fYMuFzjnXHR4F12z/+CDD7juuuuqf8/MzGTSpElYLBbmzp1LQkI983S9XC9rIE9OGcifxl/Kf7Yd51+bfmTiP78g1N+HmDB/ruwexi1Du9E9ovXXwPCIq36rBgObOm3u1vMsx9xcU/Auht6gxig8zT9MTaEM8MKxItEmXFSyf/HFFzEYDFx/vaoBW61WNm7cSGhoKPv27ePee+9l9erVWCyWZgm2LQowG/n1NXHceGUs7+/I4IecYn7KLeH1L9NZ9vkxrukdweTBXUjsH43FbETTNHSeah22JJ3Oc63ejsJ6ScOPEaIeF5zsV6xYwaZNm3j99derk5fJZMJkUrMUBgwYQGxsLMeOHeOyy5owaOelLGYjdwyrOQElp7Cct7Yd570dmaS++x06nTrNXdOgT5SF4b0iGd47nKt6hBNglklRQoiWdUFZZsuWLSxbtow333wTP7+as+/y8vIIDg7GYDCQkZFBeno6MTEXMJ+7HbAG+TL32j7cN6Y33x7PZ/MPp3C5NDQ09mQWsPybn3j1i2P4GHRc2jmYSIuZCIuJLiF+xIb70y08gG5h/lh8jZwurUTTNKxBLVBvF0J0CA0m+9TUVLZt20Z+fj4jRoxg9uzZLF26FLvdzsyZ6nTx+Ph4Fi5cyPbt21m8eDFGoxG9Xs+jjz5KSEhIS3+GNk2n03FFtzCu6BZWa3t5pZMd6fl8fuQUe0+cJjO/lN0Zpzl1numcA7oEMWFgZ7qH++NvMhJgNqhbkxE/k4FAXyO+PvWs3CeE6NB0mgdOCc3MzGTMmDGsX7+erl27tvbbt2lldifH80r5KbeE43mllFQ4CQ3woczu5OO9WXyXef512wN9jXQK9iUqyJfoIF9CA0z4GvXYnRo/nizmRH4ZfaIsJHQPIy4ygAiLmehgX4J8a070sTtclFQ4KK10UmZX//R66BrqT7BfE04IEkI0q4vJnVIsbmP8TAb6RgfSN/rcFfTuGdkTW2E5eSV2Su0OSiqctW4Lyx3kFJaTVVCOrbCcQ9lFFJRVUuFwYdTr6B4RQKdgX774MZeVu2tfczcy0Ex0kC/ZheWcLKq/dxHkayQmzJ8uIX6U2p1kFZQR6OvDVT3C6Brmz2FbEem5pXQK8qWnNYDOIX5EWswEmI3YnS4qHS4cLg2nS6NrqB+xYf4Y9DrySyvJKSonp7ACW2E5OUUV5BbbsVQdvOIiAhjQJbjB8Q2H00VuiZ1gPx98fQy4XBpFFQ4cThc6nQ4/HwN+Jun9iI5Hkr2XiQpSrfamUGMFYNCrgXRN08jIKyPzdCmniu38fLqMIznF5BRVcGmnIDqH+BHkZ8TfZMDXR5WKKp0uMvNLycgrIyO/lPTcEgLMRvpEBXKquILXvkjH7nRhMRvpHuHP9z8X8M4O+/kDA0wGPRoalc5zO5j+JgNllc7qCxnpdap3YTLqMRn0RASasQaqE4zK7E4y80s5mF1EhcNV/fzySidnX2kyxN8Ha6AZPx8DRoOe06V2ThZVEGExM6JPJINiQrA7XZwutbPr+Gn2ZBbQOcSX0f2iiAnzI+t0OSV2Bz0jLfSMtODSNIrKHRRXOCiuqKSkwkl5pROnS8PiayTQ14cyu4P80krCAkwM6R5G93D/WrOyXC6NH3KK2PlTPjmFFRj0OoJ8jfyyr/Wc6btOl4amaRgNamqqw+kiq0Ct32P20RPmb6q+Twg3SfYdgF5fe0qkTqcjNtyf2PB6Fga7AOWVTk4VV9A52K/6/QpKK6t7CqV2ByajHh+D+qfTwfHcUg7nFKvVkwPNWAN9sQaZq3/2MxmodLrIKargh+widmecJj23hEqni4pKF6eKKzhsK0IH+JuNRFrM3HZ1N2LD/CkoqyS/tBJ/k4FgPx98DHo0TaOkqjeSU1hBhcNFpdNFn6hAftEzguN5pfxn23Fe/zK9+nN1DfVjcGwIx06V8PQnjbgGbyMFmAwE+vrg66OnuMJJYVkldmcdl2z86Ht6RARg1OsoKndQVF5Jid2JTgfhAWYsZgMnTpfVOlj6+RgY2DWYmDB/cosrKCirJNyiem4uTaOkwoGGOisc1MyxvFI74QFmuob6UVLhICO/FLvDRadgPyIDzZiNeowGXfX/X6dgXwZ2DcbfZGTbsTwOZBcS4mciKsiMS4OSCgehASau6BZKVKCZo6dKOHaqBGugme7hAVS6XGQXlFNc7sCg11X/M+r1Z/2uw+yjJ8TPhE4H32WcZu+JAqKCfEnoHkp0kC/llS40tOrPc6ZKpwu9Tlfd0GkJLpdGaaWT4nIHGhrRQb5tcnq1JHvRLHx9DHQNrX3wCPb3Idjfp86SFMCQ7mF1bj+Tj0FPlxA/uoT4tcric+WVqodgNhqwmI2EBtQseJZdUE5+qZ3OwX6YffQcPakSmMmox2I2EuhrxGI24m9WPSKDriZB+5kMhPqb+Pl0GdvS8zhsK6bU7qC80kWA2UiQn5E+1kASuocSE+qPBvx8uox1B2x8cSQXo15HYFUvIdBXna+RU1RBUYWD6y7rRPdwf/Q6HeWVTn48WcKujNN8fvgUEYEmgnx9yMgrZXt6HnqdjgCzAR06Su3O6lle4QEmMvNL+fpoLv4mAzFh/vj6GDiQVciWHyqwO2vKb3X/P+nq7J2B6lHW97zmZDEbibCYqHRqlNgdlFY4sTtd+Bh0xIT5Yw00k1tsJ6+qzGcNMhPo64PJoKfSqRoP+aWVlNodVDhcdAsPYFDXYPzNRrJOl1Fid2INNBPs58OPJ4s5mF1EbrGd4gpHrTgCzUb6RgcSbjFhMftU/b8Zq/5GfOge4c8vejbxEovNQAZohRCN5nJp2J0ufsotZe+JAorLKxnSI4x+0UGUVzrJKarAqNfhZzKQXVDOzp/yyS4sp0+UhR4RFk4WVfBTbglmo56oIF8CfX1waeog4nRp1QcU9bMLl6ZRZndVjT05GdA5mPiYELIKytj5U351703TwFZYTm6JHbNRj7/JPVPNQIndSfqpEk4VVxBuMREWYKawvJKcwnKKK5zYHU6Mej0Rgeq+AJMBo0HHkZxi9mYWYHe6iAryJcBkJKeonIKySrqHB3BJpyCig30JMBuxmA1YzD44NY1D2YX8YCumoLSS4goHheXq1p1pTQY9ux4ee0Hn18gArRCiVej1Onz1dU8iCDAb6XFGAouwmBnQpY4LvDSDyEAzA7uGtMhrn8lV1SM5sxTqcmnnlEYbomkapXYnxRUOfAx6j5xIKcleCCHqUVdSb2qiBzVOFmA2evRseRmyF0KIDkCSvRBCdACS7IUQogOQZC+EEB2AJHshhOgAJNkLIUQH4JF5QE6nE4Ds7GxPvL0QQngld85059Cm8EiyP3nyJAAzZszwxNsLIYRXO3nyJN26dWvSczyyXEJ5eTn79u0jMjISg0GWmxVCiMZwOp2cPHmSAQMG4OvbtNVvPZLshRBCtC4ZoBVCiA7A65L9li1bSEpKYuzYsSxdutTT4dQpKyuLW2+9leTkZMaPH88bb7wBwOnTp5k5cyaJiYnMnDmTgoLzX2LQE5xOJ5MmTeKee+4BICMjg+nTpzN27Fjmzp2L3d7wBUlaW2FhIXPmzGHcuHFcd9117Nq1q83v69dff53x48czYcIEUlNTqaioaJP7ev78+Vx99dVMmDChelt9+1bTNB5//HHGjh1LSkoK+/fvbzMxP/3004wbN46UlBTuvfdeCgsLq+9bsmQJY8eOJSkpia1bt3oiZKDuuN1effVV+vbtS15eHnCB+1rzIg6HQxszZox2/PhxraKiQktJSdEOHz7s6bDOYbPZtH379mmapmlFRUVaYmKidvjwYe3pp5/WlixZommapi1ZskR75plnPBlmnV599VUtNTVVu/vuuzVN07Q5c+Zoq1at0jRN0/73f/9XW758uSfDq9ODDz6ovfvuu5qmaVpFRYVWUFDQpvd1dna2NmrUKK2srEzTNLWPP/jggza5r7dt26bt27dPGz9+fPW2+vbtpk2btLvuuktzuVzarl27tGnTprWZmLdu3apVVlZqmqZpzzzzTHXMhw8f1lJSUrSKigrt+PHj2pgxYzSHw9Fm4tY0Tfv555+1O++8U/vlL3+p5ebmapp2Yfvaq1r2e/bsoVu3bsTExGAymRg/fjzr16/3dFjnsFqt9O/fHwCLxUJcXBw2m43169czadIkACZNmsS6des8GOW5srOz2bRpE9OmTQNU6+Hrr78mKSkJgMmTJ7e5/V1UVMT27durYzaZTAQFBbX5fe10OikvL8fhcFBeXk5kZGSb3NdDhgwhOLj2MsX17Vv3dp1Ox6BBgygsLCQnJ6e1Q64z5uHDh2M0qsmHgwYNqp7CuH79esaPH4/JZCImJoZu3bqxZ8+eVo8Z6o4b4Mknn+SBBx6odfWrC9nXXpXsbTYb0dHR1b9HRUVhs9k8GFHDMjMzOXDgAPHx8eTm5mK1qqstRUZGkpub6+HoanviiSd44IEH0OvVn0V+fj5BQUHVX5Lo6Og2t78zMzMJCwtj/vz5TJo0iQULFlBaWtqm93VUVBR33nkno0aNYvjw4VgsFvr379/m97Vbffv27O9nW/0MH3zwASNGjADafk5Zt24dVquVfv361dp+Ifvaq5K9tykpKWHOnDk89NBDWCyWWvfpdLo2dZ3KjRs3EhYWxoABAzwdSpM4HA6+//57brrpJlauXImfn985YzltbV8XFBSwfv161q9fz9atWykrK/NorfhitLV925AXX3wRg8HA9ddf7+lQGlRWVsaSJUu47777muX1vOriJVFRUbXOurXZbERFRXkwovpVVlYyZ84cUlJSSExMBCA8PJycnBysVis5OTmEhTV8DdbW8u2337Jhwwa2bNlCRUUFxcXF/OUvf6GwsBCHw4HRaCQ7O7vN7e/o6Giio6OJj48HYNy4cSxdurRN7+svv/ySrl27VseUmJjIt99+2+b3tVt9+/bs72db+wwrVqxg06ZNvP7669UHqLacU44fP05mZiYTJ04E1P6cMmUK77333gXta69q2V922WWkp6eTkZGB3W5n9erVjB492tNhnUPTNBYsWEBcXBwzZ86s3j569GhWrlwJwMqVKxkzZoyHIjzXH/7wB7Zs2cKGDRv4+9//ztChQ/nb3/7GVVddxdq1awH48MMP29z+joyMJDo6mqNHjwLw1Vdf0bNnzza9rzt37sx3331HWVkZmqbx1Vdf0atXrza/r93q27fu7ZqmsXv3bgIDA6vLPZ62ZcsWli1bxosvvoifn1/19tGjR7N69WrsdjsZGRmkp6czcOBAD0Zao2/fvnz11Vds2LCBDRs2EB0dzYoVK4iMjLygfe11J1Vt3ryZJ554AqfTydSpU5k1a5anQzrHjh07mDFjBn369Kmuf6empjJw4EDmzp1LVlYWnTt3ZtGiRYSEhHg22Dp88803vPrqqyxZsoSMjAzuv/9+CgoKuOSSS3j22WcxmUyeDrGWAwcOsGDBAiorK4mJieHJJ5/E5XK16X29ePFiPv74Y4xGI5dccgl/+ctfsNlsbW5fp6amsm3bNvLz8wkPD2f27Nlce+21de5bTdNYuHAhW7duxc/PjyeeeILLLrusTcS8dOlS7HZ79d9AfHw8CxcuBFRp54MPPsBgMPDQQw8xcuTIVo+5vrinT59eff/o0aN5//33CQsLu6B97XXJXgghRNN5VRlHCCHEhZFkL4QQHYAkeyGE6AAk2QshRAcgyV4IIToASfZCCNEBSLIXQogOQJK9EEJ0AP8PinupuZKn62gAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
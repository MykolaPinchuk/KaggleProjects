{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This is a new version of MLEAP scripts, started in late Aug 2022.\nIt will combine IProject_MLEAP_ANN and IP_MLEAP script, while improving them.","metadata":{}},{"cell_type":"markdown","source":"#### Outline\n\n1. Load libraries and data.\n2. pEDA. Look at feature distribution, fix them if they do not look right.\n3. Train-test split. Most likely couple years into test set. 2015-2018?. Impute missing values.\n4. Transform numerical features, add ohe for inds.\n5. Fit xgb as a baseline, then xgb optuna.\n6. Fit DL.\n\n","metadata":{}},{"cell_type":"code","source":"# 0. Import libraries #\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport os, time, math, re, warnings, random, gc, dill, optuna, pickle, shap\nimport statsmodels.api as sm\nfrom random import sample\n\nfrom sklearn.model_selection import train_test_split, KFold, PredefinedSplit\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNetCV\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn.inspection import permutation_importance\nfrom category_encoders import MEstimateEncoder\nfrom xgboost import XGBRegressor\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import regularizers\n\nplt.style.use('seaborn-white')\nwarnings.simplefilter(action='ignore')\npd.set_option('display.max_columns', 110)\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2022-09-06T21:15:35.876256Z","iopub.execute_input":"2022-09-06T21:15:35.876755Z","iopub.status.idle":"2022-09-06T21:15:35.888293Z","shell.execute_reply.started":"2022-09-06T21:15:35.876717Z","shell.execute_reply":"2022-09-06T21:15:35.887305Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"### target encoding ###\n# source: https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices/notebook\n\nclass CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=4)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded","metadata":{"execution":{"iopub.status.busy":"2022-09-06T21:34:17.560915Z","iopub.execute_input":"2022-09-06T21:34:17.561996Z","iopub.status.idle":"2022-09-06T21:34:17.572966Z","shell.execute_reply.started":"2022-09-06T21:34:17.561932Z","shell.execute_reply":"2022-09-06T21:34:17.571484Z"},"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"code","source":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T21:34:17.860935Z","iopub.execute_input":"2022-09-06T21:34:17.862299Z","iopub.status.idle":"2022-09-06T21:34:17.871440Z","shell.execute_reply.started":"2022-09-06T21:34:17.862249Z","shell.execute_reply":"2022-09-06T21:34:17.870244Z"},"trusted":true},"execution_count":212,"outputs":[{"name":"stdout","text":"REPLICAS:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"#min_prd_list = range(100, 676, 25)\nmin_prd_list = [150]\n# min_prd_list = [150, 250, 350, 450, 550, 650]\n#min_prd = min_prd_list[0]\nwindows_width = 3*12\ncv_regularizer=0.2\noptuna_trials = 20\ntime0 = time.time()\n\nresults = pd.DataFrame(columns = ['min_prd', 'xgbf_train', 'xgbf_val', 'xgbf_test', \n                                  'xgbgs_train', 'xgbgs_val', 'xgbgs_test', \n                                  'xgbo_train', 'xgbo_val', 'xgbo_test'])\nresults.min_prd = min_prd_list\n\nfor min_prd in min_prd_list:\n\n    with open('../input/mleap-46-preprocessed/MLEAP_46_v0.pkl', 'rb') as pickled_one:\n        df = pickle.load(pickled_one)\n    df = df[df.prd.isin(range(min_prd-1, min_prd+windows_width+10))]\n    df_cnt = df.count()\n    empty_cols = list(df_cnt[df_cnt<int(df.shape[0]/2)].index)\n    df.drop(columns=empty_cols, inplace=True)\n    #display(df.shape, df.head(), df.year.describe(), df.count())\n\n    features_miss_dummies = ['amhd', 'BAspr']\n    for col in features_miss_dummies:\n        if col in df.columns:\n            df[col+'_miss'] = df[col].isnull().astype(int)\n\n    temp_cols = ['PERMNO', 'year', 'prd']\n    df.reset_index(inplace=True, drop=True)\n    X = df.copy()\n    y = X.pop('RET')\n\n    train_indx = X.prd<(min_prd+windows_width-1)\n    val_indx = X['prd'].isin(range(min_prd+windows_width-1, min_prd+windows_width+2))\n    val_indx_extra = X['prd'].isin(range(min_prd+windows_width+5, min_prd+windows_width+8))\n    test_indx = X['prd'].isin(range(min_prd+windows_width+2, min_prd+windows_width+5))\n\n    X_train = X[train_indx]\n    X_val = X[val_indx]\n    X_val_extra = X[val_indx_extra]\n    X_test = X[test_indx]\n    y_train = y[train_indx]\n    y_val = y[val_indx]\n    y_val_extra = y[val_indx_extra]\n    y_test = y[test_indx]\n\n    #display(X_train.head(3), X_train.tail(3), y_train.head(3), y_train.tail(3))\n    display(X_train.shape, X_val.shape, X_test.shape, X_train.prd.describe(), X_val.prd.describe(), X_test.prd.describe())\n\n    X_train.drop(columns=temp_cols, inplace=True)\n    X_val.drop(columns=temp_cols, inplace=True)\n    X_val_extra.drop(columns=temp_cols, inplace=True)\n    X_test.drop(columns=temp_cols, inplace=True)\n\n    #display(X_train.tail())\n    col_cat = ['ind']\n    col_num = [x for x in X_train.columns if x not in col_cat]\n    for col in col_num:\n        X_train[col] = X_train[col].fillna(X_train[col].median())\n        X_val[col] = X_val[col].fillna(X_train[col].median())\n        X_val_extra[col] = X_val_extra[col].fillna(X_train[col].median())\n        X_test[col] = X_test[col].fillna(X_train[col].median())\n    for col in col_cat:\n        X_train[col] = X_train[col].fillna(value=-1000)\n        X_val[col] = X_val[col].fillna(value=-1000)\n        X_val_extra[col] = X_val_extra[col].fillna(value=-1000)\n        X_test[col] = X_test[col].fillna(value=-1000)\n\n    #display(X_train.tail())\n    feature_transformer = ColumnTransformer([('num', StandardScaler(), col_num),\n                                            (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\", drop='if_binary'), col_cat)], \n                                            remainder=\"passthrough\")\n\n    print('Number of features before transformation: ', X_train.shape)\n    train_index, val_index, val_index_extra, test_index = X_train.index, X_val.index, X_val_extra.index, X_test.index\n    X_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\n    X_val = pd.DataFrame(feature_transformer.transform(X_val), columns=feature_transformer.get_feature_names_out())\n    X_val_extra = pd.DataFrame(feature_transformer.transform(X_val_extra), columns=feature_transformer.get_feature_names_out())\n    X_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\n    print('time to do feature proprocessing: ')\n    print('Number of features after transformation: ', X_train.shape, X_val.shape, X_val_extra.shape, X_test.shape)\n    X_train.index = train_index\n    X_val.index = val_index\n    X_val_extra.index = val_index_extra\n    X_test.index = test_index\n    #display(X_train.tail())\n\n    X = pd.concat([X_train, X_val])\n    y = pd.concat([y_train, y_val])\n    #display(X,y)\n\n    X_ = pd.concat([X_train, X_val, X_val_extra])\n    y_ = pd.concat([y_train, y_val, y_val_extra])\n    #display(X,y, X_,y_)\n\n    print('mae of a constant model', mean_absolute_error(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\n    print('R2 of a constant model', r2_score(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\n\n    xgb1 = XGBRegressor(tree_method = 'gpu_hist', n_estimators=400, max_depth=4, eta=0.02, colsample_bytree=0.4, subsample=0.6)\n    xgb1.fit(X_train, y_train)\n    print('fixed XGB train:', mean_absolute_error(y_train, xgb1.predict(X_train)), r2_score(y_train, xgb1.predict(X_train)))\n    print('XGB val:', mean_absolute_error(y_val, xgb1.predict(X_val)), r2_score(y_val, xgb1.predict(X_val)))\n    print('XGB val extra:', mean_absolute_error(y_val_extra, xgb1.predict(X_val_extra)), r2_score(y_val_extra, xgb1.predict(X_val_extra)))\n    print('XGB test:', mean_absolute_error(y_test, xgb1.predict(X_test)), r2_score(y_test, xgb1.predict(X_test)))\n\n    results.loc[results.min_prd==min_prd,'xgbf_train':'xgbf_test'] = \\\n    [r2_score(y_train, xgb1.predict(X_train)), \n    r2_score(y_val, xgb1.predict(X_val)),\n    r2_score(y_test, xgb1.predict(X_test))]\n\n    time1 = time.time()\n\n    # Create a list where train data indices are -1 and validation data indices are 0\n    split_index = [-1 if x in X_train.index else 0 for x in X.index]\n    pds = PredefinedSplit(test_fold = split_index)\n\n    xgb = XGBRegressor(tree_method = 'gpu_hist')\n    param_grid = {'n_estimators':[400, 600, 800], 'max_depth':[2,3,4,5], 'eta':[0.006, 0.012, 0.02], \n                  'subsample':[0.6], 'colsample_bytree':[0.6]}\n    xgbgs = GridSearchCV(estimator = xgb, cv=pds, param_grid=param_grid)\n\n    # Fit with all data\n    xgbgs.fit(X_, y_)\n\n    print('gs XGB', xgbgs.best_params_, xgbgs.best_score_, time.time()-time1)\n    print('XGB train:', mean_absolute_error(y_train, xgbgs.predict(X_train)), r2_score(y_train, xgbgs.predict(X_train)))\n    print('XGB validation:', mean_absolute_error(y_val, xgbgs.predict(X_val)), r2_score(y_val, xgbgs.predict(X_val)))\n    print('XGB validation extra:', mean_absolute_error(y_val_extra, xgbgs.predict(X_val_extra)), r2_score(y_val_extra, xgbgs.predict(X_val_extra)))\n    print('XGB test:', mean_absolute_error(y_test, xgbgs.predict(X_test)), r2_score(y_test, xgbgs.predict(X_test)))\n\n    results.loc[results.min_prd==min_prd,'xgbgs_train':'xgbgs_test'] = \\\n    [r2_score(y_train, xgbgs.predict(X_train)), \n    r2_score(y_val, xgbgs.predict(X_val)),\n    r2_score(y_test, xgbgs.predict(X_test))]\n\n    time1 = time.time()\n    def objective(trial, cv_runs=1, n_splits=2, n_jobs=-1):\n\n        params = {\n        \"tree_method\": 'gpu_hist',\n        \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 800, 1500),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 6),\n        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.0005, 0.03),\n        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.05, 0.95),\n        \"subsample\": trial.suggest_uniform(\"subsample\", 0.1, 0.95),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 0.1, 50.0),\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 0.1, 500.0),\n        \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-10, 100.0),\n        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 0.1, 50)    }\n\n        model = XGBRegressor(**params, njobs=-1)\n        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose = False)\n\n        score_train = r2_score(y_train, model.predict(X_train))\n        score_val = r2_score(y_val, model.predict(X_val))\n        score_val_extra = r2_score(y_val_extra, model.predict(X_val_extra)) \n        score_val = (score_val+score_val_extra)/2\n        overfit = np.abs(score_train-score_val)\n\n        return score_val-cv_regularizer*overfit\n\n\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=optuna_trials)\n    print('Total time for hypermarameter optimization ', time.time()-time1)\n    hp = study.best_params\n    for key, value in hp.items():\n        print(f\"{key:>20s} : {value}\")\n    print(f\"{'best objective value':>20s} : {study.best_value}\")\n    optuna_hyperpars = study.best_params\n    optuna_hyperpars['tree_method']='gpu_hist'\n    optuna_xgb = XGBRegressor(**optuna_hyperpars)\n    optuna_xgb.fit(X, y)\n    print('Optuna XGB train: \\n', \n          mean_absolute_error(y_train, optuna_xgb.predict(X_train)), r2_score(y_train, optuna_xgb.predict(X_train)), '\\nvalidation \\n',\n          mean_absolute_error(y_val, optuna_xgb.predict(X_val)), r2_score(y_val, optuna_xgb.predict(X_val)),\n          mean_absolute_error(y_val_extra, optuna_xgb.predict(X_val_extra)), r2_score(y_val_extra, optuna_xgb.predict(X_val_extra)), '\\ntest \\n',\n          mean_absolute_error(y_test, optuna_xgb.predict(X_test)), r2_score(y_test, optuna_xgb.predict(X_test)))\n\n    results.loc[results.min_prd==min_prd,'xgbo_train':'xgbo_test'] = \\\n    [r2_score(y_train, optuna_xgb.predict(X_train)), \n    r2_score(y_val, optuna_xgb.predict(X_val)),\n    r2_score(y_test, optuna_xgb.predict(X_test))]\n\n    display(results)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T21:34:19.922753Z","iopub.execute_input":"2022-09-06T21:34:19.923137Z","iopub.status.idle":"2022-09-06T21:35:47.674084Z","shell.execute_reply.started":"2022-09-06T21:34:19.923105Z","shell.execute_reply":"2022-09-06T21:35:47.673242Z"},"trusted":true},"execution_count":213,"outputs":[{"output_type":"display_data","data":{"text/plain":"(46500, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(4444, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(4403, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    46500.000000\nmean       167.403097\nstd         10.350122\nmin        149.000000\n25%        159.000000\n50%        168.000000\n75%        176.000000\nmax        184.000000\nName: prd, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    4444.000000\nmean      185.997525\nstd         0.816079\nmin       185.000000\n25%       185.000000\n50%       186.000000\n75%       187.000000\nmax       187.000000\nName: prd, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    4403.000000\nmean      188.997956\nstd         0.818208\nmin       188.000000\n25%       188.000000\n50%       189.000000\n75%       190.000000\nmax       190.000000\nName: prd, dtype: float64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (46500, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (46500, 84) (4444, 84) (4381, 84) (4403, 84)\nmae of a constant model 7.707782488355303\nR2 of a constant model 0.0\nfixed XGB train: 7.153201360601873 0.07116040354151332\nXGB val: 8.837832454907955 0.008860833991066297\nXGB val extra: 7.211958123190973 0.0036993266374161227\nXGB test: 10.277253411139476 0.03135074261835891\ngs XGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 5, 'n_estimators': 400, 'subsample': 0.6} 0.010984067391343721 51.05036783218384\nXGB train: 7.238038585013199 0.04442135756862975\nXGB validation: 8.665303652164834 0.05698181575167449\nXGB validation extra: 7.015380940639335 0.06510190636891111\nXGB test: 10.293781281549693 0.025865666367645757\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-06 21:35:15,286]\u001b[0m A new study created in memory with name: no-name-5fc2fc34-6e1e-4dc6-b422-0f7476d51047\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:16,635]\u001b[0m Trial 0 finished with value: 0.0012920285579554047 and parameters: {'n_estimators': 1376, 'max_depth': 4, 'learning_rate': 0.012789215246487693, 'colsample_bytree': 0.6355143467934535, 'subsample': 0.5072585288686067, 'alpha': 2.67552498595899, 'lambda': 57.50655673297819, 'gamma': 2.423454826234995e-06, 'min_child_weight': 0.15551689060047094}. Best is trial 0 with value: 0.0012920285579554047.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:18,210]\u001b[0m Trial 1 finished with value: 0.0013823920153221755 and parameters: {'n_estimators': 1019, 'max_depth': 6, 'learning_rate': 0.025598116857956495, 'colsample_bytree': 0.09432854850096978, 'subsample': 0.6682072123239617, 'alpha': 1.751345863622901, 'lambda': 15.875375159879173, 'gamma': 1.0551369383196207, 'min_child_weight': 36.351140107857184}. Best is trial 1 with value: 0.0013823920153221755.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:20,011]\u001b[0m Trial 2 finished with value: -0.0006766602390844822 and parameters: {'n_estimators': 1089, 'max_depth': 5, 'learning_rate': 0.007922336354018577, 'colsample_bytree': 0.8990368012799363, 'subsample': 0.2440940256444418, 'alpha': 0.2562726778235969, 'lambda': 0.9416749536824359, 'gamma': 8.28887726974972e-06, 'min_child_weight': 2.6272415569812315}. Best is trial 1 with value: 0.0013823920153221755.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:24,114]\u001b[0m Trial 3 finished with value: 0.0025351919390721673 and parameters: {'n_estimators': 1109, 'max_depth': 5, 'learning_rate': 0.003991923746164417, 'colsample_bytree': 0.11911608256091716, 'subsample': 0.8321740324137318, 'alpha': 38.14384760479112, 'lambda': 0.919102947981509, 'gamma': 8.080601753928222e-08, 'min_child_weight': 3.3409210797251485}. Best is trial 3 with value: 0.0025351919390721673.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:26,496]\u001b[0m Trial 4 finished with value: 0.004916752611773245 and parameters: {'n_estimators': 1276, 'max_depth': 5, 'learning_rate': 0.014955937443179796, 'colsample_bytree': 0.05424447913361741, 'subsample': 0.3359078234876546, 'alpha': 0.7361852383426646, 'lambda': 233.11983587322933, 'gamma': 2.6154073790159096e-08, 'min_child_weight': 0.6063828489917221}. Best is trial 4 with value: 0.004916752611773245.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:28,709]\u001b[0m Trial 5 finished with value: 0.00645188917769175 and parameters: {'n_estimators': 958, 'max_depth': 2, 'learning_rate': 0.0026114529507136495, 'colsample_bytree': 0.48546546022289766, 'subsample': 0.7927542903142305, 'alpha': 4.831888328421457, 'lambda': 0.1508056081109888, 'gamma': 8.947251748469447e-09, 'min_child_weight': 1.5486078360302657}. Best is trial 5 with value: 0.00645188917769175.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:30,332]\u001b[0m Trial 6 finished with value: 0.0015339381471036083 and parameters: {'n_estimators': 859, 'max_depth': 5, 'learning_rate': 0.014976284992778562, 'colsample_bytree': 0.5482063567431943, 'subsample': 0.7461576517495405, 'alpha': 0.20113775646945747, 'lambda': 272.2194148134768, 'gamma': 0.004505311238000451, 'min_child_weight': 3.067843904743241}. Best is trial 5 with value: 0.00645188917769175.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:31,147]\u001b[0m Trial 7 finished with value: 0.005898129278584196 and parameters: {'n_estimators': 1185, 'max_depth': 2, 'learning_rate': 0.0232341788711708, 'colsample_bytree': 0.6103280888712602, 'subsample': 0.6347653486462322, 'alpha': 0.15154186983784151, 'lambda': 55.832368021880754, 'gamma': 2.7110686119906404e-09, 'min_child_weight': 28.49437217512307}. Best is trial 5 with value: 0.00645188917769175.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:33,312]\u001b[0m Trial 8 finished with value: 0.005679804538662436 and parameters: {'n_estimators': 1494, 'max_depth': 4, 'learning_rate': 0.009416942951035276, 'colsample_bytree': 0.08155349520789226, 'subsample': 0.3764130272588605, 'alpha': 1.4980222586754184, 'lambda': 7.077490992394749, 'gamma': 1.6908932778634174e-05, 'min_child_weight': 0.21555883061354372}. Best is trial 5 with value: 0.00645188917769175.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:34,354]\u001b[0m Trial 9 finished with value: -0.001980820802610351 and parameters: {'n_estimators': 1284, 'max_depth': 6, 'learning_rate': 0.021837224099446505, 'colsample_bytree': 0.9019698626110213, 'subsample': 0.30965216640999627, 'alpha': 45.13133124614734, 'lambda': 0.6459489691336264, 'gamma': 0.009187959389642009, 'min_child_weight': 1.1938359882537906}. Best is trial 5 with value: 0.00645188917769175.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:36,227]\u001b[0m Trial 10 finished with value: 0.005470339646312894 and parameters: {'n_estimators': 809, 'max_depth': 2, 'learning_rate': 0.0020200389858096393, 'colsample_bytree': 0.33683291856474495, 'subsample': 0.8851755037967206, 'alpha': 9.7509077898656, 'lambda': 0.1756617178029031, 'gamma': 3.1807697260115045e-10, 'min_child_weight': 11.517471004285145}. Best is trial 5 with value: 0.00645188917769175.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:36,898]\u001b[0m Trial 11 finished with value: 0.005634866285639828 and parameters: {'n_estimators': 967, 'max_depth': 2, 'learning_rate': 0.029788473526025986, 'colsample_bytree': 0.6987959837539542, 'subsample': 0.610572187276832, 'alpha': 7.263219609085672, 'lambda': 37.19827605746622, 'gamma': 6.181137868121978e-10, 'min_child_weight': 45.037352866224296}. Best is trial 5 with value: 0.00645188917769175.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:37,634]\u001b[0m Trial 12 finished with value: 0.005400277260225073 and parameters: {'n_estimators': 1228, 'max_depth': 3, 'learning_rate': 0.02042824091242608, 'colsample_bytree': 0.394129903593211, 'subsample': 0.9442525394305917, 'alpha': 7.389014574301527, 'lambda': 3.974116346187221, 'gamma': 1.2415392183894937e-08, 'min_child_weight': 9.138689242416536}. Best is trial 5 with value: 0.00645188917769175.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:38,352]\u001b[0m Trial 13 finished with value: 0.006597493077447813 and parameters: {'n_estimators': 948, 'max_depth': 3, 'learning_rate': 0.020064602357582735, 'colsample_bytree': 0.3940887396961351, 'subsample': 0.4935649400205025, 'alpha': 0.11115579808368467, 'lambda': 0.12281884457900652, 'gamma': 1.2074518744798049e-10, 'min_child_weight': 10.771037083367533}. Best is trial 13 with value: 0.006597493077447813.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:39,177]\u001b[0m Trial 14 finished with value: 0.0049726537504887645 and parameters: {'n_estimators': 951, 'max_depth': 3, 'learning_rate': 0.018514419579373276, 'colsample_bytree': 0.2999346600729005, 'subsample': 0.5040837743325846, 'alpha': 0.5669231826049443, 'lambda': 0.10247230566922853, 'gamma': 1.4780367542345664e-10, 'min_child_weight': 8.508623098840394}. Best is trial 13 with value: 0.006597493077447813.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:40,541]\u001b[0m Trial 15 finished with value: 0.005928377214546065 and parameters: {'n_estimators': 893, 'max_depth': 3, 'learning_rate': 0.006961599671162815, 'colsample_bytree': 0.4809372912692957, 'subsample': 0.1471527326255226, 'alpha': 18.418086689724884, 'lambda': 0.27204410445676447, 'gamma': 67.11634485229713, 'min_child_weight': 0.749453340218223}. Best is trial 13 with value: 0.006597493077447813.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:43,331]\u001b[0m Trial 16 finished with value: 0.0035496079484242937 and parameters: {'n_estimators': 1036, 'max_depth': 3, 'learning_rate': 0.0007495492437425968, 'colsample_bytree': 0.22701285682950742, 'subsample': 0.42210173991285305, 'alpha': 2.9985114662718826, 'lambda': 2.600796568269944, 'gamma': 2.389573740768803e-07, 'min_child_weight': 5.454693574884429}. Best is trial 13 with value: 0.006597493077447813.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:44,048]\u001b[0m Trial 17 finished with value: 0.007201674191538943 and parameters: {'n_estimators': 919, 'max_depth': 2, 'learning_rate': 0.017887947404402794, 'colsample_bytree': 0.7647654057694923, 'subsample': 0.7650978363135915, 'alpha': 0.6604227266527427, 'lambda': 0.36644525166701475, 'gamma': 0.000358111670683785, 'min_child_weight': 17.968404377574277}. Best is trial 17 with value: 0.007201674191538943.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:44,770]\u001b[0m Trial 18 finished with value: 0.005706593245340219 and parameters: {'n_estimators': 814, 'max_depth': 3, 'learning_rate': 0.01806299167403315, 'colsample_bytree': 0.750540482362438, 'subsample': 0.7134598156844603, 'alpha': 0.43631844507800854, 'lambda': 0.3996908260741205, 'gamma': 0.003800252625810637, 'min_child_weight': 18.69086602706694}. Best is trial 17 with value: 0.007201674191538943.\u001b[0m\n\u001b[32m[I 2022-09-06 21:35:45,446]\u001b[0m Trial 19 finished with value: 0.006018756718625794 and parameters: {'n_estimators': 900, 'max_depth': 2, 'learning_rate': 0.025887889023394003, 'colsample_bytree': 0.7953998616194979, 'subsample': 0.5657869469504095, 'alpha': 0.11398547737509385, 'lambda': 1.5525505225511886, 'gamma': 0.0004950370370309583, 'min_child_weight': 15.61989534892089}. Best is trial 17 with value: 0.007201674191538943.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  30.163309335708618\n        n_estimators : 919\n           max_depth : 2\n       learning_rate : 0.017887947404402794\n    colsample_bytree : 0.7647654057694923\n           subsample : 0.7650978363135915\n               alpha : 0.6604227266527427\n              lambda : 0.36644525166701475\n               gamma : 0.000358111670683785\n    min_child_weight : 17.968404377574277\nbest objective value : 0.007201674191538943\nOptuna XGB train: \n 7.259029341925926 0.03384663439728741 \nvalidation \n 8.674986716477399 0.04865068017421925 7.2227155499822135 -0.0008894694902390476 \ntest \n 10.30235048820971 0.025893714298076187\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   min_prd xgbf_train  xgbf_val xgbf_test xgbgs_train xgbgs_val xgbgs_test  \\\n0      150    0.07116  0.008861  0.031351    0.044421  0.056982   0.025866   \n\n  xgbo_train  xgbo_val xgbo_test  \n0   0.033847  0.048651  0.025894  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>min_prd</th>\n      <th>xgbf_train</th>\n      <th>xgbf_val</th>\n      <th>xgbf_test</th>\n      <th>xgbgs_train</th>\n      <th>xgbgs_val</th>\n      <th>xgbgs_test</th>\n      <th>xgbo_train</th>\n      <th>xgbo_val</th>\n      <th>xgbo_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>150</td>\n      <td>0.07116</td>\n      <td>0.008861</td>\n      <td>0.031351</td>\n      <td>0.044421</td>\n      <td>0.056982</td>\n      <td>0.025866</td>\n      <td>0.033847</td>\n      <td>0.048651</td>\n      <td>0.025894</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"display(results.iloc[:,1:].mean())\n# cv_regularizer = 0.5\n# optuna_trials = 80\nprint(time.time()-time0)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T21:26:09.738704Z","iopub.execute_input":"2022-09-06T21:26:09.738995Z","iopub.status.idle":"2022-09-06T21:26:09.752279Z","shell.execute_reply.started":"2022-09-06T21:26:09.738959Z","shell.execute_reply":"2022-09-06T21:26:09.751359Z"},"trusted":true},"execution_count":198,"outputs":[{"output_type":"display_data","data":{"text/plain":"xgbf_train     0.053382\nxgbf_val       0.008023\nxgbf_test      0.008769\nxgbgs_train    0.029245\nxgbgs_val      0.043444\nxgbgs_test     0.007270\nxgbo_train     0.036133\nxgbo_val       0.054458\nxgbo_test      0.006025\ndtype: float64"},"metadata":{}},{"name":"stdout","text":"633.7301712036133\n","output_type":"stream"}]},{"cell_type":"code","source":"# general point:\n# compared to NN, xgb is harder to regularize\n# in NN, you can simply shrink coefficient towards constant prediction.\n# in xgb, you can not do that. the only way to regularize is via hyperparameters.\n# in other words, by tweaking hyperpars, in NN you can approach R^2=0.0 prediction from a constant model arbitrarily close\n# in xgb, you can not do that.\n# by setting eta as low as 0.1% you can bring r2 down to 0.1%, but lowering eta further actyally increases abs(r2).\n","metadata":{"execution":{"iopub.status.busy":"2022-09-06T19:39:46.588332Z","iopub.execute_input":"2022-09-06T19:39:46.589277Z","iopub.status.idle":"2022-09-06T19:39:46.597724Z","shell.execute_reply.started":"2022-09-06T19:39:46.589242Z","shell.execute_reply":"2022-09-06T19:39:46.596791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna_xgb","metadata":{"execution":{"iopub.status.busy":"2022-09-06T19:39:46.599286Z","iopub.execute_input":"2022-09-06T19:39:46.599627Z","iopub.status.idle":"2022-09-06T19:39:46.616001Z","shell.execute_reply.started":"2022-09-06T19:39:46.599594Z","shell.execute_reply":"2022-09-06T19:39:46.614929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explainerxgbc = shap.TreeExplainer(optuna_xgb)\nshap_values_XGBoost_test = explainerxgbc.shap_values(X_test)\n\nvals = np.abs(shap_values_XGBoost_test).mean(0)\nfeature_names = X_test.columns\nfeature_importance = pd.DataFrame(list(zip(feature_names, vals)),\n                                 columns=['col_name','feature_importance_vals'])\nfeature_importance.sort_values(by=['feature_importance_vals'],\n                              ascending=False, inplace=True)\n\nshap.summary_plot(shap_values_XGBoost_test, X_test, \n                  plot_type=\"bar\", plot_size=(6,6), max_display=20)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T19:40:51.981860Z","iopub.execute_input":"2022-09-06T19:40:51.982485Z","iopub.status.idle":"2022-09-06T19:40:53.305810Z","shell.execute_reply.started":"2022-09-06T19:40:51.982448Z","shell.execute_reply":"2022-09-06T19:40:53.304889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate performance of XGB models:\nr2_xgb1 = r2_score(y_test, xgb1.predict(X_test))\nr2_xgbgs = r2_score(y_test, xgbgs.predict(X_test))\nr2_xgbo = r2_score(y_test, optuna_xgb.predict(X_test))\n\nprint('Min_prd: ', min_prd)\nprint('Constant guess: ', mean_absolute_error(y_test, np.ones(len(y_test))*y_test.mean()), \n      r2_score(y_test, np.ones(len(y_test))*y_test.mean()))\nprint('XGB test:', mean_absolute_error(y_test, xgb1.predict(X_test)), r2_xgb1)\nprint('XGB GS test:', mean_absolute_error(y_test, xgbgs.predict(X_test)), r2_xgbgs)\nprint('Optuna XGB test:', mean_absolute_error(y_test, optuna_xgb.predict(X_test)), r2_xgbo)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-06T19:41:06.869568Z","iopub.execute_input":"2022-09-06T19:41:06.870028Z","iopub.status.idle":"2022-09-06T19:41:07.010243Z","shell.execute_reply.started":"2022-09-06T19:41:06.869967Z","shell.execute_reply":"2022-09-06T19:41:07.009120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total time for a script: ', time.time()-time0)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T00:36:53.131169Z","iopub.status.idle":"2022-09-06T00:36:53.131976Z","shell.execute_reply.started":"2022-09-06T00:36:53.131718Z","shell.execute_reply":"2022-09-06T00:36:53.131742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results.iloc[:,1:].mean()","metadata":{"execution":{"iopub.status.busy":"2022-09-06T00:36:53.133368Z","iopub.status.idle":"2022-09-06T00:36:53.134132Z","shell.execute_reply.started":"2022-09-06T00:36:53.133849Z","shell.execute_reply":"2022-09-06T00:36:53.133875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3yr window, trials=20, cv_reg=0.03: 0.88%. runs 1 hr.\n# 3yr, t=40, cv_reg=0.04: 0.96%.\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-06T00:36:53.135461Z","iopub.status.idle":"2022-09-06T00:36:53.136216Z","shell.execute_reply.started":"2022-09-06T00:36:53.135933Z","shell.execute_reply":"2022-09-06T00:36:53.135958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(X_train, X_val, X_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T00:45:09.378763Z","iopub.execute_input":"2022-09-06T00:45:09.379158Z","iopub.status.idle":"2022-09-06T00:45:09.707560Z","shell.execute_reply.started":"2022-09-06T00:45:09.379127Z","shell.execute_reply":"2022-09-06T00:45:09.706650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neurons_base = 16\ndropout_rate = 0.05\n# n_b=8 was ok with small overfit.\n# n_b=32 starts clearly overfitting. \n# 128 fits clearly slower than 64 and becomes somewhat unstable. regularization could make it work, but i see no reason to go wider.\n# 64 seems to have nice balance of flexibility and runtime, but its variance may be too large. dropout makes variance vene worse.\n# 6 hidden layers is probably most this architecture can hold\n\n# in this framework the optimal model seems to have width of 16 or 32, somehow regularized. try l1/l2?\n# w32 can take at most 0.03 dropout.\n# w16 looks good w/o dropout.\n\n# more general point:\n# main drawback of dropout is in incresing variance\n# for textbook problems with high s/n ratio (e.g., mnist) this may be ok.\n# for application like this with very low s/n ratio dropout may be a bad idea.\n\nmodel_snn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*32, activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=X_train.shape[1:]),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*16, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*8, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    Dense(1)])\n\nprint(model_snn.count_params())","metadata":{"execution":{"iopub.status.busy":"2022-09-06T00:45:30.311529Z","iopub.execute_input":"2022-09-06T00:45:30.312230Z","iopub.status.idle":"2022-09-06T00:45:30.385460Z","shell.execute_reply.started":"2022-09-06T00:45:30.312193Z","shell.execute_reply":"2022-09-06T00:45:30.384376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neurons_base = 4\ndropout_rate = 0.01\n\nmodel_snn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*8, activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=X_train.shape[1:]),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n    tf.keras.layers.AlphaDropout(dropout_rate),\n    Dense(1)])\n\nprint(model_snn.count_params())\n\n# similar problem as before: model seems ok in terms of flexibility and variance, but adding dropout breaks it before i can fix overfitting.\n# the solution is to either use smaller models or to use laternative regularizers (which do not increase variance.)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T19:49:53.032114Z","iopub.execute_input":"2022-09-06T19:49:53.032709Z","iopub.status.idle":"2022-09-06T19:49:53.094099Z","shell.execute_reply.started":"2022-09-06T19:49:53.032673Z","shell.execute_reply":"2022-09-06T19:49:53.093029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neurons_base = 32\nl2_reg_rate = 0.2\n\nmodel_snn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*8, activation=\"selu\", kernel_initializer=\"lecun_normal\", \n                          kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate), input_shape=X_train.shape[1:]),\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base/2, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(units=neurons_base/4, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    Dense(1)])\n\nprint(model_snn.count_params())","metadata":{"execution":{"iopub.status.busy":"2022-09-06T21:45:59.704254Z","iopub.execute_input":"2022-09-06T21:45:59.704619Z","iopub.status.idle":"2022-09-06T21:45:59.764128Z","shell.execute_reply.started":"2022-09-06T21:45:59.704587Z","shell.execute_reply":"2022-09-06T21:45:59.763058Z"},"trusted":true},"execution_count":240,"outputs":[{"name":"stdout","text":"65665\n","output_type":"stream"}]},{"cell_type":"code","source":"early_stopping50 = EarlyStopping(patience=50, restore_best_weights=True)\ntime1 = time.time()\noptimizer_adam = tf.keras.optimizers.Adam()\nmodel_snn.compile(loss= \"mean_squared_error\" , optimizer=optimizer_adam, metrics=[\"mean_squared_error\"])\nhistory = model_snn.fit(X_train, y_train, validation_data=(X_val, y_val), \n                         batch_size=2048, epochs=1000, verbose=2, callbacks=[early_stopping50])\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))\n\nprint([r2_score(y_train, model_snn.predict(X_train)), \n       r2_score(y_val, model_snn.predict(X_val)),\n       r2_score(y_test, model_snn.predict(X_test))])\nprint(time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T21:45:59.925828Z","iopub.execute_input":"2022-09-06T21:45:59.926753Z","iopub.status.idle":"2022-09-06T21:46:24.374960Z","shell.execute_reply.started":"2022-09-06T21:45:59.926718Z","shell.execute_reply":"2022-09-06T21:46:24.373446Z"},"trusted":true},"execution_count":241,"outputs":[{"name":"stdout","text":"Epoch 1/1000\n23/23 - 1s - loss: 186.2213 - mean_squared_error: 99.6393 - val_loss: 209.2541 - val_mean_squared_error: 137.8215\nEpoch 2/1000\n23/23 - 0s - loss: 159.5781 - mean_squared_error: 99.0751 - val_loss: 187.3236 - val_mean_squared_error: 137.6768\nEpoch 3/1000\n23/23 - 0s - loss: 141.1014 - mean_squared_error: 99.0143 - val_loss: 172.3707 - val_mean_squared_error: 137.7165\nEpoch 4/1000\n23/23 - 0s - loss: 128.5203 - mean_squared_error: 98.9902 - val_loss: 162.0690 - val_mean_squared_error: 137.5974\nEpoch 5/1000\n23/23 - 0s - loss: 120.0193 - mean_squared_error: 99.0399 - val_loss: 155.9344 - val_mean_squared_error: 138.4511\nEpoch 6/1000\n23/23 - 0s - loss: 114.1460 - mean_squared_error: 99.0362 - val_loss: 149.9845 - val_mean_squared_error: 137.2420\nEpoch 7/1000\n23/23 - 0s - loss: 110.0857 - mean_squared_error: 99.0374 - val_loss: 147.8445 - val_mean_squared_error: 138.4294\nEpoch 8/1000\n23/23 - 0s - loss: 107.2931 - mean_squared_error: 99.0517 - val_loss: 145.0645 - val_mean_squared_error: 138.0189\nEpoch 9/1000\n23/23 - 0s - loss: 105.3107 - mean_squared_error: 99.0977 - val_loss: 143.0648 - val_mean_squared_error: 137.7080\nEpoch 10/1000\n23/23 - 0s - loss: 103.8491 - mean_squared_error: 99.0921 - val_loss: 141.3761 - val_mean_squared_error: 137.2306\nEpoch 11/1000\n23/23 - 0s - loss: 102.7787 - mean_squared_error: 99.1133 - val_loss: 141.2760 - val_mean_squared_error: 138.0489\nEpoch 12/1000\n23/23 - 0s - loss: 101.9781 - mean_squared_error: 99.0469 - val_loss: 140.0409 - val_mean_squared_error: 137.4638\nEpoch 13/1000\n23/23 - 0s - loss: 101.5216 - mean_squared_error: 99.1709 - val_loss: 140.6677 - val_mean_squared_error: 138.5490\nEpoch 14/1000\n23/23 - 0s - loss: 101.0638 - mean_squared_error: 99.0837 - val_loss: 139.5025 - val_mean_squared_error: 137.6788\nEpoch 15/1000\n23/23 - 0s - loss: 100.7308 - mean_squared_error: 99.0097 - val_loss: 139.5717 - val_mean_squared_error: 137.9948\nEpoch 16/1000\n23/23 - 0s - loss: 100.5675 - mean_squared_error: 99.0823 - val_loss: 139.2183 - val_mean_squared_error: 137.8231\nEpoch 17/1000\n23/23 - 0s - loss: 100.4117 - mean_squared_error: 99.0437 - val_loss: 139.9044 - val_mean_squared_error: 138.6576\nEpoch 18/1000\n23/23 - 0s - loss: 100.2945 - mean_squared_error: 99.1102 - val_loss: 139.0217 - val_mean_squared_error: 137.8383\nEpoch 19/1000\n23/23 - 0s - loss: 100.1585 - mean_squared_error: 98.9996 - val_loss: 138.2222 - val_mean_squared_error: 137.1231\nEpoch 20/1000\n23/23 - 0s - loss: 100.2438 - mean_squared_error: 99.2137 - val_loss: 138.4001 - val_mean_squared_error: 137.3837\nEpoch 21/1000\n23/23 - 0s - loss: 100.0746 - mean_squared_error: 99.0872 - val_loss: 138.6402 - val_mean_squared_error: 137.6622\nEpoch 22/1000\n23/23 - 0s - loss: 99.9786 - mean_squared_error: 99.0039 - val_loss: 138.2821 - val_mean_squared_error: 137.3478\nEpoch 23/1000\n23/23 - 0s - loss: 99.9356 - mean_squared_error: 99.0198 - val_loss: 138.9604 - val_mean_squared_error: 138.0554\nEpoch 24/1000\n23/23 - 0s - loss: 99.8960 - mean_squared_error: 99.0140 - val_loss: 138.5823 - val_mean_squared_error: 137.7168\nEpoch 25/1000\n23/23 - 0s - loss: 99.9070 - mean_squared_error: 99.0354 - val_loss: 138.1450 - val_mean_squared_error: 137.3277\nEpoch 26/1000\n23/23 - 0s - loss: 99.8531 - mean_squared_error: 99.0233 - val_loss: 138.8399 - val_mean_squared_error: 137.9965\nEpoch 27/1000\n23/23 - 0s - loss: 99.8663 - mean_squared_error: 99.0435 - val_loss: 138.1071 - val_mean_squared_error: 137.3223\nEpoch 28/1000\n23/23 - 0s - loss: 99.7809 - mean_squared_error: 98.9658 - val_loss: 138.1046 - val_mean_squared_error: 137.2753\nEpoch 29/1000\n23/23 - 0s - loss: 99.7533 - mean_squared_error: 98.9665 - val_loss: 139.0384 - val_mean_squared_error: 138.2460\nEpoch 30/1000\n23/23 - 0s - loss: 99.7927 - mean_squared_error: 98.9984 - val_loss: 139.3776 - val_mean_squared_error: 138.6438\nEpoch 31/1000\n23/23 - 0s - loss: 99.8090 - mean_squared_error: 99.0387 - val_loss: 138.0205 - val_mean_squared_error: 137.2620\nEpoch 32/1000\n23/23 - 0s - loss: 99.6868 - mean_squared_error: 98.9381 - val_loss: 138.2428 - val_mean_squared_error: 137.4585\nEpoch 33/1000\n23/23 - 0s - loss: 99.7168 - mean_squared_error: 98.9369 - val_loss: 138.7369 - val_mean_squared_error: 138.0291\nEpoch 34/1000\n23/23 - 0s - loss: 99.7106 - mean_squared_error: 98.9745 - val_loss: 138.3783 - val_mean_squared_error: 137.5820\nEpoch 35/1000\n23/23 - 0s - loss: 99.7401 - mean_squared_error: 98.9890 - val_loss: 138.5209 - val_mean_squared_error: 137.8119\nEpoch 36/1000\n23/23 - 0s - loss: 99.7001 - mean_squared_error: 98.9599 - val_loss: 137.8897 - val_mean_squared_error: 137.1833\nEpoch 37/1000\n23/23 - 0s - loss: 99.7463 - mean_squared_error: 99.0336 - val_loss: 138.7629 - val_mean_squared_error: 138.0210\nEpoch 38/1000\n23/23 - 0s - loss: 99.6709 - mean_squared_error: 98.9411 - val_loss: 138.2689 - val_mean_squared_error: 137.5466\nEpoch 39/1000\n23/23 - 0s - loss: 99.7612 - mean_squared_error: 99.0187 - val_loss: 138.0481 - val_mean_squared_error: 137.3425\nEpoch 40/1000\n23/23 - 0s - loss: 99.6881 - mean_squared_error: 98.9648 - val_loss: 139.5925 - val_mean_squared_error: 138.8385\nEpoch 41/1000\n23/23 - 0s - loss: 99.6808 - mean_squared_error: 98.9506 - val_loss: 138.2521 - val_mean_squared_error: 137.5139\nEpoch 42/1000\n23/23 - 0s - loss: 99.6359 - mean_squared_error: 98.9117 - val_loss: 139.2767 - val_mean_squared_error: 138.5639\nEpoch 43/1000\n23/23 - 0s - loss: 99.5884 - mean_squared_error: 98.8691 - val_loss: 138.2593 - val_mean_squared_error: 137.5285\nEpoch 44/1000\n23/23 - 0s - loss: 99.6379 - mean_squared_error: 98.9014 - val_loss: 139.0924 - val_mean_squared_error: 138.3725\nEpoch 45/1000\n23/23 - 0s - loss: 99.6535 - mean_squared_error: 98.9416 - val_loss: 137.9221 - val_mean_squared_error: 137.2021\nEpoch 46/1000\n23/23 - 0s - loss: 99.7113 - mean_squared_error: 98.9916 - val_loss: 138.2564 - val_mean_squared_error: 137.5368\nEpoch 47/1000\n23/23 - 0s - loss: 99.6704 - mean_squared_error: 98.9496 - val_loss: 138.6301 - val_mean_squared_error: 137.9324\nEpoch 48/1000\n23/23 - 0s - loss: 99.6927 - mean_squared_error: 98.9940 - val_loss: 138.9494 - val_mean_squared_error: 138.2248\nEpoch 49/1000\n23/23 - 0s - loss: 99.5494 - mean_squared_error: 98.8182 - val_loss: 138.9882 - val_mean_squared_error: 138.2661\nEpoch 50/1000\n23/23 - 0s - loss: 99.5436 - mean_squared_error: 98.8202 - val_loss: 137.5838 - val_mean_squared_error: 136.8611\nEpoch 51/1000\n23/23 - 0s - loss: 99.6194 - mean_squared_error: 98.8887 - val_loss: 138.1699 - val_mean_squared_error: 137.4325\nEpoch 52/1000\n23/23 - 0s - loss: 99.6854 - mean_squared_error: 98.9763 - val_loss: 137.8480 - val_mean_squared_error: 137.1404\nEpoch 53/1000\n23/23 - 0s - loss: 99.5262 - mean_squared_error: 98.8031 - val_loss: 139.6008 - val_mean_squared_error: 138.8889\nEpoch 54/1000\n23/23 - 0s - loss: 99.5460 - mean_squared_error: 98.8196 - val_loss: 138.3684 - val_mean_squared_error: 137.6411\nEpoch 55/1000\n23/23 - 0s - loss: 99.6372 - mean_squared_error: 98.9131 - val_loss: 138.3968 - val_mean_squared_error: 137.6803\nEpoch 56/1000\n23/23 - 0s - loss: 99.6389 - mean_squared_error: 98.9409 - val_loss: 138.2852 - val_mean_squared_error: 137.5665\nEpoch 57/1000\n23/23 - 0s - loss: 99.6818 - mean_squared_error: 98.9543 - val_loss: 137.8915 - val_mean_squared_error: 137.1810\nEpoch 58/1000\n23/23 - 0s - loss: 99.5973 - mean_squared_error: 98.8788 - val_loss: 138.0735 - val_mean_squared_error: 137.3497\nEpoch 59/1000\n23/23 - 0s - loss: 99.6802 - mean_squared_error: 98.9497 - val_loss: 138.4921 - val_mean_squared_error: 137.8294\nEpoch 60/1000\n23/23 - 0s - loss: 99.5915 - mean_squared_error: 98.8886 - val_loss: 138.6673 - val_mean_squared_error: 137.9523\nEpoch 61/1000\n23/23 - 0s - loss: 99.5797 - mean_squared_error: 98.8976 - val_loss: 138.0580 - val_mean_squared_error: 137.3412\nEpoch 62/1000\n23/23 - 0s - loss: 99.5184 - mean_squared_error: 98.8102 - val_loss: 139.0607 - val_mean_squared_error: 138.3433\nEpoch 63/1000\n23/23 - 0s - loss: 99.4580 - mean_squared_error: 98.7268 - val_loss: 139.0888 - val_mean_squared_error: 138.3763\nEpoch 64/1000\n23/23 - 0s - loss: 99.4874 - mean_squared_error: 98.7674 - val_loss: 139.0536 - val_mean_squared_error: 138.2984\nEpoch 65/1000\n23/23 - 0s - loss: 99.6033 - mean_squared_error: 98.8935 - val_loss: 138.3044 - val_mean_squared_error: 137.5981\nEpoch 66/1000\n23/23 - 0s - loss: 99.4313 - mean_squared_error: 98.7043 - val_loss: 138.9576 - val_mean_squared_error: 138.2155\nEpoch 67/1000\n23/23 - 0s - loss: 99.5562 - mean_squared_error: 98.8188 - val_loss: 138.2277 - val_mean_squared_error: 137.4922\nEpoch 68/1000\n23/23 - 0s - loss: 99.5271 - mean_squared_error: 98.7904 - val_loss: 138.7587 - val_mean_squared_error: 138.0532\nEpoch 69/1000\n23/23 - 0s - loss: 99.6102 - mean_squared_error: 98.8778 - val_loss: 138.8181 - val_mean_squared_error: 138.0976\nEpoch 70/1000\n23/23 - 0s - loss: 99.4736 - mean_squared_error: 98.7423 - val_loss: 138.5986 - val_mean_squared_error: 137.8668\nEpoch 71/1000\n23/23 - 0s - loss: 99.4040 - mean_squared_error: 98.6765 - val_loss: 138.9026 - val_mean_squared_error: 138.1596\nEpoch 72/1000\n23/23 - 0s - loss: 99.5109 - mean_squared_error: 98.7701 - val_loss: 137.4303 - val_mean_squared_error: 136.6942\nEpoch 73/1000\n23/23 - 0s - loss: 99.5279 - mean_squared_error: 98.7976 - val_loss: 138.8814 - val_mean_squared_error: 138.1493\nEpoch 74/1000\n23/23 - 0s - loss: 99.5035 - mean_squared_error: 98.7703 - val_loss: 140.0146 - val_mean_squared_error: 139.2755\nEpoch 75/1000\n23/23 - 0s - loss: 99.5577 - mean_squared_error: 98.8132 - val_loss: 138.1797 - val_mean_squared_error: 137.4093\nEpoch 76/1000\n23/23 - 0s - loss: 99.5201 - mean_squared_error: 98.7734 - val_loss: 139.5036 - val_mean_squared_error: 138.7828\nEpoch 77/1000\n23/23 - 0s - loss: 99.3982 - mean_squared_error: 98.6415 - val_loss: 138.5819 - val_mean_squared_error: 137.8204\nEpoch 78/1000\n23/23 - 0s - loss: 99.4274 - mean_squared_error: 98.6747 - val_loss: 139.2906 - val_mean_squared_error: 138.5514\nEpoch 79/1000\n23/23 - 0s - loss: 99.4294 - mean_squared_error: 98.6999 - val_loss: 138.4373 - val_mean_squared_error: 137.6702\nEpoch 80/1000\n23/23 - 0s - loss: 99.3905 - mean_squared_error: 98.6205 - val_loss: 139.4462 - val_mean_squared_error: 138.7103\nEpoch 81/1000\n23/23 - 0s - loss: 99.5222 - mean_squared_error: 98.7805 - val_loss: 139.6361 - val_mean_squared_error: 138.8903\nEpoch 82/1000\n23/23 - 0s - loss: 99.4594 - mean_squared_error: 98.7051 - val_loss: 137.7138 - val_mean_squared_error: 136.9498\nEpoch 83/1000\n23/23 - 0s - loss: 99.4715 - mean_squared_error: 98.7218 - val_loss: 138.1427 - val_mean_squared_error: 137.4025\nEpoch 84/1000\n23/23 - 0s - loss: 99.3737 - mean_squared_error: 98.6214 - val_loss: 138.5809 - val_mean_squared_error: 137.8071\nEpoch 85/1000\n23/23 - 0s - loss: 99.3277 - mean_squared_error: 98.5600 - val_loss: 138.3878 - val_mean_squared_error: 137.6226\nEpoch 86/1000\n23/23 - 0s - loss: 99.5034 - mean_squared_error: 98.7374 - val_loss: 138.3520 - val_mean_squared_error: 137.5940\nEpoch 87/1000\n23/23 - 0s - loss: 99.3972 - mean_squared_error: 98.6173 - val_loss: 138.8989 - val_mean_squared_error: 138.1126\nEpoch 88/1000\n23/23 - 0s - loss: 99.3943 - mean_squared_error: 98.6157 - val_loss: 138.1848 - val_mean_squared_error: 137.4272\nEpoch 89/1000\n23/23 - 0s - loss: 99.3317 - mean_squared_error: 98.5471 - val_loss: 138.8087 - val_mean_squared_error: 138.0213\nEpoch 90/1000\n23/23 - 0s - loss: 99.3273 - mean_squared_error: 98.5361 - val_loss: 139.1135 - val_mean_squared_error: 138.3289\nEpoch 91/1000\n23/23 - 0s - loss: 99.3641 - mean_squared_error: 98.5831 - val_loss: 139.0094 - val_mean_squared_error: 138.2202\nEpoch 92/1000\n23/23 - 0s - loss: 99.5902 - mean_squared_error: 98.8362 - val_loss: 137.9848 - val_mean_squared_error: 137.2308\nEpoch 93/1000\n23/23 - 0s - loss: 99.3583 - mean_squared_error: 98.5654 - val_loss: 139.2915 - val_mean_squared_error: 138.5054\nEpoch 94/1000\n23/23 - 0s - loss: 99.3163 - mean_squared_error: 98.5324 - val_loss: 139.2731 - val_mean_squared_error: 138.4681\nEpoch 95/1000\n23/23 - 0s - loss: 99.3469 - mean_squared_error: 98.5488 - val_loss: 138.1630 - val_mean_squared_error: 137.3721\nEpoch 96/1000\n23/23 - 0s - loss: 99.3528 - mean_squared_error: 98.5715 - val_loss: 138.9612 - val_mean_squared_error: 138.1724\nEpoch 97/1000\n23/23 - 0s - loss: 99.3184 - mean_squared_error: 98.5128 - val_loss: 138.2240 - val_mean_squared_error: 137.4216\nEpoch 98/1000\n23/23 - 0s - loss: 99.3323 - mean_squared_error: 98.5272 - val_loss: 138.1590 - val_mean_squared_error: 137.3556\nEpoch 99/1000\n23/23 - 0s - loss: 99.2631 - mean_squared_error: 98.4567 - val_loss: 138.3761 - val_mean_squared_error: 137.5739\nEpoch 100/1000\n23/23 - 0s - loss: 99.3194 - mean_squared_error: 98.5153 - val_loss: 139.9130 - val_mean_squared_error: 139.1032\nEpoch 101/1000\n23/23 - 0s - loss: 99.3229 - mean_squared_error: 98.5144 - val_loss: 138.3327 - val_mean_squared_error: 137.5222\nEpoch 102/1000\n23/23 - 0s - loss: 99.2939 - mean_squared_error: 98.4730 - val_loss: 138.3270 - val_mean_squared_error: 137.5057\nEpoch 103/1000\n23/23 - 0s - loss: 99.4292 - mean_squared_error: 98.6016 - val_loss: 137.8830 - val_mean_squared_error: 137.0606\nEpoch 104/1000\n23/23 - 0s - loss: 99.4020 - mean_squared_error: 98.5874 - val_loss: 137.8686 - val_mean_squared_error: 137.0691\nEpoch 105/1000\n23/23 - 0s - loss: 99.2759 - mean_squared_error: 98.4679 - val_loss: 139.2148 - val_mean_squared_error: 138.3892\nEpoch 106/1000\n23/23 - 0s - loss: 99.4671 - mean_squared_error: 98.6624 - val_loss: 139.3213 - val_mean_squared_error: 138.5505\nEpoch 107/1000\n23/23 - 0s - loss: 99.3454 - mean_squared_error: 98.5509 - val_loss: 138.3899 - val_mean_squared_error: 137.5741\nEpoch 108/1000\n23/23 - 0s - loss: 99.1845 - mean_squared_error: 98.3601 - val_loss: 139.3000 - val_mean_squared_error: 138.4698\nEpoch 109/1000\n23/23 - 0s - loss: 99.3614 - mean_squared_error: 98.5409 - val_loss: 137.7341 - val_mean_squared_error: 136.9242\nEpoch 110/1000\n23/23 - 0s - loss: 99.2672 - mean_squared_error: 98.4560 - val_loss: 138.2747 - val_mean_squared_error: 137.4628\nEpoch 111/1000\n23/23 - 0s - loss: 99.3415 - mean_squared_error: 98.5149 - val_loss: 139.4454 - val_mean_squared_error: 138.6279\nEpoch 112/1000\n23/23 - 0s - loss: 99.2754 - mean_squared_error: 98.4530 - val_loss: 138.1901 - val_mean_squared_error: 137.3666\nEpoch 113/1000\n23/23 - 0s - loss: 99.2034 - mean_squared_error: 98.3779 - val_loss: 139.2287 - val_mean_squared_error: 138.4079\nEpoch 114/1000\n23/23 - 0s - loss: 99.1880 - mean_squared_error: 98.3536 - val_loss: 139.2750 - val_mean_squared_error: 138.4459\nEpoch 115/1000\n23/23 - 0s - loss: 99.2915 - mean_squared_error: 98.4660 - val_loss: 138.1208 - val_mean_squared_error: 137.3005\nEpoch 116/1000\n23/23 - 0s - loss: 99.2046 - mean_squared_error: 98.3694 - val_loss: 138.6068 - val_mean_squared_error: 137.7531\nEpoch 117/1000\n23/23 - 0s - loss: 99.3228 - mean_squared_error: 98.4874 - val_loss: 138.2869 - val_mean_squared_error: 137.4611\nEpoch 118/1000\n23/23 - 0s - loss: 99.3441 - mean_squared_error: 98.4873 - val_loss: 138.5104 - val_mean_squared_error: 137.6631\nEpoch 119/1000\n23/23 - 0s - loss: 99.2036 - mean_squared_error: 98.3511 - val_loss: 137.6735 - val_mean_squared_error: 136.8184\nEpoch 120/1000\n23/23 - 0s - loss: 99.1726 - mean_squared_error: 98.3092 - val_loss: 140.1790 - val_mean_squared_error: 139.3147\nEpoch 121/1000\n23/23 - 0s - loss: 99.2085 - mean_squared_error: 98.3453 - val_loss: 141.1736 - val_mean_squared_error: 140.3248\nEpoch 122/1000\n23/23 - 0s - loss: 99.2165 - mean_squared_error: 98.3791 - val_loss: 138.2408 - val_mean_squared_error: 137.3759\nMinimum Validation Loss: 137.4303\n[0.014376829435559513, 0.021009261736364304, 0.0068991278743961715]\n24.311588287353516\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"X_train.skew()","metadata":{"execution":{"iopub.status.busy":"2022-09-06T01:58:14.615470Z","iopub.execute_input":"2022-09-06T01:58:14.616043Z","iopub.status.idle":"2022-09-06T01:58:14.787794Z","shell.execute_reply.started":"2022-09-06T01:58:14.615998Z","shell.execute_reply":"2022-09-06T01:58:14.786906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val","metadata":{"execution":{"iopub.status.busy":"2022-09-06T00:36:53.150674Z","iopub.status.idle":"2022-09-06T00:36:53.151429Z","shell.execute_reply.started":"2022-09-06T00:36:53.151166Z","shell.execute_reply":"2022-09-06T00:36:53.151191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on nns:\n# - try classic regularizers (l1, l2 etc)\n# - try different architecture (not snnn)\n# classic architecture:\n# He initialization, elu activation, batch norm, l2 reg, adam.\n\n# - try exotic architecture, e.g., wide'n'deep\n# \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classic architecture:\n\nneurons_base = 32\nl2_reg_rate = 0.5\nhe_init = tf.keras.initializers.HeNormal()\n\nmodel_nn = Sequential([\n    tf.keras.layers.Dense(units=neurons_base*8, activation=\"elu\", kernel_initializer=he_init, \n                          kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate), input_shape=X_train.shape[1:]),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(units=neurons_base*4, activation=\"elu\", kernel_initializer=he_init,\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.BatchNormalization(),    \n    tf.keras.layers.Dense(units=neurons_base*2, activation=\"elu\", kernel_initializer=he_init,\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.BatchNormalization(),    \n    tf.keras.layers.Dense(units=neurons_base, activation=\"elu\", kernel_initializer=he_init,\n                         kernel_regularizer=tf.keras.regularizers.l2(l=l2_reg_rate)),\n    tf.keras.layers.Dense(1)])\n\nprint(model_nn.count_params())\n","metadata":{"execution":{"iopub.status.busy":"2022-09-06T20:35:05.415443Z","iopub.execute_input":"2022-09-06T20:35:05.415892Z","iopub.status.idle":"2022-09-06T20:35:05.530840Z","shell.execute_reply.started":"2022-09-06T20:35:05.415854Z","shell.execute_reply":"2022-09-06T20:35:05.529848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping50 = EarlyStopping(patience=50, restore_best_weights=True)\ntime1 = time.time()\noptimizer_adam = tf.keras.optimizers.Adam()\nmodel_nn.compile(loss= \"mean_squared_error\" , optimizer=optimizer_adam, metrics=[\"mean_squared_error\"])\nhistory = model_nn.fit(X_train, y_train, validation_data=(X_val, y_val), \n                         batch_size=2048, epochs=1000, verbose=2, callbacks=[early_stopping50])\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))\n\nprint([r2_score(y_train, model_nn.predict(X_train)), \n       r2_score(y_val, model_nn.predict(X_val)),\n       r2_score(y_test, model_nn.predict(X_test))])\nprint(time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T20:35:05.606202Z","iopub.execute_input":"2022-09-06T20:35:05.606530Z","iopub.status.idle":"2022-09-06T20:35:50.233161Z","shell.execute_reply.started":"2022-09-06T20:35:05.606503Z","shell.execute_reply":"2022-09-06T20:35:50.232273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
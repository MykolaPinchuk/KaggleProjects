{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This is a new version of MLEAP scripts, started in late Aug 2022.\nIt will combine IProject_MLEAP_ANN and IP_MLEAP script, while improving them.","metadata":{}},{"cell_type":"markdown","source":"#### Outline\n\n1. Load libraries and data.\n2. pEDA. Look at feature distribution, fix them if they do not look right.\n3. Train-test split. Most likely couple years into test set. 2015-2018?. Impute missing values.\n4. Transform numerical features, add ohe for inds.\n5. Fit classic models: ols as a baseline, then xgb.\n6. Fir DL.\n\n\nNotes:\nideally, I want to use time-based cross-validation.\nsince I have panel data, it is not a trivial task.\nneed to find some solution online.\ne.g., https://towardsdatascience.com/time-based-cross-validation-d259b13d42b8.\n\nfor now, will try to do siple for loop.\n","metadata":{}},{"cell_type":"code","source":"# 0. Import libraries #\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, time, math, re, warnings, random, gc, dill, optuna, pickle\nimport statsmodels.api as sm\nfrom random import sample\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNetCV\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn.inspection import permutation_importance\nfrom category_encoders import MEstimateEncoder\nfrom xgboost import XGBRegressor\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nplt.style.use('seaborn-white')\nwarnings.simplefilter(action='ignore')\npd.set_option('display.max_columns', 110)\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T20:26:23.304403Z","iopub.execute_input":"2022-08-25T20:26:23.304988Z","iopub.status.idle":"2022-08-25T20:26:23.314844Z","shell.execute_reply.started":"2022-08-25T20:26:23.304954Z","shell.execute_reply":"2022-08-25T20:26:23.313708Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"### target encoding ###\n# source: https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices/notebook\n\nclass CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=4)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded","metadata":{"execution":{"iopub.status.busy":"2022-08-25T20:26:23.346892Z","iopub.execute_input":"2022-08-25T20:26:23.347515Z","iopub.status.idle":"2022-08-25T20:26:23.358026Z","shell.execute_reply.started":"2022-08-25T20:26:23.347489Z","shell.execute_reply":"2022-08-25T20:26:23.357018Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T20:26:23.385016Z","iopub.execute_input":"2022-08-25T20:26:23.386522Z","iopub.status.idle":"2022-08-25T20:26:23.393819Z","shell.execute_reply.started":"2022-08-25T20:26:23.386485Z","shell.execute_reply":"2022-08-25T20:26:23.392369Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"REPLICAS:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"# for loop to see appx performance over the whole sample with some rolling window\n\ntime0 = time.time()\n\nmin_prd_list = range(100, 676, 25)\nwindows_width = 3*12\ncv_regularizer=0.04\noptuna_trials = 20\n\nresults = pd.DataFrame(columns = ['min_prd', 'xgbf', 'xgbgs', 'xgbo'])\nresults.min_prd = min_prd_list\n\nfor min_prd in min_prd_list:\n    \n    \n    with open('../input/kaggle-46pkl/IMLEAP_v4.pkl', 'rb') as pickled_one:\n        df = pickle.load(pickled_one)\n    df = df[df.prd.isin(range(min_prd-1, min_prd+windows_width+2))]\n    df_cnt = df.count()\n    empty_cols = list(df_cnt[df_cnt<int(df.shape[0]/2)].index)\n    df.drop(columns=empty_cols, inplace=True)\n    display(df.shape, df.head(), df.year.describe(), df.count())\n    \n    df = df[(df.RET>-50)&(df.RET<75)]\n    meanret = df.groupby('prd').RET.mean().to_frame().reset_index().rename(columns={'RET':'mRET'})\n    df = pd.merge(df, meanret, on='prd', how='left')\n    df.RET = df.RET-df.mRET\n    df.drop(columns='mRET', inplace=True)\n\n    features_miss_dummies = ['amhd', 'BAspr']\n    for col in features_miss_dummies:\n        if col in df.columns:\n            df[col+'_miss'] = df[col].isnull().astype(int)\n\n    temp_cols = ['PERMNO', 'prd', 'year']\n    train = df[df.prd<(min_prd+windows_width)]\n    test = df[df.prd==(min_prd+windows_width)]\n    train.drop(columns=temp_cols, inplace=True)\n    test.drop(columns=temp_cols, inplace=True)\n\n    col_ignore = ['RET']\n    col_cat = ['ind']\n    col_num = [x for x in train.columns if x not in col_ignore+col_cat]\n    for col in col_num:\n        train[col] = train[col].fillna(train[col].median())\n        test[col] = test[col].fillna(train[col].median())\n    for col in col_cat:\n        train[col] = train[col].fillna(value=-1000)\n        test[col] = test[col].fillna(value=-1000)\n\n    X_train = train.copy()\n    y_train = X_train.pop('RET')\n    X_test = test.copy()\n    y_test = X_test.pop('RET')\n\n    feature_transformer = ColumnTransformer([('num', StandardScaler(), col_num),\n                                            (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\", drop='if_binary'), col_cat)], \n                                            remainder=\"passthrough\")\n\n    print('Number of features before transformation: ', X_train.shape)\n    X_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\n    X_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\n    print('time to do feature proprocessing: ')\n    print('Number of features after transformation: ', X_train.shape)\n\n    print('mae of a constant model', mean_absolute_error(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\n    print('R2 of a constant model', r2_score(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\n\n    xgb1 = XGBRegressor(tree_method = 'gpu_hist', n_estimators=300, max_depth=5, eta=0.03, colsample_bytree=0.6)\n    xgb1.fit(X_train, y_train)\n    print('XGB train:', mean_absolute_error(y_train, xgb1.predict(X_train)), r2_score(y_train, xgb1.predict(X_train)))\n\n    time1 = time.time()\n    xgb = XGBRegressor(tree_method = 'gpu_hist')\n    param_grid = {'n_estimators':[400, 700], 'max_depth':[2,3,4], 'eta':[0.006, 0.012, 0.02], 'subsample':[0.6], 'colsample_bytree':[0.6]}\n    xgbm = GridSearchCV(xgb, param_grid, cv=2, verbose=2, scoring='r2')\n    xgbm.fit(X_train, y_train)\n    print('XGB', xgbm.best_params_, xgbm.best_score_, time.time()-time1)\n    print('XGB train:', mean_absolute_error(y_train, xgbm.predict(X_train)), r2_score(y_train, xgbm.predict(X_train)), time.time()-time1)\n\n    time1 = time.time()\n    def objective(trial, cv_runs=1, n_splits=2, n_jobs=-1):\n\n        params = {\n        \"tree_method\": 'gpu_hist',\n        \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 1000),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 5),\n        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.001, 0.05),\n        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.1, 0.95),\n        \"subsample\": trial.suggest_uniform(\"subsample\", 0.3, 0.95),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 0.1, 30.0),\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 0.1, 200.0),\n        \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-10, 10.0),\n        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 0.1, 50)    }\n\n        temp_out = []\n\n        for i in range(cv_runs):\n\n            X = X_train\n            y = y_train\n            model = XGBRegressor(**params, njobs=-1)\n            rkf = KFold(n_splits=n_splits, shuffle=True)\n            X_values = X.values\n            y_values = y.values\n            y_pred = np.zeros_like(y_values)\n            y_pred_train = np.zeros_like(y_values)\n            for train_index, test_index in rkf.split(X_values):\n                X_A, X_B = X_values[train_index, :], X_values[test_index, :]\n                y_A, y_B = y_values[train_index], y_values[test_index]\n                model.fit(X_A, y_A, eval_set=[(X_B, y_B)], verbose = False)\n                y_pred[test_index] = model.predict(X_B)\n                y_pred_train[train_index] = model.predict(X_A)\n\n            score_train = r2_score(y_train, y_pred_train)\n            score_test = r2_score(y_train, y_pred) \n            overfit = (score_train-score_test)\n            temp_out.append(score_test-cv_regularizer*overfit)\n\n        return (np.mean(temp_out))\n\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=optuna_trials)\n    print('Total time for hypermarameter optimization ', time.time()-time1)\n    hp = study.best_params\n    for key, value in hp.items():\n        print(f\"{key:>20s} : {value}\")\n    print(f\"{'best objective value':>20s} : {study.best_value}\")\n    optuna_hyperpars = study.best_params\n    optuna_hyperpars['tree_method']='gpu_hist'\n    optuna_xgb = XGBRegressor(**optuna_hyperpars)\n    optuna_xgb.fit(X_train, y_train)\n    print('Optuna XGB train:', \n          mean_absolute_error(y_train, optuna_xgb.predict(X_train)), r2_score(y_train, optuna_xgb.predict(X_train)), time.time()-time1)\n\n    # Evaluate performance of XGB models:\n    r2_xgb1 = r2_score(y_test, xgb1.predict(X_test))\n    r2_xgbgs = r2_score(y_test, xgbm.predict(X_test))\n    r2_xgbo = r2_score(y_test, optuna_xgb.predict(X_test))\n\n    print('Min_prd: ', min_prd)\n    print('Constant guess: ', mean_absolute_error(y_test, np.ones(len(y_test))*y_test.mean()), \n          r2_score(y_test, np.ones(len(y_test))*y_test.mean()))\n    print('XGB test:', mean_absolute_error(y_test, xgb1.predict(X_test)), r2_xgb1)\n    print('XGB GS test:', mean_absolute_error(y_test, xgbm.predict(X_test)), r2_xgbgs)\n    print('Optuna XGB test:', mean_absolute_error(y_test, optuna_xgb.predict(X_test)), r2_xgbo)\n\n    results.loc[results.min_prd==min_prd,'xgbf':'xgbo'] = r2_xgb1, r2_xgbgs, r2_xgbo\n    \nprint(time.time()-time0, results)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T20:26:23.428209Z","iopub.execute_input":"2022-08-25T20:26:23.429515Z","iopub.status.idle":"2022-08-25T21:27:23.666446Z","shell.execute_reply.started":"2022-08-25T20:26:23.429479Z","shell.execute_reply":"2022-08-25T21:27:23.665643Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"(31363, 40)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    PERMNO  prd     mom242  year      RET   ind        bm        op        gp  \\\n24   10006   99  30.007610  1966  -1.8425  25.0 -0.483038  0.179707  0.260061   \n25   10006  100  22.973353  1966 -13.9454  25.0 -0.483038  0.179707  0.260061   \n26   10006  101   0.562306  1966  -4.8379  25.0 -0.483038  0.179707  0.260061   \n27   10006  102  -6.780997  1966  -2.9268  25.0 -0.483038  0.179707  0.260061   \n28   10006  103  -8.513334  1966   0.9968  25.0 -0.483038  0.179707  0.260061   \n\n         inv    mom11     mom122      amhd  ivol_capm  ivol_ff5   beta_bw  \\\n24  0.077403   5.4095  23.511075  1.475168   1.402148  1.282759  1.336867   \n25  0.077403  -1.8425  29.337614  1.478980   0.790153  0.754158  1.239788   \n26  0.077403 -13.9454  20.186279  1.582242   1.380279  1.368466  1.238541   \n27  0.077403  -4.8379   5.036237  1.641163   1.941973  1.031749  1.220998   \n28  0.077403  -2.9268  -9.564465  1.713909   2.434331  1.877713  1.166406   \n\n       MAX     vol1m     vol6m    vol12m      size       lbm       lop  \\\n24  3.3976  1.506242  1.833065  1.648786  5.695347 -0.417907  0.135547   \n25  1.4671  0.877792  1.758302  1.629121  5.680309 -0.417907  0.135547   \n26  2.1292  2.117274  1.705033  1.723923  5.521941 -0.417907  0.135547   \n27  5.3222  2.173122  1.674638  1.793334  5.476547 -0.417907  0.135547   \n28  7.8011  2.697039  1.892122  1.886296  5.451468 -0.417907  0.135547   \n\n         lgp      linv      llme    l1amhd   l1MAX    l3amhd   l3MAX  \\\n24  0.222194  0.067345  5.434935  1.516443  2.6538  1.479387  4.2841   \n25  0.222194  0.067345  5.444597  1.475168  3.3976  1.498098  3.1745   \n26  0.222194  0.067345  5.491554  1.478980  1.4671  1.516443  2.6538   \n27  0.222194  0.067345  5.479246  1.582242  2.1292  1.475168  3.3976   \n28  0.222194  0.067345  5.582127  1.641163  5.3222  1.478980  1.4671   \n\n      l6amhd   l6MAX   l12amhd  l12MAX  l12mom122  l12ivol_capm  l12ivol_ff5  \\\n24  1.436185  4.0548  1.669988  2.6538  18.881331      0.765013     0.702024   \n25  1.411486  4.5856  1.606326  3.3976  -0.948286      0.890444     0.810150   \n26  1.439482  3.1527  1.516363  1.4671  -1.278890      0.985169     0.908360   \n27  1.479387  4.2841  1.522883  2.1292  -2.716252      1.199252     1.070752   \n28  1.498098  3.1745  1.485769  5.3222  -6.697673      1.477127     1.395748   \n\n    l12beta_bw  l12vol6m  l12vol12m  \n24    1.195248  1.193920   1.231535  \n25    1.250279  1.236353   1.235768  \n26    1.250547  1.195605   1.222002  \n27    1.265243  1.204190   1.233468  \n28    1.287226  1.312899   1.275484  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>10006</td>\n      <td>99</td>\n      <td>30.007610</td>\n      <td>1966</td>\n      <td>-1.8425</td>\n      <td>25.0</td>\n      <td>-0.483038</td>\n      <td>0.179707</td>\n      <td>0.260061</td>\n      <td>0.077403</td>\n      <td>5.4095</td>\n      <td>23.511075</td>\n      <td>1.475168</td>\n      <td>1.402148</td>\n      <td>1.282759</td>\n      <td>1.336867</td>\n      <td>3.3976</td>\n      <td>1.506242</td>\n      <td>1.833065</td>\n      <td>1.648786</td>\n      <td>5.695347</td>\n      <td>-0.417907</td>\n      <td>0.135547</td>\n      <td>0.222194</td>\n      <td>0.067345</td>\n      <td>5.434935</td>\n      <td>1.516443</td>\n      <td>2.6538</td>\n      <td>1.479387</td>\n      <td>4.2841</td>\n      <td>1.436185</td>\n      <td>4.0548</td>\n      <td>1.669988</td>\n      <td>2.6538</td>\n      <td>18.881331</td>\n      <td>0.765013</td>\n      <td>0.702024</td>\n      <td>1.195248</td>\n      <td>1.193920</td>\n      <td>1.231535</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>10006</td>\n      <td>100</td>\n      <td>22.973353</td>\n      <td>1966</td>\n      <td>-13.9454</td>\n      <td>25.0</td>\n      <td>-0.483038</td>\n      <td>0.179707</td>\n      <td>0.260061</td>\n      <td>0.077403</td>\n      <td>-1.8425</td>\n      <td>29.337614</td>\n      <td>1.478980</td>\n      <td>0.790153</td>\n      <td>0.754158</td>\n      <td>1.239788</td>\n      <td>1.4671</td>\n      <td>0.877792</td>\n      <td>1.758302</td>\n      <td>1.629121</td>\n      <td>5.680309</td>\n      <td>-0.417907</td>\n      <td>0.135547</td>\n      <td>0.222194</td>\n      <td>0.067345</td>\n      <td>5.444597</td>\n      <td>1.475168</td>\n      <td>3.3976</td>\n      <td>1.498098</td>\n      <td>3.1745</td>\n      <td>1.411486</td>\n      <td>4.5856</td>\n      <td>1.606326</td>\n      <td>3.3976</td>\n      <td>-0.948286</td>\n      <td>0.890444</td>\n      <td>0.810150</td>\n      <td>1.250279</td>\n      <td>1.236353</td>\n      <td>1.235768</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>10006</td>\n      <td>101</td>\n      <td>0.562306</td>\n      <td>1966</td>\n      <td>-4.8379</td>\n      <td>25.0</td>\n      <td>-0.483038</td>\n      <td>0.179707</td>\n      <td>0.260061</td>\n      <td>0.077403</td>\n      <td>-13.9454</td>\n      <td>20.186279</td>\n      <td>1.582242</td>\n      <td>1.380279</td>\n      <td>1.368466</td>\n      <td>1.238541</td>\n      <td>2.1292</td>\n      <td>2.117274</td>\n      <td>1.705033</td>\n      <td>1.723923</td>\n      <td>5.521941</td>\n      <td>-0.417907</td>\n      <td>0.135547</td>\n      <td>0.222194</td>\n      <td>0.067345</td>\n      <td>5.491554</td>\n      <td>1.478980</td>\n      <td>1.4671</td>\n      <td>1.516443</td>\n      <td>2.6538</td>\n      <td>1.439482</td>\n      <td>3.1527</td>\n      <td>1.516363</td>\n      <td>1.4671</td>\n      <td>-1.278890</td>\n      <td>0.985169</td>\n      <td>0.908360</td>\n      <td>1.250547</td>\n      <td>1.195605</td>\n      <td>1.222002</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>10006</td>\n      <td>102</td>\n      <td>-6.780997</td>\n      <td>1966</td>\n      <td>-2.9268</td>\n      <td>25.0</td>\n      <td>-0.483038</td>\n      <td>0.179707</td>\n      <td>0.260061</td>\n      <td>0.077403</td>\n      <td>-4.8379</td>\n      <td>5.036237</td>\n      <td>1.641163</td>\n      <td>1.941973</td>\n      <td>1.031749</td>\n      <td>1.220998</td>\n      <td>5.3222</td>\n      <td>2.173122</td>\n      <td>1.674638</td>\n      <td>1.793334</td>\n      <td>5.476547</td>\n      <td>-0.417907</td>\n      <td>0.135547</td>\n      <td>0.222194</td>\n      <td>0.067345</td>\n      <td>5.479246</td>\n      <td>1.582242</td>\n      <td>2.1292</td>\n      <td>1.475168</td>\n      <td>3.3976</td>\n      <td>1.479387</td>\n      <td>4.2841</td>\n      <td>1.522883</td>\n      <td>2.1292</td>\n      <td>-2.716252</td>\n      <td>1.199252</td>\n      <td>1.070752</td>\n      <td>1.265243</td>\n      <td>1.204190</td>\n      <td>1.233468</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>10006</td>\n      <td>103</td>\n      <td>-8.513334</td>\n      <td>1966</td>\n      <td>0.9968</td>\n      <td>25.0</td>\n      <td>-0.483038</td>\n      <td>0.179707</td>\n      <td>0.260061</td>\n      <td>0.077403</td>\n      <td>-2.9268</td>\n      <td>-9.564465</td>\n      <td>1.713909</td>\n      <td>2.434331</td>\n      <td>1.877713</td>\n      <td>1.166406</td>\n      <td>7.8011</td>\n      <td>2.697039</td>\n      <td>1.892122</td>\n      <td>1.886296</td>\n      <td>5.451468</td>\n      <td>-0.417907</td>\n      <td>0.135547</td>\n      <td>0.222194</td>\n      <td>0.067345</td>\n      <td>5.582127</td>\n      <td>1.641163</td>\n      <td>5.3222</td>\n      <td>1.478980</td>\n      <td>1.4671</td>\n      <td>1.498098</td>\n      <td>3.1745</td>\n      <td>1.485769</td>\n      <td>5.3222</td>\n      <td>-6.697673</td>\n      <td>1.477127</td>\n      <td>1.395748</td>\n      <td>1.287226</td>\n      <td>1.312899</td>\n      <td>1.275484</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    31363.000000\nmean      1967.710965\nstd          1.003547\nmin       1966.000000\n25%       1967.000000\n50%       1968.000000\n75%       1969.000000\nmax       1969.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          31363\nprd             31363\nmom242          31136\nyear            31363\nRET             31363\nind             31363\nbm              31363\nop              31363\ngp              31363\ninv             31363\nmom11           31363\nmom122          31363\namhd            29013\nivol_capm       31361\nivol_ff5        31361\nbeta_bw         31363\nMAX             31363\nvol1m           31360\nvol6m           31357\nvol12m          31350\nsize            31363\nlbm             31363\nlop             31363\nlgp             31363\nlinv            31363\nllme            31363\nl1amhd          28926\nl1MAX           31362\nl3amhd          28737\nl3MAX           31360\nl6amhd          28420\nl6MAX           31357\nl12amhd         27713\nl12MAX          31362\nl12mom122       31191\nl12ivol_capm    31349\nl12ivol_ff5     31349\nl12beta_bw      31352\nl12vol6m        31339\nl12vol12m       31166\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (29248, 37)\ntime to do feature proprocessing: \nNumber of features after transformation:  (29248, 81)\nmae of a constant model 6.553607277016165\nR2 of a constant model 0.0\nXGB train: 6.110803010839697 0.1613195732684598\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.6s\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:26:59,584]\u001b[0m A new study created in memory with name: no-name-42a6b2fb-da50-4d0d-b517-c775148162db\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 2, 'n_estimators': 400, 'subsample': 0.6} 0.007141845676770453 33.45027804374695\nXGB train: 6.501211644578929 0.017764871358617373 33.639312744140625\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:27:03,002]\u001b[0m Trial 0 finished with value: 0.00837475305945023 and parameters: {'n_estimators': 811, 'max_depth': 3, 'learning_rate': 0.015809168749134343, 'colsample_bytree': 0.7303260396555257, 'subsample': 0.821827140244139, 'alpha': 4.585072642654388, 'lambda': 172.61709004372338, 'gamma': 1.246469979908026e-07, 'min_child_weight': 2.789055118345178}. Best is trial 0 with value: 0.00837475305945023.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:06,074]\u001b[0m Trial 1 finished with value: -0.0035525262176526323 and parameters: {'n_estimators': 785, 'max_depth': 3, 'learning_rate': 0.042476489217899926, 'colsample_bytree': 0.25503878339370606, 'subsample': 0.5739258233263153, 'alpha': 4.034067844032434, 'lambda': 0.36699803832709577, 'gamma': 7.90757179229881e-10, 'min_child_weight': 49.49373547616465}. Best is trial 0 with value: 0.00837475305945023.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:09,789]\u001b[0m Trial 2 finished with value: 0.008508418281056118 and parameters: {'n_estimators': 923, 'max_depth': 3, 'learning_rate': 0.0015997043735014086, 'colsample_bytree': 0.1625037930223523, 'subsample': 0.4747227065218722, 'alpha': 10.767228516137198, 'lambda': 0.9691377076725195, 'gamma': 0.024257099835968948, 'min_child_weight': 17.721346819660326}. Best is trial 2 with value: 0.008508418281056118.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:13,970]\u001b[0m Trial 3 finished with value: 0.002267636177486396 and parameters: {'n_estimators': 820, 'max_depth': 4, 'learning_rate': 0.014006192735750909, 'colsample_bytree': 0.17208763561782123, 'subsample': 0.788418327590304, 'alpha': 21.137088010473736, 'lambda': 36.13765749904336, 'gamma': 4.521720087759255e-06, 'min_child_weight': 0.11702385968360329}. Best is trial 2 with value: 0.008508418281056118.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:21,269]\u001b[0m Trial 4 finished with value: -0.023742791060107262 and parameters: {'n_estimators': 938, 'max_depth': 5, 'learning_rate': 0.01686637378285496, 'colsample_bytree': 0.4501012579691429, 'subsample': 0.6639047842718813, 'alpha': 2.6208895558783225, 'lambda': 0.6746211611268512, 'gamma': 5.894881809812456e-07, 'min_child_weight': 0.27439466725633604}. Best is trial 2 with value: 0.008508418281056118.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:25,307]\u001b[0m Trial 5 finished with value: -0.032748278134937636 and parameters: {'n_estimators': 594, 'max_depth': 5, 'learning_rate': 0.04938534746609031, 'colsample_bytree': 0.5148476618642368, 'subsample': 0.7130699918539938, 'alpha': 28.50949894173401, 'lambda': 5.8817820332168695, 'gamma': 1.6382680945296018e-08, 'min_child_weight': 40.40628143040986}. Best is trial 2 with value: 0.008508418281056118.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:30,499]\u001b[0m Trial 6 finished with value: 0.0083566021809057 and parameters: {'n_estimators': 765, 'max_depth': 5, 'learning_rate': 0.003639436468717945, 'colsample_bytree': 0.5886797794869518, 'subsample': 0.4452491078785596, 'alpha': 5.920283251663971, 'lambda': 2.7894739813391687, 'gamma': 0.48041844096399944, 'min_child_weight': 17.0261783543155}. Best is trial 2 with value: 0.008508418281056118.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:34,409]\u001b[0m Trial 7 finished with value: -0.029008799904184722 and parameters: {'n_estimators': 506, 'max_depth': 5, 'learning_rate': 0.028449845686626753, 'colsample_bytree': 0.4435040428991308, 'subsample': 0.6041827078522906, 'alpha': 0.2778939099373685, 'lambda': 0.3104634888242724, 'gamma': 3.695129855819989e-08, 'min_child_weight': 3.8728480624612973}. Best is trial 2 with value: 0.008508418281056118.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:37,205]\u001b[0m Trial 8 finished with value: 0.009532061543418147 and parameters: {'n_estimators': 512, 'max_depth': 4, 'learning_rate': 0.018874559541743472, 'colsample_bytree': 0.41751396101005933, 'subsample': 0.3226404471250187, 'alpha': 17.51444680556717, 'lambda': 30.46722245902103, 'gamma': 2.4173576944855752e-08, 'min_child_weight': 0.30007850015016113}. Best is trial 8 with value: 0.009532061543418147.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:39,592]\u001b[0m Trial 9 finished with value: 0.0022670569985659963 and parameters: {'n_estimators': 603, 'max_depth': 3, 'learning_rate': 0.03289396008643933, 'colsample_bytree': 0.3063093676506532, 'subsample': 0.7888111578535582, 'alpha': 0.37967647564440266, 'lambda': 127.29843039679879, 'gamma': 0.07005403946799858, 'min_child_weight': 0.33640807842731213}. Best is trial 8 with value: 0.009532061543418147.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:41,800]\u001b[0m Trial 10 finished with value: -0.005052741486834263 and parameters: {'n_estimators': 656, 'max_depth': 2, 'learning_rate': 0.037140140387834655, 'colsample_bytree': 0.9370902607491525, 'subsample': 0.30886179782799245, 'alpha': 0.8953407008483726, 'lambda': 19.37724705564046, 'gamma': 0.0002819882294272769, 'min_child_weight': 0.7139451831428689}. Best is trial 8 with value: 0.009532061543418147.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:46,647]\u001b[0m Trial 11 finished with value: 0.008242460691157312 and parameters: {'n_estimators': 999, 'max_depth': 4, 'learning_rate': 0.005725702490994824, 'colsample_bytree': 0.10185014646806137, 'subsample': 0.30794743689298304, 'alpha': 11.04815499570917, 'lambda': 1.3666878364515835, 'gamma': 0.0006128864158100818, 'min_child_weight': 9.876480473605001}. Best is trial 8 with value: 0.009532061543418147.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:49,531]\u001b[0m Trial 12 finished with value: 0.006202725660415691 and parameters: {'n_estimators': 916, 'max_depth': 2, 'learning_rate': 0.02102343024287804, 'colsample_bytree': 0.3187270737468344, 'subsample': 0.4523284635279272, 'alpha': 11.606200390673704, 'lambda': 8.457881590557013, 'gamma': 0.010743560086111853, 'min_child_weight': 0.9989933392571378}. Best is trial 8 with value: 0.009532061543418147.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:53,261]\u001b[0m Trial 13 finished with value: 0.007086511033928441 and parameters: {'n_estimators': 692, 'max_depth': 4, 'learning_rate': 0.0010940590504802368, 'colsample_bytree': 0.624211619429593, 'subsample': 0.43688719448138996, 'alpha': 1.1091293345756552, 'lambda': 0.1211446698329884, 'gamma': 3.7484992745551125e-05, 'min_child_weight': 6.844835971931055}. Best is trial 8 with value: 0.009532061543418147.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:55,965]\u001b[0m Trial 14 finished with value: 0.011514032845086612 and parameters: {'n_estimators': 515, 'max_depth': 3, 'learning_rate': 0.010410483464710794, 'colsample_bytree': 0.3695446944536873, 'subsample': 0.5267656343893188, 'alpha': 0.12323610234667441, 'lambda': 55.78352402158807, 'gamma': 7.219311092685869, 'min_child_weight': 1.2647527759912247}. Best is trial 14 with value: 0.011514032845086612.\u001b[0m\n\u001b[32m[I 2022-08-25 20:27:58,767]\u001b[0m Trial 15 finished with value: 0.00941172465152562 and parameters: {'n_estimators': 520, 'max_depth': 4, 'learning_rate': 0.010383384128106198, 'colsample_bytree': 0.382431002293202, 'subsample': 0.543463264726572, 'alpha': 0.15487290360742018, 'lambda': 48.313600762558934, 'gamma': 3.005994459857169e-10, 'min_child_weight': 1.3124348860825465}. Best is trial 14 with value: 0.011514032845086612.\u001b[0m\n\u001b[32m[I 2022-08-25 20:28:00,755]\u001b[0m Trial 16 finished with value: 0.006231374748850619 and parameters: {'n_estimators': 579, 'max_depth': 2, 'learning_rate': 0.02295233389317946, 'colsample_bytree': 0.8134641095239329, 'subsample': 0.9296641244987146, 'alpha': 0.6687880759927279, 'lambda': 61.43869434096587, 'gamma': 7.1716480962127065, 'min_child_weight': 0.40758179139631634}. Best is trial 14 with value: 0.011514032845086612.\u001b[0m\n\u001b[32m[I 2022-08-25 20:28:03,514]\u001b[0m Trial 17 finished with value: 0.006431081569637759 and parameters: {'n_estimators': 684, 'max_depth': 3, 'learning_rate': 0.011316888935904811, 'colsample_bytree': 0.5732870201884485, 'subsample': 0.3723072962198952, 'alpha': 0.1236982009586694, 'lambda': 15.509815931629378, 'gamma': 4.021433146101847e-06, 'min_child_weight': 0.10944803553248937}. Best is trial 14 with value: 0.011514032845086612.\u001b[0m\n\u001b[32m[I 2022-08-25 20:28:06,616]\u001b[0m Trial 18 finished with value: -0.0033405339171231176 and parameters: {'n_estimators': 552, 'max_depth': 4, 'learning_rate': 0.029593059445084287, 'colsample_bytree': 0.40967955820369784, 'subsample': 0.5096587894992003, 'alpha': 1.793960366916939, 'lambda': 19.088721598718216, 'gamma': 2.5981258912669616e-09, 'min_child_weight': 1.8674452991361064}. Best is trial 14 with value: 0.011514032845086612.\u001b[0m\n\u001b[32m[I 2022-08-25 20:28:09,238]\u001b[0m Trial 19 finished with value: 0.006617864753115318 and parameters: {'n_estimators': 633, 'max_depth': 3, 'learning_rate': 0.020081494567729882, 'colsample_bytree': 0.7120850643195373, 'subsample': 0.37512432169806736, 'alpha': 0.4125133127666231, 'lambda': 81.4460677841877, 'gamma': 3.9143247597409188, 'min_child_weight': 0.5886630261590433}. Best is trial 14 with value: 0.011514032845086612.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  69.65527367591858\n        n_estimators : 515\n           max_depth : 3\n       learning_rate : 0.010410483464710794\n    colsample_bytree : 0.3695446944536873\n           subsample : 0.5267656343893188\n               alpha : 0.12323610234667441\n              lambda : 55.78352402158807\n               gamma : 7.219311092685869\n    min_child_weight : 1.2647527759912247\nbest objective value : 0.011514032845086612\nOptuna XGB train: 6.450757514878683 0.03505892810226641 70.69066262245178\nMin_prd:  100\nConstant guess:  6.674820474635347 0.0\nXGB test: 6.797339346041856 -0.03392572645519665\nXGB GS test: 6.768171325492354 -0.01937416663345548\nOptuna XGB test: 6.77696546348316 -0.02464833390884169\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(40682, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    PERMNO  prd     mom482     mom242  year      RET   ind       bm        op  \\\n49   10006  124  57.022356  27.230111  1968 -10.5198  25.0 -0.22327  0.183384   \n50   10006  125  45.576895  32.149862  1968  -6.2596  25.0 -0.22327  0.183384   \n51   10006  126  16.380849  21.566933  1968   4.3219  25.0 -0.22327  0.183384   \n52   10006  127  32.954723  53.105785  1968   9.7618  25.0 -0.22327  0.183384   \n53   10006  128  34.099293  39.415200  1968   3.9450  25.0 -0.22327  0.183384   \n\n          gp       inv    mom11     mom122      amhd  ivol_capm  ivol_ff5  \\\n49  0.269118  0.100395   3.4619  12.086336  1.536049   1.377650  1.078594   \n50  0.269118  0.100395 -10.5198  24.581595  1.493226   2.217285  1.948001   \n51  0.269118  0.100395  -6.2596  13.253947  1.469247   4.800074  4.663338   \n52  0.269118  0.100395   4.3219  11.098127  1.375395   1.477982  1.203894   \n53  0.269118  0.100395   9.7618  21.666549  1.246353   1.734429  1.621548   \n\n     beta_bw     MAX     vol1m     vol6m    vol12m      size       lbm  \\\n49  0.854703  4.9820  1.945352  2.653852  2.174071  5.867580 -0.149515   \n50  0.794842  2.7293  2.301335  2.797800  2.238881  5.751293 -0.149515   \n51  0.777908  7.2477  4.297812  3.251701  2.512787  5.691229 -0.149515   \n52  0.787439  4.4095  1.764988  3.249921  2.531631  5.737749 -0.149515   \n53  0.750551  5.4695  1.618184  3.253052  2.540064  5.824760 -0.149515   \n\n         lop       lgp      linv      llme    l1amhd      l1MAX    l3amhd  \\\n49  0.173745  0.242714  0.119169  5.740148  1.573985  21.135115  1.636271   \n50  0.173745  0.242714  0.119169  5.660875  1.536049   4.982000  1.641999   \n51  0.173745  0.242714  0.119169  5.648296  1.493226   2.729300  1.573985   \n52  0.173745  0.242714  0.119169  5.606947  1.469247   7.247700  1.536049   \n53  0.173745  0.242714  0.119169  5.549943  1.375395   4.409500  1.493226   \n\n        l3MAX    l6amhd   l6MAX   l12amhd     l12MAX  l12mom122  l12ivol_capm  \\\n49   4.208600  1.653423  2.5316  1.833293  21.135115   6.066114      1.906794   \n50   2.202200  1.585251  1.7344  1.792446   4.982000  27.909142      1.503199   \n51  21.135115  1.624355  2.1833  1.744677   2.729300  25.117139      1.051638   \n52   4.982000  1.636271  4.2086  1.727351   7.247700  26.865911      1.174851   \n53   2.729300  1.641999  2.2022  1.738743   4.409500  20.035787      1.903329   \n\n    l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n49     1.545510    1.069805  1.668624   1.814489  \n50     1.346875    1.007441  1.599164   1.760787  \n51     0.849621    0.989661  1.421761   1.677152  \n52     1.018713    1.014681  1.442506   1.555119  \n53     1.637691    0.996995  1.592287   1.605068  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49</th>\n      <td>10006</td>\n      <td>124</td>\n      <td>57.022356</td>\n      <td>27.230111</td>\n      <td>1968</td>\n      <td>-10.5198</td>\n      <td>25.0</td>\n      <td>-0.22327</td>\n      <td>0.183384</td>\n      <td>0.269118</td>\n      <td>0.100395</td>\n      <td>3.4619</td>\n      <td>12.086336</td>\n      <td>1.536049</td>\n      <td>1.377650</td>\n      <td>1.078594</td>\n      <td>0.854703</td>\n      <td>4.9820</td>\n      <td>1.945352</td>\n      <td>2.653852</td>\n      <td>2.174071</td>\n      <td>5.867580</td>\n      <td>-0.149515</td>\n      <td>0.173745</td>\n      <td>0.242714</td>\n      <td>0.119169</td>\n      <td>5.740148</td>\n      <td>1.573985</td>\n      <td>21.135115</td>\n      <td>1.636271</td>\n      <td>4.208600</td>\n      <td>1.653423</td>\n      <td>2.5316</td>\n      <td>1.833293</td>\n      <td>21.135115</td>\n      <td>6.066114</td>\n      <td>1.906794</td>\n      <td>1.545510</td>\n      <td>1.069805</td>\n      <td>1.668624</td>\n      <td>1.814489</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>10006</td>\n      <td>125</td>\n      <td>45.576895</td>\n      <td>32.149862</td>\n      <td>1968</td>\n      <td>-6.2596</td>\n      <td>25.0</td>\n      <td>-0.22327</td>\n      <td>0.183384</td>\n      <td>0.269118</td>\n      <td>0.100395</td>\n      <td>-10.5198</td>\n      <td>24.581595</td>\n      <td>1.493226</td>\n      <td>2.217285</td>\n      <td>1.948001</td>\n      <td>0.794842</td>\n      <td>2.7293</td>\n      <td>2.301335</td>\n      <td>2.797800</td>\n      <td>2.238881</td>\n      <td>5.751293</td>\n      <td>-0.149515</td>\n      <td>0.173745</td>\n      <td>0.242714</td>\n      <td>0.119169</td>\n      <td>5.660875</td>\n      <td>1.536049</td>\n      <td>4.982000</td>\n      <td>1.641999</td>\n      <td>2.202200</td>\n      <td>1.585251</td>\n      <td>1.7344</td>\n      <td>1.792446</td>\n      <td>4.982000</td>\n      <td>27.909142</td>\n      <td>1.503199</td>\n      <td>1.346875</td>\n      <td>1.007441</td>\n      <td>1.599164</td>\n      <td>1.760787</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>10006</td>\n      <td>126</td>\n      <td>16.380849</td>\n      <td>21.566933</td>\n      <td>1968</td>\n      <td>4.3219</td>\n      <td>25.0</td>\n      <td>-0.22327</td>\n      <td>0.183384</td>\n      <td>0.269118</td>\n      <td>0.100395</td>\n      <td>-6.2596</td>\n      <td>13.253947</td>\n      <td>1.469247</td>\n      <td>4.800074</td>\n      <td>4.663338</td>\n      <td>0.777908</td>\n      <td>7.2477</td>\n      <td>4.297812</td>\n      <td>3.251701</td>\n      <td>2.512787</td>\n      <td>5.691229</td>\n      <td>-0.149515</td>\n      <td>0.173745</td>\n      <td>0.242714</td>\n      <td>0.119169</td>\n      <td>5.648296</td>\n      <td>1.493226</td>\n      <td>2.729300</td>\n      <td>1.573985</td>\n      <td>21.135115</td>\n      <td>1.624355</td>\n      <td>2.1833</td>\n      <td>1.744677</td>\n      <td>2.729300</td>\n      <td>25.117139</td>\n      <td>1.051638</td>\n      <td>0.849621</td>\n      <td>0.989661</td>\n      <td>1.421761</td>\n      <td>1.677152</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>10006</td>\n      <td>127</td>\n      <td>32.954723</td>\n      <td>53.105785</td>\n      <td>1968</td>\n      <td>9.7618</td>\n      <td>25.0</td>\n      <td>-0.22327</td>\n      <td>0.183384</td>\n      <td>0.269118</td>\n      <td>0.100395</td>\n      <td>4.3219</td>\n      <td>11.098127</td>\n      <td>1.375395</td>\n      <td>1.477982</td>\n      <td>1.203894</td>\n      <td>0.787439</td>\n      <td>4.4095</td>\n      <td>1.764988</td>\n      <td>3.249921</td>\n      <td>2.531631</td>\n      <td>5.737749</td>\n      <td>-0.149515</td>\n      <td>0.173745</td>\n      <td>0.242714</td>\n      <td>0.119169</td>\n      <td>5.606947</td>\n      <td>1.469247</td>\n      <td>7.247700</td>\n      <td>1.536049</td>\n      <td>4.982000</td>\n      <td>1.636271</td>\n      <td>4.2086</td>\n      <td>1.727351</td>\n      <td>7.247700</td>\n      <td>26.865911</td>\n      <td>1.174851</td>\n      <td>1.018713</td>\n      <td>1.014681</td>\n      <td>1.442506</td>\n      <td>1.555119</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>10006</td>\n      <td>128</td>\n      <td>34.099293</td>\n      <td>39.415200</td>\n      <td>1968</td>\n      <td>3.9450</td>\n      <td>25.0</td>\n      <td>-0.22327</td>\n      <td>0.183384</td>\n      <td>0.269118</td>\n      <td>0.100395</td>\n      <td>9.7618</td>\n      <td>21.666549</td>\n      <td>1.246353</td>\n      <td>1.734429</td>\n      <td>1.621548</td>\n      <td>0.750551</td>\n      <td>5.4695</td>\n      <td>1.618184</td>\n      <td>3.253052</td>\n      <td>2.540064</td>\n      <td>5.824760</td>\n      <td>-0.149515</td>\n      <td>0.173745</td>\n      <td>0.242714</td>\n      <td>0.119169</td>\n      <td>5.549943</td>\n      <td>1.375395</td>\n      <td>4.409500</td>\n      <td>1.493226</td>\n      <td>2.729300</td>\n      <td>1.641999</td>\n      <td>2.2022</td>\n      <td>1.738743</td>\n      <td>4.409500</td>\n      <td>20.035787</td>\n      <td>1.903329</td>\n      <td>1.637691</td>\n      <td>0.996995</td>\n      <td>1.592287</td>\n      <td>1.605068</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    40682.000000\nmean      1969.798437\nstd          0.978257\nmin       1968.000000\n25%       1969.000000\n50%       1970.000000\n75%       1971.000000\nmax       1971.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          40682\nprd             40682\nmom482          35826\nmom242          40286\nyear            40682\nRET             40682\nind             40682\nbm              40682\nop              40682\ngp              40682\ninv             40678\nmom11           40682\nmom122          40682\namhd            37268\nivol_capm       40681\nivol_ff5        40681\nbeta_bw         40682\nMAX             40682\nvol1m           40681\nvol6m           40682\nvol12m          40678\nsize            40682\nlbm             40682\nlop             40682\nlgp             40682\nlinv            40682\nllme            40682\nl1amhd          37313\nl1MAX           40682\nl3amhd          37398\nl3MAX           40682\nl6amhd          37547\nl6MAX           40682\nl12amhd         37988\nl12MAX          40682\nl12mom122       40497\nl12ivol_capm    40673\nl12ivol_ff5     40673\nl12beta_bw      40680\nl12vol6m        40637\nl12vol12m       40296\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (38133, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (38133, 82)\nmae of a constant model 7.1541100803200415\nR2 of a constant model 0.0\nXGB train: 6.700516343240393 0.15021333381905422\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.5s\nXGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 4, 'n_estimators': 400, 'subsample': 0.6} 0.008323971099045424 34.313915729522705\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:28:47,329]\u001b[0m A new study created in memory with name: no-name-a7ff125b-761e-458c-837c-69df14e61abb\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 7.036265023358253 0.043365857443366185 34.68202042579651\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:28:51,373]\u001b[0m Trial 0 finished with value: 0.015288317643964829 and parameters: {'n_estimators': 983, 'max_depth': 3, 'learning_rate': 0.01154814845863925, 'colsample_bytree': 0.2293283693559149, 'subsample': 0.3650444826578865, 'alpha': 0.15329303614416784, 'lambda': 0.49187784197675005, 'gamma': 1.2155606555846599e-05, 'min_child_weight': 0.1531219653388143}. Best is trial 0 with value: 0.015288317643964829.\u001b[0m\n\u001b[32m[I 2022-08-25 20:28:55,283]\u001b[0m Trial 1 finished with value: 0.01121760968834697 and parameters: {'n_estimators': 509, 'max_depth': 5, 'learning_rate': 0.0281792222801985, 'colsample_bytree': 0.42170961849016797, 'subsample': 0.8712022017176322, 'alpha': 0.12345806987126445, 'lambda': 29.718661974350074, 'gamma': 4.0955384605193656e-10, 'min_child_weight': 25.38752740649166}. Best is trial 0 with value: 0.015288317643964829.\u001b[0m\n\u001b[32m[I 2022-08-25 20:28:57,773]\u001b[0m Trial 2 finished with value: 0.012197031031307788 and parameters: {'n_estimators': 595, 'max_depth': 2, 'learning_rate': 0.038700962135322106, 'colsample_bytree': 0.7989144643973461, 'subsample': 0.7365354539999182, 'alpha': 2.323863394897519, 'lambda': 1.012208405221031, 'gamma': 0.023656352088085714, 'min_child_weight': 0.10057856014160865}. Best is trial 0 with value: 0.015288317643964829.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:00,485]\u001b[0m Trial 3 finished with value: 0.016869291871707246 and parameters: {'n_estimators': 594, 'max_depth': 3, 'learning_rate': 0.03487770265849893, 'colsample_bytree': 0.5425913807674901, 'subsample': 0.48963844944489276, 'alpha': 8.577392593748177, 'lambda': 92.53353479953861, 'gamma': 2.106980187333726e-07, 'min_child_weight': 8.41633966039991}. Best is trial 3 with value: 0.016869291871707246.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:03,689]\u001b[0m Trial 4 finished with value: 0.011138548578994852 and parameters: {'n_estimators': 975, 'max_depth': 2, 'learning_rate': 0.03916820548130943, 'colsample_bytree': 0.3606350376830697, 'subsample': 0.37778885842918053, 'alpha': 3.5389486604695795, 'lambda': 25.86847665264067, 'gamma': 5.581231523137758e-06, 'min_child_weight': 0.9511239595966817}. Best is trial 3 with value: 0.016869291871707246.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:08,271]\u001b[0m Trial 5 finished with value: 0.015780190519206448 and parameters: {'n_estimators': 551, 'max_depth': 5, 'learning_rate': 0.010944506510966994, 'colsample_bytree': 0.5852309229035544, 'subsample': 0.7051762367810461, 'alpha': 0.2085642059301049, 'lambda': 0.2948867054003147, 'gamma': 0.002998755855934184, 'min_child_weight': 0.3996006277768115}. Best is trial 3 with value: 0.016869291871707246.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:12,366]\u001b[0m Trial 6 finished with value: 0.0005281978453430597 and parameters: {'n_estimators': 957, 'max_depth': 3, 'learning_rate': 0.0489906850473388, 'colsample_bytree': 0.5387249149776698, 'subsample': 0.7885206932974845, 'alpha': 18.542819034008804, 'lambda': 0.430619659323344, 'gamma': 0.00047941205500501337, 'min_child_weight': 0.42513594364153945}. Best is trial 3 with value: 0.016869291871707246.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:16,521]\u001b[0m Trial 7 finished with value: 0.013886576694722099 and parameters: {'n_estimators': 991, 'max_depth': 3, 'learning_rate': 0.03701927330872319, 'colsample_bytree': 0.89714152272185, 'subsample': 0.9367138362076384, 'alpha': 0.4413995920789478, 'lambda': 180.20264382807972, 'gamma': 4.23669349669202, 'min_child_weight': 0.41877339259581076}. Best is trial 3 with value: 0.016869291871707246.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:19,630]\u001b[0m Trial 8 finished with value: 0.012863711184526266 and parameters: {'n_estimators': 741, 'max_depth': 3, 'learning_rate': 0.029848400643517806, 'colsample_bytree': 0.5595718222436867, 'subsample': 0.8947872713193465, 'alpha': 0.4746088200017323, 'lambda': 1.8509090865319549, 'gamma': 4.8702597015467546e-08, 'min_child_weight': 0.549667735181222}. Best is trial 3 with value: 0.016869291871707246.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:24,031]\u001b[0m Trial 9 finished with value: 0.004332917429890324 and parameters: {'n_estimators': 968, 'max_depth': 3, 'learning_rate': 0.04177597216616276, 'colsample_bytree': 0.7908361357933275, 'subsample': 0.571052589274461, 'alpha': 0.48815813001567465, 'lambda': 23.69118360308065, 'gamma': 2.5863193769462374, 'min_child_weight': 0.2337273361772171}. Best is trial 3 with value: 0.016869291871707246.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:27,605]\u001b[0m Trial 10 finished with value: 0.015138453889128966 and parameters: {'n_estimators': 668, 'max_depth': 4, 'learning_rate': 0.01894048150873029, 'colsample_bytree': 0.1278161832203784, 'subsample': 0.5178265101091879, 'alpha': 29.21766705936898, 'lambda': 153.5643735706002, 'gamma': 2.5343184287584116e-08, 'min_child_weight': 9.8735793101512}. Best is trial 3 with value: 0.016869291871707246.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:32,086]\u001b[0m Trial 11 finished with value: 0.015846222217641374 and parameters: {'n_estimators': 516, 'max_depth': 5, 'learning_rate': 0.003002951918971153, 'colsample_bytree': 0.7228808459721286, 'subsample': 0.6679586912576212, 'alpha': 8.916831143390201, 'lambda': 0.11851733540397844, 'gamma': 0.0012792698827219788, 'min_child_weight': 3.389885996359482}. Best is trial 3 with value: 0.016869291871707246.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:35,865]\u001b[0m Trial 12 finished with value: 0.019601826882610914 and parameters: {'n_estimators': 629, 'max_depth': 4, 'learning_rate': 0.004423172033049411, 'colsample_bytree': 0.6735849428919823, 'subsample': 0.48707545624879967, 'alpha': 8.372359940656272, 'lambda': 5.184004263691553, 'gamma': 1.7191556342510688e-06, 'min_child_weight': 4.081022186681033}. Best is trial 12 with value: 0.019601826882610914.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:39,597]\u001b[0m Trial 13 finished with value: 0.01186682595571737 and parameters: {'n_estimators': 645, 'max_depth': 4, 'learning_rate': 0.020833765810898117, 'colsample_bytree': 0.669141171257281, 'subsample': 0.46574921606804226, 'alpha': 6.300724393060571, 'lambda': 10.226735198726303, 'gamma': 5.63809145155985e-07, 'min_child_weight': 4.444936035903661}. Best is trial 12 with value: 0.019601826882610914.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:44,123]\u001b[0m Trial 14 finished with value: 0.01665228237919445 and parameters: {'n_estimators': 794, 'max_depth': 4, 'learning_rate': 0.005046521613894572, 'colsample_bytree': 0.40096720778527606, 'subsample': 0.45187345246599964, 'alpha': 9.180465197337234, 'lambda': 3.7740444537125946, 'gamma': 3.121835684772409e-10, 'min_child_weight': 45.39171071417573}. Best is trial 12 with value: 0.019601826882610914.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:48,390]\u001b[0m Trial 15 finished with value: 0.017476401731491994 and parameters: {'n_estimators': 728, 'max_depth': 4, 'learning_rate': 0.021888276105678985, 'colsample_bytree': 0.9337014618477268, 'subsample': 0.31075117163086463, 'alpha': 1.2974028556509813, 'lambda': 76.22851728490984, 'gamma': 1.628776050564034e-08, 'min_child_weight': 9.81000036774673}. Best is trial 12 with value: 0.019601826882610914.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:53,145]\u001b[0m Trial 16 finished with value: 0.012320554268728974 and parameters: {'n_estimators': 808, 'max_depth': 4, 'learning_rate': 0.01564370745280419, 'colsample_bytree': 0.942208021591829, 'subsample': 0.31921399867866596, 'alpha': 1.2451228157208596, 'lambda': 5.912198323887011, 'gamma': 6.005626525694106e-09, 'min_child_weight': 1.5552311683015252}. Best is trial 12 with value: 0.019601826882610914.\u001b[0m\n\u001b[32m[I 2022-08-25 20:29:57,375]\u001b[0m Trial 17 finished with value: 0.01978513447381966 and parameters: {'n_estimators': 709, 'max_depth': 4, 'learning_rate': 0.008387138866353446, 'colsample_bytree': 0.8445083533050689, 'subsample': 0.3022790767756601, 'alpha': 1.294635770631884, 'lambda': 57.654590387654764, 'gamma': 1.032000595807169e-06, 'min_child_weight': 10.280741968150178}. Best is trial 17 with value: 0.01978513447381966.\u001b[0m\n\u001b[32m[I 2022-08-25 20:30:03,024]\u001b[0m Trial 18 finished with value: 0.018898060759563268 and parameters: {'n_estimators': 665, 'max_depth': 5, 'learning_rate': 0.007883494850443252, 'colsample_bytree': 0.6686782034881534, 'subsample': 0.5717656261689891, 'alpha': 3.3731760177954544, 'lambda': 11.500244488068056, 'gamma': 3.9235086987928775e-05, 'min_child_weight': 4.525076479364637}. Best is trial 17 with value: 0.01978513447381966.\u001b[0m\n\u001b[32m[I 2022-08-25 20:30:08,387]\u001b[0m Trial 19 finished with value: 0.015423439877069607 and parameters: {'n_estimators': 887, 'max_depth': 4, 'learning_rate': 0.0018043482722739125, 'colsample_bytree': 0.8367110848767474, 'subsample': 0.4166316537111114, 'alpha': 0.8057182793240335, 'lambda': 2.470583572837432, 'gamma': 9.320217393823002e-07, 'min_child_weight': 18.905527871445365}. Best is trial 17 with value: 0.01978513447381966.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  81.06092238426208\n        n_estimators : 709\n           max_depth : 4\n       learning_rate : 0.008387138866353446\n    colsample_bytree : 0.8445083533050689\n           subsample : 0.3022790767756601\n               alpha : 1.294635770631884\n              lambda : 57.654590387654764\n               gamma : 1.032000595807169e-06\n    min_child_weight : 10.280741968150178\nbest objective value : 0.01978513447381966\nOptuna XGB train: 6.971079713781372 0.058627818958291056 83.22256517410278\nMin_prd:  125\nConstant guess:  6.801798451895731 0.0\nXGB test: 6.690736270893462 0.001886781638528956\nXGB GS test: 6.7089180299557585 0.006943571377436508\nOptuna XGB test: 6.683467341627174 0.004293040007036231\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(50984, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    PERMNO  prd     mom482     mom242  year     RET   ind        bm        op  \\\n74   10006  149 -11.907145 -28.068949  1970  8.9537  25.0 -0.192505  0.140962   \n75   10006  150  -0.991806 -21.116609  1970 -4.5062  25.0 -0.192505  0.140962   \n76   10006  151  11.783248 -29.778642  1970  8.8171  25.0 -0.192505  0.140962   \n77   10006  152   4.517407 -29.833415  1970  1.5353  25.0 -0.192505  0.140962   \n78   10006  153  18.690525 -30.734165  1971  4.0036  25.0 -0.192505  0.140962   \n\n          gp       inv   mom11     mom122      amhd  ivol_capm  ivol_ff5  \\\n74  0.224605  0.154915  4.9963 -17.560372  2.513800   1.195243  1.150948   \n75  0.224605  0.154915  8.9537 -12.901430  2.586287   1.067049  1.027625   \n76  0.224605  0.154915 -4.5062 -14.344204  2.608496   1.592679  1.337876   \n77  0.224605  0.154915  8.8171 -17.941026  2.622414   1.200474  1.015513   \n78  0.224605  0.154915  1.5353  -8.976912  2.604032   0.765013  0.696519   \n\n     beta_bw     MAX     vol1m     vol6m    vol12m      size       lbm  \\\n74  0.868877  2.5408  1.271715  1.649324  1.410050  5.406362 -0.516957   \n75  0.862274  2.9512  1.165072  1.689843  1.429232  5.497059 -0.516957   \n76  0.828411  2.3886  1.610320  1.667813  1.457507  5.455755 -0.516957   \n77  0.831283  2.5782  1.351295  1.411577  1.459923  5.531153 -0.516957   \n78  0.827540  1.4066  0.866870  1.234667  1.431408  5.545719 -0.516957   \n\n         lop       lgp      linv      llme    l1amhd   l1MAX    l3amhd  \\\n74  0.139113  0.231174  0.041194  5.536724  2.464311  2.0168  2.158325   \n75  0.139113  0.231174  0.041194  5.536724  2.513800  2.5408  2.316701   \n76  0.139113  0.231174  0.041194  5.644581  2.586287  2.9512  2.464311   \n77  0.139113  0.231174  0.041194  5.634556  2.608496  2.3886  2.513800   \n78  0.139113  0.231174  0.041194  5.621882  2.622414  2.5782  2.586287   \n\n     l3MAX    l6amhd   l6MAX   l12amhd  l12MAX  l12mom122  l12ivol_capm  \\\n74  2.7241  1.844002  1.8199  1.418393  2.0168 -25.445548      1.197438   \n75  5.5990  1.876815  2.5908  1.450799  2.5408 -15.063563      0.765013   \n76  2.0168  1.998218  1.9670  1.574844  2.9512 -19.087141      1.129631   \n77  2.5408  2.158325  2.7241  1.667734  2.3886 -18.329996      1.325809   \n78  2.9512  2.316701  5.5990  1.762020  2.5782 -21.681417      1.111892   \n\n    l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n74     0.833119    0.936794  1.853300   2.111649  \n75     0.647098    1.029569  1.737736   2.018194  \n76     1.097229    1.015623  1.335658   1.622773  \n77     1.023188    1.006169  1.294217   1.635130  \n78     0.742139    0.998186  1.266684   1.593312  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>74</th>\n      <td>10006</td>\n      <td>149</td>\n      <td>-11.907145</td>\n      <td>-28.068949</td>\n      <td>1970</td>\n      <td>8.9537</td>\n      <td>25.0</td>\n      <td>-0.192505</td>\n      <td>0.140962</td>\n      <td>0.224605</td>\n      <td>0.154915</td>\n      <td>4.9963</td>\n      <td>-17.560372</td>\n      <td>2.513800</td>\n      <td>1.195243</td>\n      <td>1.150948</td>\n      <td>0.868877</td>\n      <td>2.5408</td>\n      <td>1.271715</td>\n      <td>1.649324</td>\n      <td>1.410050</td>\n      <td>5.406362</td>\n      <td>-0.516957</td>\n      <td>0.139113</td>\n      <td>0.231174</td>\n      <td>0.041194</td>\n      <td>5.536724</td>\n      <td>2.464311</td>\n      <td>2.0168</td>\n      <td>2.158325</td>\n      <td>2.7241</td>\n      <td>1.844002</td>\n      <td>1.8199</td>\n      <td>1.418393</td>\n      <td>2.0168</td>\n      <td>-25.445548</td>\n      <td>1.197438</td>\n      <td>0.833119</td>\n      <td>0.936794</td>\n      <td>1.853300</td>\n      <td>2.111649</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>10006</td>\n      <td>150</td>\n      <td>-0.991806</td>\n      <td>-21.116609</td>\n      <td>1970</td>\n      <td>-4.5062</td>\n      <td>25.0</td>\n      <td>-0.192505</td>\n      <td>0.140962</td>\n      <td>0.224605</td>\n      <td>0.154915</td>\n      <td>8.9537</td>\n      <td>-12.901430</td>\n      <td>2.586287</td>\n      <td>1.067049</td>\n      <td>1.027625</td>\n      <td>0.862274</td>\n      <td>2.9512</td>\n      <td>1.165072</td>\n      <td>1.689843</td>\n      <td>1.429232</td>\n      <td>5.497059</td>\n      <td>-0.516957</td>\n      <td>0.139113</td>\n      <td>0.231174</td>\n      <td>0.041194</td>\n      <td>5.536724</td>\n      <td>2.513800</td>\n      <td>2.5408</td>\n      <td>2.316701</td>\n      <td>5.5990</td>\n      <td>1.876815</td>\n      <td>2.5908</td>\n      <td>1.450799</td>\n      <td>2.5408</td>\n      <td>-15.063563</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>1.029569</td>\n      <td>1.737736</td>\n      <td>2.018194</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>10006</td>\n      <td>151</td>\n      <td>11.783248</td>\n      <td>-29.778642</td>\n      <td>1970</td>\n      <td>8.8171</td>\n      <td>25.0</td>\n      <td>-0.192505</td>\n      <td>0.140962</td>\n      <td>0.224605</td>\n      <td>0.154915</td>\n      <td>-4.5062</td>\n      <td>-14.344204</td>\n      <td>2.608496</td>\n      <td>1.592679</td>\n      <td>1.337876</td>\n      <td>0.828411</td>\n      <td>2.3886</td>\n      <td>1.610320</td>\n      <td>1.667813</td>\n      <td>1.457507</td>\n      <td>5.455755</td>\n      <td>-0.516957</td>\n      <td>0.139113</td>\n      <td>0.231174</td>\n      <td>0.041194</td>\n      <td>5.644581</td>\n      <td>2.586287</td>\n      <td>2.9512</td>\n      <td>2.464311</td>\n      <td>2.0168</td>\n      <td>1.998218</td>\n      <td>1.9670</td>\n      <td>1.574844</td>\n      <td>2.9512</td>\n      <td>-19.087141</td>\n      <td>1.129631</td>\n      <td>1.097229</td>\n      <td>1.015623</td>\n      <td>1.335658</td>\n      <td>1.622773</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>10006</td>\n      <td>152</td>\n      <td>4.517407</td>\n      <td>-29.833415</td>\n      <td>1970</td>\n      <td>1.5353</td>\n      <td>25.0</td>\n      <td>-0.192505</td>\n      <td>0.140962</td>\n      <td>0.224605</td>\n      <td>0.154915</td>\n      <td>8.8171</td>\n      <td>-17.941026</td>\n      <td>2.622414</td>\n      <td>1.200474</td>\n      <td>1.015513</td>\n      <td>0.831283</td>\n      <td>2.5782</td>\n      <td>1.351295</td>\n      <td>1.411577</td>\n      <td>1.459923</td>\n      <td>5.531153</td>\n      <td>-0.516957</td>\n      <td>0.139113</td>\n      <td>0.231174</td>\n      <td>0.041194</td>\n      <td>5.634556</td>\n      <td>2.608496</td>\n      <td>2.3886</td>\n      <td>2.513800</td>\n      <td>2.5408</td>\n      <td>2.158325</td>\n      <td>2.7241</td>\n      <td>1.667734</td>\n      <td>2.3886</td>\n      <td>-18.329996</td>\n      <td>1.325809</td>\n      <td>1.023188</td>\n      <td>1.006169</td>\n      <td>1.294217</td>\n      <td>1.635130</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>10006</td>\n      <td>153</td>\n      <td>18.690525</td>\n      <td>-30.734165</td>\n      <td>1971</td>\n      <td>4.0036</td>\n      <td>25.0</td>\n      <td>-0.192505</td>\n      <td>0.140962</td>\n      <td>0.224605</td>\n      <td>0.154915</td>\n      <td>1.5353</td>\n      <td>-8.976912</td>\n      <td>2.604032</td>\n      <td>0.765013</td>\n      <td>0.696519</td>\n      <td>0.827540</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>1.234667</td>\n      <td>1.431408</td>\n      <td>5.545719</td>\n      <td>-0.516957</td>\n      <td>0.139113</td>\n      <td>0.231174</td>\n      <td>0.041194</td>\n      <td>5.621882</td>\n      <td>2.622414</td>\n      <td>2.5782</td>\n      <td>2.586287</td>\n      <td>2.9512</td>\n      <td>2.316701</td>\n      <td>5.5990</td>\n      <td>1.762020</td>\n      <td>2.5782</td>\n      <td>-21.681417</td>\n      <td>1.111892</td>\n      <td>0.742139</td>\n      <td>0.998186</td>\n      <td>1.266684</td>\n      <td>1.593312</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    50984.000000\nmean      1971.849776\nstd          0.964612\nmin       1970.000000\n25%       1971.000000\n50%       1972.000000\n75%       1973.000000\nmax       1973.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          50984\nprd             50984\nmom482          43631\nmom242          50521\nyear            50984\nRET             50984\nind             50984\nbm              50984\nop              50984\ngp              50984\ninv             50962\nmom11           50984\nmom122          50984\namhd            44589\nivol_capm       50981\nivol_ff5        50981\nbeta_bw         50984\nMAX             50984\nvol1m           50979\nvol6m           50984\nvol12m          50984\nsize            50984\nlbm             50984\nlop             50984\nlgp             50984\nlinv            50984\nllme            50984\nl1amhd          44685\nl1MAX           50984\nl3amhd          44913\nl3MAX           50984\nl6amhd          45179\nl6MAX           50984\nl12amhd         45585\nl12MAX          50984\nl12mom122       50788\nl12ivol_capm    50980\nl12ivol_ff5     50980\nl12beta_bw      50984\nl12vol6m        50942\nl12vol12m       50509\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (47985, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (47985, 84)\nmae of a constant model 7.537774691011074\nR2 of a constant model 0.0\nXGB train: 7.029949276574985 0.12444542849884155\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.6s\nXGB {'colsample_bytree': 0.6, 'eta': 0.012, 'max_depth': 4, 'n_estimators': 400, 'subsample': 0.6} 0.012395595575939333 36.19267225265503\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:30:50,065]\u001b[0m A new study created in memory with name: no-name-988d4d85-bbbd-414a-b82c-8423eb0176dc\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 7.264593573026108 0.053180788794843004 36.91641306877136\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:30:58,377]\u001b[0m Trial 0 finished with value: -0.014986951626088657 and parameters: {'n_estimators': 977, 'max_depth': 5, 'learning_rate': 0.039496235929273746, 'colsample_bytree': 0.47755882240892644, 'subsample': 0.4937362023406756, 'alpha': 7.205838412740077, 'lambda': 71.99196404996096, 'gamma': 8.921361117124002, 'min_child_weight': 2.582826224626684}. Best is trial 0 with value: -0.014986951626088657.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:02,047]\u001b[0m Trial 1 finished with value: 0.006455059442313697 and parameters: {'n_estimators': 676, 'max_depth': 3, 'learning_rate': 0.03871467579249942, 'colsample_bytree': 0.1423404311938064, 'subsample': 0.5440010105600128, 'alpha': 1.5160563582558173, 'lambda': 5.831062709432314, 'gamma': 6.652695464129989e-07, 'min_child_weight': 7.790574045374248}. Best is trial 1 with value: 0.006455059442313697.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:04,585]\u001b[0m Trial 2 finished with value: 0.01641066848331539 and parameters: {'n_estimators': 535, 'max_depth': 3, 'learning_rate': 0.013858241605672308, 'colsample_bytree': 0.8103376027975585, 'subsample': 0.9436046217238852, 'alpha': 0.3786176803261718, 'lambda': 80.96062129548245, 'gamma': 1.6575510918590155e-10, 'min_child_weight': 0.2916098749750353}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:09,841]\u001b[0m Trial 3 finished with value: 0.014014877300596265 and parameters: {'n_estimators': 602, 'max_depth': 5, 'learning_rate': 0.008038554923843345, 'colsample_bytree': 0.5450194023272155, 'subsample': 0.42236713616055793, 'alpha': 0.5156588443661235, 'lambda': 6.145385065255142, 'gamma': 0.5702301682850031, 'min_child_weight': 0.5573602523684063}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:14,179]\u001b[0m Trial 4 finished with value: 0.011934634087673304 and parameters: {'n_estimators': 670, 'max_depth': 4, 'learning_rate': 0.012814872359681186, 'colsample_bytree': 0.8275116180603401, 'subsample': 0.9393805559112951, 'alpha': 0.5200262773531348, 'lambda': 0.22515107645357568, 'gamma': 9.846762862642917e-05, 'min_child_weight': 15.90596643693858}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:17,313]\u001b[0m Trial 5 finished with value: 0.012564402701505172 and parameters: {'n_estimators': 680, 'max_depth': 3, 'learning_rate': 0.03474706551674443, 'colsample_bytree': 0.8371814560764129, 'subsample': 0.8545434974277755, 'alpha': 0.4490335483383168, 'lambda': 1.7732976477734772, 'gamma': 0.002226883408934108, 'min_child_weight': 5.283598294468197}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:22,671]\u001b[0m Trial 6 finished with value: -0.012104122025399611 and parameters: {'n_estimators': 710, 'max_depth': 5, 'learning_rate': 0.04569857569540417, 'colsample_bytree': 0.13506217818754318, 'subsample': 0.35721660823045615, 'alpha': 2.330937491501635, 'lambda': 17.170349171822714, 'gamma': 5.724358832371222e-09, 'min_child_weight': 18.86814974372036}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:26,575]\u001b[0m Trial 7 finished with value: -0.00368852890533947 and parameters: {'n_estimators': 618, 'max_depth': 4, 'learning_rate': 0.04822458902882899, 'colsample_bytree': 0.6354433719583665, 'subsample': 0.926719850310094, 'alpha': 18.756177730991954, 'lambda': 0.5728985960804278, 'gamma': 1.5787320956031926e-09, 'min_child_weight': 0.4529337190762664}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:29,692]\u001b[0m Trial 8 finished with value: 0.010164142396866338 and parameters: {'n_estimators': 866, 'max_depth': 2, 'learning_rate': 0.006143343357880012, 'colsample_bytree': 0.9398116891924905, 'subsample': 0.30850122971833666, 'alpha': 1.9863283010784523, 'lambda': 1.4972032431301914, 'gamma': 0.00010743773872165146, 'min_child_weight': 11.075295663141143}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:34,802]\u001b[0m Trial 9 finished with value: 0.005380829377283748 and parameters: {'n_estimators': 884, 'max_depth': 4, 'learning_rate': 0.018807779724028036, 'colsample_bytree': 0.29720593164473624, 'subsample': 0.36483835938987497, 'alpha': 1.7322947355908846, 'lambda': 1.7200269794277545, 'gamma': 7.227101190241856e-07, 'min_child_weight': 0.4777330630183373}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:36,845]\u001b[0m Trial 10 finished with value: 0.01383652695709987 and parameters: {'n_estimators': 522, 'max_depth': 2, 'learning_rate': 0.02857546406616763, 'colsample_bytree': 0.6952534888228216, 'subsample': 0.7079897601801419, 'alpha': 0.11574356722049711, 'lambda': 136.4704769035254, 'gamma': 1.3071224043629877e-10, 'min_child_weight': 0.11295124637097059}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:39,294]\u001b[0m Trial 11 finished with value: 0.0057483645171761645 and parameters: {'n_estimators': 509, 'max_depth': 3, 'learning_rate': 0.002107232056357572, 'colsample_bytree': 0.4324617603353397, 'subsample': 0.7357186672238909, 'alpha': 0.1977575788848776, 'lambda': 23.27973516951134, 'gamma': 0.5401169877230758, 'min_child_weight': 0.5077644542742967}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:44,638]\u001b[0m Trial 12 finished with value: 0.010396992370441137 and parameters: {'n_estimators': 586, 'max_depth': 5, 'learning_rate': 0.015979760169911362, 'colsample_bytree': 0.6256150686698542, 'subsample': 0.47076213585641175, 'alpha': 0.47324517858442194, 'lambda': 28.315898860796793, 'gamma': 0.02247163362956837, 'min_child_weight': 0.1368916682306429}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:47,452]\u001b[0m Trial 13 finished with value: 0.013975074459802865 and parameters: {'n_estimators': 580, 'max_depth': 3, 'learning_rate': 0.00962572603288966, 'colsample_bytree': 0.35659264357325626, 'subsample': 0.6511655357734595, 'alpha': 0.298360536515026, 'lambda': 8.149814388398184, 'gamma': 3.372857518801088e-07, 'min_child_weight': 1.180642712312662}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:52,241]\u001b[0m Trial 14 finished with value: 0.01205130742962173 and parameters: {'n_estimators': 772, 'max_depth': 4, 'learning_rate': 0.022422194183225035, 'colsample_bytree': 0.7430402848985427, 'subsample': 0.8047724522571369, 'alpha': 0.9045088476652751, 'lambda': 159.30766000520507, 'gamma': 0.01630429920015994, 'min_child_weight': 0.22342032482458293}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:55,125]\u001b[0m Trial 15 finished with value: 0.006273267858214201 and parameters: {'n_estimators': 780, 'max_depth': 2, 'learning_rate': 0.0014460923452759844, 'colsample_bytree': 0.934015624635097, 'subsample': 0.5753642719021366, 'alpha': 0.12863236285172666, 'lambda': 43.45463242737087, 'gamma': 2.2213474059987943e-08, 'min_child_weight': 1.2430387359102502}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:31:59,683]\u001b[0m Trial 16 finished with value: 0.00841908512768729 and parameters: {'n_estimators': 559, 'max_depth': 5, 'learning_rate': 0.02549250564664385, 'colsample_bytree': 0.5700050958955118, 'subsample': 0.6597887031237504, 'alpha': 4.285507834384223, 'lambda': 0.1109073625182816, 'gamma': 5.667824265485289, 'min_child_weight': 39.92235671095481}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:32:03,953]\u001b[0m Trial 17 finished with value: 0.01457687903193294 and parameters: {'n_estimators': 617, 'max_depth': 4, 'learning_rate': 0.009821867327713722, 'colsample_bytree': 0.777789309718163, 'subsample': 0.431718836571434, 'alpha': 0.7915274177486985, 'lambda': 6.57629000291715, 'gamma': 6.872924368465088e-06, 'min_child_weight': 0.27387073720619387}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:32:06,494]\u001b[0m Trial 18 finished with value: 0.01470306302829162 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.015982296566305502, 'colsample_bytree': 0.7744283161046868, 'subsample': 0.8006221451648263, 'alpha': 0.945070283452711, 'lambda': 14.206890737096323, 'gamma': 7.030250560052055e-06, 'min_child_weight': 0.23397947578381584}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n\u001b[32m[I 2022-08-25 20:32:09,201]\u001b[0m Trial 19 finished with value: 0.014143560176219361 and parameters: {'n_estimators': 519, 'max_depth': 3, 'learning_rate': 0.019668247588654993, 'colsample_bytree': 0.8623464659948394, 'subsample': 0.8171097583440599, 'alpha': 4.7583078219074055, 'lambda': 66.59891675718431, 'gamma': 1.1155889135100209e-10, 'min_child_weight': 1.0815177197435901}. Best is trial 2 with value: 0.01641066848331539.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  79.1415696144104\n        n_estimators : 535\n           max_depth : 3\n       learning_rate : 0.013858241605672308\n    colsample_bytree : 0.8103376027975585\n           subsample : 0.9436046217238852\n               alpha : 0.3786176803261718\n              lambda : 80.96062129548245\n               gamma : 1.6575510918590155e-10\n    min_child_weight : 0.2916098749750353\nbest objective value : 0.01641066848331539\nOptuna XGB train: 7.305544621701751 0.03659721634402702 80.53257203102112\nMin_prd:  150\nConstant guess:  8.924405010653333 0.0\nXGB test: 8.760029922668958 0.009361205960809249\nXGB GS test: 8.769167863016227 0.018258046195946398\nOptuna XGB test: 8.762136421188014 0.019385496099062816\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(59945, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd     mom482     mom242  year     RET   ind       bm        op  \\\n99    10006  174  -8.863675  24.298177  1972  1.7951  25.0 -0.12852  0.102706   \n100   10006  175  -8.895430  19.337724  1972 -6.6230  25.0 -0.12852  0.102706   \n101   10006  176 -23.761723   5.490262  1972 -2.1741  25.0 -0.12852  0.102706   \n102   10006  177 -27.752649   2.121427  1973 -6.4767  25.0 -0.12852  0.102706   \n103   10006  178 -20.022258  -1.415186  1973 -8.0078  25.0 -0.12852  0.102706   \n\n           gp       inv   mom11     mom122      amhd  ivol_capm  ivol_ff5  \\\n99   0.189707  0.057118  3.9857 -13.084494  1.727817   0.765013  0.647098   \n100  0.189707  0.057118  1.7951   2.102147  1.706153   0.916285  0.827985   \n101  0.189707  0.057118 -6.6230   7.548838  1.804927   1.910382  1.747425   \n102  0.189707  0.057118 -2.1741  -4.357035  1.890130   1.299676  1.228433   \n103  0.189707  0.057118 -6.4767  -6.618875  1.939386   1.020299  0.940395   \n\n      beta_bw     MAX     vol1m     vol6m    vol12m      size       lbm  \\\n99   0.838275  1.7642  0.866870  1.356555  1.390944  5.658946 -0.062534   \n100  0.797384  1.9770  0.938854  1.161795  1.337902  5.680660 -0.062534   \n101  0.685677  1.5767  1.941405  1.246814  1.360487  5.603795 -0.062534   \n102  0.781756  2.8151  1.426847  1.273572  1.401402  5.587195 -0.062534   \n103  0.771634  1.5254  1.104205  1.297380  1.415379  5.524929 -0.062534   \n\n          lop       lgp      linv      llme    l1amhd   l1MAX    l3amhd  \\\n99   0.116521  0.201542  0.081797  5.774872  1.737888  2.8289  1.627297   \n100  0.116521  0.201542  0.081797  5.657089  1.727817  1.7642  1.662882   \n101  0.116521  0.201542  0.081797  5.614529  1.706153  1.9770  1.737888   \n102  0.116521  0.201542  0.081797  5.663813  1.804927  1.5767  1.727817   \n103  0.116521  0.201542  0.081797  5.668655  1.890130  2.8151  1.706153   \n\n      l3MAX    l6amhd   l6MAX   l12amhd  l12MAX  l12mom122  l12ivol_capm  \\\n99   2.3539  1.606479  2.5787  1.817857  2.8289  34.408776      0.765013   \n100  1.7081  1.633409  3.6509  1.772195  1.7642  39.316493      1.461319   \n101  2.8289  1.621238  5.1584  1.690663  1.9770  13.329088      1.336760   \n102  1.7642  1.627297  2.3539  1.636980  1.5767   7.864953      0.840915   \n103  1.9770  1.662882  1.7081  1.606000  2.8151   8.899177      0.765013   \n\n     l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n99      0.647098    0.879409  1.515860   1.391454  \n100     1.333326    0.980061  1.402991   1.390889  \n101     1.041994    1.010340  1.508092   1.425334  \n102     0.653553    0.982159  1.507691   1.433275  \n103     0.647098    1.008138  1.454644   1.423127  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>99</th>\n      <td>10006</td>\n      <td>174</td>\n      <td>-8.863675</td>\n      <td>24.298177</td>\n      <td>1972</td>\n      <td>1.7951</td>\n      <td>25.0</td>\n      <td>-0.12852</td>\n      <td>0.102706</td>\n      <td>0.189707</td>\n      <td>0.057118</td>\n      <td>3.9857</td>\n      <td>-13.084494</td>\n      <td>1.727817</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.838275</td>\n      <td>1.7642</td>\n      <td>0.866870</td>\n      <td>1.356555</td>\n      <td>1.390944</td>\n      <td>5.658946</td>\n      <td>-0.062534</td>\n      <td>0.116521</td>\n      <td>0.201542</td>\n      <td>0.081797</td>\n      <td>5.774872</td>\n      <td>1.737888</td>\n      <td>2.8289</td>\n      <td>1.627297</td>\n      <td>2.3539</td>\n      <td>1.606479</td>\n      <td>2.5787</td>\n      <td>1.817857</td>\n      <td>2.8289</td>\n      <td>34.408776</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.879409</td>\n      <td>1.515860</td>\n      <td>1.391454</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>10006</td>\n      <td>175</td>\n      <td>-8.895430</td>\n      <td>19.337724</td>\n      <td>1972</td>\n      <td>-6.6230</td>\n      <td>25.0</td>\n      <td>-0.12852</td>\n      <td>0.102706</td>\n      <td>0.189707</td>\n      <td>0.057118</td>\n      <td>1.7951</td>\n      <td>2.102147</td>\n      <td>1.706153</td>\n      <td>0.916285</td>\n      <td>0.827985</td>\n      <td>0.797384</td>\n      <td>1.9770</td>\n      <td>0.938854</td>\n      <td>1.161795</td>\n      <td>1.337902</td>\n      <td>5.680660</td>\n      <td>-0.062534</td>\n      <td>0.116521</td>\n      <td>0.201542</td>\n      <td>0.081797</td>\n      <td>5.657089</td>\n      <td>1.727817</td>\n      <td>1.7642</td>\n      <td>1.662882</td>\n      <td>1.7081</td>\n      <td>1.633409</td>\n      <td>3.6509</td>\n      <td>1.772195</td>\n      <td>1.7642</td>\n      <td>39.316493</td>\n      <td>1.461319</td>\n      <td>1.333326</td>\n      <td>0.980061</td>\n      <td>1.402991</td>\n      <td>1.390889</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>10006</td>\n      <td>176</td>\n      <td>-23.761723</td>\n      <td>5.490262</td>\n      <td>1972</td>\n      <td>-2.1741</td>\n      <td>25.0</td>\n      <td>-0.12852</td>\n      <td>0.102706</td>\n      <td>0.189707</td>\n      <td>0.057118</td>\n      <td>-6.6230</td>\n      <td>7.548838</td>\n      <td>1.804927</td>\n      <td>1.910382</td>\n      <td>1.747425</td>\n      <td>0.685677</td>\n      <td>1.5767</td>\n      <td>1.941405</td>\n      <td>1.246814</td>\n      <td>1.360487</td>\n      <td>5.603795</td>\n      <td>-0.062534</td>\n      <td>0.116521</td>\n      <td>0.201542</td>\n      <td>0.081797</td>\n      <td>5.614529</td>\n      <td>1.706153</td>\n      <td>1.9770</td>\n      <td>1.737888</td>\n      <td>2.8289</td>\n      <td>1.621238</td>\n      <td>5.1584</td>\n      <td>1.690663</td>\n      <td>1.9770</td>\n      <td>13.329088</td>\n      <td>1.336760</td>\n      <td>1.041994</td>\n      <td>1.010340</td>\n      <td>1.508092</td>\n      <td>1.425334</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>10006</td>\n      <td>177</td>\n      <td>-27.752649</td>\n      <td>2.121427</td>\n      <td>1973</td>\n      <td>-6.4767</td>\n      <td>25.0</td>\n      <td>-0.12852</td>\n      <td>0.102706</td>\n      <td>0.189707</td>\n      <td>0.057118</td>\n      <td>-2.1741</td>\n      <td>-4.357035</td>\n      <td>1.890130</td>\n      <td>1.299676</td>\n      <td>1.228433</td>\n      <td>0.781756</td>\n      <td>2.8151</td>\n      <td>1.426847</td>\n      <td>1.273572</td>\n      <td>1.401402</td>\n      <td>5.587195</td>\n      <td>-0.062534</td>\n      <td>0.116521</td>\n      <td>0.201542</td>\n      <td>0.081797</td>\n      <td>5.663813</td>\n      <td>1.804927</td>\n      <td>1.5767</td>\n      <td>1.727817</td>\n      <td>1.7642</td>\n      <td>1.627297</td>\n      <td>2.3539</td>\n      <td>1.636980</td>\n      <td>1.5767</td>\n      <td>7.864953</td>\n      <td>0.840915</td>\n      <td>0.653553</td>\n      <td>0.982159</td>\n      <td>1.507691</td>\n      <td>1.433275</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>10006</td>\n      <td>178</td>\n      <td>-20.022258</td>\n      <td>-1.415186</td>\n      <td>1973</td>\n      <td>-8.0078</td>\n      <td>25.0</td>\n      <td>-0.12852</td>\n      <td>0.102706</td>\n      <td>0.189707</td>\n      <td>0.057118</td>\n      <td>-6.4767</td>\n      <td>-6.618875</td>\n      <td>1.939386</td>\n      <td>1.020299</td>\n      <td>0.940395</td>\n      <td>0.771634</td>\n      <td>1.5254</td>\n      <td>1.104205</td>\n      <td>1.297380</td>\n      <td>1.415379</td>\n      <td>5.524929</td>\n      <td>-0.062534</td>\n      <td>0.116521</td>\n      <td>0.201542</td>\n      <td>0.081797</td>\n      <td>5.668655</td>\n      <td>1.890130</td>\n      <td>2.8151</td>\n      <td>1.706153</td>\n      <td>1.9770</td>\n      <td>1.662882</td>\n      <td>1.7081</td>\n      <td>1.606000</td>\n      <td>2.8151</td>\n      <td>8.899177</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>1.008138</td>\n      <td>1.454644</td>\n      <td>1.423127</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    59945.000000\nmean      1973.906748\nstd          0.951204\nmin       1972.000000\n25%       1973.000000\n50%       1974.000000\n75%       1975.000000\nmax       1975.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          59945\nprd             59945\nmom482          50928\nmom242          58102\nyear            59945\nRET             59945\nind             59945\nbm              59945\nop              59945\ngp              59945\ninv             59921\nmom11           59945\nmom122          59945\namhd            45301\nivol_capm       59933\nivol_ff5        59933\nbeta_bw         59945\nMAX             59945\nvol1m           59925\nvol6m           59929\nvol12m          59919\nsize            59945\nlbm             59945\nlop             59945\nlgp             59945\nlinv            59945\nllme            59945\nl1amhd          45543\nl1MAX           59944\nl3amhd          46032\nl3MAX           59943\nl6amhd          46751\nl6MAX           59940\nl12amhd         48575\nl12MAX          59944\nl12mom122       59661\nl12ivol_capm    59930\nl12ivol_ff5     59930\nl12beta_bw      59941\nl12vol6m        59872\nl12vol12m       57924\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (56061, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (56061, 85)\nmae of a constant model 8.558942696185106\nR2 of a constant model 0.0\nXGB train: 8.164309167669105 0.1153934212396065\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\nXGB {'colsample_bytree': 0.6, 'eta': 0.012, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.022448372303792707 38.4695348739624\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:32:52,737]\u001b[0m A new study created in memory with name: no-name-ac791e38-bfe0-4620-84d4-0df22ed7b334\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 8.31880391898526 0.07409681937414536 39.4064404964447\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:32:58,043]\u001b[0m Trial 0 finished with value: 0.018514943850713315 and parameters: {'n_estimators': 831, 'max_depth': 4, 'learning_rate': 0.0030593424229678166, 'colsample_bytree': 0.5415326874933835, 'subsample': 0.5984404864569632, 'alpha': 8.350014148514163, 'lambda': 3.534050812904276, 'gamma': 3.630810963124753e-05, 'min_child_weight': 7.631115727348554}. Best is trial 0 with value: 0.018514943850713315.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:01,076]\u001b[0m Trial 1 finished with value: 0.020374639823574302 and parameters: {'n_estimators': 591, 'max_depth': 3, 'learning_rate': 0.0212008815190838, 'colsample_bytree': 0.5020753284865785, 'subsample': 0.5212851063881505, 'alpha': 7.661214511865505, 'lambda': 10.21063366054143, 'gamma': 4.194026018821317e-05, 'min_child_weight': 0.523520157461911}. Best is trial 1 with value: 0.020374639823574302.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:08,456]\u001b[0m Trial 2 finished with value: 0.001950797565977872 and parameters: {'n_estimators': 843, 'max_depth': 5, 'learning_rate': 0.03409908566143999, 'colsample_bytree': 0.2483201906895766, 'subsample': 0.9475006215733326, 'alpha': 16.98097241689328, 'lambda': 9.337738733766937, 'gamma': 0.031473380488227405, 'min_child_weight': 25.882344662688546}. Best is trial 1 with value: 0.020374639823574302.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:11,357]\u001b[0m Trial 3 finished with value: 0.02076048884487489 and parameters: {'n_estimators': 571, 'max_depth': 3, 'learning_rate': 0.014510780818581107, 'colsample_bytree': 0.39423563252497573, 'subsample': 0.9041839859112399, 'alpha': 0.2551199710928685, 'lambda': 42.47791159712386, 'gamma': 6.456099143781376e-07, 'min_child_weight': 19.186061100408022}. Best is trial 3 with value: 0.02076048884487489.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:16,718]\u001b[0m Trial 4 finished with value: -0.0004507679697464736 and parameters: {'n_estimators': 805, 'max_depth': 4, 'learning_rate': 0.04609610940516087, 'colsample_bytree': 0.6996112385025346, 'subsample': 0.5343181894431391, 'alpha': 1.4156361509247717, 'lambda': 0.12206219573885889, 'gamma': 5.612116417775386e-10, 'min_child_weight': 38.59480231747363}. Best is trial 3 with value: 0.02076048884487489.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:19,991]\u001b[0m Trial 5 finished with value: 0.016795580778487876 and parameters: {'n_estimators': 632, 'max_depth': 3, 'learning_rate': 0.0393733082681064, 'colsample_bytree': 0.8561316161132698, 'subsample': 0.754041888245733, 'alpha': 20.753998879807487, 'lambda': 42.66635564611407, 'gamma': 6.5455119754754245e-06, 'min_child_weight': 2.6305756759894483}. Best is trial 3 with value: 0.02076048884487489.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:24,089]\u001b[0m Trial 6 finished with value: 0.016798473004328737 and parameters: {'n_estimators': 805, 'max_depth': 3, 'learning_rate': 0.01439112311976946, 'colsample_bytree': 0.14760620928879287, 'subsample': 0.3408132323909669, 'alpha': 8.618137766869784, 'lambda': 11.560086518366402, 'gamma': 0.30634589430301257, 'min_child_weight': 0.6289158507475836}. Best is trial 3 with value: 0.02076048884487489.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:29,250]\u001b[0m Trial 7 finished with value: 0.0067071212684111725 and parameters: {'n_estimators': 595, 'max_depth': 5, 'learning_rate': 0.04479084610173289, 'colsample_bytree': 0.6672298346672024, 'subsample': 0.9097983553968383, 'alpha': 1.306965931421392, 'lambda': 56.693722591621516, 'gamma': 0.44850773534092725, 'min_child_weight': 38.225614007310675}. Best is trial 3 with value: 0.02076048884487489.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:35,500]\u001b[0m Trial 8 finished with value: -0.007639936163013509 and parameters: {'n_estimators': 970, 'max_depth': 4, 'learning_rate': 0.04255236711128314, 'colsample_bytree': 0.45207030603566556, 'subsample': 0.37076866463033664, 'alpha': 2.164363105991835, 'lambda': 7.699653148837831, 'gamma': 1.5761358837795816e-07, 'min_child_weight': 0.1613950327860414}. Best is trial 3 with value: 0.02076048884487489.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:39,834]\u001b[0m Trial 9 finished with value: 0.008490704329593217 and parameters: {'n_estimators': 916, 'max_depth': 3, 'learning_rate': 0.0012621740452093463, 'colsample_bytree': 0.26185131998278427, 'subsample': 0.9355637968569128, 'alpha': 1.954493423875318, 'lambda': 8.342766370586949, 'gamma': 1.8662090384246062e-08, 'min_child_weight': 0.9880031912627031}. Best is trial 3 with value: 0.02076048884487489.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:42,020]\u001b[0m Trial 10 finished with value: 0.017009216489560802 and parameters: {'n_estimators': 500, 'max_depth': 2, 'learning_rate': 0.013765263303356853, 'colsample_bytree': 0.9329373919902637, 'subsample': 0.7558853636385232, 'alpha': 0.12354965948563644, 'lambda': 197.56365767984124, 'gamma': 0.0010617168425160585, 'min_child_weight': 8.04511245693784}. Best is trial 3 with value: 0.02076048884487489.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:44,704]\u001b[0m Trial 11 finished with value: 0.01970121239575845 and parameters: {'n_estimators': 657, 'max_depth': 2, 'learning_rate': 0.021140328948597957, 'colsample_bytree': 0.4193104534277997, 'subsample': 0.4679234016391863, 'alpha': 0.13867679305442723, 'lambda': 1.4423722471748288, 'gamma': 5.290174615532113e-06, 'min_child_weight': 0.17476829254489076}. Best is trial 3 with value: 0.02076048884487489.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:47,431]\u001b[0m Trial 12 finished with value: 0.02111617359632856 and parameters: {'n_estimators': 502, 'max_depth': 3, 'learning_rate': 0.028881818943109795, 'colsample_bytree': 0.5704099786595481, 'subsample': 0.7320738207841643, 'alpha': 0.3590072219759687, 'lambda': 38.227084845968385, 'gamma': 0.001537880650602972, 'min_child_weight': 0.5436131995994252}. Best is trial 12 with value: 0.02111617359632856.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:49,584]\u001b[0m Trial 13 finished with value: 0.019735270821288006 and parameters: {'n_estimators': 502, 'max_depth': 2, 'learning_rate': 0.03080022290664037, 'colsample_bytree': 0.34342912614358556, 'subsample': 0.7768556050327742, 'alpha': 0.3969762386887329, 'lambda': 51.74438400839108, 'gamma': 0.003474316679612265, 'min_child_weight': 2.9117194799039714}. Best is trial 12 with value: 0.02111617359632856.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:53,023]\u001b[0m Trial 14 finished with value: 0.02210224742800277 and parameters: {'n_estimators': 681, 'max_depth': 3, 'learning_rate': 0.012352255179372554, 'colsample_bytree': 0.630017570188665, 'subsample': 0.8263993213290479, 'alpha': 0.39241857146648035, 'lambda': 188.57096900189796, 'gamma': 1.2189481265207593e-07, 'min_child_weight': 11.760249354667314}. Best is trial 14 with value: 0.02210224742800277.\u001b[0m\n\u001b[32m[I 2022-08-25 20:33:57,853]\u001b[0m Trial 15 finished with value: 0.018420163173571587 and parameters: {'n_estimators': 725, 'max_depth': 4, 'learning_rate': 0.027811683636903343, 'colsample_bytree': 0.6412067390886769, 'subsample': 0.6785704500230905, 'alpha': 0.5799441382536388, 'lambda': 190.60998067838585, 'gamma': 1.442341322039531e-10, 'min_child_weight': 7.535519858662257}. Best is trial 14 with value: 0.02210224742800277.\u001b[0m\n\u001b[32m[I 2022-08-25 20:34:00,720]\u001b[0m Trial 16 finished with value: 0.018499925763758095 and parameters: {'n_estimators': 687, 'max_depth': 2, 'learning_rate': 0.007269126662245471, 'colsample_bytree': 0.76669650878831, 'subsample': 0.811313389754864, 'alpha': 0.829691378417447, 'lambda': 100.12577013808027, 'gamma': 6.397556987948785, 'min_child_weight': 1.385230138114048}. Best is trial 14 with value: 0.02210224742800277.\u001b[0m\n\u001b[32m[I 2022-08-25 20:34:04,416]\u001b[0m Trial 17 finished with value: 0.0202391504026533 and parameters: {'n_estimators': 750, 'max_depth': 3, 'learning_rate': 0.01970242246739156, 'colsample_bytree': 0.5676191293345482, 'subsample': 0.6747834052171436, 'alpha': 0.2540829784480251, 'lambda': 21.327661316054005, 'gamma': 6.348261537555616e-09, 'min_child_weight': 0.33343840620496595}. Best is trial 14 with value: 0.02210224742800277.\u001b[0m\n\u001b[32m[I 2022-08-25 20:34:08,830]\u001b[0m Trial 18 finished with value: 0.010314808077421304 and parameters: {'n_estimators': 553, 'max_depth': 4, 'learning_rate': 0.03590692278152806, 'colsample_bytree': 0.7787418574912003, 'subsample': 0.6639682411872041, 'alpha': 3.2256111599631474, 'lambda': 1.6200348803978861, 'gamma': 0.0004973614032902294, 'min_child_weight': 4.03310164862797}. Best is trial 14 with value: 0.02210224742800277.\u001b[0m\n\u001b[32m[I 2022-08-25 20:34:11,810]\u001b[0m Trial 19 finished with value: 0.015339636422353265 and parameters: {'n_estimators': 736, 'max_depth': 2, 'learning_rate': 0.04984872034958527, 'colsample_bytree': 0.6140218618142853, 'subsample': 0.8540925177035236, 'alpha': 0.2667416509555533, 'lambda': 0.16845088073981446, 'gamma': 4.433472625257446e-07, 'min_child_weight': 14.930153631130294}. Best is trial 14 with value: 0.02210224742800277.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  79.07651734352112\n        n_estimators : 681\n           max_depth : 3\n       learning_rate : 0.012352255179372554\n    colsample_bytree : 0.630017570188665\n           subsample : 0.8263993213290479\n               alpha : 0.39241857146648035\n              lambda : 188.57096900189796\n               gamma : 1.2189481265207593e-07\n    min_child_weight : 11.760249354667314\nbest objective value : 0.02210224742800277\nOptuna XGB train: 8.438046684016827 0.03911375520040972 80.86829543113708\nMin_prd:  175\nConstant guess:  8.25713871823768 0.0\nXGB test: 8.288244243217152 -0.008671408117530532\nXGB GS test: 8.282135384707418 -0.002783352890953994\nOptuna XGB test: 8.279505662507296 -0.0008202101224408231\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(74160, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd     mom482     mom242  year      RET   ind        bm  \\\n124   10006  199 -21.326783 -27.592396  1974   7.4600  25.0 -0.095507   \n125   10006  200 -15.979064 -20.880103  1974 -14.9857  25.0 -0.095507   \n126   10006  201 -25.154673 -19.973751  1975  22.5261  25.0 -0.095507   \n127   10006  202 -15.116342  -6.138191  1975   5.7854  25.0 -0.095507   \n128   10006  203 -18.160941  -9.913526  1975  -3.6453  25.0 -0.095507   \n\n           op       gp       inv    mom11     mom122      amhd  ivol_capm  \\\n124  0.111088  0.19813  0.145981  14.5694 -33.892050  2.612473   2.720668   \n125  0.111088  0.19813  0.145981   7.4600 -10.641475  2.712756   2.445177   \n126  0.111088  0.19813  0.145981 -14.9857 -34.175124  2.796417   1.958997   \n127  0.111088  0.19813  0.145981  22.5261 -43.065927  2.849530   1.996934   \n128  0.111088  0.19813  0.145981   5.7854 -26.745104  2.862670   2.014875   \n\n     ivol_ff5   beta_bw     MAX     vol1m     vol6m    vol12m      size  \\\n124  2.269109  0.912102  5.8604  2.919359  2.337286  2.451826  5.314277   \n125  2.150569  0.895589  5.0044  2.517541  2.414667  2.482452  5.378412   \n126  1.641160  0.853395  3.7549  2.233901  2.438581  2.319402  5.224262   \n127  1.390339  0.798751  6.7922  1.687576  2.442646  2.256743  5.432138   \n128  1.868052  0.806562  4.9189  2.116001  2.397099  2.261266  5.477258   \n\n          lbm       lop       lgp      linv      llme    l1amhd   l1MAX  \\\n124  0.012504  0.109494  0.199984  0.018882  5.573985  2.463967  3.2387   \n125  0.012504  0.109494  0.199984  0.018882  5.400138  2.612473  5.8604   \n126  0.012504  0.109494  0.199984  0.018882  5.782123  2.712756  5.0044   \n127  0.012504  0.109494  0.199984  0.018882  5.771265  2.796417  3.7549   \n128  0.012504  0.109494  0.199984  0.018882  5.717440  2.849530  6.7922   \n\n       l3amhd   l3MAX    l6amhd   l6MAX   l12amhd  l12MAX  l12mom122  \\\n124  2.372470  6.6347  2.400974  3.3731  2.461242  3.2387 -10.931905   \n125  2.411410  5.1454  2.349388  2.6834  2.454348  5.8604  -4.724409   \n126  2.463967  3.2387  2.386218  3.9473  2.464810  5.0044 -17.450559   \n127  2.612473  5.8604  2.372470  6.6347  2.433094  3.7549  28.761815   \n128  2.712756  5.0044  2.411410  5.1454  2.395316  6.7922  37.577008   \n\n     l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n124      1.703990     1.341432    0.816881  1.535675   1.535648  \n125      1.712226     1.619320    0.855923  1.606818   1.565273  \n126      2.707695     2.404910    0.931452  2.173476   1.863954  \n127      1.482107     1.414542    1.011982  2.404947   2.013676  \n128      2.066732     1.866476    0.992914  2.510439   2.032948  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>124</th>\n      <td>10006</td>\n      <td>199</td>\n      <td>-21.326783</td>\n      <td>-27.592396</td>\n      <td>1974</td>\n      <td>7.4600</td>\n      <td>25.0</td>\n      <td>-0.095507</td>\n      <td>0.111088</td>\n      <td>0.19813</td>\n      <td>0.145981</td>\n      <td>14.5694</td>\n      <td>-33.892050</td>\n      <td>2.612473</td>\n      <td>2.720668</td>\n      <td>2.269109</td>\n      <td>0.912102</td>\n      <td>5.8604</td>\n      <td>2.919359</td>\n      <td>2.337286</td>\n      <td>2.451826</td>\n      <td>5.314277</td>\n      <td>0.012504</td>\n      <td>0.109494</td>\n      <td>0.199984</td>\n      <td>0.018882</td>\n      <td>5.573985</td>\n      <td>2.463967</td>\n      <td>3.2387</td>\n      <td>2.372470</td>\n      <td>6.6347</td>\n      <td>2.400974</td>\n      <td>3.3731</td>\n      <td>2.461242</td>\n      <td>3.2387</td>\n      <td>-10.931905</td>\n      <td>1.703990</td>\n      <td>1.341432</td>\n      <td>0.816881</td>\n      <td>1.535675</td>\n      <td>1.535648</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>10006</td>\n      <td>200</td>\n      <td>-15.979064</td>\n      <td>-20.880103</td>\n      <td>1974</td>\n      <td>-14.9857</td>\n      <td>25.0</td>\n      <td>-0.095507</td>\n      <td>0.111088</td>\n      <td>0.19813</td>\n      <td>0.145981</td>\n      <td>7.4600</td>\n      <td>-10.641475</td>\n      <td>2.712756</td>\n      <td>2.445177</td>\n      <td>2.150569</td>\n      <td>0.895589</td>\n      <td>5.0044</td>\n      <td>2.517541</td>\n      <td>2.414667</td>\n      <td>2.482452</td>\n      <td>5.378412</td>\n      <td>0.012504</td>\n      <td>0.109494</td>\n      <td>0.199984</td>\n      <td>0.018882</td>\n      <td>5.400138</td>\n      <td>2.612473</td>\n      <td>5.8604</td>\n      <td>2.411410</td>\n      <td>5.1454</td>\n      <td>2.349388</td>\n      <td>2.6834</td>\n      <td>2.454348</td>\n      <td>5.8604</td>\n      <td>-4.724409</td>\n      <td>1.712226</td>\n      <td>1.619320</td>\n      <td>0.855923</td>\n      <td>1.606818</td>\n      <td>1.565273</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>10006</td>\n      <td>201</td>\n      <td>-25.154673</td>\n      <td>-19.973751</td>\n      <td>1975</td>\n      <td>22.5261</td>\n      <td>25.0</td>\n      <td>-0.095507</td>\n      <td>0.111088</td>\n      <td>0.19813</td>\n      <td>0.145981</td>\n      <td>-14.9857</td>\n      <td>-34.175124</td>\n      <td>2.796417</td>\n      <td>1.958997</td>\n      <td>1.641160</td>\n      <td>0.853395</td>\n      <td>3.7549</td>\n      <td>2.233901</td>\n      <td>2.438581</td>\n      <td>2.319402</td>\n      <td>5.224262</td>\n      <td>0.012504</td>\n      <td>0.109494</td>\n      <td>0.199984</td>\n      <td>0.018882</td>\n      <td>5.782123</td>\n      <td>2.712756</td>\n      <td>5.0044</td>\n      <td>2.463967</td>\n      <td>3.2387</td>\n      <td>2.386218</td>\n      <td>3.9473</td>\n      <td>2.464810</td>\n      <td>5.0044</td>\n      <td>-17.450559</td>\n      <td>2.707695</td>\n      <td>2.404910</td>\n      <td>0.931452</td>\n      <td>2.173476</td>\n      <td>1.863954</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>10006</td>\n      <td>202</td>\n      <td>-15.116342</td>\n      <td>-6.138191</td>\n      <td>1975</td>\n      <td>5.7854</td>\n      <td>25.0</td>\n      <td>-0.095507</td>\n      <td>0.111088</td>\n      <td>0.19813</td>\n      <td>0.145981</td>\n      <td>22.5261</td>\n      <td>-43.065927</td>\n      <td>2.849530</td>\n      <td>1.996934</td>\n      <td>1.390339</td>\n      <td>0.798751</td>\n      <td>6.7922</td>\n      <td>1.687576</td>\n      <td>2.442646</td>\n      <td>2.256743</td>\n      <td>5.432138</td>\n      <td>0.012504</td>\n      <td>0.109494</td>\n      <td>0.199984</td>\n      <td>0.018882</td>\n      <td>5.771265</td>\n      <td>2.796417</td>\n      <td>3.7549</td>\n      <td>2.612473</td>\n      <td>5.8604</td>\n      <td>2.372470</td>\n      <td>6.6347</td>\n      <td>2.433094</td>\n      <td>3.7549</td>\n      <td>28.761815</td>\n      <td>1.482107</td>\n      <td>1.414542</td>\n      <td>1.011982</td>\n      <td>2.404947</td>\n      <td>2.013676</td>\n    </tr>\n    <tr>\n      <th>128</th>\n      <td>10006</td>\n      <td>203</td>\n      <td>-18.160941</td>\n      <td>-9.913526</td>\n      <td>1975</td>\n      <td>-3.6453</td>\n      <td>25.0</td>\n      <td>-0.095507</td>\n      <td>0.111088</td>\n      <td>0.19813</td>\n      <td>0.145981</td>\n      <td>5.7854</td>\n      <td>-26.745104</td>\n      <td>2.862670</td>\n      <td>2.014875</td>\n      <td>1.868052</td>\n      <td>0.806562</td>\n      <td>4.9189</td>\n      <td>2.116001</td>\n      <td>2.397099</td>\n      <td>2.261266</td>\n      <td>5.477258</td>\n      <td>0.012504</td>\n      <td>0.109494</td>\n      <td>0.199984</td>\n      <td>0.018882</td>\n      <td>5.717440</td>\n      <td>2.849530</td>\n      <td>6.7922</td>\n      <td>2.712756</td>\n      <td>5.0044</td>\n      <td>2.411410</td>\n      <td>5.1454</td>\n      <td>2.395316</td>\n      <td>6.7922</td>\n      <td>37.577008</td>\n      <td>2.066732</td>\n      <td>1.866476</td>\n      <td>0.992914</td>\n      <td>2.510439</td>\n      <td>2.032948</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    74160.000000\nmean      1976.049757\nstd          0.951021\nmin       1974.000000\n25%       1975.000000\n50%       1976.000000\n75%       1977.000000\nmax       1978.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          74160\nprd             74160\nmom482          54046\nmom242          71549\nyear            74160\nRET             74160\nind             74160\nbm              74160\nop              74160\ngp              74160\ninv             74145\nmom11           74160\nmom122          74160\namhd            45795\nivol_capm       74145\nivol_ff5        74145\nbeta_bw         74160\nMAX             74160\nvol1m           74124\nvol6m           74103\nvol12m          74048\nsize            74160\nlbm             74160\nlop             74160\nlgp             74160\nlinv            74160\nllme            74160\nl1amhd          45652\nl1MAX           74158\nl3amhd          45391\nl3MAX           74149\nl6amhd          45090\nl6MAX           74127\nl12amhd         45135\nl12MAX          74158\nl12mom122       72354\nl12ivol_capm    74063\nl12ivol_ff5     74063\nl12beta_bw      74101\nl12vol6m        73795\nl12vol12m       71835\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (69310, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (69310, 85)\nmae of a constant model 7.861186206831879\nR2 of a constant model 0.0\nXGB train: 7.600086536833699 0.10428903353658525\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\nXGB {'colsample_bytree': 0.6, 'eta': 0.012, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.01848511126796154 40.80734419822693\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:34:58,537]\u001b[0m A new study created in memory with name: no-name-7b087586-0e0e-42f6-aaf6-aa722ea1e219\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 7.731967824273231 0.06495266870263083 41.918771743774414\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:35:06,759]\u001b[0m Trial 0 finished with value: -0.017480878919772437 and parameters: {'n_estimators': 835, 'max_depth': 5, 'learning_rate': 0.048413636947056665, 'colsample_bytree': 0.34244229462823017, 'subsample': 0.7648419304842575, 'alpha': 17.07778781810277, 'lambda': 6.243702986672548, 'gamma': 0.3363649898490194, 'min_child_weight': 5.030066166702621}. Best is trial 0 with value: -0.017480878919772437.\u001b[0m\n\u001b[32m[I 2022-08-25 20:35:14,505]\u001b[0m Trial 1 finished with value: 0.013755001573807563 and parameters: {'n_estimators': 795, 'max_depth': 5, 'learning_rate': 0.00761188937345186, 'colsample_bytree': 0.17320538707515393, 'subsample': 0.4862969292505399, 'alpha': 9.640530254327272, 'lambda': 115.77951708351858, 'gamma': 0.00034832353843975046, 'min_child_weight': 0.24449324289712906}. Best is trial 1 with value: 0.013755001573807563.\u001b[0m\n\u001b[32m[I 2022-08-25 20:35:20,157]\u001b[0m Trial 2 finished with value: 0.0151619776721157 and parameters: {'n_estimators': 563, 'max_depth': 5, 'learning_rate': 0.0050173738906820415, 'colsample_bytree': 0.3924659952635474, 'subsample': 0.5210584668057889, 'alpha': 24.067548709908237, 'lambda': 6.207347137974942, 'gamma': 1.916437525097666e-05, 'min_child_weight': 0.13026703233168657}. Best is trial 2 with value: 0.0151619776721157.\u001b[0m\n\u001b[32m[I 2022-08-25 20:35:27,591]\u001b[0m Trial 3 finished with value: 0.0031870915751818062 and parameters: {'n_estimators': 750, 'max_depth': 5, 'learning_rate': 0.026650428993984468, 'colsample_bytree': 0.407251412288127, 'subsample': 0.7162250214093671, 'alpha': 7.6367080543133055, 'lambda': 9.011418592331234, 'gamma': 0.0044065412004384175, 'min_child_weight': 0.45438993185702314}. Best is trial 2 with value: 0.0151619776721157.\u001b[0m\n\u001b[32m[I 2022-08-25 20:35:32,340]\u001b[0m Trial 4 finished with value: 0.016289454064616363 and parameters: {'n_estimators': 644, 'max_depth': 4, 'learning_rate': 0.003567597519292111, 'colsample_bytree': 0.9391713475226822, 'subsample': 0.47756823338305215, 'alpha': 0.2318314220373237, 'lambda': 3.2570048381870285, 'gamma': 0.004740881684304755, 'min_child_weight': 10.148655265325896}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:35:37,868]\u001b[0m Trial 5 finished with value: 0.014949062103369153 and parameters: {'n_estimators': 538, 'max_depth': 5, 'learning_rate': 0.014419232298695173, 'colsample_bytree': 0.3990786601509507, 'subsample': 0.6840999763866289, 'alpha': 0.3235704569779428, 'lambda': 100.56976629260717, 'gamma': 4.252231991839215e-08, 'min_child_weight': 0.5144166737916612}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:35:43,324]\u001b[0m Trial 6 finished with value: 0.012228781419628207 and parameters: {'n_estimators': 567, 'max_depth': 5, 'learning_rate': 0.00797801739453708, 'colsample_bytree': 0.2981708691573653, 'subsample': 0.738380183988242, 'alpha': 0.7882352388011925, 'lambda': 0.11132201591682703, 'gamma': 0.1867395000572846, 'min_child_weight': 0.9332134552743206}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:35:48,512]\u001b[0m Trial 7 finished with value: 0.012875143486220555 and parameters: {'n_estimators': 943, 'max_depth': 3, 'learning_rate': 0.016274533522941476, 'colsample_bytree': 0.7255055441905697, 'subsample': 0.30569623139808716, 'alpha': 6.589057931815592, 'lambda': 4.616804122946398, 'gamma': 9.941729821239304e-07, 'min_child_weight': 23.825980015904996}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:35:58,657]\u001b[0m Trial 8 finished with value: -0.04540837413336775 and parameters: {'n_estimators': 977, 'max_depth': 5, 'learning_rate': 0.04933163132411877, 'colsample_bytree': 0.8960101335115087, 'subsample': 0.4118785648698896, 'alpha': 0.21706569941737414, 'lambda': 0.26677917967107934, 'gamma': 1.1153897855923505e-10, 'min_child_weight': 2.280691208463637}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:36:02,282]\u001b[0m Trial 9 finished with value: 0.009363609818849794 and parameters: {'n_estimators': 637, 'max_depth': 3, 'learning_rate': 0.0419123783638042, 'colsample_bytree': 0.7764441690169672, 'subsample': 0.9381113630021125, 'alpha': 1.0372150088905443, 'lambda': 1.2136007357553653, 'gamma': 0.0005797683151589998, 'min_child_weight': 0.29821348981935814}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:36:05,426]\u001b[0m Trial 10 finished with value: 0.015757697363638034 and parameters: {'n_estimators': 688, 'max_depth': 2, 'learning_rate': 0.02949793778678942, 'colsample_bytree': 0.610579821686323, 'subsample': 0.5835203702259182, 'alpha': 0.14567225011115237, 'lambda': 0.8230654382493774, 'gamma': 1.8897858724960288, 'min_child_weight': 37.04322381027228}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:36:08,801]\u001b[0m Trial 11 finished with value: 0.014427116599008596 and parameters: {'n_estimators': 691, 'max_depth': 2, 'learning_rate': 0.03165778241947768, 'colsample_bytree': 0.62809171679478, 'subsample': 0.538667134498947, 'alpha': 0.10468603809200251, 'lambda': 0.9229848068536036, 'gamma': 6.645303529051625, 'min_child_weight': 48.04932087851388}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:36:12,410]\u001b[0m Trial 12 finished with value: 0.013028379138585535 and parameters: {'n_estimators': 676, 'max_depth': 2, 'learning_rate': 0.03301677957522743, 'colsample_bytree': 0.9217697265328375, 'subsample': 0.5853624352715869, 'alpha': 0.11288012258462296, 'lambda': 0.5849517677230047, 'gamma': 0.057950073948116056, 'min_child_weight': 12.918402459353947}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:36:16,878]\u001b[0m Trial 13 finished with value: 0.013752265420968813 and parameters: {'n_estimators': 627, 'max_depth': 4, 'learning_rate': 0.019359809760841278, 'colsample_bytree': 0.5779125514613912, 'subsample': 0.3876776721337096, 'alpha': 0.40819179895062635, 'lambda': 24.349632349587303, 'gamma': 3.224670908479292, 'min_child_weight': 9.156050242068025}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:36:22,501]\u001b[0m Trial 14 finished with value: 0.01072210751819912 and parameters: {'n_estimators': 748, 'max_depth': 4, 'learning_rate': 0.02432108564667466, 'colsample_bytree': 0.7709060183826079, 'subsample': 0.6433696974062779, 'alpha': 2.976551379188293, 'lambda': 1.8441489500997215, 'gamma': 0.010099315535435121, 'min_child_weight': 47.75512157333077}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:36:27,238]\u001b[0m Trial 15 finished with value: 0.008582798765886902 and parameters: {'n_estimators': 881, 'max_depth': 3, 'learning_rate': 0.0011630584466711027, 'colsample_bytree': 0.5022774153928171, 'subsample': 0.44558937474178867, 'alpha': 0.5778961248327661, 'lambda': 32.99034351393998, 'gamma': 2.35213895103114e-05, 'min_child_weight': 3.7826903473103135}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:36:32,335]\u001b[0m Trial 16 finished with value: 0.00036611402533621995 and parameters: {'n_estimators': 693, 'max_depth': 4, 'learning_rate': 0.03567176578848965, 'colsample_bytree': 0.6791256912851698, 'subsample': 0.595577645840666, 'alpha': 1.7203478909327472, 'lambda': 2.245355651512584, 'gamma': 0.42020892431574575, 'min_child_weight': 15.243835568198467}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:36:34,874]\u001b[0m Trial 17 finished with value: 0.015551369513596343 and parameters: {'n_estimators': 507, 'max_depth': 2, 'learning_rate': 0.02522908263313803, 'colsample_bytree': 0.8170200238216265, 'subsample': 0.8272128116003005, 'alpha': 0.2110400577074528, 'lambda': 0.28213056634879596, 'gamma': 0.0038567276602919334, 'min_child_weight': 25.72723688534202}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:36:38,383]\u001b[0m Trial 18 finished with value: 0.009564507477562267 and parameters: {'n_estimators': 626, 'max_depth': 3, 'learning_rate': 0.03794079692036145, 'colsample_bytree': 0.5593487121707716, 'subsample': 0.3186917779334927, 'alpha': 0.18669877210385316, 'lambda': 17.519624163490057, 'gamma': 9.798264635823848, 'min_child_weight': 7.2024199378073845}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n\u001b[32m[I 2022-08-25 20:36:43,525]\u001b[0m Trial 19 finished with value: 0.014098786768907294 and parameters: {'n_estimators': 746, 'max_depth': 4, 'learning_rate': 0.011877225252914677, 'colsample_bytree': 0.1300886844995942, 'subsample': 0.5459725344936935, 'alpha': 1.5371309005207638, 'lambda': 0.45548289816880044, 'gamma': 1.5322955066346292e-06, 'min_child_weight': 1.8896563583173922}. Best is trial 4 with value: 0.016289454064616363.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  104.98953151702881\n        n_estimators : 644\n           max_depth : 4\n       learning_rate : 0.003567597519292111\n    colsample_bytree : 0.9391713475226822\n           subsample : 0.47756823338305215\n               alpha : 0.2318314220373237\n              lambda : 3.2570048381870285\n               gamma : 0.004740881684304755\n    min_child_weight : 10.148655265325896\nbest objective value : 0.016289454064616363\nOptuna XGB train: 7.836983763119917 0.030940659282065797 107.67837500572205\nMin_prd:  200\nConstant guess:  6.8284052824169645 0.0\nXGB test: 6.723532156790887 0.012098797248819793\nXGB GS test: 6.736076781695843 0.010889794009659393\nOptuna XGB test: 6.758095387179109 0.007636890323768797\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(86617, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd     mom482     mom242  year     RET   ind        bm  \\\n149   10006  224  -2.366213  38.903820  1976  9.7961  25.0  0.487787   \n150   10006  225  21.818300  31.999660  1977  1.0635  25.0  0.487787   \n151   10006  226  21.822937  25.721451  1977 -2.5956  25.0  0.487787   \n152   10006  227  15.859033  31.116312  1977 -0.0164  25.0  0.487787   \n153   10006  228  13.940975  34.038497  1977  4.6925  25.0  0.487787   \n\n           op        gp       inv   mom11     mom122      amhd  ivol_capm  \\\n149  0.124561  0.219545  0.023495  0.6156  24.003392  1.901191   0.984374   \n150  0.124561  0.219545  0.023495  9.7961  25.368526  1.914337   1.215784   \n151  0.124561  0.219545  0.023495  1.0635  14.105366  1.897737   0.815442   \n152  0.124561  0.219545  0.023495 -2.5956  11.744288  1.907512   1.593928   \n153  0.124561  0.219545  0.023495 -0.0164   5.392767  1.922541   1.202520   \n\n     ivol_ff5   beta_bw     MAX     vol1m     vol6m    vol12m      size  \\\n149  0.787596  0.802318  2.7468  1.211152  1.164005  1.364113  5.622267   \n150  1.011524  0.828570  2.6743  1.243655  1.191593  1.385471  5.719358   \n151  0.700757  0.781620  2.1569  0.866870  1.158762  1.189728  5.733493   \n152  1.484515  0.778512  4.8943  1.578993  1.259617  1.189544  5.697775   \n153  1.060071  0.771213  1.8924  1.243518  1.228898  1.189544  5.701405   \n\n          lbm       lop       lgp      linv      llme    l1amhd   l1MAX  \\\n149  0.562476  0.107357  0.197156  0.162551  5.391124  1.931497  1.4516   \n150  0.562476  0.107357  0.197156  0.162551  5.391124  1.901191  2.7468   \n151  0.562476  0.107357  0.197156  0.162551  5.582603  1.914337  2.6743   \n152  0.562476  0.107357  0.197156  0.162551  5.603824  1.897737  2.1569   \n153  0.562476  0.107357  0.197156  0.162551  5.639910  1.907512  4.8943   \n\n       l3amhd   l3MAX    l6amhd   l6MAX   l12amhd  l12MAX  l12mom122  \\\n149  1.895809  2.1869  2.025173  1.4066  2.413926  1.4516  -1.586476   \n150  1.889733  2.5620  1.985085  3.9655  2.252034  2.7468  18.010264   \n151  1.931497  1.4516  1.970979  1.7263  2.171167  2.6743  -4.147920   \n152  1.901191  2.7468  1.895809  2.1869  2.125732  2.1569   9.306295   \n153  1.914337  2.6743  1.889733  2.5620  2.078258  4.8943  17.070464   \n\n     l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n149      1.154582     1.120293    0.842820  1.482218   1.779160  \n150      0.891562     0.775986    0.772055  1.400632   1.614133  \n151      2.437163     2.002417    0.814432  1.668506   1.703926  \n152      1.674217     1.578206    0.804047  1.694692   1.667251  \n153      1.304524     1.025788    0.812099  1.607106   1.619101  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>149</th>\n      <td>10006</td>\n      <td>224</td>\n      <td>-2.366213</td>\n      <td>38.903820</td>\n      <td>1976</td>\n      <td>9.7961</td>\n      <td>25.0</td>\n      <td>0.487787</td>\n      <td>0.124561</td>\n      <td>0.219545</td>\n      <td>0.023495</td>\n      <td>0.6156</td>\n      <td>24.003392</td>\n      <td>1.901191</td>\n      <td>0.984374</td>\n      <td>0.787596</td>\n      <td>0.802318</td>\n      <td>2.7468</td>\n      <td>1.211152</td>\n      <td>1.164005</td>\n      <td>1.364113</td>\n      <td>5.622267</td>\n      <td>0.562476</td>\n      <td>0.107357</td>\n      <td>0.197156</td>\n      <td>0.162551</td>\n      <td>5.391124</td>\n      <td>1.931497</td>\n      <td>1.4516</td>\n      <td>1.895809</td>\n      <td>2.1869</td>\n      <td>2.025173</td>\n      <td>1.4066</td>\n      <td>2.413926</td>\n      <td>1.4516</td>\n      <td>-1.586476</td>\n      <td>1.154582</td>\n      <td>1.120293</td>\n      <td>0.842820</td>\n      <td>1.482218</td>\n      <td>1.779160</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>10006</td>\n      <td>225</td>\n      <td>21.818300</td>\n      <td>31.999660</td>\n      <td>1977</td>\n      <td>1.0635</td>\n      <td>25.0</td>\n      <td>0.487787</td>\n      <td>0.124561</td>\n      <td>0.219545</td>\n      <td>0.023495</td>\n      <td>9.7961</td>\n      <td>25.368526</td>\n      <td>1.914337</td>\n      <td>1.215784</td>\n      <td>1.011524</td>\n      <td>0.828570</td>\n      <td>2.6743</td>\n      <td>1.243655</td>\n      <td>1.191593</td>\n      <td>1.385471</td>\n      <td>5.719358</td>\n      <td>0.562476</td>\n      <td>0.107357</td>\n      <td>0.197156</td>\n      <td>0.162551</td>\n      <td>5.391124</td>\n      <td>1.901191</td>\n      <td>2.7468</td>\n      <td>1.889733</td>\n      <td>2.5620</td>\n      <td>1.985085</td>\n      <td>3.9655</td>\n      <td>2.252034</td>\n      <td>2.7468</td>\n      <td>18.010264</td>\n      <td>0.891562</td>\n      <td>0.775986</td>\n      <td>0.772055</td>\n      <td>1.400632</td>\n      <td>1.614133</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>10006</td>\n      <td>226</td>\n      <td>21.822937</td>\n      <td>25.721451</td>\n      <td>1977</td>\n      <td>-2.5956</td>\n      <td>25.0</td>\n      <td>0.487787</td>\n      <td>0.124561</td>\n      <td>0.219545</td>\n      <td>0.023495</td>\n      <td>1.0635</td>\n      <td>14.105366</td>\n      <td>1.897737</td>\n      <td>0.815442</td>\n      <td>0.700757</td>\n      <td>0.781620</td>\n      <td>2.1569</td>\n      <td>0.866870</td>\n      <td>1.158762</td>\n      <td>1.189728</td>\n      <td>5.733493</td>\n      <td>0.562476</td>\n      <td>0.107357</td>\n      <td>0.197156</td>\n      <td>0.162551</td>\n      <td>5.582603</td>\n      <td>1.914337</td>\n      <td>2.6743</td>\n      <td>1.931497</td>\n      <td>1.4516</td>\n      <td>1.970979</td>\n      <td>1.7263</td>\n      <td>2.171167</td>\n      <td>2.6743</td>\n      <td>-4.147920</td>\n      <td>2.437163</td>\n      <td>2.002417</td>\n      <td>0.814432</td>\n      <td>1.668506</td>\n      <td>1.703926</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>10006</td>\n      <td>227</td>\n      <td>15.859033</td>\n      <td>31.116312</td>\n      <td>1977</td>\n      <td>-0.0164</td>\n      <td>25.0</td>\n      <td>0.487787</td>\n      <td>0.124561</td>\n      <td>0.219545</td>\n      <td>0.023495</td>\n      <td>-2.5956</td>\n      <td>11.744288</td>\n      <td>1.907512</td>\n      <td>1.593928</td>\n      <td>1.484515</td>\n      <td>0.778512</td>\n      <td>4.8943</td>\n      <td>1.578993</td>\n      <td>1.259617</td>\n      <td>1.189544</td>\n      <td>5.697775</td>\n      <td>0.562476</td>\n      <td>0.107357</td>\n      <td>0.197156</td>\n      <td>0.162551</td>\n      <td>5.603824</td>\n      <td>1.897737</td>\n      <td>2.1569</td>\n      <td>1.901191</td>\n      <td>2.7468</td>\n      <td>1.895809</td>\n      <td>2.1869</td>\n      <td>2.125732</td>\n      <td>2.1569</td>\n      <td>9.306295</td>\n      <td>1.674217</td>\n      <td>1.578206</td>\n      <td>0.804047</td>\n      <td>1.694692</td>\n      <td>1.667251</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>10006</td>\n      <td>228</td>\n      <td>13.940975</td>\n      <td>34.038497</td>\n      <td>1977</td>\n      <td>4.6925</td>\n      <td>25.0</td>\n      <td>0.487787</td>\n      <td>0.124561</td>\n      <td>0.219545</td>\n      <td>0.023495</td>\n      <td>-0.0164</td>\n      <td>5.392767</td>\n      <td>1.922541</td>\n      <td>1.202520</td>\n      <td>1.060071</td>\n      <td>0.771213</td>\n      <td>1.8924</td>\n      <td>1.243518</td>\n      <td>1.228898</td>\n      <td>1.189544</td>\n      <td>5.701405</td>\n      <td>0.562476</td>\n      <td>0.107357</td>\n      <td>0.197156</td>\n      <td>0.162551</td>\n      <td>5.639910</td>\n      <td>1.907512</td>\n      <td>4.8943</td>\n      <td>1.914337</td>\n      <td>2.6743</td>\n      <td>1.889733</td>\n      <td>2.5620</td>\n      <td>2.078258</td>\n      <td>4.8943</td>\n      <td>17.070464</td>\n      <td>1.304524</td>\n      <td>1.025788</td>\n      <td>0.812099</td>\n      <td>1.607106</td>\n      <td>1.619101</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    86617.000000\nmean      1978.074396\nstd          0.947723\nmin       1976.000000\n25%       1977.000000\n50%       1978.000000\n75%       1979.000000\nmax       1980.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          86617\nprd             86617\nmom482          72687\nmom242          84429\nyear            86617\nRET             86617\nind             86617\nbm              86617\nop              86617\ngp              86617\ninv             86574\nmom11           86617\nmom122          86617\namhd            49136\nivol_capm       86601\nivol_ff5        86601\nbeta_bw         86617\nMAX             86617\nvol1m           86551\nvol6m           86496\nvol12m          86386\nsize            86617\nlbm             86617\nlop             86617\nlgp             86617\nlinv            86617\nllme            86617\nl1amhd          48938\nl1MAX           86613\nl3amhd          48550\nl3MAX           86592\nl6amhd          47948\nl6MAX           86568\nl12amhd         46559\nl12MAX          86613\nl12mom122       82984\nl12ivol_capm    86431\nl12ivol_ff5     86431\nl12beta_bw      86509\nl12vol6m        86014\nl12vol12m       85416\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (82013, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (82013, 85)\nmae of a constant model 7.7454386005664935\nR2 of a constant model 0.0\nXGB train: 7.384893941000947 0.0828598058566341\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\nXGB {'colsample_bytree': 0.6, 'eta': 0.012, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.013254809837052517 43.72090935707092\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:37:34,612]\u001b[0m A new study created in memory with name: no-name-9f7db972-f75c-4494-8bf3-dc44987488f8\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 7.483541971299699 0.053299962005836754 45.05655264854431\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:37:39,591]\u001b[0m Trial 0 finished with value: 0.011794808934071426 and parameters: {'n_estimators': 622, 'max_depth': 4, 'learning_rate': 0.016958475971440366, 'colsample_bytree': 0.13371013751424343, 'subsample': 0.8384707775972222, 'alpha': 0.12819699545139285, 'lambda': 19.429037240979593, 'gamma': 0.49533111883986464, 'min_child_weight': 1.2598683978033811}. Best is trial 0 with value: 0.011794808934071426.\u001b[0m\n\u001b[32m[I 2022-08-25 20:37:44,452]\u001b[0m Trial 1 finished with value: 0.012672678305798636 and parameters: {'n_estimators': 859, 'max_depth': 3, 'learning_rate': 0.01014131486519938, 'colsample_bytree': 0.12255263234902204, 'subsample': 0.470355892022717, 'alpha': 0.3622937164385349, 'lambda': 0.6516320681240616, 'gamma': 8.027898109114712e-08, 'min_child_weight': 26.589155297801575}. Best is trial 1 with value: 0.012672678305798636.\u001b[0m\n\u001b[32m[I 2022-08-25 20:37:54,811]\u001b[0m Trial 2 finished with value: 0.013596185898776883 and parameters: {'n_estimators': 963, 'max_depth': 5, 'learning_rate': 0.010694609234586209, 'colsample_bytree': 0.8793453128310107, 'subsample': 0.3883406064078038, 'alpha': 0.3186556431485726, 'lambda': 118.15567382945247, 'gamma': 3.821422409727154e-09, 'min_child_weight': 10.950778695037108}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:37:59,970]\u001b[0m Trial 3 finished with value: 0.009253809300778675 and parameters: {'n_estimators': 865, 'max_depth': 3, 'learning_rate': 0.0018853358306778014, 'colsample_bytree': 0.4496557959861741, 'subsample': 0.8382030315624704, 'alpha': 2.941521775175162, 'lambda': 0.21032198054338275, 'gamma': 0.29689904215653573, 'min_child_weight': 29.096832220456523}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:38:02,828]\u001b[0m Trial 4 finished with value: 0.013370082871746009 and parameters: {'n_estimators': 563, 'max_depth': 2, 'learning_rate': 0.04685478902647342, 'colsample_bytree': 0.3439073683311372, 'subsample': 0.8999058200866414, 'alpha': 4.681597973421191, 'lambda': 0.8658934808901421, 'gamma': 0.0005746448216590015, 'min_child_weight': 0.16168401774182864}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:38:08,162]\u001b[0m Trial 5 finished with value: 0.006630803443527318 and parameters: {'n_estimators': 917, 'max_depth': 3, 'learning_rate': 0.04160818119266227, 'colsample_bytree': 0.6684432457596814, 'subsample': 0.768725793124354, 'alpha': 9.030305348460052, 'lambda': 2.0283662096389805, 'gamma': 7.343234014338153e-05, 'min_child_weight': 0.9139900784592797}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:38:16,352]\u001b[0m Trial 6 finished with value: -0.0026661743601163867 and parameters: {'n_estimators': 746, 'max_depth': 5, 'learning_rate': 0.03182116637062295, 'colsample_bytree': 0.3282387024366764, 'subsample': 0.8520681779670924, 'alpha': 0.46031688121007647, 'lambda': 0.3195292284635068, 'gamma': 6.9960667162113035, 'min_child_weight': 7.1478028600590635}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:38:23,140]\u001b[0m Trial 7 finished with value: -0.014015169450408852 and parameters: {'n_estimators': 663, 'max_depth': 5, 'learning_rate': 0.04921204940934762, 'colsample_bytree': 0.21002670199885937, 'subsample': 0.4293891063888293, 'alpha': 2.3978828048930088, 'lambda': 0.13692714458164035, 'gamma': 1.1181301108925159e-08, 'min_child_weight': 1.5487447941661068}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:38:27,528]\u001b[0m Trial 8 finished with value: 0.012069414591749043 and parameters: {'n_estimators': 916, 'max_depth': 2, 'learning_rate': 0.009187126759195596, 'colsample_bytree': 0.8866661000171799, 'subsample': 0.7453801972059182, 'alpha': 0.23544782396821218, 'lambda': 0.19935491393272312, 'gamma': 2.2585544391443764e-10, 'min_child_weight': 0.4398385979149334}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:38:30,698]\u001b[0m Trial 9 finished with value: 0.012196359507337436 and parameters: {'n_estimators': 508, 'max_depth': 3, 'learning_rate': 0.020445981508957198, 'colsample_bytree': 0.3176407456939237, 'subsample': 0.666655251775114, 'alpha': 4.978463969764574, 'lambda': 0.335200530835183, 'gamma': 0.026878459271327593, 'min_child_weight': 0.18865213626066338}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:38:38,534]\u001b[0m Trial 10 finished with value: 0.008368268722250511 and parameters: {'n_estimators': 997, 'max_depth': 4, 'learning_rate': 0.02973565932544768, 'colsample_bytree': 0.9173239470487514, 'subsample': 0.3260124906363018, 'alpha': 0.869380209024603, 'lambda': 170.05368240198766, 'gamma': 4.3754294953692613e-07, 'min_child_weight': 5.673299098728548}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:38:41,435]\u001b[0m Trial 11 finished with value: 0.013151753960206307 and parameters: {'n_estimators': 554, 'max_depth': 2, 'learning_rate': 0.039256480417070624, 'colsample_bytree': 0.6811965297950126, 'subsample': 0.5391800118923142, 'alpha': 28.45254054555109, 'lambda': 8.579902252097805, 'gamma': 0.0003054279425979364, 'min_child_weight': 0.11049082451585665}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:38:49,375]\u001b[0m Trial 12 finished with value: 0.011043522601545178 and parameters: {'n_estimators': 747, 'max_depth': 5, 'learning_rate': 0.023017044906359786, 'colsample_bytree': 0.5729008357760873, 'subsample': 0.30617112395116786, 'alpha': 1.00587822774488, 'lambda': 193.26551329576176, 'gamma': 0.0010746748272279947, 'min_child_weight': 7.43078029632691}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:38:54,626]\u001b[0m Trial 13 finished with value: 0.007084859208099706 and parameters: {'n_estimators': 664, 'max_depth': 4, 'learning_rate': 0.04817718305136671, 'colsample_bytree': 0.46446290337223095, 'subsample': 0.9392826486447499, 'alpha': 11.000442202701853, 'lambda': 36.76259876694522, 'gamma': 3.5453062048725234e-06, 'min_child_weight': 3.029340360188961}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:38:58,629]\u001b[0m Trial 14 finished with value: 0.007260493404707976 and parameters: {'n_estimators': 818, 'max_depth': 2, 'learning_rate': 0.0016483611438212128, 'colsample_bytree': 0.7675616349730718, 'subsample': 0.6071898083867056, 'alpha': 1.0395183633965914, 'lambda': 1.5037431977614564, 'gamma': 3.1468712555757437e-10, 'min_child_weight': 17.21478919962676}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:39:06,082]\u001b[0m Trial 15 finished with value: 0.012041940700240044 and parameters: {'n_estimators': 995, 'max_depth': 4, 'learning_rate': 0.012527374770139843, 'colsample_bytree': 0.3419096111377023, 'subsample': 0.4121467495639227, 'alpha': 0.12034735129971752, 'lambda': 4.250690319749854, 'gamma': 0.002091817667034333, 'min_child_weight': 0.42255799139842576}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:39:12,469]\u001b[0m Trial 16 finished with value: 0.008477548001028335 and parameters: {'n_estimators': 609, 'max_depth': 5, 'learning_rate': 0.03596653265028846, 'colsample_bytree': 0.5757971149718324, 'subsample': 0.9493979786422923, 'alpha': 5.920517319504213, 'lambda': 55.926363633999145, 'gamma': 3.973117721490665e-06, 'min_child_weight': 13.925021882476479}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:39:16,454]\u001b[0m Trial 17 finished with value: 0.011789787534458987 and parameters: {'n_estimators': 786, 'max_depth': 2, 'learning_rate': 0.028635669197512675, 'colsample_bytree': 0.8541255841157769, 'subsample': 0.6310613763367062, 'alpha': 15.718610433726784, 'lambda': 1.0262695356612277, 'gamma': 2.1446372227041366e-08, 'min_child_weight': 3.566292227683355}. Best is trial 2 with value: 0.013596185898776883.\u001b[0m\n\u001b[32m[I 2022-08-25 20:39:20,936]\u001b[0m Trial 18 finished with value: 0.01447795241982691 and parameters: {'n_estimators': 701, 'max_depth': 3, 'learning_rate': 0.016556589404129664, 'colsample_bytree': 0.4065998411555825, 'subsample': 0.5362055623259836, 'alpha': 1.5234730901197817, 'lambda': 4.027889687332672, 'gamma': 9.48207934555906e-06, 'min_child_weight': 44.67666021919712}. Best is trial 18 with value: 0.01447795241982691.\u001b[0m\n\u001b[32m[I 2022-08-25 20:39:26,510]\u001b[0m Trial 19 finished with value: 0.01442121854170641 and parameters: {'n_estimators': 711, 'max_depth': 4, 'learning_rate': 0.01602746853587012, 'colsample_bytree': 0.7479695960487137, 'subsample': 0.5224777774992586, 'alpha': 0.5763240550544594, 'lambda': 7.9013250573630565, 'gamma': 2.3570273258289335e-09, 'min_child_weight': 39.47111708956595}. Best is trial 18 with value: 0.01447795241982691.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  111.90343046188354\n        n_estimators : 701\n           max_depth : 3\n       learning_rate : 0.016556589404129664\n    colsample_bytree : 0.4065998411555825\n           subsample : 0.5362055623259836\n               alpha : 1.5234730901197817\n              lambda : 4.027889687332672\n               gamma : 9.48207934555906e-06\n    min_child_weight : 44.67666021919712\nbest objective value : 0.01447795241982691\nOptuna XGB train: 7.532710768229944 0.03515546864141861 114.39416766166687\nMin_prd:  225\nConstant guess:  10.789309041003193 0.0\nXGB test: 10.584344777730841 0.0246590710211394\nXGB GS test: 10.597557070825852 0.024404214808965596\nOptuna XGB test: 10.602054445815849 0.024533244962536838\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(85749, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd     mom482     mom242  year     RET   ind        bm       op  \\\n174   10006  249  15.440490 -13.483924  1979 -1.9895  25.0  0.344796  0.12391   \n175   10006  250   7.656898 -12.128055  1979 -1.8823  25.0  0.344796  0.12391   \n176   10006  251  13.910247 -12.205583  1979  7.6646  25.0  0.344796  0.12391   \n177   10006  252  27.035379  -9.191941  1979  7.0125  25.0  0.344796  0.12391   \n178   10006  253  12.516907  -8.290927  1979 -3.9070  25.0  0.344796  0.12391   \n\n           gp      inv   mom11    mom122      amhd  ivol_capm  ivol_ff5  \\\n174  0.224713  0.08608 -2.3800 -9.398265  1.806977   1.121349  1.068897   \n175  0.224713  0.08608 -1.9895  1.438464  1.785460   1.139783  0.994278   \n176  0.224713  0.08608 -1.8823  1.566341  1.729562   0.792122  0.658194   \n177  0.224713  0.08608  7.6646 -3.544113  1.714285   1.413330  1.234720   \n178  0.224713  0.08608  7.0125 -5.728738  1.721803   1.335360  1.185008   \n\n      beta_bw     MAX     vol1m     vol6m    vol12m      size       lbm  \\\n174  0.843122  2.7610  1.183510  1.465939  1.408005  5.595858  0.246732   \n175  0.807884  1.9893  1.186615  1.436818  1.338013  5.583587  0.246732   \n176  0.804317  2.0897  0.962481  1.390096  1.338323  5.554358  0.246732   \n177  0.836807  3.4514  1.590503  1.451393  1.387657  5.635703  0.246732   \n178  0.845385  3.3821  1.438224  1.410186  1.388858  5.711155  0.246732   \n\n          lop       lgp      linv      llme    l1amhd   l1MAX    l3amhd  \\\n174  0.128162  0.228031  0.051037  5.707839  1.735479  2.7014  1.882601   \n175  0.128162  0.228031  0.051037  5.576376  1.806977  2.7610  1.824922   \n176  0.128162  0.228031  0.051037  5.542759  1.785460  1.9893  1.735479   \n177  0.128162  0.228031  0.051037  5.580500  1.729562  2.0897  1.806977   \n178  0.128162  0.228031  0.051037  5.682150  1.714285  3.4514  1.785460   \n\n      l3MAX    l6amhd   l6MAX   l12amhd  l12MAX  l12mom122  l12ivol_capm  \\\n174  1.4066  1.911064  2.5307  1.878987  2.7014  -2.840033      1.105690   \n175  3.1948  1.979787  2.2025  1.919239  2.7610  -2.197162      1.708117   \n176  2.7014  1.932696  3.3774  1.943009  1.9893 -12.452139      0.828827   \n177  2.7610  1.882601  1.4066  1.951792  2.0897 -14.287881      0.990059   \n178  1.9893  1.824922  3.1948  1.942359  3.4514 -15.414663      1.309469   \n\n     l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n174     0.886346    0.936283  1.255599   1.221990  \n175     1.620786    0.976068  1.289759   1.310662  \n176     0.717779    0.988329  1.308817   1.268762  \n177     0.892042    0.992036  1.315554   1.254191  \n178     0.923172    0.948718  1.362666   1.272217  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>174</th>\n      <td>10006</td>\n      <td>249</td>\n      <td>15.440490</td>\n      <td>-13.483924</td>\n      <td>1979</td>\n      <td>-1.9895</td>\n      <td>25.0</td>\n      <td>0.344796</td>\n      <td>0.12391</td>\n      <td>0.224713</td>\n      <td>0.08608</td>\n      <td>-2.3800</td>\n      <td>-9.398265</td>\n      <td>1.806977</td>\n      <td>1.121349</td>\n      <td>1.068897</td>\n      <td>0.843122</td>\n      <td>2.7610</td>\n      <td>1.183510</td>\n      <td>1.465939</td>\n      <td>1.408005</td>\n      <td>5.595858</td>\n      <td>0.246732</td>\n      <td>0.128162</td>\n      <td>0.228031</td>\n      <td>0.051037</td>\n      <td>5.707839</td>\n      <td>1.735479</td>\n      <td>2.7014</td>\n      <td>1.882601</td>\n      <td>1.4066</td>\n      <td>1.911064</td>\n      <td>2.5307</td>\n      <td>1.878987</td>\n      <td>2.7014</td>\n      <td>-2.840033</td>\n      <td>1.105690</td>\n      <td>0.886346</td>\n      <td>0.936283</td>\n      <td>1.255599</td>\n      <td>1.221990</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>10006</td>\n      <td>250</td>\n      <td>7.656898</td>\n      <td>-12.128055</td>\n      <td>1979</td>\n      <td>-1.8823</td>\n      <td>25.0</td>\n      <td>0.344796</td>\n      <td>0.12391</td>\n      <td>0.224713</td>\n      <td>0.08608</td>\n      <td>-1.9895</td>\n      <td>1.438464</td>\n      <td>1.785460</td>\n      <td>1.139783</td>\n      <td>0.994278</td>\n      <td>0.807884</td>\n      <td>1.9893</td>\n      <td>1.186615</td>\n      <td>1.436818</td>\n      <td>1.338013</td>\n      <td>5.583587</td>\n      <td>0.246732</td>\n      <td>0.128162</td>\n      <td>0.228031</td>\n      <td>0.051037</td>\n      <td>5.576376</td>\n      <td>1.806977</td>\n      <td>2.7610</td>\n      <td>1.824922</td>\n      <td>3.1948</td>\n      <td>1.979787</td>\n      <td>2.2025</td>\n      <td>1.919239</td>\n      <td>2.7610</td>\n      <td>-2.197162</td>\n      <td>1.708117</td>\n      <td>1.620786</td>\n      <td>0.976068</td>\n      <td>1.289759</td>\n      <td>1.310662</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>10006</td>\n      <td>251</td>\n      <td>13.910247</td>\n      <td>-12.205583</td>\n      <td>1979</td>\n      <td>7.6646</td>\n      <td>25.0</td>\n      <td>0.344796</td>\n      <td>0.12391</td>\n      <td>0.224713</td>\n      <td>0.08608</td>\n      <td>-1.8823</td>\n      <td>1.566341</td>\n      <td>1.729562</td>\n      <td>0.792122</td>\n      <td>0.658194</td>\n      <td>0.804317</td>\n      <td>2.0897</td>\n      <td>0.962481</td>\n      <td>1.390096</td>\n      <td>1.338323</td>\n      <td>5.554358</td>\n      <td>0.246732</td>\n      <td>0.128162</td>\n      <td>0.228031</td>\n      <td>0.051037</td>\n      <td>5.542759</td>\n      <td>1.785460</td>\n      <td>1.9893</td>\n      <td>1.735479</td>\n      <td>2.7014</td>\n      <td>1.932696</td>\n      <td>3.3774</td>\n      <td>1.943009</td>\n      <td>1.9893</td>\n      <td>-12.452139</td>\n      <td>0.828827</td>\n      <td>0.717779</td>\n      <td>0.988329</td>\n      <td>1.308817</td>\n      <td>1.268762</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>10006</td>\n      <td>252</td>\n      <td>27.035379</td>\n      <td>-9.191941</td>\n      <td>1979</td>\n      <td>7.0125</td>\n      <td>25.0</td>\n      <td>0.344796</td>\n      <td>0.12391</td>\n      <td>0.224713</td>\n      <td>0.08608</td>\n      <td>7.6646</td>\n      <td>-3.544113</td>\n      <td>1.714285</td>\n      <td>1.413330</td>\n      <td>1.234720</td>\n      <td>0.836807</td>\n      <td>3.4514</td>\n      <td>1.590503</td>\n      <td>1.451393</td>\n      <td>1.387657</td>\n      <td>5.635703</td>\n      <td>0.246732</td>\n      <td>0.128162</td>\n      <td>0.228031</td>\n      <td>0.051037</td>\n      <td>5.580500</td>\n      <td>1.729562</td>\n      <td>2.0897</td>\n      <td>1.806977</td>\n      <td>2.7610</td>\n      <td>1.882601</td>\n      <td>1.4066</td>\n      <td>1.951792</td>\n      <td>2.0897</td>\n      <td>-14.287881</td>\n      <td>0.990059</td>\n      <td>0.892042</td>\n      <td>0.992036</td>\n      <td>1.315554</td>\n      <td>1.254191</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>10006</td>\n      <td>253</td>\n      <td>12.516907</td>\n      <td>-8.290927</td>\n      <td>1979</td>\n      <td>-3.9070</td>\n      <td>25.0</td>\n      <td>0.344796</td>\n      <td>0.12391</td>\n      <td>0.224713</td>\n      <td>0.08608</td>\n      <td>7.0125</td>\n      <td>-5.728738</td>\n      <td>1.721803</td>\n      <td>1.335360</td>\n      <td>1.185008</td>\n      <td>0.845385</td>\n      <td>3.3821</td>\n      <td>1.438224</td>\n      <td>1.410186</td>\n      <td>1.388858</td>\n      <td>5.711155</td>\n      <td>0.246732</td>\n      <td>0.128162</td>\n      <td>0.228031</td>\n      <td>0.051037</td>\n      <td>5.682150</td>\n      <td>1.714285</td>\n      <td>3.4514</td>\n      <td>1.785460</td>\n      <td>1.9893</td>\n      <td>1.824922</td>\n      <td>3.1948</td>\n      <td>1.942359</td>\n      <td>3.4514</td>\n      <td>-15.414663</td>\n      <td>1.309469</td>\n      <td>0.923172</td>\n      <td>0.948718</td>\n      <td>1.362666</td>\n      <td>1.272217</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    85749.000000\nmean      1980.137028\nstd          0.947544\nmin       1979.000000\n25%       1979.000000\n50%       1980.000000\n75%       1981.000000\nmax       1982.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          85749\nprd             85749\nmom482          80250\nmom242          84505\nyear            85749\nRET             85749\nind             85749\nbm              85749\nop              85749\ngp              85749\ninv             85737\nmom11           85749\nmom122          85749\namhd            49668\nivol_capm       85738\nivol_ff5        85738\nbeta_bw         85749\nMAX             85749\nvol1m           85690\nvol6m           85641\nvol12m          85532\nsize            85749\nlbm             85749\nlop             85749\nlgp             85749\nlinv            85749\nllme            85749\nl1amhd          49554\nl1MAX           85746\nl3amhd          49309\nl3MAX           85726\nl6amhd          48799\nl6MAX           85697\nl12amhd         47442\nl12MAX          85746\nl12mom122       84890\nl12ivol_capm    85580\nl12ivol_ff5     85580\nl12beta_bw      85644\nl12vol6m        85271\nl12vol12m       84763\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (81307, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (81307, 85)\nmae of a constant model 8.116751240947098\nR2 of a constant model 0.0\nXGB train: 7.8489579147754664 0.08026146156005265\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\nXGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.010465055299653359 44.187318563461304\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:40:17,820]\u001b[0m A new study created in memory with name: no-name-3efb788b-cd07-4337-99bc-36b04dc24e77\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 8.016250291531522 0.031354032007939625 45.50160336494446\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:40:25,493]\u001b[0m Trial 0 finished with value: 0.0006103057716062722 and parameters: {'n_estimators': 991, 'max_depth': 4, 'learning_rate': 0.039715185693922794, 'colsample_bytree': 0.3044855299741879, 'subsample': 0.8642642025859553, 'alpha': 0.2034515796835656, 'lambda': 112.28746913704283, 'gamma': 0.054001199826481334, 'min_child_weight': 5.082308123428978}. Best is trial 0 with value: 0.0006103057716062722.\u001b[0m\n\u001b[32m[I 2022-08-25 20:40:29,395]\u001b[0m Trial 1 finished with value: 0.009345943286151147 and parameters: {'n_estimators': 802, 'max_depth': 2, 'learning_rate': 0.00997950899495097, 'colsample_bytree': 0.7157617217345404, 'subsample': 0.8402113131280957, 'alpha': 1.4014308381872345, 'lambda': 44.466147812169005, 'gamma': 1.1039066333222566e-06, 'min_child_weight': 0.4203740734080024}. Best is trial 1 with value: 0.009345943286151147.\u001b[0m\n\u001b[32m[I 2022-08-25 20:40:33,706]\u001b[0m Trial 2 finished with value: 0.010221703186951224 and parameters: {'n_estimators': 721, 'max_depth': 3, 'learning_rate': 0.01290241067591168, 'colsample_bytree': 0.2749518549412728, 'subsample': 0.8313759681950501, 'alpha': 5.511897084644901, 'lambda': 1.3710802848001882, 'gamma': 3.448423643073357e-05, 'min_child_weight': 0.4332511549112824}. Best is trial 2 with value: 0.010221703186951224.\u001b[0m\n\u001b[32m[I 2022-08-25 20:40:37,214]\u001b[0m Trial 3 finished with value: 0.005834169227522215 and parameters: {'n_estimators': 716, 'max_depth': 2, 'learning_rate': 0.003577401736020094, 'colsample_bytree': 0.4039159870653759, 'subsample': 0.41019092328771717, 'alpha': 1.3584230269511077, 'lambda': 21.896233117594637, 'gamma': 4.870608398218454e-10, 'min_child_weight': 4.205167569011776}. Best is trial 2 with value: 0.010221703186951224.\u001b[0m\n\u001b[32m[I 2022-08-25 20:40:41,248]\u001b[0m Trial 4 finished with value: 0.00487241338514552 and parameters: {'n_estimators': 676, 'max_depth': 3, 'learning_rate': 0.0365605592145103, 'colsample_bytree': 0.40373795169210014, 'subsample': 0.4998832286742613, 'alpha': 7.7794595946686576, 'lambda': 0.16311063160008207, 'gamma': 0.0023372760557712107, 'min_child_weight': 10.847831482616591}. Best is trial 2 with value: 0.010221703186951224.\u001b[0m\n\u001b[32m[I 2022-08-25 20:40:48,123]\u001b[0m Trial 5 finished with value: 0.004468025282347042 and parameters: {'n_estimators': 885, 'max_depth': 4, 'learning_rate': 0.023147564748245832, 'colsample_bytree': 0.7306051023341912, 'subsample': 0.7839467133041801, 'alpha': 11.024053771556572, 'lambda': 1.5897446561342976, 'gamma': 9.220149225514336e-08, 'min_child_weight': 7.165339144297029}. Best is trial 2 with value: 0.010221703186951224.\u001b[0m\n\u001b[32m[I 2022-08-25 20:40:53,571]\u001b[0m Trial 6 finished with value: 0.006060769930261589 and parameters: {'n_estimators': 711, 'max_depth': 4, 'learning_rate': 0.03331371003985176, 'colsample_bytree': 0.5867594782686426, 'subsample': 0.7739566989215145, 'alpha': 0.12465967117069435, 'lambda': 73.24783139575271, 'gamma': 3.241565961037078e-05, 'min_child_weight': 6.568701819985077}. Best is trial 2 with value: 0.010221703186951224.\u001b[0m\n\u001b[32m[I 2022-08-25 20:40:57,975]\u001b[0m Trial 7 finished with value: 0.004682416334472015 and parameters: {'n_estimators': 531, 'max_depth': 4, 'learning_rate': 0.04786418937420828, 'colsample_bytree': 0.8578629447737067, 'subsample': 0.6674129586705213, 'alpha': 0.20435155302230498, 'lambda': 42.15064408469578, 'gamma': 9.097742506894027e-10, 'min_child_weight': 7.7228134028982165}. Best is trial 2 with value: 0.010221703186951224.\u001b[0m\n\u001b[32m[I 2022-08-25 20:41:05,305]\u001b[0m Trial 8 finished with value: 0.0034149584395505583 and parameters: {'n_estimators': 703, 'max_depth': 5, 'learning_rate': 0.022297215666682465, 'colsample_bytree': 0.44612031031724153, 'subsample': 0.8352565243226937, 'alpha': 3.909128170497869, 'lambda': 23.449299727561915, 'gamma': 0.0003261555523035457, 'min_child_weight': 3.6307942063626557}. Best is trial 2 with value: 0.010221703186951224.\u001b[0m\n\u001b[32m[I 2022-08-25 20:41:10,780]\u001b[0m Trial 9 finished with value: 0.004354601993215883 and parameters: {'n_estimators': 876, 'max_depth': 3, 'learning_rate': 0.04216710170658302, 'colsample_bytree': 0.9221287547023945, 'subsample': 0.9394961336083745, 'alpha': 1.2579085693714263, 'lambda': 15.649234734280707, 'gamma': 1.6586623491736586e-05, 'min_child_weight': 1.094023270362992}. Best is trial 2 with value: 0.010221703186951224.\u001b[0m\n\u001b[32m[I 2022-08-25 20:41:16,886]\u001b[0m Trial 10 finished with value: 0.006432346213223409 and parameters: {'n_estimators': 587, 'max_depth': 5, 'learning_rate': 0.014412874173272054, 'colsample_bytree': 0.10533319410931896, 'subsample': 0.6023102150822633, 'alpha': 21.28649387954271, 'lambda': 1.2659943404911613, 'gamma': 0.431102416334548, 'min_child_weight': 0.11934757898951663}. Best is trial 2 with value: 0.010221703186951224.\u001b[0m\n\u001b[32m[I 2022-08-25 20:41:20,940]\u001b[0m Trial 11 finished with value: 0.007411326102904927 and parameters: {'n_estimators': 846, 'max_depth': 2, 'learning_rate': 0.006360623129686185, 'colsample_bytree': 0.17681269790057785, 'subsample': 0.6758014204384764, 'alpha': 0.7050368509407772, 'lambda': 4.209334064245846, 'gamma': 1.2432823841321472e-07, 'min_child_weight': 0.5121957639256436}. Best is trial 2 with value: 0.010221703186951224.\u001b[0m\n\u001b[32m[I 2022-08-25 20:41:25,092]\u001b[0m Trial 12 finished with value: 0.010514478544349589 and parameters: {'n_estimators': 795, 'max_depth': 2, 'learning_rate': 0.01333553318511066, 'colsample_bytree': 0.6301362336029659, 'subsample': 0.9435279727020769, 'alpha': 3.7118501959119388, 'lambda': 0.3991058811136779, 'gamma': 4.1136186863764407e-07, 'min_child_weight': 47.23383698732}. Best is trial 12 with value: 0.010514478544349589.\u001b[0m\n\u001b[32m[I 2022-08-25 20:41:28,987]\u001b[0m Trial 13 finished with value: 0.010697830193806964 and parameters: {'n_estimators': 620, 'max_depth': 3, 'learning_rate': 0.015418111313419566, 'colsample_bytree': 0.6014203404940136, 'subsample': 0.9447919074508159, 'alpha': 3.877424066038285, 'lambda': 0.15962393232819785, 'gamma': 4.474944977432207e-08, 'min_child_weight': 25.721454743805236}. Best is trial 13 with value: 0.010697830193806964.\u001b[0m\n\u001b[32m[I 2022-08-25 20:41:32,135]\u001b[0m Trial 14 finished with value: 0.008791494360848282 and parameters: {'n_estimators': 622, 'max_depth': 2, 'learning_rate': 0.018531613202142954, 'colsample_bytree': 0.6317052676408362, 'subsample': 0.9404334140276814, 'alpha': 3.643942350488216, 'lambda': 0.11722377444261482, 'gamma': 1.1674731201393716e-08, 'min_child_weight': 37.50582316650838}. Best is trial 13 with value: 0.010697830193806964.\u001b[0m\n\u001b[32m[I 2022-08-25 20:41:36,805]\u001b[0m Trial 15 finished with value: 0.006500595382982279 and parameters: {'n_estimators': 797, 'max_depth': 3, 'learning_rate': 0.02884944538917231, 'colsample_bytree': 0.5366464363336452, 'subsample': 0.30595762558737993, 'alpha': 26.138816042656533, 'lambda': 0.4160264174621192, 'gamma': 9.22767409269341e-09, 'min_child_weight': 42.25542831573051}. Best is trial 13 with value: 0.010697830193806964.\u001b[0m\n\u001b[32m[I 2022-08-25 20:41:40,278]\u001b[0m Trial 16 finished with value: 0.009922703961454128 and parameters: {'n_estimators': 621, 'max_depth': 2, 'learning_rate': 0.01654288535237818, 'colsample_bytree': 0.7393117829258804, 'subsample': 0.9399999595024425, 'alpha': 2.387971650383775, 'lambda': 0.355178232811645, 'gamma': 1.3377641308562284e-06, 'min_child_weight': 19.419668948283455}. Best is trial 13 with value: 0.010697830193806964.\u001b[0m\n\u001b[32m[I 2022-08-25 20:41:43,526]\u001b[0m Trial 17 finished with value: 0.0027525395656522234 and parameters: {'n_estimators': 511, 'max_depth': 3, 'learning_rate': 0.0011486648700119902, 'colsample_bytree': 0.6298988247317243, 'subsample': 0.7339692724267285, 'alpha': 0.555254596124783, 'lambda': 0.4097941622815327, 'gamma': 1.0857858913931163e-10, 'min_child_weight': 18.889513110602902}. Best is trial 13 with value: 0.010697830193806964.\u001b[0m\n\u001b[32m[I 2022-08-25 20:41:48,029]\u001b[0m Trial 18 finished with value: 0.008366074631181499 and parameters: {'n_estimators': 945, 'max_depth': 2, 'learning_rate': 0.00881590548098532, 'colsample_bytree': 0.8124648673052758, 'subsample': 0.8879065458295812, 'alpha': 11.099627851719205, 'lambda': 0.2643047274032188, 'gamma': 4.3106328087957583e-07, 'min_child_weight': 19.59005969077467}. Best is trial 13 with value: 0.010697830193806964.\u001b[0m\n\u001b[32m[I 2022-08-25 20:41:52,650]\u001b[0m Trial 19 finished with value: 0.008344580951969606 and parameters: {'n_estimators': 771, 'max_depth': 3, 'learning_rate': 0.028057603863953486, 'colsample_bytree': 0.4951205540035952, 'subsample': 0.5397074050011486, 'alpha': 2.6088797143676388, 'lambda': 0.7688803186068579, 'gamma': 1.2797154612592592e-08, 'min_child_weight': 48.84664564786554}. Best is trial 13 with value: 0.010697830193806964.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  94.83282732963562\n        n_estimators : 620\n           max_depth : 3\n       learning_rate : 0.015418111313419566\n    colsample_bytree : 0.6014203404940136\n           subsample : 0.9447919074508159\n               alpha : 3.877424066038285\n              lambda : 0.15962393232819785\n               gamma : 4.474944977432207e-08\n    min_child_weight : 25.721454743805236\nbest objective value : 0.010697830193806964\nOptuna XGB train: 8.015395809073299 0.029664219580690987 96.95533061027527\nMin_prd:  250\nConstant guess:  7.309043435698192 0.0\nXGB test: 7.3501955324514405 -0.004758927497545029\nXGB GS test: 7.307363885485978 0.003917956329142047\nOptuna XGB test: 7.317106562321939 0.00593865869626331\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(85011, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd     mom482     mom242  year     RET   ind       bm        op  \\\n199   10006  274  37.459012  59.700850  1981 -3.2759  25.0  0.51329  0.111463   \n200   10006  275  32.174173  43.778358  1981 -1.7113  25.0  0.51329  0.111463   \n201   10006  276  21.810870  32.034169  1981 -7.7127  25.0  0.51329  0.111463   \n202   10006  277  13.128183  28.372543  1981  5.5495  25.0  0.51329  0.111463   \n203   10006  278  22.130729  27.011807  1981 -8.8825  25.0  0.51329  0.111463   \n\n           gp       inv   mom11     mom122      amhd  ivol_capm  ivol_ff5  \\\n199  0.226944  0.098149  9.8296   6.843997  1.283075   1.471052  1.422033   \n200  0.226944  0.098149 -3.2759  25.866894  1.260908   1.104413  0.732167   \n201  0.226944  0.098149 -1.7113  49.228166  1.200905   1.244822  0.936037   \n202  0.226944  0.098149 -7.7127  52.793976  1.102388   1.034190  0.905935   \n203  0.226944  0.098149  5.5495  30.979424  1.017502   0.944081  0.780361   \n\n      beta_bw     MAX     vol1m     vol6m    vol12m      size       lbm  \\\n199  0.972026  4.0494  1.629143  1.728732  1.872404  6.130050  0.545005   \n200  0.959088  2.6871  1.273156  1.607273  1.853357  6.107744  0.545005   \n201  0.876275  3.1196  1.359986  1.517022  1.666039  6.090044  0.545005   \n202  0.832826  2.3112  1.060035  1.523327  1.546585  6.021416  0.545005   \n203  0.808140  3.5774  1.012657  1.340960  1.497498  6.072026  0.545005   \n\n          lop       lgp    linv      llme    l1amhd   l1MAX    l3amhd   l3MAX  \\\n199  0.118539  0.224607  0.1738  5.907127  1.292463  3.2930  1.272274  2.2447   \n200  0.118539  0.224607  0.1738  5.832092  1.283075  4.0494  1.268666  6.0923   \n201  0.118539  0.224607  0.1738  5.643256  1.260908  2.6871  1.292463  3.2930   \n202  0.118539  0.224607  0.1738  5.615421  1.200905  3.1196  1.283075  4.0494   \n203  0.118539  0.224607  0.1738  5.677941  1.102388  2.3112  1.260908  2.6871   \n\n       l6amhd   l6MAX   l12amhd  l12MAX  l12mom122  l12ivol_capm  l12ivol_ff5  \\\n199  1.206043  3.9760  1.301524  3.2930   9.938743      1.724933     1.648195   \n200  1.296753  4.1908  1.308714  4.0494  34.869606      1.187340     1.172984   \n201  1.324853  4.0910  1.282287  2.6871  16.788256      2.176823     1.783361   \n202  1.272274  2.2447  1.266251  3.1196 -10.965141      1.950141     1.698754   \n203  1.268666  6.0923  1.228240  2.3112 -11.056036      1.381642     1.058600   \n\n     l12beta_bw  l12vol6m  l12vol12m  \n199    1.034048  1.662274   1.467041  \n200    1.045721  1.718915   1.508377  \n201    1.098593  2.078251   1.694509  \n202    1.111977  2.044336   1.789059  \n203    1.116465  2.087183   1.821832  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>199</th>\n      <td>10006</td>\n      <td>274</td>\n      <td>37.459012</td>\n      <td>59.700850</td>\n      <td>1981</td>\n      <td>-3.2759</td>\n      <td>25.0</td>\n      <td>0.51329</td>\n      <td>0.111463</td>\n      <td>0.226944</td>\n      <td>0.098149</td>\n      <td>9.8296</td>\n      <td>6.843997</td>\n      <td>1.283075</td>\n      <td>1.471052</td>\n      <td>1.422033</td>\n      <td>0.972026</td>\n      <td>4.0494</td>\n      <td>1.629143</td>\n      <td>1.728732</td>\n      <td>1.872404</td>\n      <td>6.130050</td>\n      <td>0.545005</td>\n      <td>0.118539</td>\n      <td>0.224607</td>\n      <td>0.1738</td>\n      <td>5.907127</td>\n      <td>1.292463</td>\n      <td>3.2930</td>\n      <td>1.272274</td>\n      <td>2.2447</td>\n      <td>1.206043</td>\n      <td>3.9760</td>\n      <td>1.301524</td>\n      <td>3.2930</td>\n      <td>9.938743</td>\n      <td>1.724933</td>\n      <td>1.648195</td>\n      <td>1.034048</td>\n      <td>1.662274</td>\n      <td>1.467041</td>\n    </tr>\n    <tr>\n      <th>200</th>\n      <td>10006</td>\n      <td>275</td>\n      <td>32.174173</td>\n      <td>43.778358</td>\n      <td>1981</td>\n      <td>-1.7113</td>\n      <td>25.0</td>\n      <td>0.51329</td>\n      <td>0.111463</td>\n      <td>0.226944</td>\n      <td>0.098149</td>\n      <td>-3.2759</td>\n      <td>25.866894</td>\n      <td>1.260908</td>\n      <td>1.104413</td>\n      <td>0.732167</td>\n      <td>0.959088</td>\n      <td>2.6871</td>\n      <td>1.273156</td>\n      <td>1.607273</td>\n      <td>1.853357</td>\n      <td>6.107744</td>\n      <td>0.545005</td>\n      <td>0.118539</td>\n      <td>0.224607</td>\n      <td>0.1738</td>\n      <td>5.832092</td>\n      <td>1.283075</td>\n      <td>4.0494</td>\n      <td>1.268666</td>\n      <td>6.0923</td>\n      <td>1.296753</td>\n      <td>4.1908</td>\n      <td>1.308714</td>\n      <td>4.0494</td>\n      <td>34.869606</td>\n      <td>1.187340</td>\n      <td>1.172984</td>\n      <td>1.045721</td>\n      <td>1.718915</td>\n      <td>1.508377</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>10006</td>\n      <td>276</td>\n      <td>21.810870</td>\n      <td>32.034169</td>\n      <td>1981</td>\n      <td>-7.7127</td>\n      <td>25.0</td>\n      <td>0.51329</td>\n      <td>0.111463</td>\n      <td>0.226944</td>\n      <td>0.098149</td>\n      <td>-1.7113</td>\n      <td>49.228166</td>\n      <td>1.200905</td>\n      <td>1.244822</td>\n      <td>0.936037</td>\n      <td>0.876275</td>\n      <td>3.1196</td>\n      <td>1.359986</td>\n      <td>1.517022</td>\n      <td>1.666039</td>\n      <td>6.090044</td>\n      <td>0.545005</td>\n      <td>0.118539</td>\n      <td>0.224607</td>\n      <td>0.1738</td>\n      <td>5.643256</td>\n      <td>1.260908</td>\n      <td>2.6871</td>\n      <td>1.292463</td>\n      <td>3.2930</td>\n      <td>1.324853</td>\n      <td>4.0910</td>\n      <td>1.282287</td>\n      <td>2.6871</td>\n      <td>16.788256</td>\n      <td>2.176823</td>\n      <td>1.783361</td>\n      <td>1.098593</td>\n      <td>2.078251</td>\n      <td>1.694509</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>10006</td>\n      <td>277</td>\n      <td>13.128183</td>\n      <td>28.372543</td>\n      <td>1981</td>\n      <td>5.5495</td>\n      <td>25.0</td>\n      <td>0.51329</td>\n      <td>0.111463</td>\n      <td>0.226944</td>\n      <td>0.098149</td>\n      <td>-7.7127</td>\n      <td>52.793976</td>\n      <td>1.102388</td>\n      <td>1.034190</td>\n      <td>0.905935</td>\n      <td>0.832826</td>\n      <td>2.3112</td>\n      <td>1.060035</td>\n      <td>1.523327</td>\n      <td>1.546585</td>\n      <td>6.021416</td>\n      <td>0.545005</td>\n      <td>0.118539</td>\n      <td>0.224607</td>\n      <td>0.1738</td>\n      <td>5.615421</td>\n      <td>1.200905</td>\n      <td>3.1196</td>\n      <td>1.283075</td>\n      <td>4.0494</td>\n      <td>1.272274</td>\n      <td>2.2447</td>\n      <td>1.266251</td>\n      <td>3.1196</td>\n      <td>-10.965141</td>\n      <td>1.950141</td>\n      <td>1.698754</td>\n      <td>1.111977</td>\n      <td>2.044336</td>\n      <td>1.789059</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>10006</td>\n      <td>278</td>\n      <td>22.130729</td>\n      <td>27.011807</td>\n      <td>1981</td>\n      <td>-8.8825</td>\n      <td>25.0</td>\n      <td>0.51329</td>\n      <td>0.111463</td>\n      <td>0.226944</td>\n      <td>0.098149</td>\n      <td>5.5495</td>\n      <td>30.979424</td>\n      <td>1.017502</td>\n      <td>0.944081</td>\n      <td>0.780361</td>\n      <td>0.808140</td>\n      <td>3.5774</td>\n      <td>1.012657</td>\n      <td>1.340960</td>\n      <td>1.497498</td>\n      <td>6.072026</td>\n      <td>0.545005</td>\n      <td>0.118539</td>\n      <td>0.224607</td>\n      <td>0.1738</td>\n      <td>5.677941</td>\n      <td>1.102388</td>\n      <td>2.3112</td>\n      <td>1.260908</td>\n      <td>2.6871</td>\n      <td>1.268666</td>\n      <td>6.0923</td>\n      <td>1.228240</td>\n      <td>2.3112</td>\n      <td>-11.056036</td>\n      <td>1.381642</td>\n      <td>1.058600</td>\n      <td>1.116465</td>\n      <td>2.087183</td>\n      <td>1.821832</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    85011.000000\nmean      1982.240404\nstd          0.975249\nmin       1981.000000\n25%       1981.000000\n50%       1982.000000\n75%       1983.000000\nmax       1984.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          85011\nprd             85011\nmom482          78370\nmom242          83792\nyear            85011\nRET             85011\nind             85011\nbm              85011\nop              85011\ngp              85011\ninv             85001\nmom11           85011\nmom122          85011\namhd            51414\nivol_capm       84999\nivol_ff5        84999\nbeta_bw         85011\nMAX             85011\nvol1m           84968\nvol6m           84955\nvol12m          84886\nsize            85011\nlbm             85011\nlop             85011\nlgp             85011\nlinv            85011\nllme            85011\nl1amhd          50650\nl1MAX           85008\nl3amhd          49057\nl3MAX           84993\nl6amhd          46663\nl6MAX           84974\nl12amhd         45569\nl12MAX          85008\nl12mom122       83983\nl12ivol_capm    84873\nl12ivol_ff5     84873\nl12beta_bw      84933\nl12vol6m        84542\nl12vol12m       83998\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (80386, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (80386, 85)\nmae of a constant model 8.383451711057207\nR2 of a constant model 0.0\nXGB train: 8.111317686498943 0.09241572742493986\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\nXGB {'colsample_bytree': 0.6, 'eta': 0.012, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.017679755082040838 44.23796725273132\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:42:43,550]\u001b[0m A new study created in memory with name: no-name-16b7aa50-9f18-4d62-80f3-af81be75bb4d\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 8.227672560980455 0.05910536002236311 45.516396284103394\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:42:47,615]\u001b[0m Trial 0 finished with value: 0.014061348592122625 and parameters: {'n_estimators': 663, 'max_depth': 3, 'learning_rate': 0.02251978511800619, 'colsample_bytree': 0.6595321042913489, 'subsample': 0.37913276511248595, 'alpha': 1.0068298446202433, 'lambda': 0.24943068905678328, 'gamma': 7.4181592327416975e-06, 'min_child_weight': 10.092520808053056}. Best is trial 0 with value: 0.014061348592122625.\u001b[0m\n\u001b[32m[I 2022-08-25 20:42:52,267]\u001b[0m Trial 1 finished with value: 0.016563321936989738 and parameters: {'n_estimators': 981, 'max_depth': 2, 'learning_rate': 0.02947310288107735, 'colsample_bytree': 0.867913262766826, 'subsample': 0.7087426325386783, 'alpha': 0.10866131290191476, 'lambda': 0.5119021459601684, 'gamma': 0.0009192854024913386, 'min_child_weight': 1.1015320312148122}. Best is trial 1 with value: 0.016563321936989738.\u001b[0m\n\u001b[32m[I 2022-08-25 20:42:56,201]\u001b[0m Trial 2 finished with value: 0.016878145798262675 and parameters: {'n_estimators': 782, 'max_depth': 2, 'learning_rate': 0.02656787351476177, 'colsample_bytree': 0.5982133589565357, 'subsample': 0.8067234051079333, 'alpha': 12.343228931742436, 'lambda': 1.2282466716786866, 'gamma': 5.822069665781775, 'min_child_weight': 40.850863793940725}. Best is trial 2 with value: 0.016878145798262675.\u001b[0m\n\u001b[32m[I 2022-08-25 20:43:04,608]\u001b[0m Trial 3 finished with value: 0.004665709998849161 and parameters: {'n_estimators': 875, 'max_depth': 5, 'learning_rate': 0.04438158165966807, 'colsample_bytree': 0.15951803300951484, 'subsample': 0.3078691795180408, 'alpha': 10.657907464707518, 'lambda': 87.49876328417056, 'gamma': 2.559351529027223e-05, 'min_child_weight': 2.1171434223566314}. Best is trial 2 with value: 0.016878145798262675.\u001b[0m\n\u001b[32m[I 2022-08-25 20:43:08,332]\u001b[0m Trial 4 finished with value: 0.007440329265726325 and parameters: {'n_estimators': 571, 'max_depth': 3, 'learning_rate': 0.0014188474361990283, 'colsample_bytree': 0.28028825926957623, 'subsample': 0.825363590256585, 'alpha': 0.6118156151189804, 'lambda': 46.8408942731088, 'gamma': 3.380715517773414e-07, 'min_child_weight': 0.38591854037442086}. Best is trial 2 with value: 0.016878145798262675.\u001b[0m\n\u001b[32m[I 2022-08-25 20:43:12,492]\u001b[0m Trial 5 finished with value: 0.017548695858342196 and parameters: {'n_estimators': 526, 'max_depth': 4, 'learning_rate': 0.020569355743149432, 'colsample_bytree': 0.6318036715885684, 'subsample': 0.5501025536200587, 'alpha': 0.8836964978982099, 'lambda': 108.61391874900436, 'gamma': 8.312541011113853e-08, 'min_child_weight': 1.282158160344808}. Best is trial 5 with value: 0.017548695858342196.\u001b[0m\n\u001b[32m[I 2022-08-25 20:43:19,726]\u001b[0m Trial 6 finished with value: -0.00024207663828120646 and parameters: {'n_estimators': 965, 'max_depth': 4, 'learning_rate': 0.03322647292560122, 'colsample_bytree': 0.5973036188861306, 'subsample': 0.6303494389133057, 'alpha': 0.35074459248696455, 'lambda': 1.1480965374814829, 'gamma': 2.3904468900749888e-08, 'min_child_weight': 4.607192681126776}. Best is trial 5 with value: 0.017548695858342196.\u001b[0m\n\u001b[32m[I 2022-08-25 20:43:24,594]\u001b[0m Trial 7 finished with value: 0.011726381587844488 and parameters: {'n_estimators': 822, 'max_depth': 3, 'learning_rate': 0.041104566989644355, 'colsample_bytree': 0.7545907195444992, 'subsample': 0.36225820164116457, 'alpha': 0.8286857700315611, 'lambda': 70.47863892743287, 'gamma': 3.1918467842006393e-10, 'min_child_weight': 11.833059918178218}. Best is trial 5 with value: 0.017548695858342196.\u001b[0m\n\u001b[32m[I 2022-08-25 20:43:32,428]\u001b[0m Trial 8 finished with value: 0.00439142727692321 and parameters: {'n_estimators': 958, 'max_depth': 4, 'learning_rate': 0.0363665508197037, 'colsample_bytree': 0.7563321558711643, 'subsample': 0.8497854035413952, 'alpha': 0.11845578144432736, 'lambda': 31.111466377565275, 'gamma': 0.3660128634618636, 'min_child_weight': 0.3068413408299318}. Best is trial 5 with value: 0.017548695858342196.\u001b[0m\n\u001b[32m[I 2022-08-25 20:43:36,191]\u001b[0m Trial 9 finished with value: 0.017249470800553068 and parameters: {'n_estimators': 613, 'max_depth': 3, 'learning_rate': 0.019066361812579515, 'colsample_bytree': 0.7850137674985391, 'subsample': 0.6231979672486971, 'alpha': 3.4400754552389485, 'lambda': 9.44077091066192, 'gamma': 0.24336570635382998, 'min_child_weight': 42.82737519950133}. Best is trial 5 with value: 0.017548695858342196.\u001b[0m\n\u001b[32m[I 2022-08-25 20:43:41,723]\u001b[0m Trial 10 finished with value: 0.01786912788213532 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.011300417355726664, 'colsample_bytree': 0.3845839376208076, 'subsample': 0.48866294741132743, 'alpha': 3.1023429443419395, 'lambda': 183.5624365963352, 'gamma': 3.205844695952883e-10, 'min_child_weight': 0.1056885654096167}. Best is trial 10 with value: 0.01786912788213532.\u001b[0m\n\u001b[32m[I 2022-08-25 20:43:47,250]\u001b[0m Trial 11 finished with value: 0.017730117964793277 and parameters: {'n_estimators': 514, 'max_depth': 5, 'learning_rate': 0.010865408777912124, 'colsample_bytree': 0.41174996660858754, 'subsample': 0.5168618760039146, 'alpha': 2.928059628780314, 'lambda': 185.6520179323266, 'gamma': 3.9512826196379327e-10, 'min_child_weight': 0.128074112183414}. Best is trial 10 with value: 0.01786912788213532.\u001b[0m\n\u001b[32m[I 2022-08-25 20:43:52,767]\u001b[0m Trial 12 finished with value: 0.01635632373290661 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.009369332179948182, 'colsample_bytree': 0.3996702095652483, 'subsample': 0.4772101539141641, 'alpha': 3.3509069708963377, 'lambda': 6.9506330426781915, 'gamma': 1.1556771282313475e-10, 'min_child_weight': 0.11155000140704802}. Best is trial 10 with value: 0.01786912788213532.\u001b[0m\n\u001b[32m[I 2022-08-25 20:44:00,109]\u001b[0m Trial 13 finished with value: 0.018248456036676686 and parameters: {'n_estimators': 693, 'max_depth': 5, 'learning_rate': 0.011868495043167594, 'colsample_bytree': 0.43539904579824357, 'subsample': 0.46481811563000125, 'alpha': 29.008487087999395, 'lambda': 191.6403821494657, 'gamma': 3.0020182671759544e-09, 'min_child_weight': 0.11334395933925108}. Best is trial 13 with value: 0.018248456036676686.\u001b[0m\n\u001b[32m[I 2022-08-25 20:44:07,430]\u001b[0m Trial 14 finished with value: 0.015711338646481547 and parameters: {'n_estimators': 695, 'max_depth': 5, 'learning_rate': 0.011238402603065481, 'colsample_bytree': 0.4529348786698585, 'subsample': 0.44360476753556843, 'alpha': 27.883483193976463, 'lambda': 19.519735613589557, 'gamma': 7.77397963504622e-09, 'min_child_weight': 0.33340922314747984}. Best is trial 13 with value: 0.018248456036676686.\u001b[0m\n\u001b[32m[I 2022-08-25 20:44:14,830]\u001b[0m Trial 15 finished with value: 0.010435178600975023 and parameters: {'n_estimators': 721, 'max_depth': 5, 'learning_rate': 0.001337131251678985, 'colsample_bytree': 0.2820149941591299, 'subsample': 0.9363450177141652, 'alpha': 7.8045781538737, 'lambda': 17.73254506682873, 'gamma': 1.1008056980030182e-06, 'min_child_weight': 0.18924611811511083}. Best is trial 13 with value: 0.018248456036676686.\u001b[0m\n\u001b[32m[I 2022-08-25 20:44:19,491]\u001b[0m Trial 16 finished with value: 0.014400910728485624 and parameters: {'n_estimators': 635, 'max_depth': 4, 'learning_rate': 0.015236666235181336, 'colsample_bytree': 0.10819362829991214, 'subsample': 0.5922577363972193, 'alpha': 29.852900926965553, 'lambda': 3.085676946679329, 'gamma': 0.0005877646409733828, 'min_child_weight': 0.6552586386927389}. Best is trial 13 with value: 0.018248456036676686.\u001b[0m\n\u001b[32m[I 2022-08-25 20:44:25,867]\u001b[0m Trial 17 finished with value: 0.015326232270691721 and parameters: {'n_estimators': 598, 'max_depth': 5, 'learning_rate': 0.005973626799662113, 'colsample_bytree': 0.28672963472269575, 'subsample': 0.420810927998709, 'alpha': 6.499315881430297, 'lambda': 180.30982258867132, 'gamma': 3.5138171752656e-09, 'min_child_weight': 0.20751314263937656}. Best is trial 13 with value: 0.018248456036676686.\u001b[0m\n\u001b[32m[I 2022-08-25 20:44:31,835]\u001b[0m Trial 18 finished with value: 0.0173884416402144 and parameters: {'n_estimators': 767, 'max_depth': 4, 'learning_rate': 0.015275810280607515, 'colsample_bytree': 0.516621421424375, 'subsample': 0.7284745703192703, 'alpha': 1.9311162333151755, 'lambda': 33.58055499713106, 'gamma': 2.9820062291234537e-09, 'min_child_weight': 0.6399836876882763}. Best is trial 13 with value: 0.018248456036676686.\u001b[0m\n\u001b[32m[I 2022-08-25 20:44:38,159]\u001b[0m Trial 19 finished with value: 0.015757752137877716 and parameters: {'n_estimators': 559, 'max_depth': 5, 'learning_rate': 0.016528551464532183, 'colsample_bytree': 0.35560886192099833, 'subsample': 0.5077190939395544, 'alpha': 18.02659301839353, 'lambda': 177.0460379147291, 'gamma': 0.0005786481123867066, 'min_child_weight': 0.10080743406087193}. Best is trial 13 with value: 0.018248456036676686.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  114.61047339439392\n        n_estimators : 693\n           max_depth : 5\n       learning_rate : 0.011868495043167594\n    colsample_bytree : 0.43539904579824357\n           subsample : 0.46481811563000125\n               alpha : 29.008487087999395\n              lambda : 191.6403821494657\n               gamma : 3.0020182671759544e-09\n    min_child_weight : 0.11334395933925108\nbest objective value : 0.018248456036676686\nOptuna XGB train: 8.228583416495713 0.05303035505421494 118.83995366096497\nMin_prd:  275\nConstant guess:  7.313710789903448 0.0\nXGB test: 7.315589976502754 0.013317218293824484\nXGB GS test: 7.303835723170866 0.017266134436935476\nOptuna XGB test: 7.280995652870029 0.022633949782203455\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(89414, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd     mom482     mom242  year     RET   ind        bm  \\\n224   10006  299 -19.434584 -38.390360  1983  0.1605  25.0  0.467418   \n225   10006  300 -21.388149 -35.843377  1983  5.9567  25.0  0.467418   \n226   10006  301 -13.964189 -34.528211  1983 -1.4988  25.0  0.467418   \n227   10006  302 -17.681530 -29.776396  1983  2.7008  25.0  0.467418   \n228   10006  303 -18.595559 -22.961625  1983 -2.1893  25.0  0.784207   \n\n           op        gp       inv   mom11     mom122      amhd  ivol_capm  \\\n224  0.097309  0.220497  0.118136 -4.5159  -9.790204  1.628314   1.033030   \n225  0.097309  0.220497  0.118136  0.1605  -7.157811  1.598340   1.063466   \n226  0.097309  0.220497  0.118136  5.9567 -12.456541  1.521537   1.313733   \n227  0.097309  0.220497  0.118136 -1.4988   0.904921  1.485340   2.426025   \n228  0.088427  0.222761 -0.032575  2.7008   8.156360  1.298865   1.393089   \n\n     ivol_ff5   beta_bw     MAX     vol1m     vol6m    vol12m      size  \\\n224  0.727775  0.814121  1.4386  1.157497  1.825477  1.691859  5.560153   \n225  0.936522  0.799767  2.3259  1.152686  1.614224  1.667907  5.568027   \n226  1.155573  0.808885  4.1307  1.433440  1.474423  1.647114  5.632566   \n227  2.027979  0.825450  4.3466  2.604619  1.663623  1.780087  5.621046   \n228  1.343269  0.796333  3.7153  1.412173  1.616113  1.743533  5.654198   \n\n          lbm       lop       lgp      linv      llme    l1amhd   l1MAX  \\\n224  0.274945  0.118348  0.237469  0.091161  5.825327  1.626665  4.1337   \n225  0.274945  0.118348  0.237469  0.091161  5.740770  1.628314  1.4386   \n226  0.274945  0.118348  0.237469  0.091161  5.811722  1.598340  2.3259   \n227  0.274945  0.118348  0.237469  0.091161  5.718464  1.521537  4.1307   \n228  0.467418  0.097309  0.220497  0.118136  5.650019  1.485340  4.3466   \n\n       l3amhd   l3MAX    l6amhd   l6MAX   l12amhd  l12MAX  l12mom122  \\\n224  1.715833  4.1367  1.781569  5.0932  1.422049  4.1337 -30.659974   \n225  1.671621  4.0013  1.786906  4.5785  1.440860  1.4386 -30.101733   \n226  1.626665  4.1337  1.762098  3.9561  1.526839  2.3259 -29.730986   \n227  1.628314  1.4386  1.715833  4.1367  1.559589  4.1307 -29.282674   \n228  1.598340  2.3259  1.671621  4.0013  1.691079  4.3466 -28.654955   \n\n     l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n224      0.986262     0.964204    0.843484  1.687154   1.437885  \n225      1.193522     1.015454    0.852702  1.554393   1.440870  \n226      1.645750     1.498313    0.865615  1.602011   1.493237  \n227      0.983334     0.916348    0.864828  1.585183   1.486680  \n228      1.557424     1.486731    0.901204  1.618876   1.559004  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>224</th>\n      <td>10006</td>\n      <td>299</td>\n      <td>-19.434584</td>\n      <td>-38.390360</td>\n      <td>1983</td>\n      <td>0.1605</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>-4.5159</td>\n      <td>-9.790204</td>\n      <td>1.628314</td>\n      <td>1.033030</td>\n      <td>0.727775</td>\n      <td>0.814121</td>\n      <td>1.4386</td>\n      <td>1.157497</td>\n      <td>1.825477</td>\n      <td>1.691859</td>\n      <td>5.560153</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.825327</td>\n      <td>1.626665</td>\n      <td>4.1337</td>\n      <td>1.715833</td>\n      <td>4.1367</td>\n      <td>1.781569</td>\n      <td>5.0932</td>\n      <td>1.422049</td>\n      <td>4.1337</td>\n      <td>-30.659974</td>\n      <td>0.986262</td>\n      <td>0.964204</td>\n      <td>0.843484</td>\n      <td>1.687154</td>\n      <td>1.437885</td>\n    </tr>\n    <tr>\n      <th>225</th>\n      <td>10006</td>\n      <td>300</td>\n      <td>-21.388149</td>\n      <td>-35.843377</td>\n      <td>1983</td>\n      <td>5.9567</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>0.1605</td>\n      <td>-7.157811</td>\n      <td>1.598340</td>\n      <td>1.063466</td>\n      <td>0.936522</td>\n      <td>0.799767</td>\n      <td>2.3259</td>\n      <td>1.152686</td>\n      <td>1.614224</td>\n      <td>1.667907</td>\n      <td>5.568027</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.740770</td>\n      <td>1.628314</td>\n      <td>1.4386</td>\n      <td>1.671621</td>\n      <td>4.0013</td>\n      <td>1.786906</td>\n      <td>4.5785</td>\n      <td>1.440860</td>\n      <td>1.4386</td>\n      <td>-30.101733</td>\n      <td>1.193522</td>\n      <td>1.015454</td>\n      <td>0.852702</td>\n      <td>1.554393</td>\n      <td>1.440870</td>\n    </tr>\n    <tr>\n      <th>226</th>\n      <td>10006</td>\n      <td>301</td>\n      <td>-13.964189</td>\n      <td>-34.528211</td>\n      <td>1983</td>\n      <td>-1.4988</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>5.9567</td>\n      <td>-12.456541</td>\n      <td>1.521537</td>\n      <td>1.313733</td>\n      <td>1.155573</td>\n      <td>0.808885</td>\n      <td>4.1307</td>\n      <td>1.433440</td>\n      <td>1.474423</td>\n      <td>1.647114</td>\n      <td>5.632566</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.811722</td>\n      <td>1.598340</td>\n      <td>2.3259</td>\n      <td>1.626665</td>\n      <td>4.1337</td>\n      <td>1.762098</td>\n      <td>3.9561</td>\n      <td>1.526839</td>\n      <td>2.3259</td>\n      <td>-29.730986</td>\n      <td>1.645750</td>\n      <td>1.498313</td>\n      <td>0.865615</td>\n      <td>1.602011</td>\n      <td>1.493237</td>\n    </tr>\n    <tr>\n      <th>227</th>\n      <td>10006</td>\n      <td>302</td>\n      <td>-17.681530</td>\n      <td>-29.776396</td>\n      <td>1983</td>\n      <td>2.7008</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>-1.4988</td>\n      <td>0.904921</td>\n      <td>1.485340</td>\n      <td>2.426025</td>\n      <td>2.027979</td>\n      <td>0.825450</td>\n      <td>4.3466</td>\n      <td>2.604619</td>\n      <td>1.663623</td>\n      <td>1.780087</td>\n      <td>5.621046</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.718464</td>\n      <td>1.521537</td>\n      <td>4.1307</td>\n      <td>1.628314</td>\n      <td>1.4386</td>\n      <td>1.715833</td>\n      <td>4.1367</td>\n      <td>1.559589</td>\n      <td>4.1307</td>\n      <td>-29.282674</td>\n      <td>0.983334</td>\n      <td>0.916348</td>\n      <td>0.864828</td>\n      <td>1.585183</td>\n      <td>1.486680</td>\n    </tr>\n    <tr>\n      <th>228</th>\n      <td>10006</td>\n      <td>303</td>\n      <td>-18.595559</td>\n      <td>-22.961625</td>\n      <td>1983</td>\n      <td>-2.1893</td>\n      <td>25.0</td>\n      <td>0.784207</td>\n      <td>0.088427</td>\n      <td>0.222761</td>\n      <td>-0.032575</td>\n      <td>2.7008</td>\n      <td>8.156360</td>\n      <td>1.298865</td>\n      <td>1.393089</td>\n      <td>1.343269</td>\n      <td>0.796333</td>\n      <td>3.7153</td>\n      <td>1.412173</td>\n      <td>1.616113</td>\n      <td>1.743533</td>\n      <td>5.654198</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>5.650019</td>\n      <td>1.485340</td>\n      <td>4.3466</td>\n      <td>1.598340</td>\n      <td>2.3259</td>\n      <td>1.671621</td>\n      <td>4.0013</td>\n      <td>1.691079</td>\n      <td>4.3466</td>\n      <td>-28.654955</td>\n      <td>1.557424</td>\n      <td>1.486731</td>\n      <td>0.901204</td>\n      <td>1.618876</td>\n      <td>1.559004</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    89414.000000\nmean      1984.326616\nstd          0.986718\nmin       1983.000000\n25%       1984.000000\n50%       1984.000000\n75%       1985.000000\nmax       1986.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          89414\nprd             89414\nmom482          77366\nmom242          87910\nyear            89414\nRET             89414\nind             89414\nbm              89414\nop              89414\ngp              89414\ninv             89384\nmom11           89414\nmom122          89414\namhd            67483\nivol_capm       89406\nivol_ff5        89406\nbeta_bw         89414\nMAX             89414\nvol1m           89392\nvol6m           89332\nvol12m          89193\nsize            89414\nlbm             89414\nlop             89414\nlgp             89414\nlinv            89414\nllme            89414\nl1amhd          66888\nl1MAX           89409\nl3amhd          65668\nl3MAX           89393\nl6amhd          63736\nl6MAX           89361\nl12amhd         59151\nl12MAX          89409\nl12mom122       88531\nl12ivol_capm    89301\nl12ivol_ff5     89301\nl12beta_bw      89339\nl12vol6m        89013\nl12vol12m       88279\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (84583, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (84583, 85)\nmae of a constant model 8.393769117304654\nR2 of a constant model 0.0\nXGB train: 8.000355608201236 0.09705730394764789\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\nXGB {'colsample_bytree': 0.6, 'eta': 0.012, 'max_depth': 4, 'n_estimators': 400, 'subsample': 0.6} 0.018440684769371496 42.742186069488525\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:45:30,623]\u001b[0m A new study created in memory with name: no-name-19b3fbb8-271b-402d-a253-b31d352c4992\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 8.165630249798962 0.04491956015580256 44.55995202064514\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:45:36,827]\u001b[0m Trial 0 finished with value: 0.01133172457126716 and parameters: {'n_estimators': 563, 'max_depth': 5, 'learning_rate': 0.024621442014199153, 'colsample_bytree': 0.6692765609583952, 'subsample': 0.5708882627737302, 'alpha': 0.8095008713389503, 'lambda': 26.843108540541774, 'gamma': 2.5419559569322462e-08, 'min_child_weight': 0.3486141817549073}. Best is trial 0 with value: 0.01133172457126716.\u001b[0m\n\u001b[32m[I 2022-08-25 20:45:46,700]\u001b[0m Trial 1 finished with value: 0.013649453276395202 and parameters: {'n_estimators': 937, 'max_depth': 5, 'learning_rate': 0.008922820238053766, 'colsample_bytree': 0.5645332963763817, 'subsample': 0.5073385590714552, 'alpha': 10.532285470795207, 'lambda': 1.6395672693649879, 'gamma': 1.550942136082451e-07, 'min_child_weight': 5.159343485952076}. Best is trial 1 with value: 0.013649453276395202.\u001b[0m\n\u001b[32m[I 2022-08-25 20:45:52,358]\u001b[0m Trial 2 finished with value: 0.014390491494072023 and parameters: {'n_estimators': 907, 'max_depth': 3, 'learning_rate': 0.023418476860217176, 'colsample_bytree': 0.47115457137934746, 'subsample': 0.30161610327877164, 'alpha': 2.6199835439075474, 'lambda': 18.22071999303465, 'gamma': 0.0034299025575786294, 'min_child_weight': 3.353550106482179}. Best is trial 2 with value: 0.014390491494072023.\u001b[0m\n\u001b[32m[I 2022-08-25 20:45:59,643]\u001b[0m Trial 3 finished with value: 0.015417598827169648 and parameters: {'n_estimators': 990, 'max_depth': 4, 'learning_rate': 0.011627372967971984, 'colsample_bytree': 0.27619826944131415, 'subsample': 0.3572824784481873, 'alpha': 0.5249422408063438, 'lambda': 39.386851860331674, 'gamma': 0.9811570223868377, 'min_child_weight': 3.809676785066318}. Best is trial 3 with value: 0.015417598827169648.\u001b[0m\n\u001b[32m[I 2022-08-25 20:46:07,567]\u001b[0m Trial 4 finished with value: -0.0018566414339904677 and parameters: {'n_estimators': 995, 'max_depth': 4, 'learning_rate': 0.0342016137591052, 'colsample_bytree': 0.869097759611615, 'subsample': 0.9400845616815887, 'alpha': 0.7940956183335838, 'lambda': 2.845400723709372, 'gamma': 0.7421866034940477, 'min_child_weight': 0.14953097886022843}. Best is trial 3 with value: 0.015417598827169648.\u001b[0m\n\u001b[32m[I 2022-08-25 20:46:17,731]\u001b[0m Trial 5 finished with value: 0.014440639891649199 and parameters: {'n_estimators': 967, 'max_depth': 5, 'learning_rate': 0.006882579424644658, 'colsample_bytree': 0.8052806388155961, 'subsample': 0.37721495646873365, 'alpha': 5.320783393692608, 'lambda': 0.7550670181306298, 'gamma': 0.6452300397392654, 'min_child_weight': 15.582312333355386}. Best is trial 3 with value: 0.015417598827169648.\u001b[0m\n\u001b[32m[I 2022-08-25 20:46:22,325]\u001b[0m Trial 6 finished with value: 0.01811309964125538 and parameters: {'n_estimators': 560, 'max_depth': 4, 'learning_rate': 0.00760343789852825, 'colsample_bytree': 0.7174450812893567, 'subsample': 0.45235334667497823, 'alpha': 4.626895147286654, 'lambda': 185.1445861490581, 'gamma': 2.3073905224152802e-10, 'min_child_weight': 0.4697827310079493}. Best is trial 6 with value: 0.01811309964125538.\u001b[0m\n\u001b[32m[I 2022-08-25 20:46:25,310]\u001b[0m Trial 7 finished with value: 0.016912784104157433 and parameters: {'n_estimators': 542, 'max_depth': 2, 'learning_rate': 0.022776408624504918, 'colsample_bytree': 0.8721970147800608, 'subsample': 0.41321328279885683, 'alpha': 0.6141962561577236, 'lambda': 34.10761575859987, 'gamma': 1.4030464675600348e-07, 'min_child_weight': 0.2207824639209646}. Best is trial 6 with value: 0.01811309964125538.\u001b[0m\n\u001b[32m[I 2022-08-25 20:46:32,638]\u001b[0m Trial 8 finished with value: 0.008492242588108441 and parameters: {'n_estimators': 883, 'max_depth': 4, 'learning_rate': 0.04544184601797226, 'colsample_bytree': 0.34586722214835836, 'subsample': 0.5419684273659925, 'alpha': 0.2150437579659772, 'lambda': 164.28821825775668, 'gamma': 0.43042192776211413, 'min_child_weight': 2.721180954906831}. Best is trial 6 with value: 0.01811309964125538.\u001b[0m\n\u001b[32m[I 2022-08-25 20:46:39,331]\u001b[0m Trial 9 finished with value: -0.003866161670776147 and parameters: {'n_estimators': 826, 'max_depth': 4, 'learning_rate': 0.04621089308321264, 'colsample_bytree': 0.5063908832435995, 'subsample': 0.8551177017185829, 'alpha': 28.03113768468632, 'lambda': 8.834975429564167, 'gamma': 8.184122070585212e-09, 'min_child_weight': 2.6039105166954566}. Best is trial 6 with value: 0.01811309964125538.\u001b[0m\n\u001b[32m[I 2022-08-25 20:46:42,727]\u001b[0m Trial 10 finished with value: 0.008184921289109245 and parameters: {'n_estimators': 662, 'max_depth': 2, 'learning_rate': 0.001230446987647361, 'colsample_bytree': 0.681205583249159, 'subsample': 0.7278596019585328, 'alpha': 2.930793241603563, 'lambda': 0.10992011751669947, 'gamma': 2.813719493898946e-05, 'min_child_weight': 0.6723423072178234}. Best is trial 6 with value: 0.01811309964125538.\u001b[0m\n\u001b[32m[I 2022-08-25 20:46:45,607]\u001b[0m Trial 11 finished with value: 0.01821069155642014 and parameters: {'n_estimators': 540, 'max_depth': 2, 'learning_rate': 0.01815822525577362, 'colsample_bytree': 0.9488239234409468, 'subsample': 0.448510588807441, 'alpha': 0.10389464772484477, 'lambda': 179.87171391155377, 'gamma': 1.519574733268913e-10, 'min_child_weight': 0.1000204054237857}. Best is trial 11 with value: 0.01821069155642014.\u001b[0m\n\u001b[32m[I 2022-08-25 20:46:49,841]\u001b[0m Trial 12 finished with value: 0.018179576176211437 and parameters: {'n_estimators': 652, 'max_depth': 3, 'learning_rate': 0.016333574183233952, 'colsample_bytree': 0.9210077876266414, 'subsample': 0.672910593158526, 'alpha': 0.13154621338890607, 'lambda': 186.00376032021475, 'gamma': 1.881054989283314e-10, 'min_child_weight': 0.6344140192896075}. Best is trial 11 with value: 0.01821069155642014.\u001b[0m\n\u001b[32m[I 2022-08-25 20:46:54,053]\u001b[0m Trial 13 finished with value: 0.018872476727951493 and parameters: {'n_estimators': 674, 'max_depth': 3, 'learning_rate': 0.015507139165931536, 'colsample_bytree': 0.9265980975459144, 'subsample': 0.6849594479584783, 'alpha': 0.10086193844245119, 'lambda': 87.68914911460818, 'gamma': 1.1236155405156776e-10, 'min_child_weight': 0.11509837084394178}. Best is trial 13 with value: 0.018872476727951493.\u001b[0m\n\u001b[32m[I 2022-08-25 20:46:57,863]\u001b[0m Trial 14 finished with value: 0.01744898627401603 and parameters: {'n_estimators': 703, 'max_depth': 2, 'learning_rate': 0.033784973580884864, 'colsample_bytree': 0.9284839599648052, 'subsample': 0.750300211794828, 'alpha': 0.10684329880381749, 'lambda': 70.18242386825483, 'gamma': 8.658256679478512e-06, 'min_child_weight': 0.10723260571958702}. Best is trial 13 with value: 0.018872476727951493.\u001b[0m\n\u001b[32m[I 2022-08-25 20:47:02,455]\u001b[0m Trial 15 finished with value: 0.017777475593616157 and parameters: {'n_estimators': 773, 'max_depth': 3, 'learning_rate': 0.016797071276897054, 'colsample_bytree': 0.1365707974258205, 'subsample': 0.6249148864873859, 'alpha': 0.25802827283239593, 'lambda': 10.189110479170008, 'gamma': 1.9988241303792804e-09, 'min_child_weight': 41.51841626446887}. Best is trial 13 with value: 0.018872476727951493.\u001b[0m\n\u001b[32m[I 2022-08-25 20:47:05,628]\u001b[0m Trial 16 finished with value: 0.017519771164852663 and parameters: {'n_estimators': 613, 'max_depth': 2, 'learning_rate': 0.029522199057038657, 'colsample_bytree': 0.7770689814286085, 'subsample': 0.8300209467516054, 'alpha': 0.24133777083438004, 'lambda': 77.50968502949677, 'gamma': 0.0011113149818377458, 'min_child_weight': 1.3500746258085838}. Best is trial 13 with value: 0.018872476727951493.\u001b[0m\n\u001b[32m[I 2022-08-25 20:47:10,433]\u001b[0m Trial 17 finished with value: 0.017726851511926114 and parameters: {'n_estimators': 766, 'max_depth': 3, 'learning_rate': 0.017715559262068976, 'colsample_bytree': 0.9499600595388507, 'subsample': 0.6379003809719138, 'alpha': 0.10226102632798972, 'lambda': 74.99646688396075, 'gamma': 2.283693988741878e-06, 'min_child_weight': 0.19446382668208706}. Best is trial 13 with value: 0.018872476727951493.\u001b[0m\n\u001b[32m[I 2022-08-25 20:47:13,170]\u001b[0m Trial 18 finished with value: 0.00959552654466559 and parameters: {'n_estimators': 514, 'max_depth': 2, 'learning_rate': 0.001862841223769951, 'colsample_bytree': 0.6052086074161787, 'subsample': 0.4797595979230859, 'alpha': 0.36935568709872885, 'lambda': 0.21955673602141337, 'gamma': 1.1794786075105794e-09, 'min_child_weight': 1.344864011646526}. Best is trial 13 with value: 0.018872476727951493.\u001b[0m\n\u001b[32m[I 2022-08-25 20:47:17,107]\u001b[0m Trial 19 finished with value: 0.016867873210775045 and parameters: {'n_estimators': 624, 'max_depth': 3, 'learning_rate': 0.013508960030871603, 'colsample_bytree': 0.7950436795061555, 'subsample': 0.5998052505381176, 'alpha': 1.4718024949603927, 'lambda': 6.889042920665625, 'gamma': 0.0006533503837677921, 'min_child_weight': 0.10761227468445833}. Best is trial 13 with value: 0.018872476727951493.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  106.48562169075012\n        n_estimators : 674\n           max_depth : 3\n       learning_rate : 0.015507139165931536\n    colsample_bytree : 0.9265980975459144\n           subsample : 0.6849594479584783\n               alpha : 0.10086193844245119\n              lambda : 87.68914911460818\n               gamma : 1.1236155405156776e-10\n    min_child_weight : 0.11509837084394178\nbest objective value : 0.018872476727951493\nOptuna XGB train: 8.175172129404523 0.039448178976969284 109.0122184753418\nMin_prd:  300\nConstant guess:  9.021598745386575 0.0\nXGB test: 9.081703222798415 -0.009404386780343499\nXGB GS test: 9.050739697306778 -0.0005889493404265256\nOptuna XGB test: 9.051690485775001 -0.0018547694606243503\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(92653, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"      PERMNO  prd  mom482     mom242  year      RET   ind        bm        op  \\\n1809   10031  339     NaN        NaN  1986   4.8854  42.0 -0.662806  0.088703   \n1810   10031  351     NaN -18.540757  1987  -0.4600  42.0 -0.594143  0.054610   \n1811   10031  352     NaN -21.316912  1987  15.3195  42.0 -0.594143  0.054610   \n1812   10031  353     NaN  -6.534634  1987  -2.7227  42.0 -0.594143  0.054610   \n1813   10031  354     NaN  -8.523998  1987 -23.8558  42.0 -0.594143  0.054610   \n\n            gp       inv    mom11     mom122  amhd  ivol_capm  ivol_ff5  \\\n1809  0.587186 -0.033767  -3.1516  18.939107   NaN   0.765013  0.647098   \n1810  0.738385  0.697610  -0.4800  -2.232171   NaN   0.765013  0.647098   \n1811  0.738385  0.697610  -0.4600  -7.233473   NaN   0.765013  0.647098   \n1812  0.738385  0.697610  15.3195  -7.233473   NaN   3.389156  2.914959   \n1813  0.738385  0.697610  -2.7227   2.196919   NaN   1.130335  1.101901   \n\n       beta_bw      MAX     vol1m     vol6m    vol12m      size       lbm  \\\n1809  0.407036   1.4066  0.866870  1.133002  1.218480  2.518412 -0.216519   \n1810  0.454047   1.4066  0.866870  1.133002  1.189544  2.545080 -0.216519   \n1811  0.465710   1.4066  0.866870  1.133002  1.189544  2.545080 -0.216519   \n1812  0.434743  15.7675  3.445551  1.532002  1.253984  2.691684 -0.216519   \n1813  0.451557   2.3600  1.142533  1.601022  1.276181  2.668694 -0.216519   \n\n           lop       lgp      linv      llme  l1amhd    l1MAX  l3amhd   l3MAX  \\\n1809  0.088703  0.587186 -0.033767  2.308691     NaN   1.4066     NaN  2.9112   \n1810  0.088703  0.587186 -0.033767  2.633187     NaN   1.4066     NaN  2.8331   \n1811  0.088703  0.587186 -0.033767  2.668694     NaN   1.4066     NaN  1.4066   \n1812  0.088703  0.587186 -0.033767  2.645164     NaN   1.4066     NaN  1.4066   \n1813  0.088703  0.587186 -0.033767  2.645164     NaN  15.7675     NaN  1.4066   \n\n      l6amhd   l6MAX  l12amhd   l12MAX  l12mom122  l12ivol_capm  l12ivol_ff5  \\\n1809     NaN  2.7087      NaN   1.4066 -18.859893      0.765013     0.647098   \n1810     NaN  1.4066      NaN   1.4066   6.666485      1.923407     1.545611   \n1811     NaN  1.4066      NaN   1.4066  37.460954      1.417848     1.194093   \n1812     NaN  2.9112      NaN   1.4066  42.902406      0.765013     0.647098   \n1813     NaN  2.8331      NaN  15.7675  57.128111      0.765013     0.647098   \n\n      l12beta_bw  l12vol6m  l12vol12m  \n1809    0.531826  1.376322        NaN  \n1810    0.473251  1.593294        NaN  \n1811    0.558271  1.620862        NaN  \n1812    0.571238  1.632742        NaN  \n1813    0.582214  1.612387        NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1809</th>\n      <td>10031</td>\n      <td>339</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1986</td>\n      <td>4.8854</td>\n      <td>42.0</td>\n      <td>-0.662806</td>\n      <td>0.088703</td>\n      <td>0.587186</td>\n      <td>-0.033767</td>\n      <td>-3.1516</td>\n      <td>18.939107</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.407036</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>1.133002</td>\n      <td>1.218480</td>\n      <td>2.518412</td>\n      <td>-0.216519</td>\n      <td>0.088703</td>\n      <td>0.587186</td>\n      <td>-0.033767</td>\n      <td>2.308691</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>2.9112</td>\n      <td>NaN</td>\n      <td>2.7087</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>-18.859893</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.531826</td>\n      <td>1.376322</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1810</th>\n      <td>10031</td>\n      <td>351</td>\n      <td>NaN</td>\n      <td>-18.540757</td>\n      <td>1987</td>\n      <td>-0.4600</td>\n      <td>42.0</td>\n      <td>-0.594143</td>\n      <td>0.054610</td>\n      <td>0.738385</td>\n      <td>0.697610</td>\n      <td>-0.4800</td>\n      <td>-2.232171</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.454047</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>1.133002</td>\n      <td>1.189544</td>\n      <td>2.545080</td>\n      <td>-0.216519</td>\n      <td>0.088703</td>\n      <td>0.587186</td>\n      <td>-0.033767</td>\n      <td>2.633187</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>2.8331</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>6.666485</td>\n      <td>1.923407</td>\n      <td>1.545611</td>\n      <td>0.473251</td>\n      <td>1.593294</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1811</th>\n      <td>10031</td>\n      <td>352</td>\n      <td>NaN</td>\n      <td>-21.316912</td>\n      <td>1987</td>\n      <td>15.3195</td>\n      <td>42.0</td>\n      <td>-0.594143</td>\n      <td>0.054610</td>\n      <td>0.738385</td>\n      <td>0.697610</td>\n      <td>-0.4600</td>\n      <td>-7.233473</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.465710</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>1.133002</td>\n      <td>1.189544</td>\n      <td>2.545080</td>\n      <td>-0.216519</td>\n      <td>0.088703</td>\n      <td>0.587186</td>\n      <td>-0.033767</td>\n      <td>2.668694</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>37.460954</td>\n      <td>1.417848</td>\n      <td>1.194093</td>\n      <td>0.558271</td>\n      <td>1.620862</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1812</th>\n      <td>10031</td>\n      <td>353</td>\n      <td>NaN</td>\n      <td>-6.534634</td>\n      <td>1987</td>\n      <td>-2.7227</td>\n      <td>42.0</td>\n      <td>-0.594143</td>\n      <td>0.054610</td>\n      <td>0.738385</td>\n      <td>0.697610</td>\n      <td>15.3195</td>\n      <td>-7.233473</td>\n      <td>NaN</td>\n      <td>3.389156</td>\n      <td>2.914959</td>\n      <td>0.434743</td>\n      <td>15.7675</td>\n      <td>3.445551</td>\n      <td>1.532002</td>\n      <td>1.253984</td>\n      <td>2.691684</td>\n      <td>-0.216519</td>\n      <td>0.088703</td>\n      <td>0.587186</td>\n      <td>-0.033767</td>\n      <td>2.645164</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>2.9112</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>42.902406</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.571238</td>\n      <td>1.632742</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1813</th>\n      <td>10031</td>\n      <td>354</td>\n      <td>NaN</td>\n      <td>-8.523998</td>\n      <td>1987</td>\n      <td>-23.8558</td>\n      <td>42.0</td>\n      <td>-0.594143</td>\n      <td>0.054610</td>\n      <td>0.738385</td>\n      <td>0.697610</td>\n      <td>-2.7227</td>\n      <td>2.196919</td>\n      <td>NaN</td>\n      <td>1.130335</td>\n      <td>1.101901</td>\n      <td>0.451557</td>\n      <td>2.3600</td>\n      <td>1.142533</td>\n      <td>1.601022</td>\n      <td>1.276181</td>\n      <td>2.668694</td>\n      <td>-0.216519</td>\n      <td>0.088703</td>\n      <td>0.587186</td>\n      <td>-0.033767</td>\n      <td>2.645164</td>\n      <td>NaN</td>\n      <td>15.7675</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>2.8331</td>\n      <td>NaN</td>\n      <td>15.7675</td>\n      <td>57.128111</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.582214</td>\n      <td>1.612387</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    92653.000000\nmean      1986.389032\nstd          1.001490\nmin       1985.000000\n25%       1986.000000\n50%       1986.000000\n75%       1987.000000\nmax       1988.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          92653\nprd             92653\nmom482          76796\nmom242          91021\nyear            92653\nRET             92653\nind             92653\nbm              92653\nop              92653\ngp              92653\ninv             92559\nmom11           92653\nmom122          92653\namhd            73401\nivol_capm       92648\nivol_ff5        92648\nbeta_bw         92653\nMAX             92653\nvol1m           92638\nvol6m           92569\nvol12m          92424\nsize            92653\nlbm             92653\nlop             92653\nlgp             92653\nlinv            92653\nllme            92653\nl1amhd          73486\nl1MAX           92650\nl3amhd          73591\nl3MAX           92636\nl6amhd          73644\nl6MAX           92620\nl12amhd         74003\nl12MAX          92650\nl12mom122       92052\nl12ivol_capm    92563\nl12ivol_ff5     92563\nl12beta_bw      92596\nl12vol6m        92297\nl12vol12m       91407\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (87485, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (87485, 85)\nmae of a constant model 8.904606616730787\nR2 of a constant model 0.0\nXGB train: 8.592757719404272 0.08396147947934063\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\nXGB {'colsample_bytree': 0.6, 'eta': 0.02, 'max_depth': 3, 'n_estimators': 400, 'subsample': 0.6} 0.010663195950263271 43.85906624794006\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:48:07,714]\u001b[0m A new study created in memory with name: no-name-3619763e-f793-4526-b6b3-5282027900cd\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 8.781819533294557 0.029098676615708197 44.513224363327026\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:48:13,343]\u001b[0m Trial 0 finished with value: 0.005809530005552209 and parameters: {'n_estimators': 711, 'max_depth': 4, 'learning_rate': 0.034012829502802704, 'colsample_bytree': 0.6377745880564336, 'subsample': 0.7915834430286488, 'alpha': 3.556950829683322, 'lambda': 179.36878343604005, 'gamma': 1.5524516954314835e-07, 'min_child_weight': 1.0613723371756534}. Best is trial 0 with value: 0.005809530005552209.\u001b[0m\n\u001b[32m[I 2022-08-25 20:48:20,774]\u001b[0m Trial 1 finished with value: 0.00332523141157047 and parameters: {'n_estimators': 687, 'max_depth': 5, 'learning_rate': 0.017649328941305203, 'colsample_bytree': 0.4010402318747599, 'subsample': 0.3845140031582333, 'alpha': 0.7389622850836521, 'lambda': 4.333247252188515, 'gamma': 1.7151950026360052, 'min_child_weight': 0.6207617073354732}. Best is trial 0 with value: 0.005809530005552209.\u001b[0m\n\u001b[32m[I 2022-08-25 20:48:24,273]\u001b[0m Trial 2 finished with value: 0.00814621122268955 and parameters: {'n_estimators': 559, 'max_depth': 3, 'learning_rate': 0.03438927107229185, 'colsample_bytree': 0.15254371539277797, 'subsample': 0.7238333412969932, 'alpha': 8.697473179510514, 'lambda': 3.313743519742952, 'gamma': 1.2013256143229534, 'min_child_weight': 14.843624899789594}. Best is trial 2 with value: 0.00814621122268955.\u001b[0m\n\u001b[32m[I 2022-08-25 20:48:28,563]\u001b[0m Trial 3 finished with value: -4.272963271210626e-05 and parameters: {'n_estimators': 677, 'max_depth': 3, 'learning_rate': 0.04509836224382351, 'colsample_bytree': 0.5912310091496497, 'subsample': 0.5609682257835864, 'alpha': 1.348632962146616, 'lambda': 8.593323030563072, 'gamma': 2.725874186119497, 'min_child_weight': 0.14303910629458727}. Best is trial 2 with value: 0.00814621122268955.\u001b[0m\n\u001b[32m[I 2022-08-25 20:48:35,988]\u001b[0m Trial 4 finished with value: 0.008970125140794627 and parameters: {'n_estimators': 884, 'max_depth': 4, 'learning_rate': 0.013605958821979482, 'colsample_bytree': 0.9021908775996487, 'subsample': 0.41463948800844597, 'alpha': 0.3160362720211106, 'lambda': 143.8979255157906, 'gamma': 3.4844706914979312e-06, 'min_child_weight': 10.187011579220568}. Best is trial 4 with value: 0.008970125140794627.\u001b[0m\n\u001b[32m[I 2022-08-25 20:48:44,039]\u001b[0m Trial 5 finished with value: -0.003882570383993769 and parameters: {'n_estimators': 993, 'max_depth': 4, 'learning_rate': 0.03188253094217093, 'colsample_bytree': 0.6470931292504989, 'subsample': 0.739072417933037, 'alpha': 0.15974603202111426, 'lambda': 0.21295262812617483, 'gamma': 8.713931922917542e-07, 'min_child_weight': 36.98186390346707}. Best is trial 4 with value: 0.008970125140794627.\u001b[0m\n\u001b[32m[I 2022-08-25 20:48:53,138]\u001b[0m Trial 6 finished with value: -0.004565198522635172 and parameters: {'n_estimators': 876, 'max_depth': 5, 'learning_rate': 0.03324145025333294, 'colsample_bytree': 0.18750082630373915, 'subsample': 0.855841594403066, 'alpha': 4.257563874280012, 'lambda': 28.67659249611656, 'gamma': 0.2375456092204269, 'min_child_weight': 4.433842624185707}. Best is trial 4 with value: 0.008970125140794627.\u001b[0m\n\u001b[32m[I 2022-08-25 20:49:04,040]\u001b[0m Trial 7 finished with value: -0.011479150506548474 and parameters: {'n_estimators': 993, 'max_depth': 5, 'learning_rate': 0.027298175259775945, 'colsample_bytree': 0.5761256977961858, 'subsample': 0.6852965146756329, 'alpha': 0.18746006814913557, 'lambda': 3.2708856500329597, 'gamma': 3.8059887920733267e-07, 'min_child_weight': 2.977210202752221}. Best is trial 4 with value: 0.008970125140794627.\u001b[0m\n\u001b[32m[I 2022-08-25 20:49:11,531]\u001b[0m Trial 8 finished with value: 0.009359893789380687 and parameters: {'n_estimators': 695, 'max_depth': 5, 'learning_rate': 0.00514521402519841, 'colsample_bytree': 0.4468838931057453, 'subsample': 0.8749982845571231, 'alpha': 0.10524732228517038, 'lambda': 0.15050330427949668, 'gamma': 2.7063639671250803e-09, 'min_child_weight': 12.738556851491106}. Best is trial 8 with value: 0.009359893789380687.\u001b[0m\n\u001b[32m[I 2022-08-25 20:49:15,409]\u001b[0m Trial 9 finished with value: 0.008697320535658084 and parameters: {'n_estimators': 761, 'max_depth': 2, 'learning_rate': 0.02765189085581356, 'colsample_bytree': 0.8955496909051182, 'subsample': 0.3722363058139105, 'alpha': 4.625657688952263, 'lambda': 102.80619356923063, 'gamma': 2.08518573964548e-07, 'min_child_weight': 40.63319568406003}. Best is trial 8 with value: 0.009359893789380687.\u001b[0m\n\u001b[32m[I 2022-08-25 20:49:18,401]\u001b[0m Trial 10 finished with value: 0.004262255199292876 and parameters: {'n_estimators': 560, 'max_depth': 2, 'learning_rate': 0.0014572865742037144, 'colsample_bytree': 0.3340023028076418, 'subsample': 0.9423651131116135, 'alpha': 29.26153341565898, 'lambda': 0.13925540599555922, 'gamma': 3.2683260848240383e-10, 'min_child_weight': 9.601732669048962}. Best is trial 8 with value: 0.009359893789380687.\u001b[0m\n\u001b[32m[I 2022-08-25 20:49:25,237]\u001b[0m Trial 11 finished with value: 0.006999934243594387 and parameters: {'n_estimators': 843, 'max_depth': 4, 'learning_rate': 0.008010613287720077, 'colsample_bytree': 0.9307261576085167, 'subsample': 0.5332580236112001, 'alpha': 0.10074450479773968, 'lambda': 0.6837072170054252, 'gamma': 2.392676236553901e-10, 'min_child_weight': 10.004144203327796}. Best is trial 8 with value: 0.009359893789380687.\u001b[0m\n\u001b[32m[I 2022-08-25 20:49:34,306]\u001b[0m Trial 12 finished with value: 0.0026970855100475703 and parameters: {'n_estimators': 843, 'max_depth': 5, 'learning_rate': 0.01313308385680925, 'colsample_bytree': 0.7647054297961251, 'subsample': 0.49571388791296656, 'alpha': 0.4317154074324808, 'lambda': 0.6939604389481789, 'gamma': 0.0002165146601931334, 'min_child_weight': 17.559798020668744}. Best is trial 8 with value: 0.009359893789380687.\u001b[0m\n\u001b[32m[I 2022-08-25 20:49:40,784]\u001b[0m Trial 13 finished with value: 0.00611062945387301 and parameters: {'n_estimators': 781, 'max_depth': 4, 'learning_rate': 0.001194476517962251, 'colsample_bytree': 0.4353305612395769, 'subsample': 0.303553174383087, 'alpha': 0.3543535193185261, 'lambda': 30.233518545055233, 'gamma': 0.00040335011065053194, 'min_child_weight': 5.85272053454664}. Best is trial 8 with value: 0.009359893789380687.\u001b[0m\n\u001b[32m[I 2022-08-25 20:49:45,143]\u001b[0m Trial 14 finished with value: 0.00897302682274617 and parameters: {'n_estimators': 628, 'max_depth': 3, 'learning_rate': 0.015718489321037424, 'colsample_bytree': 0.7770560528761702, 'subsample': 0.9417281091875868, 'alpha': 0.30162999017551967, 'lambda': 0.7617678728662262, 'gamma': 5.563132294336385e-09, 'min_child_weight': 1.168409107729597}. Best is trial 8 with value: 0.009359893789380687.\u001b[0m\n\u001b[32m[I 2022-08-25 20:49:49,067]\u001b[0m Trial 15 finished with value: 0.008048383679335785 and parameters: {'n_estimators': 611, 'max_depth': 3, 'learning_rate': 0.019479616819337922, 'colsample_bytree': 0.772572739177346, 'subsample': 0.932668961030921, 'alpha': 0.10747651294013287, 'lambda': 0.529464766292646, 'gamma': 4.062796309308547e-09, 'min_child_weight': 1.4405496707757006}. Best is trial 8 with value: 0.009359893789380687.\u001b[0m\n\u001b[32m[I 2022-08-25 20:49:52,328]\u001b[0m Trial 16 finished with value: 0.00977711278845668 and parameters: {'n_estimators': 503, 'max_depth': 3, 'learning_rate': 0.0076278138071787, 'colsample_bytree': 0.28065276906543934, 'subsample': 0.8388834977563512, 'alpha': 0.815932974914638, 'lambda': 0.3242963575367397, 'gamma': 7.23861724148527e-09, 'min_child_weight': 0.3810123565400147}. Best is trial 16 with value: 0.00977711278845668.\u001b[0m\n\u001b[32m[I 2022-08-25 20:49:55,347]\u001b[0m Trial 17 finished with value: 0.008616357231295424 and parameters: {'n_estimators': 500, 'max_depth': 2, 'learning_rate': 0.007975822939409717, 'colsample_bytree': 0.2621253379525886, 'subsample': 0.8315208874750256, 'alpha': 1.0400544487829335, 'lambda': 0.10008460928815048, 'gamma': 1.0010942429743346e-08, 'min_child_weight': 0.30018060665335294}. Best is trial 16 with value: 0.00977711278845668.\u001b[0m\n\u001b[32m[I 2022-08-25 20:49:58,767]\u001b[0m Trial 18 finished with value: 0.00920487638452959 and parameters: {'n_estimators': 528, 'max_depth': 3, 'learning_rate': 0.0051726623185938915, 'colsample_bytree': 0.4637119538985687, 'subsample': 0.6354530299168308, 'alpha': 2.2923199008043675, 'lambda': 0.23337163227389607, 'gamma': 0.010000940461293076, 'min_child_weight': 0.11555115392353993}. Best is trial 16 with value: 0.00977711278845668.\u001b[0m\n\u001b[32m[I 2022-08-25 20:50:01,995]\u001b[0m Trial 19 finished with value: 0.010046485631344401 and parameters: {'n_estimators': 617, 'max_depth': 2, 'learning_rate': 0.02325594233014819, 'colsample_bytree': 0.3201790452489346, 'subsample': 0.8549237333671368, 'alpha': 0.6654114246647382, 'lambda': 1.6249527925645046, 'gamma': 1.2623897196432703e-05, 'min_child_weight': 0.40488639555076245}. Best is trial 19 with value: 0.010046485631344401.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  114.28232026100159\n        n_estimators : 617\n           max_depth : 2\n       learning_rate : 0.02325594233014819\n    colsample_bytree : 0.3201790452489346\n           subsample : 0.8549237333671368\n               alpha : 0.6654114246647382\n              lambda : 1.6249527925645046\n               gamma : 1.2623897196432703e-05\n    min_child_weight : 0.40488639555076245\nbest objective value : 0.010046485631344401\nOptuna XGB train: 8.80627536154854 0.021212191335875485 115.96125650405884\nMin_prd:  325\nConstant guess:  7.5647841018428155 0.0\nXGB test: 7.577887957775383 -0.006069675653999962\nXGB GS test: 7.52660420458592 0.004754988127891879\nOptuna XGB test: 7.5167968941732335 0.006591995701068831\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(94366, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   PERMNO  prd  mom482     mom242  year      RET   ind        bm        op  \\\n0   10005  375     NaN -72.706514  1989  -0.7000  30.0  0.490174 -0.214332   \n1   10005  376     NaN -68.539010  1989 -20.7400  30.0  0.490174 -0.214332   \n2   10005  377     NaN -60.041983  1989 -25.6500  30.0  0.490174 -0.214332   \n3   10005  378     NaN -67.083392  1989  -0.6800  30.0  0.490174 -0.214332   \n4   10005  379     NaN -70.826677  1989  32.6433  30.0  0.490174 -0.214332   \n\n    gp       inv      mom11     mom122  amhd  ivol_capm  ivol_ff5   beta_bw  \\\n0  0.0 -0.230583  -0.710000 -33.516946   NaN   0.765013  0.647098  0.843440   \n1  0.0 -0.230583  -0.700000 -48.453613   NaN   0.765013  0.647098  0.569757   \n2  0.0 -0.230583 -20.740000 -48.510651   NaN   4.169273  3.399652  0.580613   \n3  0.0 -0.230583 -22.380465 -38.209694   NaN   5.565847  5.250996  0.663164   \n4  0.0 -0.230583  -0.680000 -53.776947   NaN   0.765013  0.647098  0.372045   \n\n      MAX     vol1m     vol6m    vol12m      size      lbm       lop  \\\n0  1.4066  0.866870  1.485001  3.167929 -0.424011  0.75014 -0.084639   \n1  1.4066  0.866870  1.484870  2.598143 -0.424011  0.75014 -0.084639   \n2  1.4066  4.364358  2.310132  2.882070 -0.647218  0.75014 -0.084639   \n3  1.4066  6.813720  3.190628  2.799597 -0.934794  0.75014 -0.084639   \n4  1.4066  0.866870  2.840962  2.265160 -0.934794  0.75014 -0.084639   \n\n        lgp      linv      llme  l1amhd   l1MAX  l3amhd   l3MAX  l6amhd  \\\n0  0.015282  0.306039 -0.087557     NaN  1.4066     NaN  1.4066     NaN   \n1  0.015282  0.306039  0.163748     NaN  1.4066     NaN  1.4066     NaN   \n2  0.015282  0.306039  0.163748     NaN  1.4066     NaN  1.4066     NaN   \n3  0.015282  0.306039 -0.241753     NaN  1.4066     NaN  1.4066     NaN   \n4  0.015282  0.306039 -0.241753     NaN  1.4066     NaN  1.4066     NaN   \n\n    l6MAX  l12amhd  l12MAX  l12mom122  l12ivol_capm  l12ivol_ff5  l12beta_bw  \\\n0  1.4066      NaN  1.4066 -52.647854      0.765013     0.647098    0.380573   \n1  1.4066      NaN  1.4066 -61.937195      5.362759     5.279563    0.441740   \n2  1.4066      NaN  1.4066 -43.100755      0.765013     0.647098    0.456509   \n3  1.4066      NaN  1.4066 -22.391633      5.852977     5.112499    0.452695   \n4  1.4066      NaN  1.4066 -36.888819      4.932686     3.778440    0.664521   \n\n   l12vol6m  l12vol12m  \n0  2.621943   6.827920  \n1  3.313448   4.436441  \n2  3.313442   4.197256  \n3  4.107071   4.246072  \n4  4.378863   3.604576  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10005</td>\n      <td>375</td>\n      <td>NaN</td>\n      <td>-72.706514</td>\n      <td>1989</td>\n      <td>-0.7000</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.710000</td>\n      <td>-33.516946</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.843440</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>1.485001</td>\n      <td>3.167929</td>\n      <td>-0.424011</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.087557</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>-52.647854</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.380573</td>\n      <td>2.621943</td>\n      <td>6.827920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10005</td>\n      <td>376</td>\n      <td>NaN</td>\n      <td>-68.539010</td>\n      <td>1989</td>\n      <td>-20.7400</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.700000</td>\n      <td>-48.453613</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.569757</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>1.484870</td>\n      <td>2.598143</td>\n      <td>-0.424011</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>0.163748</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>-61.937195</td>\n      <td>5.362759</td>\n      <td>5.279563</td>\n      <td>0.441740</td>\n      <td>3.313448</td>\n      <td>4.436441</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10005</td>\n      <td>377</td>\n      <td>NaN</td>\n      <td>-60.041983</td>\n      <td>1989</td>\n      <td>-25.6500</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-20.740000</td>\n      <td>-48.510651</td>\n      <td>NaN</td>\n      <td>4.169273</td>\n      <td>3.399652</td>\n      <td>0.580613</td>\n      <td>1.4066</td>\n      <td>4.364358</td>\n      <td>2.310132</td>\n      <td>2.882070</td>\n      <td>-0.647218</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>0.163748</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>-43.100755</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.456509</td>\n      <td>3.313442</td>\n      <td>4.197256</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10005</td>\n      <td>378</td>\n      <td>NaN</td>\n      <td>-67.083392</td>\n      <td>1989</td>\n      <td>-0.6800</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-22.380465</td>\n      <td>-38.209694</td>\n      <td>NaN</td>\n      <td>5.565847</td>\n      <td>5.250996</td>\n      <td>0.663164</td>\n      <td>1.4066</td>\n      <td>6.813720</td>\n      <td>3.190628</td>\n      <td>2.799597</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>-22.391633</td>\n      <td>5.852977</td>\n      <td>5.112499</td>\n      <td>0.452695</td>\n      <td>4.107071</td>\n      <td>4.246072</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10005</td>\n      <td>379</td>\n      <td>NaN</td>\n      <td>-70.826677</td>\n      <td>1989</td>\n      <td>32.6433</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.680000</td>\n      <td>-53.776947</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.372045</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>2.840962</td>\n      <td>2.265160</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>-36.888819</td>\n      <td>4.932686</td>\n      <td>3.778440</td>\n      <td>0.664521</td>\n      <td>4.378863</td>\n      <td>3.604576</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    94366.000000\nmean      1988.458640\nstd          1.010222\nmin       1987.000000\n25%       1988.000000\n50%       1988.000000\n75%       1989.000000\nmax       1990.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          94366\nprd             94366\nmom482          78252\nmom242          92830\nyear            94366\nRET             94366\nind             94366\nbm              94366\nop              94366\ngp              94366\ninv             94274\nmom11           94366\nmom122          94366\namhd            70952\nivol_capm       94366\nivol_ff5        94366\nbeta_bw         94366\nMAX             94366\nvol1m           94355\nvol6m           94256\nvol12m          94078\nsize            94366\nlbm             94366\nlop             94366\nlgp             94366\nlinv            94366\nllme            94366\nl1amhd          71191\nl1MAX           94364\nl3amhd          71672\nl3MAX           94343\nl6amhd          72310\nl6MAX           94323\nl12amhd         73411\nl12MAX          94364\nl12mom122       93899\nl12ivol_capm    94261\nl12ivol_ff5     94261\nl12beta_bw      94292\nl12vol6m        94044\nl12vol12m       93168\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (88871, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (88871, 86)\nmae of a constant model 8.817138442623339\nR2 of a constant model 0.0\nXGB train: 8.478471230016714 0.08294077560577218\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\nXGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.010867119733478814 46.47510004043579\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:50:55,152]\u001b[0m A new study created in memory with name: no-name-25967b89-5e43-47ea-b848-74b71dce51d0\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 8.656638085401468 0.03297978664514112 47.90201115608215\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:50:59,904]\u001b[0m Trial 0 finished with value: 0.008209587951112724 and parameters: {'n_estimators': 726, 'max_depth': 3, 'learning_rate': 0.040297692152042736, 'colsample_bytree': 0.9034893109445548, 'subsample': 0.8919079951062683, 'alpha': 3.2912638286910356, 'lambda': 29.261468598020347, 'gamma': 0.00012417339382724668, 'min_child_weight': 12.404995209513311}. Best is trial 0 with value: 0.008209587951112724.\u001b[0m\n\u001b[32m[I 2022-08-25 20:51:03,265]\u001b[0m Trial 1 finished with value: 0.008200462093778987 and parameters: {'n_estimators': 638, 'max_depth': 2, 'learning_rate': 0.049456083017704114, 'colsample_bytree': 0.2874180245243252, 'subsample': 0.7742478255237798, 'alpha': 0.9011644304040384, 'lambda': 0.41498038093097556, 'gamma': 1.5778684010949337e-08, 'min_child_weight': 0.9858773376377351}. Best is trial 0 with value: 0.008209587951112724.\u001b[0m\n\u001b[32m[I 2022-08-25 20:51:10,091]\u001b[0m Trial 2 finished with value: 0.0063056390616766204 and parameters: {'n_estimators': 855, 'max_depth': 4, 'learning_rate': 0.0220847765751845, 'colsample_bytree': 0.8475262397548078, 'subsample': 0.7875270473987707, 'alpha': 1.3786440570737817, 'lambda': 9.252780143942802, 'gamma': 1.0170285168061745e-10, 'min_child_weight': 3.2474120811451512}. Best is trial 0 with value: 0.008209587951112724.\u001b[0m\n\u001b[32m[I 2022-08-25 20:51:15,309]\u001b[0m Trial 3 finished with value: 0.01192189822824498 and parameters: {'n_estimators': 845, 'max_depth': 3, 'learning_rate': 0.009068990449564034, 'colsample_bytree': 0.5400978236732108, 'subsample': 0.7096671572739489, 'alpha': 22.975358291197413, 'lambda': 117.76905647098188, 'gamma': 1.3886427266615174e-10, 'min_child_weight': 17.147587781497684}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:51:21,740]\u001b[0m Trial 4 finished with value: -0.0049295052306184495 and parameters: {'n_estimators': 781, 'max_depth': 4, 'learning_rate': 0.04892647931690586, 'colsample_bytree': 0.9045290441463603, 'subsample': 0.7145998628174558, 'alpha': 0.5258493192169842, 'lambda': 85.95494984814697, 'gamma': 9.258616923294356e-05, 'min_child_weight': 0.6640295991211533}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:51:25,632]\u001b[0m Trial 5 finished with value: 0.009031822775092003 and parameters: {'n_estimators': 748, 'max_depth': 2, 'learning_rate': 0.038853974897378615, 'colsample_bytree': 0.8051352892522299, 'subsample': 0.8067093095700664, 'alpha': 15.546135976436881, 'lambda': 19.581253753169435, 'gamma': 2.0466467161365722, 'min_child_weight': 0.3307487070446816}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:51:29,255]\u001b[0m Trial 6 finished with value: 0.008852689919283856 and parameters: {'n_estimators': 731, 'max_depth': 2, 'learning_rate': 0.006337343352246262, 'colsample_bytree': 0.24633944515375672, 'subsample': 0.8223604731973382, 'alpha': 2.835035974085313, 'lambda': 0.12628583274187957, 'gamma': 1.4694566617480858e-06, 'min_child_weight': 2.3299785550834047}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:51:32,815]\u001b[0m Trial 7 finished with value: 0.008898440009989322 and parameters: {'n_estimators': 654, 'max_depth': 2, 'learning_rate': 0.04432572563199265, 'colsample_bytree': 0.47190656050296553, 'subsample': 0.44028193989136766, 'alpha': 0.7729635491240546, 'lambda': 0.12191942115260694, 'gamma': 2.7378218412056777e-07, 'min_child_weight': 0.9400896296562298}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:51:38,561]\u001b[0m Trial 8 finished with value: 0.00985499692831605 and parameters: {'n_estimators': 983, 'max_depth': 3, 'learning_rate': 0.013590326697361307, 'colsample_bytree': 0.12372134382433926, 'subsample': 0.4859076289551678, 'alpha': 20.299078171116495, 'lambda': 5.429493454806465, 'gamma': 1.6806608103124703, 'min_child_weight': 0.8588460387279814}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:51:45,368]\u001b[0m Trial 9 finished with value: 0.004702928686169264 and parameters: {'n_estimators': 817, 'max_depth': 4, 'learning_rate': 0.023810050093924676, 'colsample_bytree': 0.3079416101111919, 'subsample': 0.7972078921371221, 'alpha': 2.790096527570247, 'lambda': 1.5988726885435718, 'gamma': 0.0019092042940706583, 'min_child_weight': 0.10828857372647958}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:51:51,176]\u001b[0m Trial 10 finished with value: 0.006685147729560687 and parameters: {'n_estimators': 518, 'max_depth': 5, 'learning_rate': 0.0016035645444565927, 'colsample_bytree': 0.6468061773049631, 'subsample': 0.5778117259782105, 'alpha': 0.13305922194796976, 'lambda': 168.28855099509292, 'gamma': 1.0419730956277113e-10, 'min_child_weight': 41.62445441399652}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:51:56,992]\u001b[0m Trial 11 finished with value: 0.00973356020167834 and parameters: {'n_estimators': 978, 'max_depth': 3, 'learning_rate': 0.015132925414958146, 'colsample_bytree': 0.1160238828953479, 'subsample': 0.3007630235570578, 'alpha': 28.131909322686354, 'lambda': 2.483415090728962, 'gamma': 7.337233559699907, 'min_child_weight': 8.591399720938913}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:52:02,940]\u001b[0m Trial 12 finished with value: 0.009440609494992938 and parameters: {'n_estimators': 997, 'max_depth': 3, 'learning_rate': 0.011452222672704793, 'colsample_bytree': 0.5173323713152371, 'subsample': 0.5765711626401862, 'alpha': 7.854391270549865, 'lambda': 45.98350271146963, 'gamma': 0.03158854413443549, 'min_child_weight': 49.1735369224806}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:52:08,699]\u001b[0m Trial 13 finished with value: 0.009950532759873412 and parameters: {'n_estimators': 906, 'max_depth': 3, 'learning_rate': 0.015833943780829342, 'colsample_bytree': 0.65586738514176, 'subsample': 0.4743729765149256, 'alpha': 8.58708815754756, 'lambda': 5.559684429006337, 'gamma': 0.054773320866641155, 'min_child_weight': 7.3623437317477265}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:52:18,370]\u001b[0m Trial 14 finished with value: -0.010735849035378754 and parameters: {'n_estimators': 889, 'max_depth': 5, 'learning_rate': 0.03084923461178811, 'colsample_bytree': 0.6672969899208647, 'subsample': 0.660054690192394, 'alpha': 8.12130595883864, 'lambda': 0.9617976017649394, 'gamma': 0.026042897285449517, 'min_child_weight': 9.28760151105822}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:52:23,858]\u001b[0m Trial 15 finished with value: 0.009521172266947276 and parameters: {'n_estimators': 903, 'max_depth': 3, 'learning_rate': 0.01992455248157341, 'colsample_bytree': 0.666784253634878, 'subsample': 0.4553172355107802, 'alpha': 10.663805404243533, 'lambda': 11.579902584907849, 'gamma': 6.838173697857423e-09, 'min_child_weight': 22.068672981189252}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:52:31,254]\u001b[0m Trial 16 finished with value: 0.004548849844262766 and parameters: {'n_estimators': 930, 'max_depth': 4, 'learning_rate': 0.031692867503292144, 'colsample_bytree': 0.4285280464178738, 'subsample': 0.34403367235426, 'alpha': 5.676979334416561, 'lambda': 180.13348618699024, 'gamma': 0.05536273039415423, 'min_child_weight': 5.403263316894045}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:52:36,334]\u001b[0m Trial 17 finished with value: 0.010885402906926522 and parameters: {'n_estimators': 838, 'max_depth': 3, 'learning_rate': 0.006984903020669869, 'colsample_bytree': 0.5955377975348611, 'subsample': 0.6496348871235489, 'alpha': 15.362391618315591, 'lambda': 53.63813309809907, 'gamma': 4.154227174779081e-06, 'min_child_weight': 19.46174157474054}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:52:42,973]\u001b[0m Trial 18 finished with value: 0.011520023798337253 and parameters: {'n_estimators': 836, 'max_depth': 4, 'learning_rate': 0.006794053763254517, 'colsample_bytree': 0.3898475241218178, 'subsample': 0.6604166003143539, 'alpha': 26.110165900036424, 'lambda': 59.861280578805435, 'gamma': 2.5264122068228435e-06, 'min_child_weight': 16.873100440241057}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n\u001b[32m[I 2022-08-25 20:52:50,671]\u001b[0m Trial 19 finished with value: 0.006438462497284572 and parameters: {'n_estimators': 672, 'max_depth': 5, 'learning_rate': 0.0014048654790154184, 'colsample_bytree': 0.41351842334673594, 'subsample': 0.7087138783014734, 'alpha': 28.142683563737425, 'lambda': 102.34289963915266, 'gamma': 3.3819113750577637e-09, 'min_child_weight': 19.964546332841365}. Best is trial 3 with value: 0.01192189822824498.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  115.52088236808777\n        n_estimators : 845\n           max_depth : 3\n       learning_rate : 0.009068990449564034\n    colsample_bytree : 0.5400978236732108\n           subsample : 0.7096671572739489\n               alpha : 22.975358291197413\n              lambda : 117.76905647098188\n               gamma : 1.3886427266615174e-10\n    min_child_weight : 17.147587781497684\nbest objective value : 0.01192189822824498\nOptuna XGB train: 8.678826805920373 0.02459732478735055 118.47987055778503\nMin_prd:  350\nConstant guess:  8.80632708605012 0.0\nXGB test: 8.900224224272616 -0.014594664544531177\nXGB GS test: 8.84693806544295 -0.005260274491055261\nOptuna XGB test: 8.838932127253665 -0.003355999634563789\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(98052, 41)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   PERMNO  prd  mom482     mom242  year      RET   ind        bm        op  \\\n0   10005  375     NaN -72.706514  1989  -0.7000  30.0  0.490174 -0.214332   \n1   10005  376     NaN -68.539010  1989 -20.7400  30.0  0.490174 -0.214332   \n2   10005  377     NaN -60.041983  1989 -25.6500  30.0  0.490174 -0.214332   \n3   10005  378     NaN -67.083392  1989  -0.6800  30.0  0.490174 -0.214332   \n4   10005  379     NaN -70.826677  1989  32.6433  30.0  0.490174 -0.214332   \n\n    gp       inv      mom11     mom122  amhd  ivol_capm  ivol_ff5   beta_bw  \\\n0  0.0 -0.230583  -0.710000 -33.516946   NaN   0.765013  0.647098  0.843440   \n1  0.0 -0.230583  -0.700000 -48.453613   NaN   0.765013  0.647098  0.569757   \n2  0.0 -0.230583 -20.740000 -48.510651   NaN   4.169273  3.399652  0.580613   \n3  0.0 -0.230583 -22.380465 -38.209694   NaN   5.565847  5.250996  0.663164   \n4  0.0 -0.230583  -0.680000 -53.776947   NaN   0.765013  0.647098  0.372045   \n\n      MAX     vol1m     vol6m    vol12m      size      lbm       lop  \\\n0  1.4066  0.866870  1.485001  3.167929 -0.424011  0.75014 -0.084639   \n1  1.4066  0.866870  1.484870  2.598143 -0.424011  0.75014 -0.084639   \n2  1.4066  4.364358  2.310132  2.882070 -0.647218  0.75014 -0.084639   \n3  1.4066  6.813720  3.190628  2.799597 -0.934794  0.75014 -0.084639   \n4  1.4066  0.866870  2.840962  2.265160 -0.934794  0.75014 -0.084639   \n\n        lgp      linv      llme  l1amhd   l1MAX  l3amhd   l3MAX  l6amhd  \\\n0  0.015282  0.306039 -0.087557     NaN  1.4066     NaN  1.4066     NaN   \n1  0.015282  0.306039  0.163748     NaN  1.4066     NaN  1.4066     NaN   \n2  0.015282  0.306039  0.163748     NaN  1.4066     NaN  1.4066     NaN   \n3  0.015282  0.306039 -0.241753     NaN  1.4066     NaN  1.4066     NaN   \n4  0.015282  0.306039 -0.241753     NaN  1.4066     NaN  1.4066     NaN   \n\n    l6MAX  l12amhd  l12MAX  l12mom122  l12ivol_capm  l12ivol_ff5  l12beta_bw  \\\n0  1.4066      NaN  1.4066 -52.647854      0.765013     0.647098    0.380573   \n1  1.4066      NaN  1.4066 -61.937195      5.362759     5.279563    0.441740   \n2  1.4066      NaN  1.4066 -43.100755      0.765013     0.647098    0.456509   \n3  1.4066      NaN  1.4066 -22.391633      5.852977     5.112499    0.452695   \n4  1.4066      NaN  1.4066 -36.888819      4.932686     3.778440    0.664521   \n\n   l12vol6m  l12vol12m  \n0  2.621943   6.827920  \n1  3.313448   4.436441  \n2  3.313442   4.197256  \n3  4.107071   4.246072  \n4  4.378863   3.604576  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10005</td>\n      <td>375</td>\n      <td>NaN</td>\n      <td>-72.706514</td>\n      <td>1989</td>\n      <td>-0.7000</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.710000</td>\n      <td>-33.516946</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.843440</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>1.485001</td>\n      <td>3.167929</td>\n      <td>-0.424011</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.087557</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>-52.647854</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.380573</td>\n      <td>2.621943</td>\n      <td>6.827920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10005</td>\n      <td>376</td>\n      <td>NaN</td>\n      <td>-68.539010</td>\n      <td>1989</td>\n      <td>-20.7400</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.700000</td>\n      <td>-48.453613</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.569757</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>1.484870</td>\n      <td>2.598143</td>\n      <td>-0.424011</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>0.163748</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>-61.937195</td>\n      <td>5.362759</td>\n      <td>5.279563</td>\n      <td>0.441740</td>\n      <td>3.313448</td>\n      <td>4.436441</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10005</td>\n      <td>377</td>\n      <td>NaN</td>\n      <td>-60.041983</td>\n      <td>1989</td>\n      <td>-25.6500</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-20.740000</td>\n      <td>-48.510651</td>\n      <td>NaN</td>\n      <td>4.169273</td>\n      <td>3.399652</td>\n      <td>0.580613</td>\n      <td>1.4066</td>\n      <td>4.364358</td>\n      <td>2.310132</td>\n      <td>2.882070</td>\n      <td>-0.647218</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>0.163748</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>-43.100755</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.456509</td>\n      <td>3.313442</td>\n      <td>4.197256</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10005</td>\n      <td>378</td>\n      <td>NaN</td>\n      <td>-67.083392</td>\n      <td>1989</td>\n      <td>-0.6800</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-22.380465</td>\n      <td>-38.209694</td>\n      <td>NaN</td>\n      <td>5.565847</td>\n      <td>5.250996</td>\n      <td>0.663164</td>\n      <td>1.4066</td>\n      <td>6.813720</td>\n      <td>3.190628</td>\n      <td>2.799597</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>-22.391633</td>\n      <td>5.852977</td>\n      <td>5.112499</td>\n      <td>0.452695</td>\n      <td>4.107071</td>\n      <td>4.246072</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10005</td>\n      <td>379</td>\n      <td>NaN</td>\n      <td>-70.826677</td>\n      <td>1989</td>\n      <td>32.6433</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.680000</td>\n      <td>-53.776947</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.372045</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>2.840962</td>\n      <td>2.265160</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>-36.888819</td>\n      <td>4.932686</td>\n      <td>3.778440</td>\n      <td>0.664521</td>\n      <td>4.378863</td>\n      <td>3.604576</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    98052.000000\nmean      1990.551962\nstd          1.006492\nmin       1989.000000\n25%       1990.000000\n50%       1991.000000\n75%       1991.000000\nmax       1992.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          98052\nprd             98052\nmom482          81859\nmom242          96658\nyear            98052\nRET             98052\nind             98052\nbm              98052\nop              98052\ngp              98052\ninv             97951\nmom11           98052\nmom122          98052\namhd            70084\nivol_capm       98049\nivol_ff5        98049\nbeta_bw         98052\nMAX             98052\nvol1m           98041\nvol6m           97967\nvol12m          97805\nsize            98052\nlbm             98052\nlop             98052\nlgp             98052\nlinv            98052\nllme            98052\nl1amhd          70160\nl1MAX           98051\nl3amhd          70307\nl3MAX           98034\nl6amhd          70538\nl6MAX           98022\nl12amhd         71705\nl12MAX          98051\nl12mom122       97737\nl12ivol_capm    97949\nl12ivol_ff5     97949\nl12beta_bw      97986\nl12vol6m        97780\nl12vol12m       96892\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (92069, 38)\ntime to do feature proprocessing: \nNumber of features after transformation:  (92069, 86)\nmae of a constant model 9.959264525018126\nR2 of a constant model 0.0\nXGB train: 9.70897017052431 0.06965662748584933\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\nXGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.005968757295727101 45.64253807067871\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:53:44,430]\u001b[0m A new study created in memory with name: no-name-f909fb93-ca5a-4bca-8e2c-40a486ba3434\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 9.888658675456666 0.025484454735415718 47.231123208999634\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:53:48,372]\u001b[0m Trial 0 finished with value: 0.006097047337995761 and parameters: {'n_estimators': 638, 'max_depth': 2, 'learning_rate': 0.014091136261926582, 'colsample_bytree': 0.7657592741211049, 'subsample': 0.8317122201794536, 'alpha': 0.13012639407147297, 'lambda': 180.40218401672968, 'gamma': 2.2277040293118926, 'min_child_weight': 18.85841234906928}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:53:53,376]\u001b[0m Trial 1 finished with value: 0.005803787153266028 and parameters: {'n_estimators': 800, 'max_depth': 3, 'learning_rate': 0.01352322830983041, 'colsample_bytree': 0.6854230011835314, 'subsample': 0.8048467774376769, 'alpha': 2.7528075345233973, 'lambda': 0.2773401387911674, 'gamma': 0.14808118657536465, 'min_child_weight': 0.47963653885367113}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:53:59,897]\u001b[0m Trial 2 finished with value: 0.0016206577369834007 and parameters: {'n_estimators': 553, 'max_depth': 5, 'learning_rate': 0.010490378098257359, 'colsample_bytree': 0.716947916616038, 'subsample': 0.34682065568161985, 'alpha': 1.3566155525992507, 'lambda': 0.4931646514720593, 'gamma': 0.002069757238112239, 'min_child_weight': 2.8815336293094003}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:54:09,451]\u001b[0m Trial 3 finished with value: -0.0008106591432756214 and parameters: {'n_estimators': 836, 'max_depth': 5, 'learning_rate': 0.012870906807554719, 'colsample_bytree': 0.8154231316073224, 'subsample': 0.8284560155116678, 'alpha': 0.41563144239349803, 'lambda': 1.984534856742768, 'gamma': 2.4690144658871684e-09, 'min_child_weight': 0.44159633289944056}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:54:18,170]\u001b[0m Trial 4 finished with value: -0.026423004749387927 and parameters: {'n_estimators': 741, 'max_depth': 5, 'learning_rate': 0.04305046663900031, 'colsample_bytree': 0.6872079777383621, 'subsample': 0.5720157066371581, 'alpha': 0.1441578312760472, 'lambda': 17.85128698651498, 'gamma': 0.9099713756792674, 'min_child_weight': 2.019161560827577}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:54:22,484]\u001b[0m Trial 5 finished with value: 0.005436484209054397 and parameters: {'n_estimators': 864, 'max_depth': 2, 'learning_rate': 0.024347535660354747, 'colsample_bytree': 0.6867249060939015, 'subsample': 0.9039953744830918, 'alpha': 0.5446029108512316, 'lambda': 116.55017907890887, 'gamma': 0.00029921309696244783, 'min_child_weight': 0.4142632910403709}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:54:32,925]\u001b[0m Trial 6 finished with value: 0.0055802402649953835 and parameters: {'n_estimators': 962, 'max_depth': 5, 'learning_rate': 0.0038989244522136444, 'colsample_bytree': 0.5476212875095464, 'subsample': 0.6664160637248668, 'alpha': 2.8954487142256995, 'lambda': 50.36938371692622, 'gamma': 0.00028856751378576875, 'min_child_weight': 5.634438381063847}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:54:38,744]\u001b[0m Trial 7 finished with value: 0.00441009752931925 and parameters: {'n_estimators': 975, 'max_depth': 3, 'learning_rate': 0.002587923030984118, 'colsample_bytree': 0.3401315750239078, 'subsample': 0.6849393276050922, 'alpha': 0.3615230337045953, 'lambda': 49.5826421138623, 'gamma': 2.1870260783408048e-10, 'min_child_weight': 0.8177169136014488}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:54:42,600]\u001b[0m Trial 8 finished with value: 0.0012622519138353494 and parameters: {'n_estimators': 513, 'max_depth': 3, 'learning_rate': 0.040230593201743665, 'colsample_bytree': 0.6833181766929823, 'subsample': 0.8337971663263721, 'alpha': 4.7550294305123995, 'lambda': 1.66893490001471, 'gamma': 4.118967422898884e-06, 'min_child_weight': 6.782710249390682}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:54:49,992]\u001b[0m Trial 9 finished with value: 0.0041881447486249185 and parameters: {'n_estimators': 625, 'max_depth': 5, 'learning_rate': 0.012815264230794474, 'colsample_bytree': 0.7530250636158089, 'subsample': 0.6263376442575039, 'alpha': 0.23657887418847495, 'lambda': 102.00494561701765, 'gamma': 2.0316056740567645, 'min_child_weight': 1.872039981963444}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:54:53,638]\u001b[0m Trial 10 finished with value: 0.004426443467175428 and parameters: {'n_estimators': 668, 'max_depth': 2, 'learning_rate': 0.030663569319016763, 'colsample_bytree': 0.9391505540412396, 'subsample': 0.45422220486276516, 'alpha': 16.5002278650971, 'lambda': 9.481063249794722, 'gamma': 6.469722125408714e-07, 'min_child_weight': 33.7689768935449}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:54:58,336]\u001b[0m Trial 11 finished with value: 0.00338708221466261 and parameters: {'n_estimators': 755, 'max_depth': 3, 'learning_rate': 0.021998970223095354, 'colsample_bytree': 0.479925525572155, 'subsample': 0.9496044288730281, 'alpha': 12.875258026209872, 'lambda': 0.10192353715448578, 'gamma': 0.047154934631359786, 'min_child_weight': 36.23131384332235}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:55:02,203]\u001b[0m Trial 12 finished with value: 0.005293082314818868 and parameters: {'n_estimators': 672, 'max_depth': 2, 'learning_rate': 0.01776400899656129, 'colsample_bytree': 0.9296905559769479, 'subsample': 0.7636948210304283, 'alpha': 1.0412176124195107, 'lambda': 0.13898136445541526, 'gamma': 5.916306250813118, 'min_child_weight': 0.14122752479056686}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:55:08,457]\u001b[0m Trial 13 finished with value: -0.008342208018380193 and parameters: {'n_estimators': 797, 'max_depth': 4, 'learning_rate': 0.03307760808188673, 'colsample_bytree': 0.5405090201265284, 'subsample': 0.7623080656823833, 'alpha': 0.10097037614336173, 'lambda': 0.5194189972897274, 'gamma': 0.02463988889006942, 'min_child_weight': 13.730055196370175}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:55:15,327]\u001b[0m Trial 14 finished with value: 0.002123005815270127 and parameters: {'n_estimators': 902, 'max_depth': 4, 'learning_rate': 0.017628325120499427, 'colsample_bytree': 0.1978317183064311, 'subsample': 0.8494504140567535, 'alpha': 5.616559179441564, 'lambda': 3.184346124593261, 'gamma': 0.07349493743751542, 'min_child_weight': 0.1633845941463256}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:55:18,534]\u001b[0m Trial 15 finished with value: 0.00532710248638083 and parameters: {'n_estimators': 595, 'max_depth': 2, 'learning_rate': 0.007724555856647964, 'colsample_bytree': 0.8400070768158526, 'subsample': 0.7530027887943209, 'alpha': 0.8892050267720533, 'lambda': 0.5669570970589229, 'gamma': 8.714549163559084, 'min_child_weight': 0.7456287711701894}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:55:22,930]\u001b[0m Trial 16 finished with value: 0.0038707947941404733 and parameters: {'n_estimators': 705, 'max_depth': 3, 'learning_rate': 0.01804523239701946, 'colsample_bytree': 0.4425302037040553, 'subsample': 0.5190238266163124, 'alpha': 2.018397789033592, 'lambda': 8.600167603605932, 'gamma': 0.007460895330584896, 'min_child_weight': 14.458132078605749}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:55:29,412]\u001b[0m Trial 17 finished with value: -0.0024457352124196263 and parameters: {'n_estimators': 803, 'max_depth': 4, 'learning_rate': 0.029894610996803118, 'colsample_bytree': 0.6099497765118429, 'subsample': 0.7149762889233483, 'alpha': 7.460420893172996, 'lambda': 25.78992185127024, 'gamma': 0.4783160576865317, 'min_child_weight': 0.2712278219105067}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:55:32,749]\u001b[0m Trial 18 finished with value: 0.0047264281095799636 and parameters: {'n_estimators': 638, 'max_depth': 2, 'learning_rate': 0.006955553825168343, 'colsample_bytree': 0.38264336770536206, 'subsample': 0.8980941067837911, 'alpha': 26.710073322307057, 'lambda': 185.78609227236967, 'gamma': 3.2170080309454654e-07, 'min_child_weight': 0.844163207707567}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n\u001b[32m[I 2022-08-25 20:55:38,477]\u001b[0m Trial 19 finished with value: -0.004636100983582386 and parameters: {'n_estimators': 912, 'max_depth': 3, 'learning_rate': 0.04788248348579216, 'colsample_bytree': 0.8334595861436189, 'subsample': 0.8089483900111172, 'alpha': 2.8737878686692424, 'lambda': 0.30393883196568594, 'gamma': 4.064507883244331e-05, 'min_child_weight': 4.08138219664404}. Best is trial 0 with value: 0.006097047337995761.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  114.0503785610199\n        n_estimators : 638\n           max_depth : 2\n       learning_rate : 0.014091136261926582\n    colsample_bytree : 0.7657592741211049\n           subsample : 0.8317122201794536\n               alpha : 0.13012639407147297\n              lambda : 180.40218401672968\n               gamma : 2.2277040293118926\n    min_child_weight : 18.85841234906928\nbest objective value : 0.006097047337995761\nOptuna XGB train: 9.937875927825779 0.011762849940295084 115.91636371612549\nMin_prd:  375\nConstant guess:  9.550258459737007 0.0\nXGB test: 9.528634419328005 0.001776083736201195\nXGB GS test: 9.503797490986711 0.006979402041612848\nOptuna XGB test: 9.498108312795948 0.008173245684614527\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(99307, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd      mom482      mom242  year      RET   ind        bm  \\\n263   10010  399  283.349209  170.270066  1991  14.7642  12.0 -1.763275   \n264   10010  400  283.349209  170.270066  1991  10.5694  12.0 -1.763275   \n265   10010  401  283.349209  170.270066  1991 -24.3011  12.0 -1.763275   \n266   10010  402  283.349209  170.270066  1991 -14.3330  12.0 -1.763275   \n267   10010  403  283.349209  170.270066  1991  -1.4001  12.0 -1.763275   \n\n           op       gp       inv      mom11      mom122      amhd  ivol_capm  \\\n263  0.178266  0.82803  0.349928 -13.655300   59.863713  1.269015   3.168363   \n264  0.178266  0.82803  0.349928  14.764200   11.031084  1.250800   2.607292   \n265  0.178266  0.82803  0.349928  10.569400   71.406961  1.198504   2.826425   \n266  0.178266  0.82803  0.349928 -22.380465  105.899232  1.138996   5.012703   \n267  0.178266  0.82803  0.349928 -14.333000   88.254769  1.051825   3.935613   \n\n     ivol_ff5   beta_bw      MAX     vol1m     vol6m    vol12m     BAspr  \\\n263  2.753972  1.340979   6.5211  3.155761  3.825545  3.964292  1.709402   \n264  2.407733  1.317632   7.1780  2.694437  3.645754  3.826436  1.492537   \n265  2.613714  1.122542   8.3759  3.266944  3.547472  3.565168  0.671141   \n266  3.518111  1.187104   8.4676  5.131519  3.878334  3.760797  1.739130   \n267  2.822852  1.288922  12.3630  4.489517  3.720855  3.783681  2.803738   \n\n         size       lbm       lop       lgp      linv      llme    l1amhd  \\\n263  4.658076 -0.665503  0.215755  0.874858  0.193029  4.197954  1.303864   \n264  4.800046 -0.665503  0.215755  0.874858  0.193029  4.436899  1.269015   \n265  4.960313 -0.665503  0.215755  0.874858  0.193029  4.149217  1.250800   \n266  4.687965 -0.665503  0.215755  0.874858  0.193029  4.051237  1.198504   \n267  4.539475 -0.665503  0.215755  0.874858  0.193029  3.926769  1.138996   \n\n      l1MAX   l1BAspr    l3amhd   l3MAX   l3BAspr    l6amhd   l6MAX   l6BAspr  \\\n263  7.2371  1.481481  4.484977  9.2373  0.689655  5.531972  5.4495  2.666667   \n264  6.5211  1.709402  2.476694  8.7479  1.503759  5.081887  9.6156  1.000000   \n265  7.1780  1.492537  1.303864  7.2371  1.481481  4.906170  7.9750  1.694915   \n266  8.3759  0.671141  1.269015  6.5211  1.709402  4.484977  9.2373  0.689655   \n267  8.4676  1.739130  1.250800  7.1780  1.492537  2.476694  8.7479  1.503759   \n\n      l12amhd  l12MAX  l12BAspr   l12mom122  l12ivol_capm  l12ivol_ff5  \\\n263  6.251243  7.2371  1.250000  105.899232      5.558217     4.995912   \n264  6.231516  6.5211  2.020202  105.899232      4.219118     3.955294   \n265  6.204714  7.1780  1.351351  105.899232      3.588282     2.519782   \n266  6.049708  8.3759  1.470588  105.899232      3.145976     2.794118   \n267  5.832994  8.4676  3.389831  105.899232      3.990279     3.948573   \n\n     l12beta_bw  l12vol6m  l12vol12m  \n263    1.019399  5.667817   5.290583  \n264    1.094237  5.676083   5.315685  \n265    1.442106  6.022361   5.494856  \n266    1.488411  5.660681   5.441735  \n267    1.612393  5.553907   5.300420  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>263</th>\n      <td>10010</td>\n      <td>399</td>\n      <td>283.349209</td>\n      <td>170.270066</td>\n      <td>1991</td>\n      <td>14.7642</td>\n      <td>12.0</td>\n      <td>-1.763275</td>\n      <td>0.178266</td>\n      <td>0.82803</td>\n      <td>0.349928</td>\n      <td>-13.655300</td>\n      <td>59.863713</td>\n      <td>1.269015</td>\n      <td>3.168363</td>\n      <td>2.753972</td>\n      <td>1.340979</td>\n      <td>6.5211</td>\n      <td>3.155761</td>\n      <td>3.825545</td>\n      <td>3.964292</td>\n      <td>1.709402</td>\n      <td>4.658076</td>\n      <td>-0.665503</td>\n      <td>0.215755</td>\n      <td>0.874858</td>\n      <td>0.193029</td>\n      <td>4.197954</td>\n      <td>1.303864</td>\n      <td>7.2371</td>\n      <td>1.481481</td>\n      <td>4.484977</td>\n      <td>9.2373</td>\n      <td>0.689655</td>\n      <td>5.531972</td>\n      <td>5.4495</td>\n      <td>2.666667</td>\n      <td>6.251243</td>\n      <td>7.2371</td>\n      <td>1.250000</td>\n      <td>105.899232</td>\n      <td>5.558217</td>\n      <td>4.995912</td>\n      <td>1.019399</td>\n      <td>5.667817</td>\n      <td>5.290583</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>10010</td>\n      <td>400</td>\n      <td>283.349209</td>\n      <td>170.270066</td>\n      <td>1991</td>\n      <td>10.5694</td>\n      <td>12.0</td>\n      <td>-1.763275</td>\n      <td>0.178266</td>\n      <td>0.82803</td>\n      <td>0.349928</td>\n      <td>14.764200</td>\n      <td>11.031084</td>\n      <td>1.250800</td>\n      <td>2.607292</td>\n      <td>2.407733</td>\n      <td>1.317632</td>\n      <td>7.1780</td>\n      <td>2.694437</td>\n      <td>3.645754</td>\n      <td>3.826436</td>\n      <td>1.492537</td>\n      <td>4.800046</td>\n      <td>-0.665503</td>\n      <td>0.215755</td>\n      <td>0.874858</td>\n      <td>0.193029</td>\n      <td>4.436899</td>\n      <td>1.269015</td>\n      <td>6.5211</td>\n      <td>1.709402</td>\n      <td>2.476694</td>\n      <td>8.7479</td>\n      <td>1.503759</td>\n      <td>5.081887</td>\n      <td>9.6156</td>\n      <td>1.000000</td>\n      <td>6.231516</td>\n      <td>6.5211</td>\n      <td>2.020202</td>\n      <td>105.899232</td>\n      <td>4.219118</td>\n      <td>3.955294</td>\n      <td>1.094237</td>\n      <td>5.676083</td>\n      <td>5.315685</td>\n    </tr>\n    <tr>\n      <th>265</th>\n      <td>10010</td>\n      <td>401</td>\n      <td>283.349209</td>\n      <td>170.270066</td>\n      <td>1991</td>\n      <td>-24.3011</td>\n      <td>12.0</td>\n      <td>-1.763275</td>\n      <td>0.178266</td>\n      <td>0.82803</td>\n      <td>0.349928</td>\n      <td>10.569400</td>\n      <td>71.406961</td>\n      <td>1.198504</td>\n      <td>2.826425</td>\n      <td>2.613714</td>\n      <td>1.122542</td>\n      <td>8.3759</td>\n      <td>3.266944</td>\n      <td>3.547472</td>\n      <td>3.565168</td>\n      <td>0.671141</td>\n      <td>4.960313</td>\n      <td>-0.665503</td>\n      <td>0.215755</td>\n      <td>0.874858</td>\n      <td>0.193029</td>\n      <td>4.149217</td>\n      <td>1.250800</td>\n      <td>7.1780</td>\n      <td>1.492537</td>\n      <td>1.303864</td>\n      <td>7.2371</td>\n      <td>1.481481</td>\n      <td>4.906170</td>\n      <td>7.9750</td>\n      <td>1.694915</td>\n      <td>6.204714</td>\n      <td>7.1780</td>\n      <td>1.351351</td>\n      <td>105.899232</td>\n      <td>3.588282</td>\n      <td>2.519782</td>\n      <td>1.442106</td>\n      <td>6.022361</td>\n      <td>5.494856</td>\n    </tr>\n    <tr>\n      <th>266</th>\n      <td>10010</td>\n      <td>402</td>\n      <td>283.349209</td>\n      <td>170.270066</td>\n      <td>1991</td>\n      <td>-14.3330</td>\n      <td>12.0</td>\n      <td>-1.763275</td>\n      <td>0.178266</td>\n      <td>0.82803</td>\n      <td>0.349928</td>\n      <td>-22.380465</td>\n      <td>105.899232</td>\n      <td>1.138996</td>\n      <td>5.012703</td>\n      <td>3.518111</td>\n      <td>1.187104</td>\n      <td>8.4676</td>\n      <td>5.131519</td>\n      <td>3.878334</td>\n      <td>3.760797</td>\n      <td>1.739130</td>\n      <td>4.687965</td>\n      <td>-0.665503</td>\n      <td>0.215755</td>\n      <td>0.874858</td>\n      <td>0.193029</td>\n      <td>4.051237</td>\n      <td>1.198504</td>\n      <td>8.3759</td>\n      <td>0.671141</td>\n      <td>1.269015</td>\n      <td>6.5211</td>\n      <td>1.709402</td>\n      <td>4.484977</td>\n      <td>9.2373</td>\n      <td>0.689655</td>\n      <td>6.049708</td>\n      <td>8.3759</td>\n      <td>1.470588</td>\n      <td>105.899232</td>\n      <td>3.145976</td>\n      <td>2.794118</td>\n      <td>1.488411</td>\n      <td>5.660681</td>\n      <td>5.441735</td>\n    </tr>\n    <tr>\n      <th>267</th>\n      <td>10010</td>\n      <td>403</td>\n      <td>283.349209</td>\n      <td>170.270066</td>\n      <td>1991</td>\n      <td>-1.4001</td>\n      <td>12.0</td>\n      <td>-1.763275</td>\n      <td>0.178266</td>\n      <td>0.82803</td>\n      <td>0.349928</td>\n      <td>-14.333000</td>\n      <td>88.254769</td>\n      <td>1.051825</td>\n      <td>3.935613</td>\n      <td>2.822852</td>\n      <td>1.288922</td>\n      <td>12.3630</td>\n      <td>4.489517</td>\n      <td>3.720855</td>\n      <td>3.783681</td>\n      <td>2.803738</td>\n      <td>4.539475</td>\n      <td>-0.665503</td>\n      <td>0.215755</td>\n      <td>0.874858</td>\n      <td>0.193029</td>\n      <td>3.926769</td>\n      <td>1.138996</td>\n      <td>8.4676</td>\n      <td>1.739130</td>\n      <td>1.250800</td>\n      <td>7.1780</td>\n      <td>1.492537</td>\n      <td>2.476694</td>\n      <td>8.7479</td>\n      <td>1.503759</td>\n      <td>5.832994</td>\n      <td>8.4676</td>\n      <td>3.389831</td>\n      <td>105.899232</td>\n      <td>3.990279</td>\n      <td>3.948573</td>\n      <td>1.612393</td>\n      <td>5.553907</td>\n      <td>5.300420</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    99307.000000\nmean      1992.608507\nstd          1.007642\nmin       1991.000000\n25%       1992.000000\n50%       1993.000000\n75%       1993.000000\nmax       1994.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          99307\nprd             99307\nmom482          86889\nmom242          98087\nyear            99307\nRET             99307\nind             99307\nbm              99307\nop              99307\ngp              99307\ninv             99235\nmom11           99307\nmom122          99307\namhd            76497\nivol_capm       99305\nivol_ff5        99305\nbeta_bw         99307\nMAX             99307\nvol1m           99296\nvol6m           99255\nvol12m          99143\nBAspr           73203\nsize            99307\nlbm             99307\nlop             99307\nlgp             99307\nlinv            99307\nllme            99307\nl1amhd          76319\nl1MAX           99304\nl1BAspr         71684\nl3amhd          75954\nl3MAX           99293\nl3BAspr         68572\nl6amhd          75349\nl6MAX           99289\nl6BAspr         64086\nl12amhd         74590\nl12MAX          99304\nl12BAspr        55213\nl12mom122       99009\nl12ivol_capm    99262\nl12ivol_ff5     99262\nl12beta_bw      99286\nl12vol6m        99085\nl12vol12m       98311\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (93329, 44)\ntime to do feature proprocessing: \nNumber of features after transformation:  (93329, 92)\nmae of a constant model 9.672994876869886\nR2 of a constant model 0.0\nXGB train: 9.420535194195514 0.07314486258088526\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\nXGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.00745040954792453 48.7600462436676\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:56:34,277]\u001b[0m A new study created in memory with name: no-name-8eeb336f-cd06-4008-8a54-75b767b7ca38\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 9.595724262339575 0.026934979178415253 50.27580285072327\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:56:38,474]\u001b[0m Trial 0 finished with value: 0.005759122604463357 and parameters: {'n_estimators': 825, 'max_depth': 2, 'learning_rate': 0.04823598942492452, 'colsample_bytree': 0.80499973985738, 'subsample': 0.9156988534699153, 'alpha': 0.876543519301316, 'lambda': 31.5793389972349, 'gamma': 0.0006225576404953054, 'min_child_weight': 2.12656446496109}. Best is trial 0 with value: 0.005759122604463357.\u001b[0m\n\u001b[32m[I 2022-08-25 20:56:43,173]\u001b[0m Trial 1 finished with value: 0.005997799603415438 and parameters: {'n_estimators': 850, 'max_depth': 2, 'learning_rate': 0.013372048296814976, 'colsample_bytree': 0.8250614612843398, 'subsample': 0.7389447898319327, 'alpha': 3.3110558293805097, 'lambda': 9.035560293433845, 'gamma': 1.5501442021534912e-09, 'min_child_weight': 33.23759950154523}. Best is trial 1 with value: 0.005997799603415438.\u001b[0m\n\u001b[32m[I 2022-08-25 20:56:48,983]\u001b[0m Trial 2 finished with value: -0.005091092811945744 and parameters: {'n_estimators': 743, 'max_depth': 4, 'learning_rate': 0.03830788148199658, 'colsample_bytree': 0.2600577756950604, 'subsample': 0.7300507603787048, 'alpha': 3.5625512771694545, 'lambda': 0.29791021109693266, 'gamma': 5.317816237367425e-05, 'min_child_weight': 5.939407351414046}. Best is trial 1 with value: 0.005997799603415438.\u001b[0m\n\u001b[32m[I 2022-08-25 20:56:56,307]\u001b[0m Trial 3 finished with value: -0.009908921052918114 and parameters: {'n_estimators': 753, 'max_depth': 4, 'learning_rate': 0.0456313070133104, 'colsample_bytree': 0.8169162741777098, 'subsample': 0.48774048073969306, 'alpha': 14.982278363293466, 'lambda': 55.935253576467375, 'gamma': 0.2831983250498526, 'min_child_weight': 0.17585203592066553}. Best is trial 1 with value: 0.005997799603415438.\u001b[0m\n\u001b[32m[I 2022-08-25 20:56:59,487]\u001b[0m Trial 4 finished with value: 0.0033272405928773986 and parameters: {'n_estimators': 584, 'max_depth': 2, 'learning_rate': 0.0025661602581744094, 'colsample_bytree': 0.5706881081146735, 'subsample': 0.7386646359252153, 'alpha': 0.5912651029189474, 'lambda': 90.34358606172299, 'gamma': 0.002147512894912327, 'min_child_weight': 10.72162687779016}. Best is trial 1 with value: 0.005997799603415438.\u001b[0m\n\u001b[32m[I 2022-08-25 20:57:04,086]\u001b[0m Trial 5 finished with value: 0.007225647970322175 and parameters: {'n_estimators': 702, 'max_depth': 3, 'learning_rate': 0.014129550384694739, 'colsample_bytree': 0.6043395238932224, 'subsample': 0.4566681651440049, 'alpha': 0.9146590604723361, 'lambda': 138.93554084361423, 'gamma': 2.453422651494952e-09, 'min_child_weight': 7.915664231886733}. Best is trial 5 with value: 0.007225647970322175.\u001b[0m\n\u001b[32m[I 2022-08-25 20:57:08,696]\u001b[0m Trial 6 finished with value: 0.0054623900397761695 and parameters: {'n_estimators': 754, 'max_depth': 3, 'learning_rate': 0.021058971125594364, 'colsample_bytree': 0.170947688515061, 'subsample': 0.3063292276390272, 'alpha': 0.15069698363733078, 'lambda': 20.611176042837428, 'gamma': 0.01063261941835105, 'min_child_weight': 47.71764319508742}. Best is trial 5 with value: 0.007225647970322175.\u001b[0m\n\u001b[32m[I 2022-08-25 20:57:14,285]\u001b[0m Trial 7 finished with value: 0.004834569673709221 and parameters: {'n_estimators': 860, 'max_depth': 3, 'learning_rate': 0.02898041733867656, 'colsample_bytree': 0.32349418469345514, 'subsample': 0.9035217102073125, 'alpha': 0.19879658870026137, 'lambda': 56.71536701278386, 'gamma': 5.248348560183774, 'min_child_weight': 7.677273795383319}. Best is trial 5 with value: 0.007225647970322175.\u001b[0m\n\u001b[32m[I 2022-08-25 20:57:18,974]\u001b[0m Trial 8 finished with value: 0.00046729744551870286 and parameters: {'n_estimators': 954, 'max_depth': 2, 'learning_rate': 0.04908139682802248, 'colsample_bytree': 0.49126460316570664, 'subsample': 0.35082842314694584, 'alpha': 0.6342687285785221, 'lambda': 5.296751873506972, 'gamma': 2.5762312349051813e-06, 'min_child_weight': 1.5176083863125696}. Best is trial 5 with value: 0.007225647970322175.\u001b[0m\n\u001b[32m[I 2022-08-25 20:57:24,574]\u001b[0m Trial 9 finished with value: 0.004775071570805905 and parameters: {'n_estimators': 646, 'max_depth': 4, 'learning_rate': 0.001754379572616149, 'colsample_bytree': 0.7268854558096093, 'subsample': 0.3391127002207886, 'alpha': 10.271648709714224, 'lambda': 3.705963353115303, 'gamma': 1.6633383415373877, 'min_child_weight': 8.407273348879071}. Best is trial 5 with value: 0.007225647970322175.\u001b[0m\n\u001b[32m[I 2022-08-25 20:57:30,700]\u001b[0m Trial 10 finished with value: 0.004975366539029968 and parameters: {'n_estimators': 507, 'max_depth': 5, 'learning_rate': 0.014378103428713625, 'colsample_bytree': 0.5802615997536481, 'subsample': 0.5123630742245833, 'alpha': 1.91884837704864, 'lambda': 188.37441003817386, 'gamma': 1.5659190917020702e-10, 'min_child_weight': 0.41438136044994883}. Best is trial 5 with value: 0.007225647970322175.\u001b[0m\n\u001b[32m[I 2022-08-25 20:57:36,828]\u001b[0m Trial 11 finished with value: 0.004877126961740348 and parameters: {'n_estimators': 973, 'max_depth': 3, 'learning_rate': 0.016341534324004744, 'colsample_bytree': 0.9224484153462398, 'subsample': 0.6040721955331573, 'alpha': 4.004326896767789, 'lambda': 0.9954788072153316, 'gamma': 7.260806250464697e-10, 'min_child_weight': 49.5093195225048}. Best is trial 5 with value: 0.007225647970322175.\u001b[0m\n\u001b[32m[I 2022-08-25 20:57:41,243]\u001b[0m Trial 12 finished with value: 0.005939759479919431 and parameters: {'n_estimators': 867, 'max_depth': 2, 'learning_rate': 0.012345956724107212, 'colsample_bytree': 0.6725916271114134, 'subsample': 0.7465746129482754, 'alpha': 29.335509802244662, 'lambda': 8.395264718014547, 'gamma': 2.755132527848402e-08, 'min_child_weight': 20.205615555987762}. Best is trial 5 with value: 0.007225647970322175.\u001b[0m\n\u001b[32m[I 2022-08-25 20:57:45,499]\u001b[0m Trial 13 finished with value: 0.002475725417242082 and parameters: {'n_estimators': 665, 'max_depth': 3, 'learning_rate': 0.029173037772757312, 'colsample_bytree': 0.4080568048938435, 'subsample': 0.47149142849314124, 'alpha': 1.8165343250486155, 'lambda': 1.2179768126283113, 'gamma': 9.807793765911159e-08, 'min_child_weight': 19.89283683037597}. Best is trial 5 with value: 0.007225647970322175.\u001b[0m\n\u001b[32m[I 2022-08-25 20:57:49,803]\u001b[0m Trial 14 finished with value: 0.006642097645123558 and parameters: {'n_estimators': 811, 'max_depth': 2, 'learning_rate': 0.007885188962797864, 'colsample_bytree': 0.9265162852935449, 'subsample': 0.6112729409709918, 'alpha': 0.3136336212671205, 'lambda': 14.282482407489832, 'gamma': 9.77696718357984e-09, 'min_child_weight': 2.8305716392129923}. Best is trial 5 with value: 0.007225647970322175.\u001b[0m\n\u001b[32m[I 2022-08-25 20:57:54,747]\u001b[0m Trial 15 finished with value: 0.007488828931675319 and parameters: {'n_estimators': 665, 'max_depth': 3, 'learning_rate': 0.008154389391467096, 'colsample_bytree': 0.8967515230587886, 'subsample': 0.5942647055111392, 'alpha': 0.3080017108605482, 'lambda': 189.5739859207184, 'gamma': 1.8293111355227924e-07, 'min_child_weight': 0.8814218444600123}. Best is trial 15 with value: 0.007488828931675319.\u001b[0m\n\u001b[32m[I 2022-08-25 20:58:02,566]\u001b[0m Trial 16 finished with value: 0.001348871432479155 and parameters: {'n_estimators': 651, 'max_depth': 5, 'learning_rate': 0.022550023607395164, 'colsample_bytree': 0.6701773846208905, 'subsample': 0.41101592695257727, 'alpha': 0.10758106236024861, 'lambda': 185.83949165062643, 'gamma': 5.063346320102759e-07, 'min_child_weight': 0.7426682116303558}. Best is trial 15 with value: 0.007488828931675319.\u001b[0m\n\u001b[32m[I 2022-08-25 20:58:06,333]\u001b[0m Trial 17 finished with value: 0.006732433343621297 and parameters: {'n_estimators': 569, 'max_depth': 3, 'learning_rate': 0.007505374787053185, 'colsample_bytree': 0.463920578879656, 'subsample': 0.5434760821139741, 'alpha': 0.333850055943624, 'lambda': 0.10519607685561655, 'gamma': 1.2398245293167386e-05, 'min_child_weight': 0.8027701479785356}. Best is trial 15 with value: 0.007488828931675319.\u001b[0m\n\u001b[32m[I 2022-08-25 20:58:12,488]\u001b[0m Trial 18 finished with value: 0.006603986365645838 and parameters: {'n_estimators': 708, 'max_depth': 4, 'learning_rate': 0.00812128043981481, 'colsample_bytree': 0.6362117931655771, 'subsample': 0.4242270618682143, 'alpha': 1.037376424065012, 'lambda': 112.72537453491222, 'gamma': 7.789389325186684e-07, 'min_child_weight': 0.1629397508893784}. Best is trial 15 with value: 0.007488828931675319.\u001b[0m\n\u001b[32m[I 2022-08-25 20:58:16,500]\u001b[0m Trial 19 finished with value: 0.006869869320217454 and parameters: {'n_estimators': 603, 'max_depth': 3, 'learning_rate': 0.01927429311562409, 'colsample_bytree': 0.7503997800736122, 'subsample': 0.653589532292739, 'alpha': 0.3854449902224771, 'lambda': 39.36867245513468, 'gamma': 6.860594159723431e-09, 'min_child_weight': 4.260660099500414}. Best is trial 15 with value: 0.007488828931675319.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  102.224609375\n        n_estimators : 665\n           max_depth : 3\n       learning_rate : 0.008154389391467096\n    colsample_bytree : 0.8967515230587886\n           subsample : 0.5942647055111392\n               alpha : 0.3080017108605482\n              lambda : 189.5739859207184\n               gamma : 1.8293111355227924e-07\n    min_child_weight : 0.8814218444600123\nbest objective value : 0.007488828931675319\nOptuna XGB train: 9.629880927657037 0.016660258026348185 104.81796431541443\nMin_prd:  400\nConstant guess:  9.657962431562893 0.0\nXGB test: 9.62087685771785 0.006133389918914767\nXGB GS test: 9.622542370658485 0.007228779508588468\nOptuna XGB test: 9.629691695743013 0.004854936781629293\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(102182, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd      mom482     mom242  year      RET   ind        bm  \\\n288   10010  424  148.134180 -62.697082  1993 -15.6346  12.0 -1.623669   \n289   10010  425  101.761390 -58.326806  1993 -11.6236  12.0 -1.623669   \n290   10010  426  117.655807 -58.532664  1993  20.2928  12.0 -1.623669   \n291   10010  427  155.756932 -48.367102  1993 -13.0160  12.0 -1.623669   \n292   10010  428   61.482636 -65.093531  1993  20.5017  12.0 -1.623669   \n\n           op        gp     inv    mom11     mom122      amhd  ivol_capm  \\\n288  0.013844  0.291257  0.8003  -7.3829 -24.536334  2.356309   3.171143   \n289  0.013844  0.291257  0.8003 -15.6346 -20.026525  2.319279   2.464863   \n290  0.013844  0.291257  0.8003 -11.6236 -22.505261  2.375564   3.422118   \n291  0.013844  0.291257  0.8003  20.2928 -36.488730  2.538076   5.092653   \n292  0.013844  0.291257  0.8003 -13.0160 -36.684897  2.590794   3.559160   \n\n     ivol_ff5   beta_bw      MAX     vol1m     vol6m    vol12m     BAspr  \\\n288  2.755517  1.025037   7.1319  3.247245  3.250157  3.536904  3.773585   \n289  2.396834  0.937890   4.2443  2.455998  2.837847  3.526523  4.444444   \n290  2.553819  0.914418   5.3934  3.461057  3.038084  3.576669  2.631579   \n291  4.290265  0.700595  14.6231  5.425358  3.609285  3.578975  1.960784   \n292  2.977536  0.799717   8.4986  3.874691  3.789539  3.641639  5.000000   \n\n         size       lbm       lop       lgp    linv      llme    l1amhd  \\\n288  4.011162 -1.838236  0.165652  0.658097  0.8003  4.343682  2.344284   \n289  3.844108 -1.838236  0.165652  0.658097  0.8003  4.211913  2.356309   \n290  3.723480 -1.838236  0.165652  0.658097  0.8003  4.076367  2.319279   \n291  3.910066 -1.838236  0.165652  0.658097  0.8003  4.154188  2.375564   \n292  3.773491 -1.838236  0.165652  0.658097  0.8003  4.343945  2.538076   \n\n       l1MAX   l1BAspr    l3amhd   l3MAX   l3BAspr    l6amhd    l6MAX  \\\n288   4.9111  5.357143  2.257265  2.8461  3.896104  2.140223  15.6507   \n289   7.1319  3.773585  2.288018  2.8461  4.687500  2.159371  14.9880   \n290   4.2443  4.444444  2.344284  4.9111  5.357143  2.243236   5.4835   \n291   5.3934  2.631579  2.356309  7.1319  3.773585  2.257265   2.8461   \n292  14.6231  1.960784  2.319279  4.2443  4.444444  2.288018   2.8461   \n\n      l6BAspr   l12amhd   l12MAX  l12BAspr  l12mom122  l12ivol_capm  \\\n288  2.083333  1.239298   4.9111  3.797468 -49.976941      4.624060   \n289  2.197802  1.562790   7.1319  2.857143 -48.526911      2.413109   \n290  2.469136  1.764717   4.2443  3.389831 -40.574374      2.450042   \n291  3.896104  1.971426   5.3934  1.470588 -39.605370      5.309489   \n292  4.687500  2.095885  14.6231  2.631579 -33.948972      2.597573   \n\n     l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n288     3.990327    1.453285  3.616714   4.064687  \n289     2.010203    1.480784  3.467116   4.028793  \n290     2.158362    1.394343  3.457382   3.812707  \n291     4.505264    1.380782  3.965839   3.896158  \n292     2.269970    1.512959  4.014497   3.840770  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>288</th>\n      <td>10010</td>\n      <td>424</td>\n      <td>148.134180</td>\n      <td>-62.697082</td>\n      <td>1993</td>\n      <td>-15.6346</td>\n      <td>12.0</td>\n      <td>-1.623669</td>\n      <td>0.013844</td>\n      <td>0.291257</td>\n      <td>0.8003</td>\n      <td>-7.3829</td>\n      <td>-24.536334</td>\n      <td>2.356309</td>\n      <td>3.171143</td>\n      <td>2.755517</td>\n      <td>1.025037</td>\n      <td>7.1319</td>\n      <td>3.247245</td>\n      <td>3.250157</td>\n      <td>3.536904</td>\n      <td>3.773585</td>\n      <td>4.011162</td>\n      <td>-1.838236</td>\n      <td>0.165652</td>\n      <td>0.658097</td>\n      <td>0.8003</td>\n      <td>4.343682</td>\n      <td>2.344284</td>\n      <td>4.9111</td>\n      <td>5.357143</td>\n      <td>2.257265</td>\n      <td>2.8461</td>\n      <td>3.896104</td>\n      <td>2.140223</td>\n      <td>15.6507</td>\n      <td>2.083333</td>\n      <td>1.239298</td>\n      <td>4.9111</td>\n      <td>3.797468</td>\n      <td>-49.976941</td>\n      <td>4.624060</td>\n      <td>3.990327</td>\n      <td>1.453285</td>\n      <td>3.616714</td>\n      <td>4.064687</td>\n    </tr>\n    <tr>\n      <th>289</th>\n      <td>10010</td>\n      <td>425</td>\n      <td>101.761390</td>\n      <td>-58.326806</td>\n      <td>1993</td>\n      <td>-11.6236</td>\n      <td>12.0</td>\n      <td>-1.623669</td>\n      <td>0.013844</td>\n      <td>0.291257</td>\n      <td>0.8003</td>\n      <td>-15.6346</td>\n      <td>-20.026525</td>\n      <td>2.319279</td>\n      <td>2.464863</td>\n      <td>2.396834</td>\n      <td>0.937890</td>\n      <td>4.2443</td>\n      <td>2.455998</td>\n      <td>2.837847</td>\n      <td>3.526523</td>\n      <td>4.444444</td>\n      <td>3.844108</td>\n      <td>-1.838236</td>\n      <td>0.165652</td>\n      <td>0.658097</td>\n      <td>0.8003</td>\n      <td>4.211913</td>\n      <td>2.356309</td>\n      <td>7.1319</td>\n      <td>3.773585</td>\n      <td>2.288018</td>\n      <td>2.8461</td>\n      <td>4.687500</td>\n      <td>2.159371</td>\n      <td>14.9880</td>\n      <td>2.197802</td>\n      <td>1.562790</td>\n      <td>7.1319</td>\n      <td>2.857143</td>\n      <td>-48.526911</td>\n      <td>2.413109</td>\n      <td>2.010203</td>\n      <td>1.480784</td>\n      <td>3.467116</td>\n      <td>4.028793</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>10010</td>\n      <td>426</td>\n      <td>117.655807</td>\n      <td>-58.532664</td>\n      <td>1993</td>\n      <td>20.2928</td>\n      <td>12.0</td>\n      <td>-1.623669</td>\n      <td>0.013844</td>\n      <td>0.291257</td>\n      <td>0.8003</td>\n      <td>-11.6236</td>\n      <td>-22.505261</td>\n      <td>2.375564</td>\n      <td>3.422118</td>\n      <td>2.553819</td>\n      <td>0.914418</td>\n      <td>5.3934</td>\n      <td>3.461057</td>\n      <td>3.038084</td>\n      <td>3.576669</td>\n      <td>2.631579</td>\n      <td>3.723480</td>\n      <td>-1.838236</td>\n      <td>0.165652</td>\n      <td>0.658097</td>\n      <td>0.8003</td>\n      <td>4.076367</td>\n      <td>2.319279</td>\n      <td>4.2443</td>\n      <td>4.444444</td>\n      <td>2.344284</td>\n      <td>4.9111</td>\n      <td>5.357143</td>\n      <td>2.243236</td>\n      <td>5.4835</td>\n      <td>2.469136</td>\n      <td>1.764717</td>\n      <td>4.2443</td>\n      <td>3.389831</td>\n      <td>-40.574374</td>\n      <td>2.450042</td>\n      <td>2.158362</td>\n      <td>1.394343</td>\n      <td>3.457382</td>\n      <td>3.812707</td>\n    </tr>\n    <tr>\n      <th>291</th>\n      <td>10010</td>\n      <td>427</td>\n      <td>155.756932</td>\n      <td>-48.367102</td>\n      <td>1993</td>\n      <td>-13.0160</td>\n      <td>12.0</td>\n      <td>-1.623669</td>\n      <td>0.013844</td>\n      <td>0.291257</td>\n      <td>0.8003</td>\n      <td>20.2928</td>\n      <td>-36.488730</td>\n      <td>2.538076</td>\n      <td>5.092653</td>\n      <td>4.290265</td>\n      <td>0.700595</td>\n      <td>14.6231</td>\n      <td>5.425358</td>\n      <td>3.609285</td>\n      <td>3.578975</td>\n      <td>1.960784</td>\n      <td>3.910066</td>\n      <td>-1.838236</td>\n      <td>0.165652</td>\n      <td>0.658097</td>\n      <td>0.8003</td>\n      <td>4.154188</td>\n      <td>2.375564</td>\n      <td>5.3934</td>\n      <td>2.631579</td>\n      <td>2.356309</td>\n      <td>7.1319</td>\n      <td>3.773585</td>\n      <td>2.257265</td>\n      <td>2.8461</td>\n      <td>3.896104</td>\n      <td>1.971426</td>\n      <td>5.3934</td>\n      <td>1.470588</td>\n      <td>-39.605370</td>\n      <td>5.309489</td>\n      <td>4.505264</td>\n      <td>1.380782</td>\n      <td>3.965839</td>\n      <td>3.896158</td>\n    </tr>\n    <tr>\n      <th>292</th>\n      <td>10010</td>\n      <td>428</td>\n      <td>61.482636</td>\n      <td>-65.093531</td>\n      <td>1993</td>\n      <td>20.5017</td>\n      <td>12.0</td>\n      <td>-1.623669</td>\n      <td>0.013844</td>\n      <td>0.291257</td>\n      <td>0.8003</td>\n      <td>-13.0160</td>\n      <td>-36.684897</td>\n      <td>2.590794</td>\n      <td>3.559160</td>\n      <td>2.977536</td>\n      <td>0.799717</td>\n      <td>8.4986</td>\n      <td>3.874691</td>\n      <td>3.789539</td>\n      <td>3.641639</td>\n      <td>5.000000</td>\n      <td>3.773491</td>\n      <td>-1.838236</td>\n      <td>0.165652</td>\n      <td>0.658097</td>\n      <td>0.8003</td>\n      <td>4.343945</td>\n      <td>2.538076</td>\n      <td>14.6231</td>\n      <td>1.960784</td>\n      <td>2.319279</td>\n      <td>4.2443</td>\n      <td>4.444444</td>\n      <td>2.288018</td>\n      <td>2.8461</td>\n      <td>4.687500</td>\n      <td>2.095885</td>\n      <td>14.6231</td>\n      <td>2.631579</td>\n      <td>-33.948972</td>\n      <td>2.597573</td>\n      <td>2.269970</td>\n      <td>1.512959</td>\n      <td>4.014497</td>\n      <td>3.840770</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    102182.000000\nmean       1994.716124\nstd           0.994935\nmin        1993.000000\n25%        1994.000000\n50%        1995.000000\n75%        1996.000000\nmax        1996.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          102182\nprd             102182\nmom482           87382\nmom242          100438\nyear            102182\nRET             102182\nind             102182\nbm              102182\nop              102182\ngp              102182\ninv             102148\nmom11           102182\nmom122          102182\namhd             85532\nivol_capm       102178\nivol_ff5        102178\nbeta_bw         102182\nMAX             102182\nvol1m           102172\nvol6m           102108\nvol12m          101974\nBAspr           100566\nsize            102182\nlbm             102182\nlop             102182\nlgp             102182\nlinv            102182\nllme            102182\nl1amhd           85396\nl1MAX           102175\nl1BAspr         100597\nl3amhd           85087\nl3MAX           102157\nl3BAspr         100635\nl6amhd           84563\nl6MAX           102141\nl6BAspr         100531\nl12amhd          83700\nl12MAX          102175\nl12BAspr         94697\nl12mom122       101709\nl12ivol_capm    102101\nl12ivol_ff5     102101\nl12beta_bw      102124\nl12vol6m        101937\nl12vol12m       100735\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (95853, 44)\ntime to do feature proprocessing: \nNumber of features after transformation:  (95853, 92)\nmae of a constant model 9.375745237906912\nR2 of a constant model 0.0\nXGB train: 9.060360096757641 0.07527572391660609\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\nXGB {'colsample_bytree': 0.6, 'eta': 0.02, 'max_depth': 2, 'n_estimators': 700, 'subsample': 0.6} 0.008557722194442285 49.500277042388916\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:59:13,415]\u001b[0m A new study created in memory with name: no-name-ea8d5e35-5d64-4488-b6de-2328760a8309\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 9.264390698311827 0.018518375219927052 50.35354495048523\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 20:59:18,081]\u001b[0m Trial 0 finished with value: 0.006866988004475612 and parameters: {'n_estimators': 902, 'max_depth': 2, 'learning_rate': 0.023516894023226927, 'colsample_bytree': 0.3218806645071921, 'subsample': 0.3329226495903268, 'alpha': 0.46744653606850045, 'lambda': 0.534702536348529, 'gamma': 8.163747030006883, 'min_child_weight': 0.4712755923752075}. Best is trial 0 with value: 0.006866988004475612.\u001b[0m\n\u001b[32m[I 2022-08-25 20:59:26,077]\u001b[0m Trial 1 finished with value: 0.007179150575405751 and parameters: {'n_estimators': 922, 'max_depth': 4, 'learning_rate': 0.003156037731425779, 'colsample_bytree': 0.6781060558438197, 'subsample': 0.45565910128925075, 'alpha': 2.4681648123857562, 'lambda': 18.86556410547153, 'gamma': 0.9457583603406172, 'min_child_weight': 1.7461703259213068}. Best is trial 1 with value: 0.007179150575405751.\u001b[0m\n\u001b[32m[I 2022-08-25 20:59:37,890]\u001b[0m Trial 2 finished with value: -0.035757909662161885 and parameters: {'n_estimators': 985, 'max_depth': 5, 'learning_rate': 0.046791198674126684, 'colsample_bytree': 0.8309992916713327, 'subsample': 0.9236416644577086, 'alpha': 0.1929646239660704, 'lambda': 8.390618817537943, 'gamma': 1.7721687602267332e-10, 'min_child_weight': 0.2345736406994446}. Best is trial 1 with value: 0.007179150575405751.\u001b[0m\n\u001b[32m[I 2022-08-25 20:59:45,362]\u001b[0m Trial 3 finished with value: -0.0070915047925075745 and parameters: {'n_estimators': 642, 'max_depth': 5, 'learning_rate': 0.03539963803845552, 'colsample_bytree': 0.5422547384883791, 'subsample': 0.45261708625991737, 'alpha': 6.241058491328616, 'lambda': 63.13146900545505, 'gamma': 0.010024204235301926, 'min_child_weight': 0.4412925611029481}. Best is trial 1 with value: 0.007179150575405751.\u001b[0m\n\u001b[32m[I 2022-08-25 20:59:50,611]\u001b[0m Trial 4 finished with value: 0.005341567518041665 and parameters: {'n_estimators': 756, 'max_depth': 3, 'learning_rate': 0.002159725789425572, 'colsample_bytree': 0.6680487413912097, 'subsample': 0.6023789530718868, 'alpha': 7.2529250220366634, 'lambda': 1.3782546768128088, 'gamma': 0.3172050961077961, 'min_child_weight': 3.6691291791869634}. Best is trial 1 with value: 0.007179150575405751.\u001b[0m\n\u001b[32m[I 2022-08-25 20:59:58,814]\u001b[0m Trial 5 finished with value: -0.004053767467530763 and parameters: {'n_estimators': 669, 'max_depth': 5, 'learning_rate': 0.03948993150317632, 'colsample_bytree': 0.21406159527790541, 'subsample': 0.7398789586543537, 'alpha': 17.597829348876722, 'lambda': 76.31643984155563, 'gamma': 2.9802686904244626e-09, 'min_child_weight': 1.7114462751973192}. Best is trial 1 with value: 0.007179150575405751.\u001b[0m\n\u001b[32m[I 2022-08-25 21:00:02,685]\u001b[0m Trial 6 finished with value: 0.008109866342916206 and parameters: {'n_estimators': 675, 'max_depth': 2, 'learning_rate': 0.01567688865911201, 'colsample_bytree': 0.5643224582137997, 'subsample': 0.6698422019465207, 'alpha': 11.121249929987147, 'lambda': 21.20477068580261, 'gamma': 6.257263680842202e-07, 'min_child_weight': 0.10842289502104378}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n\u001b[32m[I 2022-08-25 21:00:12,818]\u001b[0m Trial 7 finished with value: 0.002005297406122264 and parameters: {'n_estimators': 899, 'max_depth': 5, 'learning_rate': 0.016973850863662005, 'colsample_bytree': 0.34197900157305916, 'subsample': 0.35152324108782623, 'alpha': 7.2109374907742545, 'lambda': 52.74592117729317, 'gamma': 8.023987222857947e-05, 'min_child_weight': 0.1468350610003663}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n\u001b[32m[I 2022-08-25 21:00:21,926]\u001b[0m Trial 8 finished with value: -0.0007289157511253998 and parameters: {'n_estimators': 827, 'max_depth': 5, 'learning_rate': 0.019134144490553926, 'colsample_bytree': 0.15492990294757408, 'subsample': 0.9313147848793337, 'alpha': 7.260045263583153, 'lambda': 0.1744444023252152, 'gamma': 2.499288243214174e-10, 'min_child_weight': 1.8803946732751302}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n\u001b[32m[I 2022-08-25 21:00:27,740]\u001b[0m Trial 9 finished with value: 0.003040493870302252 and parameters: {'n_estimators': 700, 'max_depth': 4, 'learning_rate': 0.01961686268987567, 'colsample_bytree': 0.4091334241386283, 'subsample': 0.7938764574976178, 'alpha': 3.025706181708436, 'lambda': 4.622447016202769, 'gamma': 0.2347925745524922, 'min_child_weight': 5.769547593162811}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n\u001b[32m[I 2022-08-25 21:00:30,950]\u001b[0m Trial 10 finished with value: 0.007034233932614404 and parameters: {'n_estimators': 556, 'max_depth': 2, 'learning_rate': 0.00989001585140035, 'colsample_bytree': 0.9249306156960093, 'subsample': 0.6219749749000828, 'alpha': 28.95326094776216, 'lambda': 147.2099442385612, 'gamma': 2.8650567475824597e-07, 'min_child_weight': 34.915567995704386}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n\u001b[32m[I 2022-08-25 21:00:34,624]\u001b[0m Trial 11 finished with value: 0.005692951426767372 and parameters: {'n_estimators': 502, 'max_depth': 3, 'learning_rate': 0.0035641992440313187, 'colsample_bytree': 0.6634873249281692, 'subsample': 0.5038380247346664, 'alpha': 1.2548612030818191, 'lambda': 21.428853039022925, 'gamma': 1.3022380770611105e-05, 'min_child_weight': 20.77072387619035}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n\u001b[32m[I 2022-08-25 21:00:41,313]\u001b[0m Trial 12 finished with value: 0.005518993413951241 and parameters: {'n_estimators': 805, 'max_depth': 4, 'learning_rate': 0.010730807162182525, 'colsample_bytree': 0.6159445315324176, 'subsample': 0.4692192046196421, 'alpha': 1.4300776019262134, 'lambda': 16.44368464438633, 'gamma': 4.653873303835251e-07, 'min_child_weight': 0.8301507429960089}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n\u001b[32m[I 2022-08-25 21:00:45,561]\u001b[0m Trial 13 finished with value: 0.007927348407604298 and parameters: {'n_estimators': 604, 'max_depth': 3, 'learning_rate': 0.009448014703854285, 'colsample_bytree': 0.8032528733727571, 'subsample': 0.7286375490833743, 'alpha': 2.3660612085508372, 'lambda': 1.8886278882087986, 'gamma': 0.0005276066958876686, 'min_child_weight': 0.14043064635501773}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n\u001b[32m[I 2022-08-25 21:00:48,936]\u001b[0m Trial 14 finished with value: 0.006451886527644351 and parameters: {'n_estimators': 605, 'max_depth': 2, 'learning_rate': 0.030218730805433493, 'colsample_bytree': 0.8013501270820698, 'subsample': 0.7420045657289521, 'alpha': 0.8026127199099293, 'lambda': 1.644637947365976, 'gamma': 0.0009929133113043712, 'min_child_weight': 0.10367009766993086}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n\u001b[32m[I 2022-08-25 21:00:52,929]\u001b[0m Trial 15 finished with value: 0.007232583790714448 and parameters: {'n_estimators': 591, 'max_depth': 3, 'learning_rate': 0.012137223288335532, 'colsample_bytree': 0.4856543982943123, 'subsample': 0.8111514962451635, 'alpha': 14.259855485400132, 'lambda': 1.6960686208335247, 'gamma': 2.4238246740717507e-07, 'min_child_weight': 0.2559567472567334}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n\u001b[32m[I 2022-08-25 21:00:57,003]\u001b[0m Trial 16 finished with value: 0.0057444115833432475 and parameters: {'n_estimators': 737, 'max_depth': 2, 'learning_rate': 0.02638863882204918, 'colsample_bytree': 0.7708590957474428, 'subsample': 0.6685045576006883, 'alpha': 3.4365702154078055, 'lambda': 0.45683088808976147, 'gamma': 8.489719340606627e-06, 'min_child_weight': 0.6209684921141292}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n\u001b[32m[I 2022-08-25 21:01:01,172]\u001b[0m Trial 17 finished with value: 0.006101701930826916 and parameters: {'n_estimators': 543, 'max_depth': 3, 'learning_rate': 0.014092199885438226, 'colsample_bytree': 0.8819521882511181, 'subsample': 0.5635895893587598, 'alpha': 0.17258528310482973, 'lambda': 4.642833780595032, 'gamma': 0.0005761952224463742, 'min_child_weight': 0.20567425054448546}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n\u001b[32m[I 2022-08-25 21:01:04,997]\u001b[0m Trial 18 finished with value: 0.006460299112269688 and parameters: {'n_estimators': 645, 'max_depth': 2, 'learning_rate': 0.007747892247220537, 'colsample_bytree': 0.5692359359481415, 'subsample': 0.7079855892180075, 'alpha': 0.6102404662377139, 'lambda': 9.398614147106814, 'gamma': 1.0318477350271396e-08, 'min_child_weight': 8.291574005603122}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n\u001b[32m[I 2022-08-25 21:01:09,691]\u001b[0m Trial 19 finished with value: 0.004478975843716718 and parameters: {'n_estimators': 710, 'max_depth': 3, 'learning_rate': 0.023976356803488506, 'colsample_bytree': 0.4788043666216234, 'subsample': 0.8516387712217813, 'alpha': 0.3224837972863442, 'lambda': 0.48824782840901565, 'gamma': 3.4142397576476443e-06, 'min_child_weight': 0.11745856015090048}. Best is trial 6 with value: 0.008109866342916206.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  116.27700185775757\n        n_estimators : 675\n           max_depth : 2\n       learning_rate : 0.01567688865911201\n    colsample_bytree : 0.5643224582137997\n           subsample : 0.6698422019465207\n               alpha : 11.121249929987147\n              lambda : 21.20477068580261\n               gamma : 6.257263680842202e-07\n    min_child_weight : 0.10842289502104378\nbest objective value : 0.008109866342916206\nOptuna XGB train: 9.273415089986655 0.015569196331451929 118.31046509742737\nMin_prd:  425\nConstant guess:  9.364989596407753 0.0\nXGB test: 9.259611324257023 0.00927523096303362\nXGB GS test: 9.274234808150892 0.007465935485271635\nOptuna XGB test: 9.279454702242596 0.007930612205281684\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(108887, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd      mom482      mom242  year     RET   ind        bm  \\\n350   10011  449  283.349209  120.876558  1995 -0.4300  34.0 -2.486223   \n351   10011  450  205.913318   95.440525  1995 -8.8033  34.0 -2.486223   \n352   10011  451  221.036390   71.141338  1995 -9.5109  34.0 -2.486223   \n353   10011  452  168.594228   68.496890  1995 -6.4900  34.0 -2.486223   \n354   10011  453  236.841444   69.211874  1996  8.0806  34.0 -2.486223   \n\n           op        gp       inv   mom11     mom122      amhd  ivol_capm  \\\n350  0.258106  0.875338  0.516551 -7.4467  62.087334  2.203319   3.397123   \n351  0.258106  0.875338  0.516551 -0.4300  43.018972  2.055711   1.691854   \n352  0.258106  0.875338  0.516551 -8.8033   4.809002  1.994961   4.082701   \n353  0.258106  0.875338  0.516551 -9.5109 -24.282511  2.029321   1.958872   \n354  0.258106  0.875338  0.516551 -6.4900 -26.926242  1.998770   2.609950   \n\n     ivol_ff5   beta_bw     MAX     vol1m     vol6m    vol12m     BAspr  \\\n350  3.021503  0.591144  5.2897  3.321408  4.042566  3.530399  4.166667   \n351  1.403498  0.529444  3.4263  1.903369  2.962005  3.527886  1.680672   \n352  3.614374  0.889628  8.0435  4.223638  2.857356  3.429300  1.886792   \n353  1.492302  0.955259  3.9016  1.971703  2.845821  3.363990  0.990099   \n354  2.444418  0.891820  4.5215  2.700381  2.993230  3.361390  3.000000   \n\n         size       lbm       lop       lgp      linv      llme    l1amhd  \\\n350  4.475688 -1.862198  0.132619  0.757579  0.335288  3.974058  2.158299   \n351  4.475688 -1.862198  0.132619  0.757579  0.335288  4.025352  2.203319   \n352  4.388676 -1.862198  0.132619  0.757579  0.335288  4.334673  2.055711   \n353  4.579211 -1.862198  0.132619  0.757579  0.335288  4.591956  1.994961   \n354  4.517336 -1.862198  0.132619  0.757579  0.335288  4.532237  2.029321   \n\n       l1MAX   l1BAspr    l3amhd    l3MAX   l3BAspr    l6amhd    l6MAX  \\\n350  11.8414  3.816794  2.246729   3.7639  2.500000  2.492715   3.4878   \n351   5.2897  4.166667  2.232079   3.3123  1.694915  2.295714  11.8848   \n352   3.4263  1.680672  2.158299  11.8414  3.816794  2.282986  17.0710   \n353   8.0435  1.886792  2.203319   5.2897  4.166667  2.246729   3.7639   \n354   3.9016  0.990099  2.055711   3.4263  1.680672  2.232079   3.3123   \n\n      l6BAspr   l12amhd   l12MAX  l12BAspr   l12mom122  l12ivol_capm  \\\n350  0.934579  4.213494  11.8414  1.351351  100.655293      1.538877   \n351  2.564103  3.981594   5.2897  2.380952   53.833664      1.642887   \n352  1.481481  3.937745   3.4263  1.550388   43.713086      2.723997   \n353  2.500000  3.821606   8.0435  2.112676   73.239085      4.861236   \n354  1.694915  3.248493   3.9016  1.538462  105.899232      2.666218   \n\n     l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n350     1.288538    0.647352  2.929669   3.074934  \n351     1.515819    0.763396  2.749820   2.941439  \n352     2.325965    0.670790  2.191232   2.755011  \n353     3.538108    0.631505  2.827082   3.005351  \n354     2.284620    0.693450  2.876936   3.023678  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>350</th>\n      <td>10011</td>\n      <td>449</td>\n      <td>283.349209</td>\n      <td>120.876558</td>\n      <td>1995</td>\n      <td>-0.4300</td>\n      <td>34.0</td>\n      <td>-2.486223</td>\n      <td>0.258106</td>\n      <td>0.875338</td>\n      <td>0.516551</td>\n      <td>-7.4467</td>\n      <td>62.087334</td>\n      <td>2.203319</td>\n      <td>3.397123</td>\n      <td>3.021503</td>\n      <td>0.591144</td>\n      <td>5.2897</td>\n      <td>3.321408</td>\n      <td>4.042566</td>\n      <td>3.530399</td>\n      <td>4.166667</td>\n      <td>4.475688</td>\n      <td>-1.862198</td>\n      <td>0.132619</td>\n      <td>0.757579</td>\n      <td>0.335288</td>\n      <td>3.974058</td>\n      <td>2.158299</td>\n      <td>11.8414</td>\n      <td>3.816794</td>\n      <td>2.246729</td>\n      <td>3.7639</td>\n      <td>2.500000</td>\n      <td>2.492715</td>\n      <td>3.4878</td>\n      <td>0.934579</td>\n      <td>4.213494</td>\n      <td>11.8414</td>\n      <td>1.351351</td>\n      <td>100.655293</td>\n      <td>1.538877</td>\n      <td>1.288538</td>\n      <td>0.647352</td>\n      <td>2.929669</td>\n      <td>3.074934</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>10011</td>\n      <td>450</td>\n      <td>205.913318</td>\n      <td>95.440525</td>\n      <td>1995</td>\n      <td>-8.8033</td>\n      <td>34.0</td>\n      <td>-2.486223</td>\n      <td>0.258106</td>\n      <td>0.875338</td>\n      <td>0.516551</td>\n      <td>-0.4300</td>\n      <td>43.018972</td>\n      <td>2.055711</td>\n      <td>1.691854</td>\n      <td>1.403498</td>\n      <td>0.529444</td>\n      <td>3.4263</td>\n      <td>1.903369</td>\n      <td>2.962005</td>\n      <td>3.527886</td>\n      <td>1.680672</td>\n      <td>4.475688</td>\n      <td>-1.862198</td>\n      <td>0.132619</td>\n      <td>0.757579</td>\n      <td>0.335288</td>\n      <td>4.025352</td>\n      <td>2.203319</td>\n      <td>5.2897</td>\n      <td>4.166667</td>\n      <td>2.232079</td>\n      <td>3.3123</td>\n      <td>1.694915</td>\n      <td>2.295714</td>\n      <td>11.8848</td>\n      <td>2.564103</td>\n      <td>3.981594</td>\n      <td>5.2897</td>\n      <td>2.380952</td>\n      <td>53.833664</td>\n      <td>1.642887</td>\n      <td>1.515819</td>\n      <td>0.763396</td>\n      <td>2.749820</td>\n      <td>2.941439</td>\n    </tr>\n    <tr>\n      <th>352</th>\n      <td>10011</td>\n      <td>451</td>\n      <td>221.036390</td>\n      <td>71.141338</td>\n      <td>1995</td>\n      <td>-9.5109</td>\n      <td>34.0</td>\n      <td>-2.486223</td>\n      <td>0.258106</td>\n      <td>0.875338</td>\n      <td>0.516551</td>\n      <td>-8.8033</td>\n      <td>4.809002</td>\n      <td>1.994961</td>\n      <td>4.082701</td>\n      <td>3.614374</td>\n      <td>0.889628</td>\n      <td>8.0435</td>\n      <td>4.223638</td>\n      <td>2.857356</td>\n      <td>3.429300</td>\n      <td>1.886792</td>\n      <td>4.388676</td>\n      <td>-1.862198</td>\n      <td>0.132619</td>\n      <td>0.757579</td>\n      <td>0.335288</td>\n      <td>4.334673</td>\n      <td>2.055711</td>\n      <td>3.4263</td>\n      <td>1.680672</td>\n      <td>2.158299</td>\n      <td>11.8414</td>\n      <td>3.816794</td>\n      <td>2.282986</td>\n      <td>17.0710</td>\n      <td>1.481481</td>\n      <td>3.937745</td>\n      <td>3.4263</td>\n      <td>1.550388</td>\n      <td>43.713086</td>\n      <td>2.723997</td>\n      <td>2.325965</td>\n      <td>0.670790</td>\n      <td>2.191232</td>\n      <td>2.755011</td>\n    </tr>\n    <tr>\n      <th>353</th>\n      <td>10011</td>\n      <td>452</td>\n      <td>168.594228</td>\n      <td>68.496890</td>\n      <td>1995</td>\n      <td>-6.4900</td>\n      <td>34.0</td>\n      <td>-2.486223</td>\n      <td>0.258106</td>\n      <td>0.875338</td>\n      <td>0.516551</td>\n      <td>-9.5109</td>\n      <td>-24.282511</td>\n      <td>2.029321</td>\n      <td>1.958872</td>\n      <td>1.492302</td>\n      <td>0.955259</td>\n      <td>3.9016</td>\n      <td>1.971703</td>\n      <td>2.845821</td>\n      <td>3.363990</td>\n      <td>0.990099</td>\n      <td>4.579211</td>\n      <td>-1.862198</td>\n      <td>0.132619</td>\n      <td>0.757579</td>\n      <td>0.335288</td>\n      <td>4.591956</td>\n      <td>1.994961</td>\n      <td>8.0435</td>\n      <td>1.886792</td>\n      <td>2.203319</td>\n      <td>5.2897</td>\n      <td>4.166667</td>\n      <td>2.246729</td>\n      <td>3.7639</td>\n      <td>2.500000</td>\n      <td>3.821606</td>\n      <td>8.0435</td>\n      <td>2.112676</td>\n      <td>73.239085</td>\n      <td>4.861236</td>\n      <td>3.538108</td>\n      <td>0.631505</td>\n      <td>2.827082</td>\n      <td>3.005351</td>\n    </tr>\n    <tr>\n      <th>354</th>\n      <td>10011</td>\n      <td>453</td>\n      <td>236.841444</td>\n      <td>69.211874</td>\n      <td>1996</td>\n      <td>8.0806</td>\n      <td>34.0</td>\n      <td>-2.486223</td>\n      <td>0.258106</td>\n      <td>0.875338</td>\n      <td>0.516551</td>\n      <td>-6.4900</td>\n      <td>-26.926242</td>\n      <td>1.998770</td>\n      <td>2.609950</td>\n      <td>2.444418</td>\n      <td>0.891820</td>\n      <td>4.5215</td>\n      <td>2.700381</td>\n      <td>2.993230</td>\n      <td>3.361390</td>\n      <td>3.000000</td>\n      <td>4.517336</td>\n      <td>-1.862198</td>\n      <td>0.132619</td>\n      <td>0.757579</td>\n      <td>0.335288</td>\n      <td>4.532237</td>\n      <td>2.029321</td>\n      <td>3.9016</td>\n      <td>0.990099</td>\n      <td>2.055711</td>\n      <td>3.4263</td>\n      <td>1.680672</td>\n      <td>2.232079</td>\n      <td>3.3123</td>\n      <td>1.694915</td>\n      <td>3.248493</td>\n      <td>3.9016</td>\n      <td>1.538462</td>\n      <td>105.899232</td>\n      <td>2.666218</td>\n      <td>2.284620</td>\n      <td>0.693450</td>\n      <td>2.876936</td>\n      <td>3.023678</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    108887.000000\nmean       1996.781535\nstd           0.968163\nmin        1995.000000\n25%        1996.000000\n50%        1997.000000\n75%        1998.000000\nmax        1998.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          108887\nprd             108887\nmom482           87758\nmom242          106704\nyear            108887\nRET             108887\nind             108887\nbm              108887\nop              108887\ngp              108887\ninv             108790\nmom11           108887\nmom122          108887\namhd             95617\nivol_capm       108881\nivol_ff5        108881\nbeta_bw         108887\nMAX             108887\nvol1m           108877\nvol6m           108802\nvol12m          108644\nBAspr           105438\nsize            108887\nlbm             108887\nlop             108887\nlgp             108887\nlinv            108887\nllme            108887\nl1amhd           95533\nl1MAX           108883\nl1BAspr         105560\nl3amhd           95274\nl3MAX           108865\nl3BAspr         105775\nl6amhd           94783\nl6MAX           108849\nl6BAspr         105924\nl12amhd          94024\nl12MAX          108883\nl12BAspr        106224\nl12mom122       108559\nl12ivol_capm    108798\nl12ivol_ff5     108798\nl12beta_bw      108824\nl12vol6m        108644\nl12vol12m       107074\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (102533, 44)\ntime to do feature proprocessing: \nNumber of features after transformation:  (102533, 92)\nmae of a constant model 10.140774622556364\nR2 of a constant model 0.0\nXGB train: 9.659322244479393 0.07092865382863278\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.2s\nXGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.009563420614281892 50.995766162872314\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:02:08,509]\u001b[0m A new study created in memory with name: no-name-ed33f6a0-9fda-4cdc-9602-60d897324a9c\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 9.832710286259864 0.02838988710259338 52.64358353614807\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:02:13,441]\u001b[0m Trial 0 finished with value: 0.00979115834059853 and parameters: {'n_estimators': 865, 'max_depth': 2, 'learning_rate': 0.023065710668784666, 'colsample_bytree': 0.6976659977019947, 'subsample': 0.6651324375532808, 'alpha': 0.5589226950553211, 'lambda': 0.14365537125435116, 'gamma': 2.0891348309890828e-05, 'min_child_weight': 2.2317107767158255}. Best is trial 0 with value: 0.00979115834059853.\u001b[0m\n\u001b[32m[I 2022-08-25 21:02:22,970]\u001b[0m Trial 1 finished with value: -0.010728277805102916 and parameters: {'n_estimators': 773, 'max_depth': 5, 'learning_rate': 0.0396561082687114, 'colsample_bytree': 0.7008145627161387, 'subsample': 0.5738330908133162, 'alpha': 3.731904248586211, 'lambda': 69.85233544992262, 'gamma': 0.4173643551843362, 'min_child_weight': 0.39570301870778596}. Best is trial 0 with value: 0.00979115834059853.\u001b[0m\n\u001b[32m[I 2022-08-25 21:02:31,936]\u001b[0m Trial 2 finished with value: -0.01438942884426983 and parameters: {'n_estimators': 771, 'max_depth': 5, 'learning_rate': 0.0394898539614269, 'colsample_bytree': 0.4502587748625898, 'subsample': 0.7900929597744242, 'alpha': 0.7936954875617113, 'lambda': 3.9414928340529425, 'gamma': 0.00011990081506057326, 'min_child_weight': 0.3555264379087119}. Best is trial 0 with value: 0.00979115834059853.\u001b[0m\n\u001b[32m[I 2022-08-25 21:02:35,427]\u001b[0m Trial 3 finished with value: 0.009335423517923505 and parameters: {'n_estimators': 595, 'max_depth': 2, 'learning_rate': 0.025576586986391515, 'colsample_bytree': 0.5043635655166238, 'subsample': 0.4979779600223623, 'alpha': 0.3894193575975183, 'lambda': 2.2626441915749513, 'gamma': 1.899986276979328e-06, 'min_child_weight': 0.6020477107168832}. Best is trial 0 with value: 0.00979115834059853.\u001b[0m\n\u001b[32m[I 2022-08-25 21:02:39,839]\u001b[0m Trial 4 finished with value: 0.00506894175879866 and parameters: {'n_estimators': 645, 'max_depth': 3, 'learning_rate': 0.04472334185308501, 'colsample_bytree': 0.48222483346651923, 'subsample': 0.3790107320866787, 'alpha': 0.21114867133135964, 'lambda': 17.411718147943425, 'gamma': 4.023653606220752e-07, 'min_child_weight': 0.7467416335752736}. Best is trial 0 with value: 0.00979115834059853.\u001b[0m\n\u001b[32m[I 2022-08-25 21:02:44,569]\u001b[0m Trial 5 finished with value: 0.0056334792969010014 and parameters: {'n_estimators': 847, 'max_depth': 2, 'learning_rate': 0.04919574038903176, 'colsample_bytree': 0.9378533984585388, 'subsample': 0.34916538858592844, 'alpha': 12.837468616350346, 'lambda': 1.9126307528777917, 'gamma': 8.493225922275254e-07, 'min_child_weight': 1.0138436946920946}. Best is trial 0 with value: 0.00979115834059853.\u001b[0m\n\u001b[32m[I 2022-08-25 21:02:49,329]\u001b[0m Trial 6 finished with value: 0.009444164219533228 and parameters: {'n_estimators': 916, 'max_depth': 2, 'learning_rate': 0.016096465854917516, 'colsample_bytree': 0.14136480549778965, 'subsample': 0.7456177081554114, 'alpha': 14.519359582709484, 'lambda': 2.885000654331083, 'gamma': 1.5544667965634191e-09, 'min_child_weight': 15.21438497884579}. Best is trial 0 with value: 0.00979115834059853.\u001b[0m\n\u001b[32m[I 2022-08-25 21:02:53,345]\u001b[0m Trial 7 finished with value: 0.009725333147728096 and parameters: {'n_estimators': 567, 'max_depth': 3, 'learning_rate': 0.018690448682913738, 'colsample_bytree': 0.7802085092509679, 'subsample': 0.8709222241669332, 'alpha': 0.817569136337732, 'lambda': 25.658650251355947, 'gamma': 4.675987254584746e-10, 'min_child_weight': 32.401096608368206}. Best is trial 0 with value: 0.00979115834059853.\u001b[0m\n\u001b[32m[I 2022-08-25 21:03:06,155]\u001b[0m Trial 8 finished with value: -0.006768053276696576 and parameters: {'n_estimators': 989, 'max_depth': 5, 'learning_rate': 0.022822767781987677, 'colsample_bytree': 0.8163157914441664, 'subsample': 0.8328954411931211, 'alpha': 0.6936962649013834, 'lambda': 1.9551650195770192, 'gamma': 0.0003564470734957435, 'min_child_weight': 0.20303747545919537}. Best is trial 0 with value: 0.00979115834059853.\u001b[0m\n\u001b[32m[I 2022-08-25 21:03:13,066]\u001b[0m Trial 9 finished with value: 0.008221977326427616 and parameters: {'n_estimators': 579, 'max_depth': 5, 'learning_rate': 0.0033438571592697337, 'colsample_bytree': 0.44891341728657486, 'subsample': 0.5687467910931968, 'alpha': 0.49182578604603433, 'lambda': 0.30058063424705506, 'gamma': 5.132546470536457e-08, 'min_child_weight': 0.5434020966623779}. Best is trial 0 with value: 0.00979115834059853.\u001b[0m\n\u001b[32m[I 2022-08-25 21:03:18,962]\u001b[0m Trial 10 finished with value: 0.0012622797654820972 and parameters: {'n_estimators': 691, 'max_depth': 4, 'learning_rate': 0.03038825408364016, 'colsample_bytree': 0.2740178510877425, 'subsample': 0.6938254039686108, 'alpha': 0.12329515855696993, 'lambda': 0.11402373837882238, 'gamma': 1.3499362192188409, 'min_child_weight': 5.121669813129131}. Best is trial 0 with value: 0.00979115834059853.\u001b[0m\n\u001b[32m[I 2022-08-25 21:03:22,709]\u001b[0m Trial 11 finished with value: 0.010134503783837628 and parameters: {'n_estimators': 515, 'max_depth': 3, 'learning_rate': 0.01199035266083901, 'colsample_bytree': 0.6553947287444576, 'subsample': 0.9356634579205897, 'alpha': 2.6608125471626014, 'lambda': 188.4389223511214, 'gamma': 0.007752820689652725, 'min_child_weight': 23.036406222029186}. Best is trial 11 with value: 0.010134503783837628.\u001b[0m\n\u001b[32m[I 2022-08-25 21:03:26,484]\u001b[0m Trial 12 finished with value: 0.009106140419727845 and parameters: {'n_estimators': 519, 'max_depth': 3, 'learning_rate': 0.007513639789608285, 'colsample_bytree': 0.665653305284111, 'subsample': 0.8896349747998827, 'alpha': 3.0211799273589346, 'lambda': 0.3248116173246768, 'gamma': 0.006804828609115584, 'min_child_weight': 4.301391977634955}. Best is trial 11 with value: 0.010134503783837628.\u001b[0m\n\u001b[32m[I 2022-08-25 21:03:33,916]\u001b[0m Trial 13 finished with value: 0.008607099148617691 and parameters: {'n_estimators': 848, 'max_depth': 4, 'learning_rate': 0.011963343218655047, 'colsample_bytree': 0.6483347266535727, 'subsample': 0.9414138670449324, 'alpha': 2.7727390623412647, 'lambda': 133.00308468312937, 'gamma': 0.01444371047827296, 'min_child_weight': 2.4766047623505987}. Best is trial 11 with value: 0.010134503783837628.\u001b[0m\n\u001b[32m[I 2022-08-25 21:03:37,800]\u001b[0m Trial 14 finished with value: 0.00988521126253392 and parameters: {'n_estimators': 701, 'max_depth': 2, 'learning_rate': 0.02918240209631346, 'colsample_bytree': 0.607124019659173, 'subsample': 0.6906454572508169, 'alpha': 1.6025729739841745, 'lambda': 13.046494330665997, 'gamma': 0.00313746707993321, 'min_child_weight': 11.057534037763881}. Best is trial 11 with value: 0.010134503783837628.\u001b[0m\n\u001b[32m[I 2022-08-25 21:03:42,616]\u001b[0m Trial 15 finished with value: 0.007663543452395805 and parameters: {'n_estimators': 694, 'max_depth': 3, 'learning_rate': 0.030657621737111222, 'colsample_bytree': 0.6022164961735125, 'subsample': 0.7537033954638482, 'alpha': 1.5628831998284225, 'lambda': 13.167011769731856, 'gamma': 0.02533702836062896, 'min_child_weight': 46.31473940288682}. Best is trial 11 with value: 0.010134503783837628.\u001b[0m\n\u001b[32m[I 2022-08-25 21:03:47,343]\u001b[0m Trial 16 finished with value: 0.006448916754391002 and parameters: {'n_estimators': 505, 'max_depth': 4, 'learning_rate': 0.03299033116316441, 'colsample_bytree': 0.8546032699463719, 'subsample': 0.4729915022447718, 'alpha': 7.127217900854694, 'lambda': 184.79180285502258, 'gamma': 7.659694591371178, 'min_child_weight': 17.059374458679216}. Best is trial 11 with value: 0.010134503783837628.\u001b[0m\n\u001b[32m[I 2022-08-25 21:03:51,259]\u001b[0m Trial 17 finished with value: 0.009250389569062312 and parameters: {'n_estimators': 658, 'max_depth': 2, 'learning_rate': 0.013468444724411765, 'colsample_bytree': 0.346925187525494, 'subsample': 0.9461851188611461, 'alpha': 26.477299760273066, 'lambda': 44.45479871549152, 'gamma': 0.0012285849339451595, 'min_child_weight': 10.67611250790153}. Best is trial 11 with value: 0.010134503783837628.\u001b[0m\n\u001b[32m[I 2022-08-25 21:03:56,173]\u001b[0m Trial 18 finished with value: 0.010214535970146946 and parameters: {'n_estimators': 733, 'max_depth': 3, 'learning_rate': 0.008268722836425688, 'colsample_bytree': 0.34251300952544905, 'subsample': 0.6220085981026944, 'alpha': 1.4632707328387815, 'lambda': 7.527001248509026, 'gamma': 0.1684758109865483, 'min_child_weight': 7.547306535443816}. Best is trial 18 with value: 0.010214535970146946.\u001b[0m\n\u001b[32m[I 2022-08-25 21:04:02,562]\u001b[0m Trial 19 finished with value: 0.008483840848966414 and parameters: {'n_estimators': 967, 'max_depth': 3, 'learning_rate': 0.003246233067595412, 'colsample_bytree': 0.3280211828404601, 'subsample': 0.6071843090816352, 'alpha': 5.231888639108838, 'lambda': 0.6959836588342136, 'gamma': 0.16303658547450572, 'min_child_weight': 25.148851118778044}. Best is trial 18 with value: 0.010214535970146946.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  114.0547513961792\n        n_estimators : 733\n           max_depth : 3\n       learning_rate : 0.008268722836425688\n    colsample_bytree : 0.34251300952544905\n           subsample : 0.6220085981026944\n               alpha : 1.4632707328387815\n              lambda : 7.527001248509026\n               gamma : 0.1684758109865483\n    min_child_weight : 7.547306535443816\nbest objective value : 0.010214535970146946\nOptuna XGB train: 9.862107081799374 0.020109116383312253 117.08282375335693\nMin_prd:  450\nConstant guess:  13.5583345263632 0.0\nXGB test: 13.366165935209699 0.01283646666221916\nXGB GS test: 13.402638448397843 0.009184515519970238\nOptuna XGB test: 13.41197447194481 0.00815673566504127\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(105719, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd     mom482     mom242  year     RET   ind        bm  \\\n375   10011  474  26.008669 -25.175669  1997  4.3137  34.0 -0.605004   \n376   10011  475  23.676379 -20.179582  1997  1.3049  34.0 -0.605004   \n377   10011  476  33.362887 -18.402128  1997  2.8533  34.0 -0.605004   \n378   10011  477  34.705872 -17.296715  1998  2.2582  34.0 -0.605004   \n607   10016  474  -9.740970  14.793497  1997 -9.7420  21.0 -0.791018   \n\n           op        gp       inv   mom11     mom122      amhd  ivol_capm  \\\n375  0.142080  0.464046  0.800300 -3.8686 -19.026681  2.047956   1.217840   \n376  0.142080  0.464046  0.800300  4.3137  -7.383117  2.008437   4.749040   \n377  0.142080  0.464046  0.800300  1.3049   0.489275  1.989774   0.918331   \n378  0.142080  0.464046  0.800300  2.8533  16.164007  1.928822   0.899183   \n607  0.072323  0.295900  0.014439  4.9171  -0.607002  1.665406   1.261913   \n\n     ivol_ff5   beta_bw      MAX     vol1m     vol6m    vol12m     BAspr  \\\n375  1.214213  0.513672   2.2136  1.234739  2.129959  2.396758  1.176471   \n376  4.067699  0.506943  20.2132  4.991303  2.652903  2.687620  1.675978   \n377  0.857661  0.504465   1.6739  1.096745  2.366091  2.661125  0.534759   \n378  0.704377  0.528401   3.8669  0.866870  2.303914  2.488976  0.537634   \n607  1.176158  0.581543   3.0901  1.264878  1.758746  2.025960  0.416667   \n\n         size       lbm       lop       lgp      linv      llme    l1amhd  \\\n375  4.412075 -1.885951  0.250310  0.753169  0.766547  4.607743  2.012275   \n376  4.458326 -1.885951  0.250310  0.753169  0.766547  4.438922  2.047956   \n377  4.491021 -1.885951  0.250310  0.753169  0.766547  4.405243  2.008437   \n378  4.523811 -1.885951  0.250310  0.753169  0.766547  4.278491  1.989774   \n607  5.310389 -1.049362 -0.000786  0.269403 -0.230583  5.210249  1.772101   \n\n       l1MAX   l1BAspr    l3amhd   l3MAX   l3BAspr    l6amhd   l6MAX  \\\n375   3.5094  2.824859  2.016314  3.2787  2.127660  1.831441  8.4297   \n376   2.2136  1.176471  2.006440  2.8381  2.298851  2.009115  9.0709   \n377  20.2132  1.675978  2.012275  3.5094  2.824859  2.051244  8.2123   \n378   1.6739  0.534759  2.047956  2.2136  1.176471  2.016314  3.2787   \n607   1.7982  1.785714  1.863802  4.8364  1.801802  1.744671  2.5832   \n\n      l6BAspr   l12amhd   l12MAX  l12BAspr  l12mom122  l12ivol_capm  \\\n375  2.941176  1.530987   3.5094  1.923077 -18.211667      1.110868   \n376  2.097902  1.626085   2.2136  3.333333 -10.711172      2.210422   \n377  2.247191  1.703041  20.2132  2.380952 -17.068809      1.792200   \n378  2.127660  1.771183   1.6739  2.816901 -14.734834      3.190956   \n607  2.040816  1.802498   1.7982  2.830189  -2.871914      1.078966   \n\n     l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n375     0.961548    0.646142  2.599593   2.582935  \n376     2.152782    0.639891  2.612252   2.373065  \n377     1.420329    0.639312  2.095041   2.374053  \n378     3.166502    0.520025  2.248575   2.392976  \n607     0.990447    0.500919  2.088419   2.299801  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>375</th>\n      <td>10011</td>\n      <td>474</td>\n      <td>26.008669</td>\n      <td>-25.175669</td>\n      <td>1997</td>\n      <td>4.3137</td>\n      <td>34.0</td>\n      <td>-0.605004</td>\n      <td>0.142080</td>\n      <td>0.464046</td>\n      <td>0.800300</td>\n      <td>-3.8686</td>\n      <td>-19.026681</td>\n      <td>2.047956</td>\n      <td>1.217840</td>\n      <td>1.214213</td>\n      <td>0.513672</td>\n      <td>2.2136</td>\n      <td>1.234739</td>\n      <td>2.129959</td>\n      <td>2.396758</td>\n      <td>1.176471</td>\n      <td>4.412075</td>\n      <td>-1.885951</td>\n      <td>0.250310</td>\n      <td>0.753169</td>\n      <td>0.766547</td>\n      <td>4.607743</td>\n      <td>2.012275</td>\n      <td>3.5094</td>\n      <td>2.824859</td>\n      <td>2.016314</td>\n      <td>3.2787</td>\n      <td>2.127660</td>\n      <td>1.831441</td>\n      <td>8.4297</td>\n      <td>2.941176</td>\n      <td>1.530987</td>\n      <td>3.5094</td>\n      <td>1.923077</td>\n      <td>-18.211667</td>\n      <td>1.110868</td>\n      <td>0.961548</td>\n      <td>0.646142</td>\n      <td>2.599593</td>\n      <td>2.582935</td>\n    </tr>\n    <tr>\n      <th>376</th>\n      <td>10011</td>\n      <td>475</td>\n      <td>23.676379</td>\n      <td>-20.179582</td>\n      <td>1997</td>\n      <td>1.3049</td>\n      <td>34.0</td>\n      <td>-0.605004</td>\n      <td>0.142080</td>\n      <td>0.464046</td>\n      <td>0.800300</td>\n      <td>4.3137</td>\n      <td>-7.383117</td>\n      <td>2.008437</td>\n      <td>4.749040</td>\n      <td>4.067699</td>\n      <td>0.506943</td>\n      <td>20.2132</td>\n      <td>4.991303</td>\n      <td>2.652903</td>\n      <td>2.687620</td>\n      <td>1.675978</td>\n      <td>4.458326</td>\n      <td>-1.885951</td>\n      <td>0.250310</td>\n      <td>0.753169</td>\n      <td>0.766547</td>\n      <td>4.438922</td>\n      <td>2.047956</td>\n      <td>2.2136</td>\n      <td>1.176471</td>\n      <td>2.006440</td>\n      <td>2.8381</td>\n      <td>2.298851</td>\n      <td>2.009115</td>\n      <td>9.0709</td>\n      <td>2.097902</td>\n      <td>1.626085</td>\n      <td>2.2136</td>\n      <td>3.333333</td>\n      <td>-10.711172</td>\n      <td>2.210422</td>\n      <td>2.152782</td>\n      <td>0.639891</td>\n      <td>2.612252</td>\n      <td>2.373065</td>\n    </tr>\n    <tr>\n      <th>377</th>\n      <td>10011</td>\n      <td>476</td>\n      <td>33.362887</td>\n      <td>-18.402128</td>\n      <td>1997</td>\n      <td>2.8533</td>\n      <td>34.0</td>\n      <td>-0.605004</td>\n      <td>0.142080</td>\n      <td>0.464046</td>\n      <td>0.800300</td>\n      <td>1.3049</td>\n      <td>0.489275</td>\n      <td>1.989774</td>\n      <td>0.918331</td>\n      <td>0.857661</td>\n      <td>0.504465</td>\n      <td>1.6739</td>\n      <td>1.096745</td>\n      <td>2.366091</td>\n      <td>2.661125</td>\n      <td>0.534759</td>\n      <td>4.491021</td>\n      <td>-1.885951</td>\n      <td>0.250310</td>\n      <td>0.753169</td>\n      <td>0.766547</td>\n      <td>4.405243</td>\n      <td>2.008437</td>\n      <td>20.2132</td>\n      <td>1.675978</td>\n      <td>2.012275</td>\n      <td>3.5094</td>\n      <td>2.824859</td>\n      <td>2.051244</td>\n      <td>8.2123</td>\n      <td>2.247191</td>\n      <td>1.703041</td>\n      <td>20.2132</td>\n      <td>2.380952</td>\n      <td>-17.068809</td>\n      <td>1.792200</td>\n      <td>1.420329</td>\n      <td>0.639312</td>\n      <td>2.095041</td>\n      <td>2.374053</td>\n    </tr>\n    <tr>\n      <th>378</th>\n      <td>10011</td>\n      <td>477</td>\n      <td>34.705872</td>\n      <td>-17.296715</td>\n      <td>1998</td>\n      <td>2.2582</td>\n      <td>34.0</td>\n      <td>-0.605004</td>\n      <td>0.142080</td>\n      <td>0.464046</td>\n      <td>0.800300</td>\n      <td>2.8533</td>\n      <td>16.164007</td>\n      <td>1.928822</td>\n      <td>0.899183</td>\n      <td>0.704377</td>\n      <td>0.528401</td>\n      <td>3.8669</td>\n      <td>0.866870</td>\n      <td>2.303914</td>\n      <td>2.488976</td>\n      <td>0.537634</td>\n      <td>4.523811</td>\n      <td>-1.885951</td>\n      <td>0.250310</td>\n      <td>0.753169</td>\n      <td>0.766547</td>\n      <td>4.278491</td>\n      <td>1.989774</td>\n      <td>1.6739</td>\n      <td>0.534759</td>\n      <td>2.047956</td>\n      <td>2.2136</td>\n      <td>1.176471</td>\n      <td>2.016314</td>\n      <td>3.2787</td>\n      <td>2.127660</td>\n      <td>1.771183</td>\n      <td>1.6739</td>\n      <td>2.816901</td>\n      <td>-14.734834</td>\n      <td>3.190956</td>\n      <td>3.166502</td>\n      <td>0.520025</td>\n      <td>2.248575</td>\n      <td>2.392976</td>\n    </tr>\n    <tr>\n      <th>607</th>\n      <td>10016</td>\n      <td>474</td>\n      <td>-9.740970</td>\n      <td>14.793497</td>\n      <td>1997</td>\n      <td>-9.7420</td>\n      <td>21.0</td>\n      <td>-0.791018</td>\n      <td>0.072323</td>\n      <td>0.295900</td>\n      <td>0.014439</td>\n      <td>4.9171</td>\n      <td>-0.607002</td>\n      <td>1.665406</td>\n      <td>1.261913</td>\n      <td>1.176158</td>\n      <td>0.581543</td>\n      <td>3.0901</td>\n      <td>1.264878</td>\n      <td>1.758746</td>\n      <td>2.025960</td>\n      <td>0.416667</td>\n      <td>5.310389</td>\n      <td>-1.049362</td>\n      <td>-0.000786</td>\n      <td>0.269403</td>\n      <td>-0.230583</td>\n      <td>5.210249</td>\n      <td>1.772101</td>\n      <td>1.7982</td>\n      <td>1.785714</td>\n      <td>1.863802</td>\n      <td>4.8364</td>\n      <td>1.801802</td>\n      <td>1.744671</td>\n      <td>2.5832</td>\n      <td>2.040816</td>\n      <td>1.802498</td>\n      <td>1.7982</td>\n      <td>2.830189</td>\n      <td>-2.871914</td>\n      <td>1.078966</td>\n      <td>0.990447</td>\n      <td>0.500919</td>\n      <td>2.088419</td>\n      <td>2.299801</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    105719.000000\nmean       1998.813175\nstd           0.951883\nmin        1997.000000\n25%        1998.000000\n50%        1999.000000\n75%        2000.000000\nmax        2000.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          105719\nprd             105719\nmom482           85412\nmom242          103700\nyear            105719\nRET             105719\nind             105719\nbm              105719\nop              105719\ngp              105719\ninv             105654\nmom11           105719\nmom122          105719\namhd             95259\nivol_capm       105718\nivol_ff5        105718\nbeta_bw         105719\nMAX             105719\nvol1m           105716\nvol6m           105677\nvol12m          105605\nBAspr            99273\nsize            105719\nlbm             105719\nlop             105719\nlgp             105719\nlinv            105719\nllme            105719\nl1amhd           95253\nl1MAX           105717\nl1BAspr          99691\nl3amhd           95191\nl3MAX           105708\nl3BAspr         100442\nl6amhd           95088\nl6MAX           105707\nl6BAspr         100452\nl12amhd          94895\nl12MAX          105717\nl12BAspr        101260\nl12mom122       105606\nl12ivol_capm    105695\nl12ivol_ff5     105695\nl12beta_bw      105714\nl12vol6m        105613\nl12vol12m       104232\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (99209, 44)\ntime to do feature proprocessing: \nNumber of features after transformation:  (99209, 92)\nmae of a constant model 12.065001504034083\nR2 of a constant model 0.0\nXGB train: 11.542158028170723 0.0683018951190858\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\nXGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.010701878300891088 50.58634114265442\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:05:02,155]\u001b[0m A new study created in memory with name: no-name-7805a597-b972-4875-9d7d-c610c9c89fc5\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 11.757632120495467 0.027636870661727486 52.19143843650818\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:05:08,683]\u001b[0m Trial 0 finished with value: 0.009766068295833298 and parameters: {'n_estimators': 518, 'max_depth': 5, 'learning_rate': 0.01861593342147072, 'colsample_bytree': 0.2323609184215765, 'subsample': 0.564220068794236, 'alpha': 0.25878484424939097, 'lambda': 9.389710674326418, 'gamma': 0.008952725288914299, 'min_child_weight': 0.2947546649591775}. Best is trial 0 with value: 0.009766068295833298.\u001b[0m\n\u001b[32m[I 2022-08-25 21:05:16,137]\u001b[0m Trial 1 finished with value: 0.011936011435644519 and parameters: {'n_estimators': 894, 'max_depth': 4, 'learning_rate': 0.008537321954931943, 'colsample_bytree': 0.2930143447949545, 'subsample': 0.7692188977885224, 'alpha': 0.11172280910297488, 'lambda': 52.891288887538195, 'gamma': 3.128679408045531e-09, 'min_child_weight': 0.47247711184827795}. Best is trial 1 with value: 0.011936011435644519.\u001b[0m\n\u001b[32m[I 2022-08-25 21:05:24,707]\u001b[0m Trial 2 finished with value: 0.011503219607737801 and parameters: {'n_estimators': 737, 'max_depth': 5, 'learning_rate': 0.010899740731237045, 'colsample_bytree': 0.3554626056021156, 'subsample': 0.4248063432561547, 'alpha': 0.41090191176238106, 'lambda': 11.07122800548652, 'gamma': 2.4696976075688654e-10, 'min_child_weight': 3.8208998138498016}. Best is trial 1 with value: 0.011936011435644519.\u001b[0m\n\u001b[32m[I 2022-08-25 21:05:28,109]\u001b[0m Trial 3 finished with value: 0.01058818445582232 and parameters: {'n_estimators': 609, 'max_depth': 2, 'learning_rate': 0.016539900957432702, 'colsample_bytree': 0.28831126472311375, 'subsample': 0.6343205513632633, 'alpha': 1.4339889420450054, 'lambda': 52.21628161754333, 'gamma': 6.613296003699566e-09, 'min_child_weight': 0.9942061730390407}. Best is trial 1 with value: 0.011936011435644519.\u001b[0m\n\u001b[32m[I 2022-08-25 21:05:34,592]\u001b[0m Trial 4 finished with value: 0.0019957637822836443 and parameters: {'n_estimators': 501, 'max_depth': 5, 'learning_rate': 0.030003928878236906, 'colsample_bytree': 0.7942224419005317, 'subsample': 0.9262823989284474, 'alpha': 8.028798023470115, 'lambda': 0.4819896771620577, 'gamma': 1.7207327259775294e-07, 'min_child_weight': 0.1467354200680515}. Best is trial 1 with value: 0.011936011435644519.\u001b[0m\n\u001b[32m[I 2022-08-25 21:05:38,493]\u001b[0m Trial 5 finished with value: 0.010770631575716177 and parameters: {'n_estimators': 707, 'max_depth': 2, 'learning_rate': 0.016159637690130055, 'colsample_bytree': 0.9206520080149222, 'subsample': 0.42358673030962973, 'alpha': 0.23813576294035035, 'lambda': 8.907871462631496, 'gamma': 1.4811063815344667e-08, 'min_child_weight': 5.799267319237354}. Best is trial 1 with value: 0.011936011435644519.\u001b[0m\n\u001b[32m[I 2022-08-25 21:05:45,623]\u001b[0m Trial 6 finished with value: -0.00765061731504687 and parameters: {'n_estimators': 560, 'max_depth': 5, 'learning_rate': 0.04817735678986124, 'colsample_bytree': 0.8628236670558492, 'subsample': 0.5472549841711833, 'alpha': 0.19879332993488055, 'lambda': 3.4742971696322535, 'gamma': 0.6739996176732602, 'min_child_weight': 0.267413014304372}. Best is trial 1 with value: 0.011936011435644519.\u001b[0m\n\u001b[32m[I 2022-08-25 21:05:53,416]\u001b[0m Trial 7 finished with value: 0.011141491328760255 and parameters: {'n_estimators': 630, 'max_depth': 5, 'learning_rate': 0.0077941241719067765, 'colsample_bytree': 0.6291640258513166, 'subsample': 0.39482901833105, 'alpha': 23.804253857881278, 'lambda': 0.37247703260819676, 'gamma': 3.192715592023682e-06, 'min_child_weight': 0.6495098188656832}. Best is trial 1 with value: 0.011936011435644519.\u001b[0m\n\u001b[32m[I 2022-08-25 21:06:01,103]\u001b[0m Trial 8 finished with value: 0.005597633153544762 and parameters: {'n_estimators': 685, 'max_depth': 5, 'learning_rate': 0.02617741886092651, 'colsample_bytree': 0.23486952000764488, 'subsample': 0.7774867966391992, 'alpha': 0.15975152672996873, 'lambda': 2.633875500016552, 'gamma': 0.0003717516425393408, 'min_child_weight': 9.594291820416307}. Best is trial 1 with value: 0.011936011435644519.\u001b[0m\n\u001b[32m[I 2022-08-25 21:06:06,348]\u001b[0m Trial 9 finished with value: 0.008257824847673793 and parameters: {'n_estimators': 588, 'max_depth': 4, 'learning_rate': 0.02291123809487099, 'colsample_bytree': 0.3297819642655415, 'subsample': 0.4905976805550427, 'alpha': 1.189196523332589, 'lambda': 0.8749405031172074, 'gamma': 7.000726045236183e-09, 'min_child_weight': 1.335827225962117}. Best is trial 1 with value: 0.011936011435644519.\u001b[0m\n\u001b[32m[I 2022-08-25 21:06:12,679]\u001b[0m Trial 10 finished with value: 0.009682978080639604 and parameters: {'n_estimators': 924, 'max_depth': 3, 'learning_rate': 0.0037111884071067795, 'colsample_bytree': 0.5100219137960402, 'subsample': 0.7241717186619676, 'alpha': 3.994226991917088, 'lambda': 176.53538887985164, 'gamma': 6.8531268080930655e-06, 'min_child_weight': 46.972799042534454}. Best is trial 1 with value: 0.011936011435644519.\u001b[0m\n\u001b[32m[I 2022-08-25 21:06:19,943]\u001b[0m Trial 11 finished with value: 0.006513595966539142 and parameters: {'n_estimators': 845, 'max_depth': 4, 'learning_rate': 0.001232946378823466, 'colsample_bytree': 0.44661599600342367, 'subsample': 0.31602168376038375, 'alpha': 0.5576847212589334, 'lambda': 34.63562743927174, 'gamma': 1.4448554428762135e-10, 'min_child_weight': 3.74755329091776}. Best is trial 1 with value: 0.011936011435644519.\u001b[0m\n\u001b[32m[I 2022-08-25 21:06:26,815]\u001b[0m Trial 12 finished with value: 0.010005033379481986 and parameters: {'n_estimators': 806, 'max_depth': 4, 'learning_rate': 0.009673951770386513, 'colsample_bytree': 0.1191785282135217, 'subsample': 0.8508829912499586, 'alpha': 0.526763712098382, 'lambda': 34.41527781103037, 'gamma': 1.264244920918424e-10, 'min_child_weight': 15.734223368111396}. Best is trial 1 with value: 0.011936011435644519.\u001b[0m\n\u001b[32m[I 2022-08-25 21:06:33,121]\u001b[0m Trial 13 finished with value: 0.009589051460140387 and parameters: {'n_estimators': 995, 'max_depth': 3, 'learning_rate': 0.03322987940084414, 'colsample_bytree': 0.40758010282543183, 'subsample': 0.6892925732557118, 'alpha': 0.12776864802773372, 'lambda': 0.12417385905028813, 'gamma': 1.8183435531575856e-07, 'min_child_weight': 1.949886711321647}. Best is trial 1 with value: 0.011936011435644519.\u001b[0m\n\u001b[32m[I 2022-08-25 21:06:40,425]\u001b[0m Trial 14 finished with value: 0.012965150933984067 and parameters: {'n_estimators': 831, 'max_depth': 4, 'learning_rate': 0.010502156218834937, 'colsample_bytree': 0.6345463422907152, 'subsample': 0.8129198571758328, 'alpha': 0.42710880135067364, 'lambda': 155.01198150902675, 'gamma': 1.3873974842266697e-10, 'min_child_weight': 0.5537201152755507}. Best is trial 14 with value: 0.012965150933984067.\u001b[0m\n\u001b[32m[I 2022-08-25 21:06:46,392]\u001b[0m Trial 15 finished with value: 0.009494384971341495 and parameters: {'n_estimators': 856, 'max_depth': 3, 'learning_rate': 0.039256210730806214, 'colsample_bytree': 0.6388355458266182, 'subsample': 0.8238362400104152, 'alpha': 0.12214587008304875, 'lambda': 188.59666422550657, 'gamma': 0.00015035939291669614, 'min_child_weight': 0.475080526916177}. Best is trial 14 with value: 0.012965150933984067.\u001b[0m\n\u001b[32m[I 2022-08-25 21:06:54,260]\u001b[0m Trial 16 finished with value: 0.010836331275002564 and parameters: {'n_estimators': 918, 'max_depth': 4, 'learning_rate': 0.011650252215992404, 'colsample_bytree': 0.6433679358842548, 'subsample': 0.9498401000909029, 'alpha': 0.7656687231822512, 'lambda': 66.07007232115042, 'gamma': 2.3774402934683168e-07, 'min_child_weight': 0.14017594106807832}. Best is trial 14 with value: 0.012965150933984067.\u001b[0m\n\u001b[32m[I 2022-08-25 21:07:01,311]\u001b[0m Trial 17 finished with value: 0.010794826815078725 and parameters: {'n_estimators': 794, 'max_depth': 4, 'learning_rate': 0.0053052664498459, 'colsample_bytree': 0.7521337827892158, 'subsample': 0.8606253140712072, 'alpha': 3.129014154054689, 'lambda': 114.0348804467665, 'gamma': 2.3965956589317366e-09, 'min_child_weight': 0.5729337252220611}. Best is trial 14 with value: 0.012965150933984067.\u001b[0m\n\u001b[32m[I 2022-08-25 21:07:07,732]\u001b[0m Trial 18 finished with value: 0.011349165528291802 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 0.02192934708007208, 'colsample_bytree': 0.11538472807707026, 'subsample': 0.7400042894550456, 'alpha': 0.10101673787800615, 'lambda': 21.896870552449492, 'gamma': 1.2721967949467918, 'min_child_weight': 0.2687708194968415}. Best is trial 14 with value: 0.012965150933984067.\u001b[0m\n\u001b[32m[I 2022-08-25 21:07:15,951]\u001b[0m Trial 19 finished with value: 0.011983980280283706 and parameters: {'n_estimators': 925, 'max_depth': 4, 'learning_rate': 0.0133894747044184, 'colsample_bytree': 0.5397103343728397, 'subsample': 0.6511390838253079, 'alpha': 0.2970649753869618, 'lambda': 85.94392328533553, 'gamma': 0.006046296312086137, 'min_child_weight': 1.1471955382144519}. Best is trial 14 with value: 0.012965150933984067.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  133.79924774169922\n        n_estimators : 831\n           max_depth : 4\n       learning_rate : 0.010502156218834937\n    colsample_bytree : 0.6345463422907152\n           subsample : 0.8129198571758328\n               alpha : 0.42710880135067364\n              lambda : 155.01198150902675\n               gamma : 1.3873974842266697e-10\n    min_child_weight : 0.5537201152755507\nbest objective value : 0.012965150933984067\nOptuna XGB train: 11.714226808212636 0.034695843641973756 138.6061770915985\nMin_prd:  475\nConstant guess:  13.648124608226308 0.0\nXGB test: 13.493621350849795 0.01653321511831174\nXGB GS test: 13.485694602288772 0.018099312155868463\nOptuna XGB test: 13.4876446904041 0.017724635657002108\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(95298, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd     mom482     mom242  year      RET   ind        bm  \\\n632   10016  499  34.913656  26.266253  1999   8.1926  21.0 -1.693802   \n633   10016  500  48.977513  40.863722  1999  -8.9248  21.0 -1.693802   \n634   10016  501  39.291939  28.261144  2000 -10.3438  21.0 -1.693802   \n635   10016  502   9.334185  17.504460  2000  12.8053  21.0 -1.693802   \n636   10016  503   9.261171  14.471627  2000  -2.4181  21.0 -1.693802   \n\n           op        gp       inv    mom11     mom122      amhd  ivol_capm  \\\n632  0.079165  0.235056 -0.230583  -4.1875  35.573893  1.207979   1.936031   \n633  0.079165  0.235056 -0.230583   8.1926  17.655505  1.219978   2.377887   \n634  0.079165  0.235056 -0.230583  -8.9248  19.780481  1.387478   2.819161   \n635  0.079165  0.235056 -0.230583 -10.3438  10.100040  1.519072   3.586856   \n636  0.079165  0.235056 -0.230583  12.8053   0.593516  1.585015   3.248652   \n\n     ivol_ff5   beta_bw     MAX     vol1m     vol6m    vol12m     BAspr  \\\n632  1.745435  0.388086  5.1903  1.980852  1.943183  1.817426  2.597403   \n633  1.967402  0.380211  4.7298  2.395814  2.129051  1.788896  0.609756   \n634  2.411974  0.368661  5.6404  2.912162  2.388399  1.920660  3.503185   \n635  3.250253  0.499061  6.6691  4.190953  2.769244  2.235977  0.352734   \n636  2.874087  0.514101  6.8621  3.299220  3.038162  2.386511  2.054795   \n\n         size      lbm       lop       lgp      linv      llme    l1amhd  \\\n632  5.827506 -0.92299  0.018059  0.235379 -0.079193  5.228399  1.455754   \n633  5.909571 -0.92299  0.018059  0.235379 -0.079193  5.330182  1.207979   \n634  5.820906 -0.92299  0.018059  0.235379 -0.079193  5.705960  1.219978   \n635  5.716281 -0.92299  0.018059  0.235379 -0.079193  5.700272  1.387478   \n636  5.840578 -0.92299  0.018059  0.235379 -0.079193  5.684946  1.519072   \n\n      l1MAX   l1BAspr    l3amhd   l3MAX   l3BAspr    l6amhd   l6MAX   l6BAspr  \\\n632  5.9423  1.269841  1.588418  4.2677  1.000000  1.682986  2.8806  1.351351   \n633  5.1903  2.597403  1.527171  2.0228  0.986842  1.645530  3.3614  0.657895   \n634  4.7298  0.609756  1.455754  5.9423  1.269841  1.668308  1.9557  0.649351   \n635  5.6404  3.503185  1.207979  5.1903  2.597403  1.588418  4.2677  1.000000   \n636  6.6691  0.352734  1.219978  4.7298  0.609756  1.527171  2.0228  0.986842   \n\n      l12amhd  l12MAX  l12BAspr  l12mom122  l12ivol_capm  l12ivol_ff5  \\\n632  2.093882  5.9423  2.654867 -20.659951      3.366311     3.204773   \n633  2.140377  5.1903  1.239669  -2.757373      2.398036     2.325290   \n634  1.911826  4.7298  1.153846  13.040913      1.523856     1.359584   \n635  1.852761  5.6404  0.784314  19.507886      0.868158     0.806485   \n636  1.817956  6.6691  1.515152  23.556268      1.370183     1.261058   \n\n     l12beta_bw  l12vol6m  l12vol12m  \n632    0.611095  2.517477   2.279780  \n633    0.585464  2.588438   2.334830  \n634    0.601084  2.584622   2.344358  \n635    0.592462  2.562278   2.221828  \n636    0.595658  2.496284   2.125555  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>632</th>\n      <td>10016</td>\n      <td>499</td>\n      <td>34.913656</td>\n      <td>26.266253</td>\n      <td>1999</td>\n      <td>8.1926</td>\n      <td>21.0</td>\n      <td>-1.693802</td>\n      <td>0.079165</td>\n      <td>0.235056</td>\n      <td>-0.230583</td>\n      <td>-4.1875</td>\n      <td>35.573893</td>\n      <td>1.207979</td>\n      <td>1.936031</td>\n      <td>1.745435</td>\n      <td>0.388086</td>\n      <td>5.1903</td>\n      <td>1.980852</td>\n      <td>1.943183</td>\n      <td>1.817426</td>\n      <td>2.597403</td>\n      <td>5.827506</td>\n      <td>-0.92299</td>\n      <td>0.018059</td>\n      <td>0.235379</td>\n      <td>-0.079193</td>\n      <td>5.228399</td>\n      <td>1.455754</td>\n      <td>5.9423</td>\n      <td>1.269841</td>\n      <td>1.588418</td>\n      <td>4.2677</td>\n      <td>1.000000</td>\n      <td>1.682986</td>\n      <td>2.8806</td>\n      <td>1.351351</td>\n      <td>2.093882</td>\n      <td>5.9423</td>\n      <td>2.654867</td>\n      <td>-20.659951</td>\n      <td>3.366311</td>\n      <td>3.204773</td>\n      <td>0.611095</td>\n      <td>2.517477</td>\n      <td>2.279780</td>\n    </tr>\n    <tr>\n      <th>633</th>\n      <td>10016</td>\n      <td>500</td>\n      <td>48.977513</td>\n      <td>40.863722</td>\n      <td>1999</td>\n      <td>-8.9248</td>\n      <td>21.0</td>\n      <td>-1.693802</td>\n      <td>0.079165</td>\n      <td>0.235056</td>\n      <td>-0.230583</td>\n      <td>8.1926</td>\n      <td>17.655505</td>\n      <td>1.219978</td>\n      <td>2.377887</td>\n      <td>1.967402</td>\n      <td>0.380211</td>\n      <td>4.7298</td>\n      <td>2.395814</td>\n      <td>2.129051</td>\n      <td>1.788896</td>\n      <td>0.609756</td>\n      <td>5.909571</td>\n      <td>-0.92299</td>\n      <td>0.018059</td>\n      <td>0.235379</td>\n      <td>-0.079193</td>\n      <td>5.330182</td>\n      <td>1.207979</td>\n      <td>5.1903</td>\n      <td>2.597403</td>\n      <td>1.527171</td>\n      <td>2.0228</td>\n      <td>0.986842</td>\n      <td>1.645530</td>\n      <td>3.3614</td>\n      <td>0.657895</td>\n      <td>2.140377</td>\n      <td>5.1903</td>\n      <td>1.239669</td>\n      <td>-2.757373</td>\n      <td>2.398036</td>\n      <td>2.325290</td>\n      <td>0.585464</td>\n      <td>2.588438</td>\n      <td>2.334830</td>\n    </tr>\n    <tr>\n      <th>634</th>\n      <td>10016</td>\n      <td>501</td>\n      <td>39.291939</td>\n      <td>28.261144</td>\n      <td>2000</td>\n      <td>-10.3438</td>\n      <td>21.0</td>\n      <td>-1.693802</td>\n      <td>0.079165</td>\n      <td>0.235056</td>\n      <td>-0.230583</td>\n      <td>-8.9248</td>\n      <td>19.780481</td>\n      <td>1.387478</td>\n      <td>2.819161</td>\n      <td>2.411974</td>\n      <td>0.368661</td>\n      <td>5.6404</td>\n      <td>2.912162</td>\n      <td>2.388399</td>\n      <td>1.920660</td>\n      <td>3.503185</td>\n      <td>5.820906</td>\n      <td>-0.92299</td>\n      <td>0.018059</td>\n      <td>0.235379</td>\n      <td>-0.079193</td>\n      <td>5.705960</td>\n      <td>1.219978</td>\n      <td>4.7298</td>\n      <td>0.609756</td>\n      <td>1.455754</td>\n      <td>5.9423</td>\n      <td>1.269841</td>\n      <td>1.668308</td>\n      <td>1.9557</td>\n      <td>0.649351</td>\n      <td>1.911826</td>\n      <td>4.7298</td>\n      <td>1.153846</td>\n      <td>13.040913</td>\n      <td>1.523856</td>\n      <td>1.359584</td>\n      <td>0.601084</td>\n      <td>2.584622</td>\n      <td>2.344358</td>\n    </tr>\n    <tr>\n      <th>635</th>\n      <td>10016</td>\n      <td>502</td>\n      <td>9.334185</td>\n      <td>17.504460</td>\n      <td>2000</td>\n      <td>12.8053</td>\n      <td>21.0</td>\n      <td>-1.693802</td>\n      <td>0.079165</td>\n      <td>0.235056</td>\n      <td>-0.230583</td>\n      <td>-10.3438</td>\n      <td>10.100040</td>\n      <td>1.519072</td>\n      <td>3.586856</td>\n      <td>3.250253</td>\n      <td>0.499061</td>\n      <td>6.6691</td>\n      <td>4.190953</td>\n      <td>2.769244</td>\n      <td>2.235977</td>\n      <td>0.352734</td>\n      <td>5.716281</td>\n      <td>-0.92299</td>\n      <td>0.018059</td>\n      <td>0.235379</td>\n      <td>-0.079193</td>\n      <td>5.700272</td>\n      <td>1.387478</td>\n      <td>5.6404</td>\n      <td>3.503185</td>\n      <td>1.207979</td>\n      <td>5.1903</td>\n      <td>2.597403</td>\n      <td>1.588418</td>\n      <td>4.2677</td>\n      <td>1.000000</td>\n      <td>1.852761</td>\n      <td>5.6404</td>\n      <td>0.784314</td>\n      <td>19.507886</td>\n      <td>0.868158</td>\n      <td>0.806485</td>\n      <td>0.592462</td>\n      <td>2.562278</td>\n      <td>2.221828</td>\n    </tr>\n    <tr>\n      <th>636</th>\n      <td>10016</td>\n      <td>503</td>\n      <td>9.261171</td>\n      <td>14.471627</td>\n      <td>2000</td>\n      <td>-2.4181</td>\n      <td>21.0</td>\n      <td>-1.693802</td>\n      <td>0.079165</td>\n      <td>0.235056</td>\n      <td>-0.230583</td>\n      <td>12.8053</td>\n      <td>0.593516</td>\n      <td>1.585015</td>\n      <td>3.248652</td>\n      <td>2.874087</td>\n      <td>0.514101</td>\n      <td>6.8621</td>\n      <td>3.299220</td>\n      <td>3.038162</td>\n      <td>2.386511</td>\n      <td>2.054795</td>\n      <td>5.840578</td>\n      <td>-0.92299</td>\n      <td>0.018059</td>\n      <td>0.235379</td>\n      <td>-0.079193</td>\n      <td>5.684946</td>\n      <td>1.519072</td>\n      <td>6.6691</td>\n      <td>0.352734</td>\n      <td>1.219978</td>\n      <td>4.7298</td>\n      <td>0.609756</td>\n      <td>1.527171</td>\n      <td>2.0228</td>\n      <td>0.986842</td>\n      <td>1.817956</td>\n      <td>6.6691</td>\n      <td>1.515152</td>\n      <td>23.556268</td>\n      <td>1.370183</td>\n      <td>1.261058</td>\n      <td>0.595658</td>\n      <td>2.496284</td>\n      <td>2.125555</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    95298.000000\nmean      2000.896399\nstd          0.960603\nmin       1999.000000\n25%       2000.000000\n50%       2001.000000\n75%       2002.000000\nmax       2003.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          95298\nprd             95298\nmom482          79488\nmom242          93550\nyear            95298\nRET             95298\nind             95298\nbm              95298\nop              95298\ngp              95298\ninv             95207\nmom11           95298\nmom122          95298\namhd            84633\nivol_capm       95293\nivol_ff5        95293\nbeta_bw         95298\nMAX             95298\nvol1m           95292\nvol6m           95206\nvol12m          95083\nBAspr           88082\nsize            95298\nlbm             95298\nlop             95298\nlgp             95298\nlinv            95298\nllme            95298\nl1amhd          84732\nl1MAX           95292\nl1BAspr         87985\nl3amhd          84898\nl3MAX           95262\nl3BAspr         87768\nl6amhd          85145\nl6MAX           95239\nl6BAspr         87471\nl12amhd         85718\nl12MAX          95292\nl12BAspr        87125\nl12mom122       95019\nl12ivol_capm    95189\nl12ivol_ff5     95189\nl12beta_bw      95215\nl12vol6m        95052\nl12vol12m       94193\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (88987, 44)\ntime to do feature proprocessing: \nNumber of features after transformation:  (88987, 92)\nmae of a constant model 12.533797015909979\nR2 of a constant model 0.0\nXGB train: 12.145985945010235 0.08088662998682272\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\nXGB {'colsample_bytree': 0.6, 'eta': 0.02, 'max_depth': 4, 'n_estimators': 400, 'subsample': 0.6} 0.015470467078182781 47.64073872566223\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:08:13,022]\u001b[0m A new study created in memory with name: no-name-7300430d-cded-4cc2-8b50-58905c9cef95\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 12.336848101879724 0.04798811067566022 48.51966881752014\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:08:17,873]\u001b[0m Trial 0 finished with value: 0.015036988860111391 and parameters: {'n_estimators': 899, 'max_depth': 2, 'learning_rate': 0.024564812074828003, 'colsample_bytree': 0.6365721970673731, 'subsample': 0.6924871799801764, 'alpha': 1.025825286496445, 'lambda': 0.6434245081022784, 'gamma': 0.00030781977021990584, 'min_child_weight': 5.646271975687925}. Best is trial 0 with value: 0.015036988860111391.\u001b[0m\n\u001b[32m[I 2022-08-25 21:08:22,623]\u001b[0m Trial 1 finished with value: 0.015103607709707974 and parameters: {'n_estimators': 580, 'max_depth': 4, 'learning_rate': 0.01790495828925795, 'colsample_bytree': 0.457669000640876, 'subsample': 0.4774399150902327, 'alpha': 1.402535820251213, 'lambda': 10.786693056743633, 'gamma': 0.2705482254398916, 'min_child_weight': 0.4918849408409259}. Best is trial 1 with value: 0.015103607709707974.\u001b[0m\n\u001b[32m[I 2022-08-25 21:08:29,627]\u001b[0m Trial 2 finished with value: 0.015455688164812962 and parameters: {'n_estimators': 909, 'max_depth': 4, 'learning_rate': 0.010795766436341874, 'colsample_bytree': 0.260335436864008, 'subsample': 0.8866824354255387, 'alpha': 0.6826640173876517, 'lambda': 177.37043796741003, 'gamma': 4.782867532584065e-07, 'min_child_weight': 23.714188388867928}. Best is trial 2 with value: 0.015455688164812962.\u001b[0m\n\u001b[32m[I 2022-08-25 21:08:37,873]\u001b[0m Trial 3 finished with value: -0.0198767759388795 and parameters: {'n_estimators': 702, 'max_depth': 5, 'learning_rate': 0.04584514017425201, 'colsample_bytree': 0.7218633772070142, 'subsample': 0.3193470328805629, 'alpha': 0.4414424895584618, 'lambda': 0.6084223420382299, 'gamma': 7.555954604788418e-09, 'min_child_weight': 0.9571462759164692}. Best is trial 2 with value: 0.015455688164812962.\u001b[0m\n\u001b[32m[I 2022-08-25 21:08:42,111]\u001b[0m Trial 4 finished with value: 0.014300275979937202 and parameters: {'n_estimators': 845, 'max_depth': 2, 'learning_rate': 0.007495270168219977, 'colsample_bytree': 0.8973948272358664, 'subsample': 0.4072266062233988, 'alpha': 0.3491438904529655, 'lambda': 1.4750438457304638, 'gamma': 1.5797442202911116, 'min_child_weight': 0.8519540861611273}. Best is trial 2 with value: 0.015455688164812962.\u001b[0m\n\u001b[32m[I 2022-08-25 21:08:46,170]\u001b[0m Trial 5 finished with value: 0.014985983536787869 and parameters: {'n_estimators': 647, 'max_depth': 3, 'learning_rate': 0.019010681232984473, 'colsample_bytree': 0.1866393657879104, 'subsample': 0.3197851404080734, 'alpha': 0.21974692304069138, 'lambda': 0.1543115141665304, 'gamma': 8.027447504969942, 'min_child_weight': 3.2704053881885042}. Best is trial 2 with value: 0.015455688164812962.\u001b[0m\n\u001b[32m[I 2022-08-25 21:08:51,182]\u001b[0m Trial 6 finished with value: 0.015767475357697167 and parameters: {'n_estimators': 580, 'max_depth': 4, 'learning_rate': 0.01562806861114117, 'colsample_bytree': 0.31679963027071767, 'subsample': 0.7946207353932981, 'alpha': 8.00308881090627, 'lambda': 144.8971814109253, 'gamma': 0.001812709895596201, 'min_child_weight': 1.498181614334771}. Best is trial 6 with value: 0.015767475357697167.\u001b[0m\n\u001b[32m[I 2022-08-25 21:08:54,617]\u001b[0m Trial 7 finished with value: 0.013675598360724154 and parameters: {'n_estimators': 652, 'max_depth': 2, 'learning_rate': 0.04587437942123426, 'colsample_bytree': 0.7741982685369114, 'subsample': 0.3861192946023877, 'alpha': 0.9047570310503907, 'lambda': 0.10394005175715207, 'gamma': 1.674156179012484e-07, 'min_child_weight': 2.634041990444356}. Best is trial 6 with value: 0.015767475357697167.\u001b[0m\n\u001b[32m[I 2022-08-25 21:09:04,024]\u001b[0m Trial 8 finished with value: 0.012117528222626465 and parameters: {'n_estimators': 794, 'max_depth': 5, 'learning_rate': 0.013364493440844713, 'colsample_bytree': 0.9259564631690919, 'subsample': 0.8006338425152084, 'alpha': 2.0418867435226224, 'lambda': 0.3510393457716808, 'gamma': 0.21345398564514578, 'min_child_weight': 0.2236319146477777}. Best is trial 6 with value: 0.015767475357697167.\u001b[0m\n\u001b[32m[I 2022-08-25 21:09:11,566]\u001b[0m Trial 9 finished with value: -0.0025103989773549093 and parameters: {'n_estimators': 709, 'max_depth': 5, 'learning_rate': 0.04122462378765526, 'colsample_bytree': 0.5054551685795269, 'subsample': 0.7575040933433813, 'alpha': 3.4368131790651613, 'lambda': 0.4316856910247526, 'gamma': 1.7457893433631526e-09, 'min_child_weight': 46.87998012456148}. Best is trial 6 with value: 0.015767475357697167.\u001b[0m\n\u001b[32m[I 2022-08-25 21:09:15,078]\u001b[0m Trial 10 finished with value: 0.009354798505630977 and parameters: {'n_estimators': 532, 'max_depth': 3, 'learning_rate': 0.0026981048902691186, 'colsample_bytree': 0.35201821539060424, 'subsample': 0.5401204091819103, 'alpha': 23.044837612911618, 'lambda': 177.11136953412682, 'gamma': 0.0005045404973219781, 'min_child_weight': 0.12238641400047931}. Best is trial 6 with value: 0.015767475357697167.\u001b[0m\n\u001b[32m[I 2022-08-25 21:09:22,513]\u001b[0m Trial 11 finished with value: 0.0126998554710191 and parameters: {'n_estimators': 942, 'max_depth': 4, 'learning_rate': 0.03028916241477062, 'colsample_bytree': 0.13100256814982003, 'subsample': 0.9303605135943152, 'alpha': 5.867908138205633, 'lambda': 179.3146324052982, 'gamma': 6.6247965701700145e-06, 'min_child_weight': 15.294133805804147}. Best is trial 6 with value: 0.015767475357697167.\u001b[0m\n\u001b[32m[I 2022-08-25 21:09:30,174]\u001b[0m Trial 12 finished with value: 0.01582082156622757 and parameters: {'n_estimators': 998, 'max_depth': 4, 'learning_rate': 0.010418306713864362, 'colsample_bytree': 0.3133044192167022, 'subsample': 0.932849274772066, 'alpha': 0.1010149308831013, 'lambda': 30.586073755056848, 'gamma': 6.280336232691761e-06, 'min_child_weight': 8.749729572829054}. Best is trial 12 with value: 0.01582082156622757.\u001b[0m\n\u001b[32m[I 2022-08-25 21:09:38,126]\u001b[0m Trial 13 finished with value: 0.009711378576610023 and parameters: {'n_estimators': 996, 'max_depth': 4, 'learning_rate': 0.030379051718340086, 'colsample_bytree': 0.3653325096739023, 'subsample': 0.8568183506356435, 'alpha': 0.10175631359744063, 'lambda': 29.037500983204335, 'gamma': 0.004861138643536735, 'min_child_weight': 8.309632142819627}. Best is trial 12 with value: 0.01582082156622757.\u001b[0m\n\u001b[32m[I 2022-08-25 21:09:41,660]\u001b[0m Trial 14 finished with value: 0.008051049797868397 and parameters: {'n_estimators': 507, 'max_depth': 3, 'learning_rate': 0.0019823189138359204, 'colsample_bytree': 0.33284945228800317, 'subsample': 0.6810861175774983, 'alpha': 17.199352123086328, 'lambda': 35.4449805636811, 'gamma': 1.1456624747812703e-05, 'min_child_weight': 1.964217994356615}. Best is trial 12 with value: 0.01582082156622757.\u001b[0m\n\u001b[32m[I 2022-08-25 21:09:47,922]\u001b[0m Trial 15 finished with value: 0.014997972671272468 and parameters: {'n_estimators': 787, 'max_depth': 4, 'learning_rate': 0.020488845783639967, 'colsample_bytree': 0.21178708776321725, 'subsample': 0.9431315008646362, 'alpha': 8.811429278556588, 'lambda': 42.48551896249097, 'gamma': 0.016458376014447235, 'min_child_weight': 8.802001280159404}. Best is trial 12 with value: 0.01582082156622757.\u001b[0m\n\u001b[32m[I 2022-08-25 21:09:51,799]\u001b[0m Trial 16 finished with value: 0.015118309558470062 and parameters: {'n_estimators': 603, 'max_depth': 3, 'learning_rate': 0.011759368598688816, 'colsample_bytree': 0.44347854196855674, 'subsample': 0.8053294524800765, 'alpha': 9.340912879168526, 'lambda': 5.701312354250799, 'gamma': 0.00013696512910726938, 'min_child_weight': 0.9920575732738177}. Best is trial 12 with value: 0.01582082156622757.\u001b[0m\n\u001b[32m[I 2022-08-25 21:10:02,761]\u001b[0m Trial 17 finished with value: 0.0011598148913604632 and parameters: {'n_estimators': 992, 'max_depth': 5, 'learning_rate': 0.03310762331148205, 'colsample_bytree': 0.5768225793835633, 'subsample': 0.6025097093020357, 'alpha': 2.8884389834930677, 'lambda': 68.78907504726136, 'gamma': 7.905187138904747e-07, 'min_child_weight': 4.53209620291069}. Best is trial 12 with value: 0.01582082156622757.\u001b[0m\n\u001b[32m[I 2022-08-25 21:10:09,370]\u001b[0m Trial 18 finished with value: 0.013866770759503566 and parameters: {'n_estimators': 850, 'max_depth': 4, 'learning_rate': 0.007366430159003911, 'colsample_bytree': 0.11273634674208688, 'subsample': 0.7231890799839331, 'alpha': 0.16433375613117415, 'lambda': 13.683926291685912, 'gamma': 1.3106126731762807e-10, 'min_child_weight': 1.5318150445160523}. Best is trial 12 with value: 0.01582082156622757.\u001b[0m\n\u001b[32m[I 2022-08-25 21:10:13,934]\u001b[0m Trial 19 finished with value: 0.015475202446663052 and parameters: {'n_estimators': 744, 'max_depth': 3, 'learning_rate': 0.016128408836031498, 'colsample_bytree': 0.283033403612979, 'subsample': 0.8480893330366869, 'alpha': 4.6714047054352354, 'lambda': 3.1364260875689562, 'gamma': 0.005374848532545634, 'min_child_weight': 0.4108004473775277}. Best is trial 12 with value: 0.01582082156622757.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  120.91310548782349\n        n_estimators : 998\n           max_depth : 4\n       learning_rate : 0.010418306713864362\n    colsample_bytree : 0.3133044192167022\n           subsample : 0.932849274772066\n               alpha : 0.1010149308831013\n              lambda : 30.586073755056848\n               gamma : 6.280336232691761e-06\n    min_child_weight : 8.749729572829054\nbest objective value : 0.01582082156622757\nOptuna XGB train: 12.33544982274985 0.04674926543109492 126.35574221611023\nMin_prd:  500\nConstant guess:  10.208351337073477 0.0\nXGB test: 9.932024684838842 0.0495424404432826\nXGB GS test: 9.903912087752586 0.05459643833826966\nOptuna XGB test: 9.899188038231635 0.055387304196670706\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(88078, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd     mom482     mom242  year      RET   ind        bm  \\\n864   10019  524 -80.628208 -72.706514  2001  64.3237  22.0  0.456985   \n865   10019  525 -80.628208 -72.706514  2002 -36.1720  22.0  0.456985   \n866   10019  526 -80.628208 -72.706514  2002   6.1732  22.0  0.456985   \n867   10019  527 -80.628208 -72.706514  2002  52.7523  22.0  0.456985   \n868   10019  528 -80.628208 -72.706514  2002   2.1971  22.0  0.456985   \n\n           op        gp       inv      mom11     mom122      amhd  ivol_capm  \\\n864  0.024248  0.438549 -0.207652 -18.449600 -61.937195  6.974454   7.874195   \n865  0.024248  0.438549 -0.207652  26.592465 -61.937195  7.029550   7.874195   \n866  0.024248  0.438549 -0.207652 -22.380465 -61.937195  7.242336   7.874195   \n867  0.024248  0.438549 -0.207652   6.173200 -61.937195  7.354029   7.257745   \n868  0.024248  0.438549 -0.207652  26.592465 -61.937195  7.376474   7.874195   \n\n     ivol_ff5   beta_bw        MAX     vol1m     vol6m    vol12m      BAspr  \\\n864  6.946893  0.574234  21.135115  8.239788  7.983689  7.756113   5.555556   \n865  6.946893  0.618013  21.135115  8.239788  7.983689  7.756113   1.904762   \n866  6.946893  0.669389  18.754700  8.239788  7.983689  7.756113   7.500000   \n867  6.191064  0.708928  10.382600  7.253446  7.983689  7.756113  10.526316   \n868  6.946893  0.689922  21.135115  8.239788  7.983689  7.756113   7.547170   \n\n         size       lbm       lop       lgp    linv      llme    l1amhd  \\\n864  1.839648  0.133067  0.095399  0.379546  0.8003  4.416116  6.841097   \n865  2.337228  0.133067  0.095399  0.379546  0.8003  3.878006  6.974454   \n866  1.890441  0.133067  0.095399  0.379546  0.8003  4.290538  7.029550   \n867  1.951566  0.133067  0.095399  0.379546  0.8003  3.921500  7.242336   \n868  2.376064  0.133067  0.095399  0.379546  0.8003  3.900881  7.354029   \n\n         l1MAX    l1BAspr    l3amhd      l3MAX    l3BAspr    l6amhd  \\\n864  13.404600   7.500000  6.246260  14.049500   4.000000  4.172441   \n865  21.135115   5.555556  6.488633  21.135115  11.504425  5.425547   \n866  21.135115   1.904762  6.841097  13.404600   7.500000  6.018584   \n867  18.754700   7.500000  6.974454  21.135115   5.555556  6.246260   \n868  10.382600  10.526316  7.029550  21.135115   1.904762  6.488633   \n\n         l6MAX    l6BAspr   l12amhd     l12MAX  l12BAspr  l12mom122  \\\n864  10.326800   8.108108  4.897832  13.404600  1.910828 -19.751637   \n865  21.135115   7.978723  4.867878  21.135115  6.060606  71.543684   \n866  21.135115   3.846154  4.726778  21.135115  2.597403  12.326471   \n867  14.049500   4.000000  4.422981  18.754700  4.166667  74.308882   \n868  21.135115  11.504425  4.332441  10.382600  2.127660  44.013624   \n\n     l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n864      7.874195     6.946893    0.828611  7.708467   6.632332  \n865      7.537647     6.946893    0.761543  7.983689   6.587764  \n866      7.874195     6.946893    0.798752  7.983689   6.964654  \n867      6.155932     5.038919    0.862209  7.983689   7.048842  \n868      5.082835     3.907795    0.890379  7.983689   7.075186  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>864</th>\n      <td>10019</td>\n      <td>524</td>\n      <td>-80.628208</td>\n      <td>-72.706514</td>\n      <td>2001</td>\n      <td>64.3237</td>\n      <td>22.0</td>\n      <td>0.456985</td>\n      <td>0.024248</td>\n      <td>0.438549</td>\n      <td>-0.207652</td>\n      <td>-18.449600</td>\n      <td>-61.937195</td>\n      <td>6.974454</td>\n      <td>7.874195</td>\n      <td>6.946893</td>\n      <td>0.574234</td>\n      <td>21.135115</td>\n      <td>8.239788</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>5.555556</td>\n      <td>1.839648</td>\n      <td>0.133067</td>\n      <td>0.095399</td>\n      <td>0.379546</td>\n      <td>0.8003</td>\n      <td>4.416116</td>\n      <td>6.841097</td>\n      <td>13.404600</td>\n      <td>7.500000</td>\n      <td>6.246260</td>\n      <td>14.049500</td>\n      <td>4.000000</td>\n      <td>4.172441</td>\n      <td>10.326800</td>\n      <td>8.108108</td>\n      <td>4.897832</td>\n      <td>13.404600</td>\n      <td>1.910828</td>\n      <td>-19.751637</td>\n      <td>7.874195</td>\n      <td>6.946893</td>\n      <td>0.828611</td>\n      <td>7.708467</td>\n      <td>6.632332</td>\n    </tr>\n    <tr>\n      <th>865</th>\n      <td>10019</td>\n      <td>525</td>\n      <td>-80.628208</td>\n      <td>-72.706514</td>\n      <td>2002</td>\n      <td>-36.1720</td>\n      <td>22.0</td>\n      <td>0.456985</td>\n      <td>0.024248</td>\n      <td>0.438549</td>\n      <td>-0.207652</td>\n      <td>26.592465</td>\n      <td>-61.937195</td>\n      <td>7.029550</td>\n      <td>7.874195</td>\n      <td>6.946893</td>\n      <td>0.618013</td>\n      <td>21.135115</td>\n      <td>8.239788</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>1.904762</td>\n      <td>2.337228</td>\n      <td>0.133067</td>\n      <td>0.095399</td>\n      <td>0.379546</td>\n      <td>0.8003</td>\n      <td>3.878006</td>\n      <td>6.974454</td>\n      <td>21.135115</td>\n      <td>5.555556</td>\n      <td>6.488633</td>\n      <td>21.135115</td>\n      <td>11.504425</td>\n      <td>5.425547</td>\n      <td>21.135115</td>\n      <td>7.978723</td>\n      <td>4.867878</td>\n      <td>21.135115</td>\n      <td>6.060606</td>\n      <td>71.543684</td>\n      <td>7.537647</td>\n      <td>6.946893</td>\n      <td>0.761543</td>\n      <td>7.983689</td>\n      <td>6.587764</td>\n    </tr>\n    <tr>\n      <th>866</th>\n      <td>10019</td>\n      <td>526</td>\n      <td>-80.628208</td>\n      <td>-72.706514</td>\n      <td>2002</td>\n      <td>6.1732</td>\n      <td>22.0</td>\n      <td>0.456985</td>\n      <td>0.024248</td>\n      <td>0.438549</td>\n      <td>-0.207652</td>\n      <td>-22.380465</td>\n      <td>-61.937195</td>\n      <td>7.242336</td>\n      <td>7.874195</td>\n      <td>6.946893</td>\n      <td>0.669389</td>\n      <td>18.754700</td>\n      <td>8.239788</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>7.500000</td>\n      <td>1.890441</td>\n      <td>0.133067</td>\n      <td>0.095399</td>\n      <td>0.379546</td>\n      <td>0.8003</td>\n      <td>4.290538</td>\n      <td>7.029550</td>\n      <td>21.135115</td>\n      <td>1.904762</td>\n      <td>6.841097</td>\n      <td>13.404600</td>\n      <td>7.500000</td>\n      <td>6.018584</td>\n      <td>21.135115</td>\n      <td>3.846154</td>\n      <td>4.726778</td>\n      <td>21.135115</td>\n      <td>2.597403</td>\n      <td>12.326471</td>\n      <td>7.874195</td>\n      <td>6.946893</td>\n      <td>0.798752</td>\n      <td>7.983689</td>\n      <td>6.964654</td>\n    </tr>\n    <tr>\n      <th>867</th>\n      <td>10019</td>\n      <td>527</td>\n      <td>-80.628208</td>\n      <td>-72.706514</td>\n      <td>2002</td>\n      <td>52.7523</td>\n      <td>22.0</td>\n      <td>0.456985</td>\n      <td>0.024248</td>\n      <td>0.438549</td>\n      <td>-0.207652</td>\n      <td>6.173200</td>\n      <td>-61.937195</td>\n      <td>7.354029</td>\n      <td>7.257745</td>\n      <td>6.191064</td>\n      <td>0.708928</td>\n      <td>10.382600</td>\n      <td>7.253446</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>10.526316</td>\n      <td>1.951566</td>\n      <td>0.133067</td>\n      <td>0.095399</td>\n      <td>0.379546</td>\n      <td>0.8003</td>\n      <td>3.921500</td>\n      <td>7.242336</td>\n      <td>18.754700</td>\n      <td>7.500000</td>\n      <td>6.974454</td>\n      <td>21.135115</td>\n      <td>5.555556</td>\n      <td>6.246260</td>\n      <td>14.049500</td>\n      <td>4.000000</td>\n      <td>4.422981</td>\n      <td>18.754700</td>\n      <td>4.166667</td>\n      <td>74.308882</td>\n      <td>6.155932</td>\n      <td>5.038919</td>\n      <td>0.862209</td>\n      <td>7.983689</td>\n      <td>7.048842</td>\n    </tr>\n    <tr>\n      <th>868</th>\n      <td>10019</td>\n      <td>528</td>\n      <td>-80.628208</td>\n      <td>-72.706514</td>\n      <td>2002</td>\n      <td>2.1971</td>\n      <td>22.0</td>\n      <td>0.456985</td>\n      <td>0.024248</td>\n      <td>0.438549</td>\n      <td>-0.207652</td>\n      <td>26.592465</td>\n      <td>-61.937195</td>\n      <td>7.376474</td>\n      <td>7.874195</td>\n      <td>6.946893</td>\n      <td>0.689922</td>\n      <td>21.135115</td>\n      <td>8.239788</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>7.547170</td>\n      <td>2.376064</td>\n      <td>0.133067</td>\n      <td>0.095399</td>\n      <td>0.379546</td>\n      <td>0.8003</td>\n      <td>3.900881</td>\n      <td>7.354029</td>\n      <td>10.382600</td>\n      <td>10.526316</td>\n      <td>7.029550</td>\n      <td>21.135115</td>\n      <td>1.904762</td>\n      <td>6.488633</td>\n      <td>21.135115</td>\n      <td>11.504425</td>\n      <td>4.332441</td>\n      <td>10.382600</td>\n      <td>2.127660</td>\n      <td>44.013624</td>\n      <td>5.082835</td>\n      <td>3.907795</td>\n      <td>0.890379</td>\n      <td>7.983689</td>\n      <td>7.075186</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    88078.000000\nmean      2003.040771\nstd          0.961813\nmin       2001.000000\n25%       2002.000000\n50%       2003.000000\n75%       2004.000000\nmax       2005.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          88078\nprd             88078\nmom482          76756\nmom242          86597\nyear            88078\nRET             88078\nind             88078\nbm              88078\nop              88078\ngp              88078\ninv             88013\nmom11           88078\nmom122          88078\namhd            79370\nivol_capm       88076\nivol_ff5        88076\nbeta_bw         88078\nMAX             88078\nvol1m           88074\nvol6m           87967\nvol12m          87795\nBAspr           85032\nsize            88078\nlbm             88078\nlop             88078\nlgp             88078\nlinv            88078\nllme            88078\nl1amhd          79247\nl1MAX           88074\nl1BAspr         85139\nl3amhd          79005\nl3MAX           88047\nl3BAspr         85303\nl6amhd          78778\nl6MAX           88017\nl6BAspr         85524\nl12amhd         78656\nl12MAX          88074\nl12BAspr        82548\nl12mom122       87808\nl12ivol_capm    87955\nl12ivol_ff5     87955\nl12beta_bw      87988\nl12vol6m        87793\nl12vol12m       87073\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (82903, 44)\ntime to do feature proprocessing: \nNumber of features after transformation:  (82903, 92)\nmae of a constant model 9.865920644923682\nR2 of a constant model 0.0\nXGB train: 9.607009612483386 0.08343238287855514\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\nXGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.007529877851147726 45.633296966552734\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:11:10,213]\u001b[0m A new study created in memory with name: no-name-7d6d3ca2-7836-4a18-a8a1-1f1d789a6da3\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 9.82901782792788 0.030747723504207736 47.32248830795288\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:11:14,104]\u001b[0m Trial 0 finished with value: 0.005271857158222116 and parameters: {'n_estimators': 832, 'max_depth': 2, 'learning_rate': 0.04931517656937908, 'colsample_bytree': 0.5824242082478082, 'subsample': 0.5498876580158043, 'alpha': 0.3508232780466895, 'lambda': 4.873293620927068, 'gamma': 1.1123842773930086e-05, 'min_child_weight': 13.922116143471701}. Best is trial 0 with value: 0.005271857158222116.\u001b[0m\n\u001b[32m[I 2022-08-25 21:11:18,129]\u001b[0m Trial 1 finished with value: -0.0034307505601002997 and parameters: {'n_estimators': 525, 'max_depth': 4, 'learning_rate': 0.04154668654512801, 'colsample_bytree': 0.16279475546246241, 'subsample': 0.5195737438702127, 'alpha': 1.2854001662645105, 'lambda': 0.8776983010417051, 'gamma': 4.626183374281864e-09, 'min_child_weight': 3.1018733212936973}. Best is trial 0 with value: 0.005271857158222116.\u001b[0m\n\u001b[32m[I 2022-08-25 21:11:21,943]\u001b[0m Trial 2 finished with value: 0.004460005361445562 and parameters: {'n_estimators': 621, 'max_depth': 2, 'learning_rate': 0.044372357005772266, 'colsample_bytree': 0.7660178361616063, 'subsample': 0.6601303316086304, 'alpha': 5.528151675603036, 'lambda': 0.1945842464699273, 'gamma': 7.027183028738426e-05, 'min_child_weight': 0.47744266774847394}. Best is trial 0 with value: 0.005271857158222116.\u001b[0m\n\u001b[32m[I 2022-08-25 21:11:25,670]\u001b[0m Trial 3 finished with value: 0.0013610749074679206 and parameters: {'n_estimators': 602, 'max_depth': 3, 'learning_rate': 0.03453023450412734, 'colsample_bytree': 0.7410625906538633, 'subsample': 0.3212309315365535, 'alpha': 5.767701744472749, 'lambda': 16.117331272509574, 'gamma': 1.0917157666219208e-07, 'min_child_weight': 5.703874873056956}. Best is trial 0 with value: 0.005271857158222116.\u001b[0m\n\u001b[32m[I 2022-08-25 21:11:28,527]\u001b[0m Trial 4 finished with value: 0.005175769368015342 and parameters: {'n_estimators': 570, 'max_depth': 2, 'learning_rate': 0.029361879456428056, 'colsample_bytree': 0.5621617040263756, 'subsample': 0.5016801456240052, 'alpha': 0.11411999808534472, 'lambda': 7.599277051621043, 'gamma': 1.985665947608276e-06, 'min_child_weight': 0.21808892651945908}. Best is trial 0 with value: 0.005271857158222116.\u001b[0m\n\u001b[32m[I 2022-08-25 21:11:36,338]\u001b[0m Trial 5 finished with value: -0.013702231041065022 and parameters: {'n_estimators': 976, 'max_depth': 4, 'learning_rate': 0.03904721387109183, 'colsample_bytree': 0.7962519368608015, 'subsample': 0.9041240349358091, 'alpha': 0.3366933825324154, 'lambda': 1.64575916008653, 'gamma': 1.2625727382773039e-09, 'min_child_weight': 3.756562699354566}. Best is trial 0 with value: 0.005271857158222116.\u001b[0m\n\u001b[32m[I 2022-08-25 21:11:44,619]\u001b[0m Trial 6 finished with value: 0.006079374037968258 and parameters: {'n_estimators': 782, 'max_depth': 5, 'learning_rate': 0.004886102494993447, 'colsample_bytree': 0.6717529875122362, 'subsample': 0.843762205674979, 'alpha': 8.122815752341076, 'lambda': 1.1106481754604145, 'gamma': 4.364600478288917e-06, 'min_child_weight': 41.44922265607433}. Best is trial 6 with value: 0.006079374037968258.\u001b[0m\n\u001b[32m[I 2022-08-25 21:11:51,884]\u001b[0m Trial 7 finished with value: 0.005094140673329833 and parameters: {'n_estimators': 942, 'max_depth': 4, 'learning_rate': 0.00117612596191627, 'colsample_bytree': 0.6921593838410368, 'subsample': 0.9030638018398458, 'alpha': 0.3733505927182204, 'lambda': 10.175531633354165, 'gamma': 2.2173962555960528e-07, 'min_child_weight': 48.23602426467869}. Best is trial 6 with value: 0.006079374037968258.\u001b[0m\n\u001b[32m[I 2022-08-25 21:11:56,216]\u001b[0m Trial 8 finished with value: 0.0031128841529662146 and parameters: {'n_estimators': 682, 'max_depth': 3, 'learning_rate': 0.048510812531917254, 'colsample_bytree': 0.16720537971768334, 'subsample': 0.8563941825437891, 'alpha': 0.10305626831495945, 'lambda': 0.7840814960924886, 'gamma': 1.401850175746061, 'min_child_weight': 0.16936046412434447}. Best is trial 6 with value: 0.006079374037968258.\u001b[0m\n\u001b[32m[I 2022-08-25 21:12:00,913]\u001b[0m Trial 9 finished with value: 0.005343320222223759 and parameters: {'n_estimators': 619, 'max_depth': 4, 'learning_rate': 0.0036249705539607726, 'colsample_bytree': 0.16179507168384044, 'subsample': 0.5031977459534516, 'alpha': 1.5669703930770145, 'lambda': 120.98316105722608, 'gamma': 2.394632481082638e-10, 'min_child_weight': 1.0601661704374767}. Best is trial 6 with value: 0.006079374037968258.\u001b[0m\n\u001b[32m[I 2022-08-25 21:12:09,406]\u001b[0m Trial 10 finished with value: 0.0005480153881687383 and parameters: {'n_estimators': 763, 'max_depth': 5, 'learning_rate': 0.014914495492979327, 'colsample_bytree': 0.9221498435111307, 'subsample': 0.7516299626386894, 'alpha': 26.361105432364557, 'lambda': 0.15867533486823057, 'gamma': 0.003936745940935409, 'min_child_weight': 49.75223614380585}. Best is trial 6 with value: 0.006079374037968258.\u001b[0m\n\u001b[32m[I 2022-08-25 21:12:17,952]\u001b[0m Trial 11 finished with value: 0.004101946995106878 and parameters: {'n_estimators': 798, 'max_depth': 5, 'learning_rate': 0.0012695367964245148, 'colsample_bytree': 0.3402841566876399, 'subsample': 0.4197287905533847, 'alpha': 3.777899914933662, 'lambda': 171.60588491433205, 'gamma': 1.60204463259904e-10, 'min_child_weight': 0.8741409023162271}. Best is trial 6 with value: 0.006079374037968258.\u001b[0m\n\u001b[32m[I 2022-08-25 21:12:25,962]\u001b[0m Trial 12 finished with value: 0.004739081364263939 and parameters: {'n_estimators': 708, 'max_depth': 5, 'learning_rate': 0.013383638920158626, 'colsample_bytree': 0.40876568993250023, 'subsample': 0.6940127684740707, 'alpha': 18.813881753710707, 'lambda': 124.564557598917, 'gamma': 0.005293228488933051, 'min_child_weight': 1.1253080589444255}. Best is trial 6 with value: 0.006079374037968258.\u001b[0m\n\u001b[32m[I 2022-08-25 21:12:35,236]\u001b[0m Trial 13 finished with value: 0.005292915591550096 and parameters: {'n_estimators': 884, 'max_depth': 5, 'learning_rate': 0.011594295919953557, 'colsample_bytree': 0.3542230579255292, 'subsample': 0.7545927868012126, 'alpha': 1.5204505700360529, 'lambda': 39.039106104921, 'gamma': 0.0008214830334523813, 'min_child_weight': 11.422475501097525}. Best is trial 6 with value: 0.006079374037968258.\u001b[0m\n\u001b[32m[I 2022-08-25 21:12:41,030]\u001b[0m Trial 14 finished with value: 0.002083052969103693 and parameters: {'n_estimators': 709, 'max_depth': 4, 'learning_rate': 0.020535522486135112, 'colsample_bytree': 0.47293780703176, 'subsample': 0.598269130902299, 'alpha': 2.8259383250412773, 'lambda': 2.095962432152752, 'gamma': 8.631177452984678, 'min_child_weight': 1.4803421553582494}. Best is trial 6 with value: 0.006079374037968258.\u001b[0m\n\u001b[32m[I 2022-08-25 21:12:44,920]\u001b[0m Trial 15 finished with value: 0.00684867658405713 and parameters: {'n_estimators': 653, 'max_depth': 3, 'learning_rate': 0.007824070307345813, 'colsample_bytree': 0.24676453294448175, 'subsample': 0.4067512062815919, 'alpha': 13.619763530169585, 'lambda': 31.163520066649205, 'gamma': 8.151000973557657e-08, 'min_child_weight': 16.13218353853298}. Best is trial 15 with value: 0.00684867658405713.\u001b[0m\n\u001b[32m[I 2022-08-25 21:12:50,126]\u001b[0m Trial 16 finished with value: 0.007240026067929538 and parameters: {'n_estimators': 851, 'max_depth': 3, 'learning_rate': 0.007476635891852674, 'colsample_bytree': 0.6353229372492886, 'subsample': 0.3115634329182021, 'alpha': 11.654027696419872, 'lambda': 47.57199675246752, 'gamma': 3.123970332470374e-08, 'min_child_weight': 27.116278923032738}. Best is trial 16 with value: 0.007240026067929538.\u001b[0m\n\u001b[32m[I 2022-08-25 21:12:55,103]\u001b[0m Trial 17 finished with value: 0.008093638401111382 and parameters: {'n_estimators': 868, 'max_depth': 3, 'learning_rate': 0.02026559337396688, 'colsample_bytree': 0.25130285484184134, 'subsample': 0.31197680711003545, 'alpha': 13.145402763210186, 'lambda': 33.91961971552681, 'gamma': 3.528776628825982e-08, 'min_child_weight': 16.864035531707575}. Best is trial 17 with value: 0.008093638401111382.\u001b[0m\n\u001b[32m[I 2022-08-25 21:13:00,467]\u001b[0m Trial 18 finished with value: 0.007073712493462876 and parameters: {'n_estimators': 892, 'max_depth': 3, 'learning_rate': 0.020682874786968848, 'colsample_bytree': 0.2740682596625951, 'subsample': 0.3138044114740055, 'alpha': 11.106558175357389, 'lambda': 57.878835527443606, 'gamma': 1.3311427436263738e-08, 'min_child_weight': 23.075817201631637}. Best is trial 17 with value: 0.008093638401111382.\u001b[0m\n\u001b[32m[I 2022-08-25 21:13:05,461]\u001b[0m Trial 19 finished with value: 0.004428430250367912 and parameters: {'n_estimators': 853, 'max_depth': 3, 'learning_rate': 0.02097690441849703, 'colsample_bytree': 0.47157952906875705, 'subsample': 0.39898838147800697, 'alpha': 25.060590342480562, 'lambda': 19.092241320238877, 'gamma': 6.974846562370376e-07, 'min_child_weight': 6.874715637767247}. Best is trial 17 with value: 0.008093638401111382.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  115.24856281280518\n        n_estimators : 868\n           max_depth : 3\n       learning_rate : 0.02026559337396688\n    colsample_bytree : 0.25130285484184134\n           subsample : 0.31197680711003545\n               alpha : 13.145402763210186\n              lambda : 33.91961971552681\n               gamma : 3.528776628825982e-08\n    min_child_weight : 16.864035531707575\nbest objective value : 0.008093638401111382\nOptuna XGB train: 9.808368749871093 0.03429281339280321 118.16722297668457\nMin_prd:  525\nConstant guess:  8.126500500194087 0.0\nXGB test: 8.060704934892494 0.026679110225521163\nXGB GS test: 8.036618679857735 0.028794101222188617\nOptuna XGB test: 8.031346259319342 0.03147307244347575\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(85043, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"      PERMNO  prd     mom482     mom242  year      RET   ind        bm  \\\n1106   10025  549 -69.024047 -64.972497  2004  12.8779  15.0 -0.513525   \n1107   10025  550 -68.586380 -58.749269  2004   0.3036  15.0 -0.513525   \n1108   10025  551 -65.920808 -67.320879  2004  -3.1697  15.0 -0.513525   \n1109   10025  552 -69.716441 -66.386080  2004  11.5088  15.0 -0.513525   \n1110   10025  553 -35.633534 -66.274593  2004 -10.9478  15.0 -0.513525   \n\n            op        gp       inv      mom11     mom122      amhd  ivol_capm  \\\n1106  0.048325  0.323181  0.070749  26.592465 -45.175222  2.862324   1.756749   \n1107  0.048325  0.323181  0.070749  12.877900  44.060028  2.804626   2.720420   \n1108  0.048325  0.323181  0.070749   0.303600  49.780673  2.835775   0.852188   \n1109  0.048325  0.323181  0.070749  -3.169700  26.547382  2.756714   1.744959   \n1110  0.048325  0.323181  0.070749  11.508800  49.680280  2.669581   1.116454   \n\n      ivol_ff5   beta_bw     MAX     vol1m     vol6m    vol12m     BAspr  \\\n1106  1.501836  0.850673  5.1208  1.820110  1.788478  4.071073  1.347150   \n1107  2.583923  0.761546  9.1867  2.873858  1.940165  3.949224  0.364299   \n1108  0.657714  0.795531  1.5453  0.901612  1.929759  3.480026  0.089286   \n1109  1.594028  0.749173  5.0395  1.725115  1.939281  2.806362  0.722022   \n1110  0.902261  0.623812  3.5474  1.141249  1.858085  2.446564  0.595238   \n\n          size       lbm       lop       lgp      linv      llme    l1amhd  \\\n1106  4.377464 -1.137114  0.059508  0.350297 -0.071339  4.634901  2.897483   \n1107  4.504830 -1.137114  0.059508  0.350297 -0.071339  3.969097  2.862324   \n1108  4.508460 -1.137114  0.059508  0.350297 -0.071339  4.052120  2.804626   \n1109  4.477179 -1.137114  0.059508  0.350297 -0.071339  4.224549  2.835775   \n1110  4.605384 -1.137114  0.059508  0.350297 -0.071339  4.054984  2.756714   \n\n       l1MAX   l1BAspr    l3amhd   l3MAX   l3BAspr    l6amhd   l6MAX  \\\n1106  3.6375  1.243094  2.862958  4.2016  0.465116  2.743738  7.5292   \n1107  5.1208  1.347150  2.887925  2.4589  0.527704  2.761634  4.4944   \n1108  9.1867  0.364299  2.897483  3.6375  1.243094  2.829408  1.8767   \n1109  1.5453  0.089286  2.862324  5.1208  1.347150  2.862958  4.2016   \n1110  5.0395  0.722022  2.804626  9.1867  0.364299  2.887925  2.4589   \n\n       l6BAspr   l12amhd  l12MAX  l12BAspr  l12mom122  l12ivol_capm  \\\n1106  0.134228  2.257347  3.6375  0.307692 -50.490385      4.315112   \n1107  0.751315  2.380322  5.1208  3.012912 -53.104849      4.405369   \n1108  1.533019  2.314870  9.1867  0.140449 -61.937195      6.009503   \n1109  0.465116  2.500611  1.5453  0.229095 -61.937195      7.350406   \n1110  0.527704  2.630135  5.0395  0.860832 -61.937195      4.355598   \n\n      l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n1106     3.883518    0.608191  5.412216   4.166177  \n1107     3.496512    0.634109  5.720214   4.387683  \n1108     5.567252    0.651940  6.150585   4.673124  \n1109     5.120025    0.674696  6.845902   5.011527  \n1110     3.619636    0.710192  5.358175   5.189241  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1106</th>\n      <td>10025</td>\n      <td>549</td>\n      <td>-69.024047</td>\n      <td>-64.972497</td>\n      <td>2004</td>\n      <td>12.8779</td>\n      <td>15.0</td>\n      <td>-0.513525</td>\n      <td>0.048325</td>\n      <td>0.323181</td>\n      <td>0.070749</td>\n      <td>26.592465</td>\n      <td>-45.175222</td>\n      <td>2.862324</td>\n      <td>1.756749</td>\n      <td>1.501836</td>\n      <td>0.850673</td>\n      <td>5.1208</td>\n      <td>1.820110</td>\n      <td>1.788478</td>\n      <td>4.071073</td>\n      <td>1.347150</td>\n      <td>4.377464</td>\n      <td>-1.137114</td>\n      <td>0.059508</td>\n      <td>0.350297</td>\n      <td>-0.071339</td>\n      <td>4.634901</td>\n      <td>2.897483</td>\n      <td>3.6375</td>\n      <td>1.243094</td>\n      <td>2.862958</td>\n      <td>4.2016</td>\n      <td>0.465116</td>\n      <td>2.743738</td>\n      <td>7.5292</td>\n      <td>0.134228</td>\n      <td>2.257347</td>\n      <td>3.6375</td>\n      <td>0.307692</td>\n      <td>-50.490385</td>\n      <td>4.315112</td>\n      <td>3.883518</td>\n      <td>0.608191</td>\n      <td>5.412216</td>\n      <td>4.166177</td>\n    </tr>\n    <tr>\n      <th>1107</th>\n      <td>10025</td>\n      <td>550</td>\n      <td>-68.586380</td>\n      <td>-58.749269</td>\n      <td>2004</td>\n      <td>0.3036</td>\n      <td>15.0</td>\n      <td>-0.513525</td>\n      <td>0.048325</td>\n      <td>0.323181</td>\n      <td>0.070749</td>\n      <td>12.877900</td>\n      <td>44.060028</td>\n      <td>2.804626</td>\n      <td>2.720420</td>\n      <td>2.583923</td>\n      <td>0.761546</td>\n      <td>9.1867</td>\n      <td>2.873858</td>\n      <td>1.940165</td>\n      <td>3.949224</td>\n      <td>0.364299</td>\n      <td>4.504830</td>\n      <td>-1.137114</td>\n      <td>0.059508</td>\n      <td>0.350297</td>\n      <td>-0.071339</td>\n      <td>3.969097</td>\n      <td>2.862324</td>\n      <td>5.1208</td>\n      <td>1.347150</td>\n      <td>2.887925</td>\n      <td>2.4589</td>\n      <td>0.527704</td>\n      <td>2.761634</td>\n      <td>4.4944</td>\n      <td>0.751315</td>\n      <td>2.380322</td>\n      <td>5.1208</td>\n      <td>3.012912</td>\n      <td>-53.104849</td>\n      <td>4.405369</td>\n      <td>3.496512</td>\n      <td>0.634109</td>\n      <td>5.720214</td>\n      <td>4.387683</td>\n    </tr>\n    <tr>\n      <th>1108</th>\n      <td>10025</td>\n      <td>551</td>\n      <td>-65.920808</td>\n      <td>-67.320879</td>\n      <td>2004</td>\n      <td>-3.1697</td>\n      <td>15.0</td>\n      <td>-0.513525</td>\n      <td>0.048325</td>\n      <td>0.323181</td>\n      <td>0.070749</td>\n      <td>0.303600</td>\n      <td>49.780673</td>\n      <td>2.835775</td>\n      <td>0.852188</td>\n      <td>0.657714</td>\n      <td>0.795531</td>\n      <td>1.5453</td>\n      <td>0.901612</td>\n      <td>1.929759</td>\n      <td>3.480026</td>\n      <td>0.089286</td>\n      <td>4.508460</td>\n      <td>-1.137114</td>\n      <td>0.059508</td>\n      <td>0.350297</td>\n      <td>-0.071339</td>\n      <td>4.052120</td>\n      <td>2.804626</td>\n      <td>9.1867</td>\n      <td>0.364299</td>\n      <td>2.897483</td>\n      <td>3.6375</td>\n      <td>1.243094</td>\n      <td>2.829408</td>\n      <td>1.8767</td>\n      <td>1.533019</td>\n      <td>2.314870</td>\n      <td>9.1867</td>\n      <td>0.140449</td>\n      <td>-61.937195</td>\n      <td>6.009503</td>\n      <td>5.567252</td>\n      <td>0.651940</td>\n      <td>6.150585</td>\n      <td>4.673124</td>\n    </tr>\n    <tr>\n      <th>1109</th>\n      <td>10025</td>\n      <td>552</td>\n      <td>-69.716441</td>\n      <td>-66.386080</td>\n      <td>2004</td>\n      <td>11.5088</td>\n      <td>15.0</td>\n      <td>-0.513525</td>\n      <td>0.048325</td>\n      <td>0.323181</td>\n      <td>0.070749</td>\n      <td>-3.169700</td>\n      <td>26.547382</td>\n      <td>2.756714</td>\n      <td>1.744959</td>\n      <td>1.594028</td>\n      <td>0.749173</td>\n      <td>5.0395</td>\n      <td>1.725115</td>\n      <td>1.939281</td>\n      <td>2.806362</td>\n      <td>0.722022</td>\n      <td>4.477179</td>\n      <td>-1.137114</td>\n      <td>0.059508</td>\n      <td>0.350297</td>\n      <td>-0.071339</td>\n      <td>4.224549</td>\n      <td>2.835775</td>\n      <td>1.5453</td>\n      <td>0.089286</td>\n      <td>2.862324</td>\n      <td>5.1208</td>\n      <td>1.347150</td>\n      <td>2.862958</td>\n      <td>4.2016</td>\n      <td>0.465116</td>\n      <td>2.500611</td>\n      <td>1.5453</td>\n      <td>0.229095</td>\n      <td>-61.937195</td>\n      <td>7.350406</td>\n      <td>5.120025</td>\n      <td>0.674696</td>\n      <td>6.845902</td>\n      <td>5.011527</td>\n    </tr>\n    <tr>\n      <th>1110</th>\n      <td>10025</td>\n      <td>553</td>\n      <td>-35.633534</td>\n      <td>-66.274593</td>\n      <td>2004</td>\n      <td>-10.9478</td>\n      <td>15.0</td>\n      <td>-0.513525</td>\n      <td>0.048325</td>\n      <td>0.323181</td>\n      <td>0.070749</td>\n      <td>11.508800</td>\n      <td>49.680280</td>\n      <td>2.669581</td>\n      <td>1.116454</td>\n      <td>0.902261</td>\n      <td>0.623812</td>\n      <td>3.5474</td>\n      <td>1.141249</td>\n      <td>1.858085</td>\n      <td>2.446564</td>\n      <td>0.595238</td>\n      <td>4.605384</td>\n      <td>-1.137114</td>\n      <td>0.059508</td>\n      <td>0.350297</td>\n      <td>-0.071339</td>\n      <td>4.054984</td>\n      <td>2.756714</td>\n      <td>5.0395</td>\n      <td>0.722022</td>\n      <td>2.804626</td>\n      <td>9.1867</td>\n      <td>0.364299</td>\n      <td>2.887925</td>\n      <td>2.4589</td>\n      <td>0.527704</td>\n      <td>2.630135</td>\n      <td>5.0395</td>\n      <td>0.860832</td>\n      <td>-61.937195</td>\n      <td>4.355598</td>\n      <td>3.619636</td>\n      <td>0.710192</td>\n      <td>5.358175</td>\n      <td>5.189241</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    85043.000000\nmean      2005.128217\nstd          0.943302\nmin       2004.000000\n25%       2004.000000\n50%       2005.000000\n75%       2006.000000\nmax       2007.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          85043\nprd             85043\nmom482          77060\nmom242          83859\nyear            85043\nRET             85043\nind             85043\nbm              85043\nop              85043\ngp              85043\ninv             84909\nmom11           85043\nmom122          85043\namhd            81466\nivol_capm       85042\nivol_ff5        85042\nbeta_bw         85043\nMAX             85043\nvol1m           85042\nvol6m           84874\nvol12m          84608\nBAspr           81271\nsize            85043\nlbm             85043\nlop             85043\nlgp             85043\nlinv            85043\nllme            85043\nl1amhd          81364\nl1MAX           85038\nl1BAspr         81177\nl3amhd          81123\nl3MAX           85001\nl3BAspr         81085\nl6amhd          80680\nl6MAX           84968\nl6BAspr         80893\nl12amhd         79796\nl12MAX          85038\nl12BAspr        81095\nl12mom122       84856\nl12ivol_capm    84929\nl12ivol_ff5     84929\nl12beta_bw      84963\nl12vol6m        84788\nl12vol12m       84320\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (80668, 44)\ntime to do feature proprocessing: \nNumber of features after transformation:  (80668, 92)\nmae of a constant model 8.207385221748945\nR2 of a constant model 0.0\nXGB train: 7.982650268503723 0.08794051382124346\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.1s\nXGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.008233215776706104 46.74818158149719\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:14:00,027]\u001b[0m A new study created in memory with name: no-name-db09d280-a45b-4d1b-a5b1-5466e0b5441a\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 8.162100935678442 0.03306926922351294 48.11498737335205\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:14:10,898]\u001b[0m Trial 0 finished with value: -0.035532998594841006 and parameters: {'n_estimators': 967, 'max_depth': 5, 'learning_rate': 0.036493494060618005, 'colsample_bytree': 0.8861460099756683, 'subsample': 0.5394896359239336, 'alpha': 3.559116036433234, 'lambda': 3.692340231453164, 'gamma': 4.342440041898271, 'min_child_weight': 0.24303445933922418}. Best is trial 0 with value: -0.035532998594841006.\u001b[0m\n\u001b[32m[I 2022-08-25 21:14:13,928]\u001b[0m Trial 1 finished with value: 0.005818748174866388 and parameters: {'n_estimators': 501, 'max_depth': 3, 'learning_rate': 0.00473181292412814, 'colsample_bytree': 0.1578953264905537, 'subsample': 0.6685764476150368, 'alpha': 6.997706440068765, 'lambda': 0.33394912321611453, 'gamma': 3.604534702674281e-10, 'min_child_weight': 0.8418535406718569}. Best is trial 1 with value: 0.005818748174866388.\u001b[0m\n\u001b[32m[I 2022-08-25 21:14:19,480]\u001b[0m Trial 2 finished with value: 0.0019380840710236137 and parameters: {'n_estimators': 954, 'max_depth': 3, 'learning_rate': 0.03912684870100631, 'colsample_bytree': 0.11969013107902189, 'subsample': 0.6148307712754221, 'alpha': 0.132450375118281, 'lambda': 30.04772635502621, 'gamma': 0.8959135218844689, 'min_child_weight': 2.685396650876831}. Best is trial 1 with value: 0.005818748174866388.\u001b[0m\n\u001b[32m[I 2022-08-25 21:14:28,776]\u001b[0m Trial 3 finished with value: 0.0030753304423783213 and parameters: {'n_estimators': 830, 'max_depth': 5, 'learning_rate': 0.005821710800962032, 'colsample_bytree': 0.8122122567959462, 'subsample': 0.6013892640763709, 'alpha': 3.2776465350101045, 'lambda': 0.6611470593335963, 'gamma': 0.08103906180585016, 'min_child_weight': 3.26858792165671}. Best is trial 1 with value: 0.005818748174866388.\u001b[0m\n\u001b[32m[I 2022-08-25 21:14:34,266]\u001b[0m Trial 4 finished with value: 0.007211506577047639 and parameters: {'n_estimators': 999, 'max_depth': 3, 'learning_rate': 0.016534055209934975, 'colsample_bytree': 0.18012112189449364, 'subsample': 0.9338078072331968, 'alpha': 1.1394950148014014, 'lambda': 0.15051671579822778, 'gamma': 1.77332629801312e-10, 'min_child_weight': 23.826545609731767}. Best is trial 4 with value: 0.007211506577047639.\u001b[0m\n\u001b[32m[I 2022-08-25 21:14:40,439]\u001b[0m Trial 5 finished with value: -0.017193115049510335 and parameters: {'n_estimators': 555, 'max_depth': 5, 'learning_rate': 0.045689910402000655, 'colsample_bytree': 0.917801788493269, 'subsample': 0.9053901171208154, 'alpha': 0.21598940740122138, 'lambda': 1.4343895293074957, 'gamma': 0.011502571717731513, 'min_child_weight': 25.119834093299453}. Best is trial 4 with value: 0.007211506577047639.\u001b[0m\n\u001b[32m[I 2022-08-25 21:14:47,112]\u001b[0m Trial 6 finished with value: 0.006423080627138256 and parameters: {'n_estimators': 651, 'max_depth': 5, 'learning_rate': 0.013030468919756913, 'colsample_bytree': 0.2612654705428128, 'subsample': 0.47990592889037914, 'alpha': 0.24924386793920686, 'lambda': 93.02884844419745, 'gamma': 3.8179958226077504e-07, 'min_child_weight': 1.4934205409548083}. Best is trial 4 with value: 0.007211506577047639.\u001b[0m\n\u001b[32m[I 2022-08-25 21:14:54,630]\u001b[0m Trial 7 finished with value: -0.0018683500965111467 and parameters: {'n_estimators': 675, 'max_depth': 5, 'learning_rate': 0.018618213712542773, 'colsample_bytree': 0.741717972544268, 'subsample': 0.5767075532031378, 'alpha': 0.14575503041398138, 'lambda': 29.701375282824152, 'gamma': 4.770450663619408, 'min_child_weight': 5.1156038708157805}. Best is trial 4 with value: 0.007211506577047639.\u001b[0m\n\u001b[32m[I 2022-08-25 21:14:59,797]\u001b[0m Trial 8 finished with value: 0.007903856140886161 and parameters: {'n_estimators': 645, 'max_depth': 4, 'learning_rate': 0.004493574017134272, 'colsample_bytree': 0.8747494045498407, 'subsample': 0.6205948467905904, 'alpha': 0.23009491642686383, 'lambda': 15.498853986844292, 'gamma': 0.009012499777006376, 'min_child_weight': 45.022442806820564}. Best is trial 8 with value: 0.007903856140886161.\u001b[0m\n\u001b[32m[I 2022-08-25 21:15:04,753]\u001b[0m Trial 9 finished with value: -0.0039061713069344214 and parameters: {'n_estimators': 839, 'max_depth': 3, 'learning_rate': 0.049435753487384916, 'colsample_bytree': 0.5613840326338263, 'subsample': 0.6330525547749157, 'alpha': 0.5674415551173484, 'lambda': 6.034549284579267, 'gamma': 0.00015496130749740998, 'min_child_weight': 0.4791574667013123}. Best is trial 8 with value: 0.007903856140886161.\u001b[0m\n\u001b[32m[I 2022-08-25 21:15:07,964]\u001b[0m Trial 10 finished with value: 0.008316811493053482 and parameters: {'n_estimators': 653, 'max_depth': 2, 'learning_rate': 0.027525831724592387, 'colsample_bytree': 0.6318382156032787, 'subsample': 0.30126822684692184, 'alpha': 0.7633790942871769, 'lambda': 182.7660188599263, 'gamma': 6.254167034703578e-05, 'min_child_weight': 10.165863055340408}. Best is trial 10 with value: 0.008316811493053482.\u001b[0m\n\u001b[32m[I 2022-08-25 21:15:11,261]\u001b[0m Trial 11 finished with value: 0.007475797999385959 and parameters: {'n_estimators': 666, 'max_depth': 2, 'learning_rate': 0.028809977998059046, 'colsample_bytree': 0.6260337680745178, 'subsample': 0.31828370844873066, 'alpha': 0.6918425797247479, 'lambda': 158.49479899104986, 'gamma': 9.06011025766414e-05, 'min_child_weight': 48.74798038603116}. Best is trial 10 with value: 0.008316811493053482.\u001b[0m\n\u001b[32m[I 2022-08-25 21:15:17,067]\u001b[0m Trial 12 finished with value: 0.0011747153449491055 and parameters: {'n_estimators': 738, 'max_depth': 4, 'learning_rate': 0.02617926422832544, 'colsample_bytree': 0.41959257109581133, 'subsample': 0.31744881842629785, 'alpha': 29.169254677373882, 'lambda': 25.1831660817801, 'gamma': 6.787770401360655e-07, 'min_child_weight': 10.313134943968887}. Best is trial 10 with value: 0.008316811493053482.\u001b[0m\n\u001b[32m[I 2022-08-25 21:15:20,102]\u001b[0m Trial 13 finished with value: 0.00876715525143933 and parameters: {'n_estimators': 601, 'max_depth': 2, 'learning_rate': 0.022127906034603753, 'colsample_bytree': 0.7211355165008039, 'subsample': 0.7676033708282312, 'alpha': 0.4120414330435958, 'lambda': 9.787651469426697, 'gamma': 0.002800463335162303, 'min_child_weight': 10.994266953505003}. Best is trial 13 with value: 0.00876715525143933.\u001b[0m\n\u001b[32m[I 2022-08-25 21:15:23,129]\u001b[0m Trial 14 finished with value: 0.008277532491030989 and parameters: {'n_estimators': 558, 'max_depth': 2, 'learning_rate': 0.03197865216439047, 'colsample_bytree': 0.6831550709514755, 'subsample': 0.7604247352274789, 'alpha': 0.5942036172447385, 'lambda': 79.80429121244788, 'gamma': 1.2497289905673687e-06, 'min_child_weight': 8.645248024910932}. Best is trial 13 with value: 0.00876715525143933.\u001b[0m\n\u001b[32m[I 2022-08-25 21:15:26,049]\u001b[0m Trial 15 finished with value: 0.009009396307618765 and parameters: {'n_estimators': 587, 'max_depth': 2, 'learning_rate': 0.023625462161335403, 'colsample_bytree': 0.4469533320911829, 'subsample': 0.7732353524100077, 'alpha': 1.8375933456955929, 'lambda': 6.836245033046999, 'gamma': 0.0012596064722560072, 'min_child_weight': 9.953199864596234}. Best is trial 15 with value: 0.009009396307618765.\u001b[0m\n\u001b[32m[I 2022-08-25 21:15:29,313]\u001b[0m Trial 16 finished with value: 0.0077216984419270504 and parameters: {'n_estimators': 579, 'max_depth': 2, 'learning_rate': 0.020754475524754904, 'colsample_bytree': 0.4362062724045989, 'subsample': 0.7990778407231343, 'alpha': 2.035752685841385, 'lambda': 5.251342939277318, 'gamma': 0.0031520242600863438, 'min_child_weight': 17.46371890667527}. Best is trial 15 with value: 0.009009396307618765.\u001b[0m\n\u001b[32m[I 2022-08-25 21:15:32,864]\u001b[0m Trial 17 finished with value: 0.006871029775715245 and parameters: {'n_estimators': 747, 'max_depth': 2, 'learning_rate': 0.010879861417132717, 'colsample_bytree': 0.42279265153152235, 'subsample': 0.8068197605811618, 'alpha': 11.39378823908829, 'lambda': 2.3664343462869355, 'gamma': 0.0010886477721390204, 'min_child_weight': 0.10925904388737118}. Best is trial 15 with value: 0.009009396307618765.\u001b[0m\n\u001b[32m[I 2022-08-25 21:15:35,605]\u001b[0m Trial 18 finished with value: 0.008129483017440802 and parameters: {'n_estimators': 508, 'max_depth': 2, 'learning_rate': 0.022201180505948426, 'colsample_bytree': 0.3052756578640014, 'subsample': 0.735162393007795, 'alpha': 1.5357849189874673, 'lambda': 10.640515411947122, 'gamma': 9.562336177051046e-09, 'min_child_weight': 5.274792189902789}. Best is trial 15 with value: 0.009009396307618765.\u001b[0m\n\u001b[32m[I 2022-08-25 21:15:40,216]\u001b[0m Trial 19 finished with value: -0.0027456804879996454 and parameters: {'n_estimators': 595, 'max_depth': 4, 'learning_rate': 0.033087369744003337, 'colsample_bytree': 0.4750024325403493, 'subsample': 0.8620175221004038, 'alpha': 0.3755791068558317, 'lambda': 1.227635869812558, 'gamma': 0.19927999140927666, 'min_child_weight': 1.742968135126798}. Best is trial 15 with value: 0.009009396307618765.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  100.19071412086487\n        n_estimators : 587\n           max_depth : 2\n       learning_rate : 0.023625462161335403\n    colsample_bytree : 0.4469533320911829\n           subsample : 0.7732353524100077\n               alpha : 1.8375933456955929\n              lambda : 6.836245033046999\n               gamma : 0.0012596064722560072\n    min_child_weight : 9.953199864596234\nbest objective value : 0.009009396307618765\nOptuna XGB train: 8.19340096650884 0.021033249982477242 101.80624341964722\nMin_prd:  550\nConstant guess:  6.757637506147568 0.0\nXGB test: 6.746015825507648 -0.0022614119899928564\nXGB GS test: 6.735048684373413 0.0013169627783855553\nOptuna XGB test: 6.736441359054837 -0.0004336835411822282\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(79401, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"      PERMNO  prd     mom482      mom242  year      RET   ind        bm  \\\n1131   10025  574  -2.974832  138.462531  2006   3.1985  15.0 -0.896731   \n1132   10025  575 -26.926201  141.474082  2006  22.0297  15.0 -0.896731   \n1133   10025  576  -2.145041  157.746715  2006   6.5899  15.0 -0.896731   \n1134   10025  577  -6.587080  170.270066  2006  -6.4885  15.0 -0.896731   \n1135   10025  578 -13.767670  170.270066  2006   0.5515  15.0 -2.833924   \n\n            op        gp       inv    mom11     mom122      amhd  ivol_capm  \\\n1131  0.092108  0.384218 -0.009293   3.6500  29.081776  1.206031   1.971906   \n1132  0.092108  0.384218 -0.009293   3.1985  23.810656  1.238849   1.932768   \n1133  0.092108  0.384218 -0.009293  22.0297  32.262780  1.233384   1.627409   \n1134  0.092108  0.384218 -0.009293   6.5899  71.854469  1.165663   0.967349   \n1135  0.138217  0.492630 -0.230583  -6.4885  98.151432  0.966655   1.729306   \n\n      ivol_ff5   beta_bw     MAX     vol1m     vol6m    vol12m     BAspr  \\\n1131  1.655145  0.772577  4.2400  1.953144  2.076001  1.899123  0.038270   \n1132  1.469588  0.733751  6.8663  2.112008  2.187022  1.887418  0.222140   \n1133  1.481364  0.771070  5.3763  1.761302  1.849104  1.931074  0.121175   \n1134  0.836301  0.720582  2.7182  1.024173  1.550442  1.889576  0.344037   \n1135  1.656696  0.677494  5.9039  1.766046  1.651156  1.792183  0.151057   \n\n          size       lbm       lop       lgp      linv      llme    l1amhd  \\\n1131  5.407530 -0.458862  0.058436  0.356411 -0.027007  5.069140  1.170735   \n1132  5.442536 -0.458862  0.058436  0.356411 -0.027007  5.148162  1.206031   \n1133  5.652782 -0.458862  0.058436  0.356411 -0.027007  5.125570  1.238849   \n1134  5.721243 -0.458862  0.058436  0.356411 -0.027007  5.065979  1.233384   \n1135  5.658745 -0.458862  0.058436  0.356411 -0.027007  4.990124  1.165663   \n\n       l1MAX   l1BAspr    l3amhd   l3MAX   l3BAspr    l6amhd    l6MAX  \\\n1131  2.8956  1.293610  1.528294  4.0896  0.431241  1.961437   1.8887   \n1132  4.2400  0.038270  1.165798  2.8000  0.617829  1.779929   1.6955   \n1133  6.8663  0.222140  1.170735  2.8956  1.293610  1.718863  15.0031   \n1134  5.3763  0.121175  1.206031  4.2400  0.038270  1.528294   4.0896   \n1135  2.7182  0.344037  1.238849  6.8663  0.222140  1.165798   2.8000   \n\n       l6BAspr   l12amhd  l12MAX  l12BAspr  l12mom122  l12ivol_capm  \\\n1131  0.458482  2.553807  2.8956  0.569064  32.664685      3.995464   \n1132  0.244260  2.424054  4.2400  0.440313  68.816168      1.778135   \n1133  0.134831  2.330424  6.8663  0.049975  88.399166      1.210893   \n1134  0.431241  2.285802  5.3763  0.633276  63.216325      1.581157   \n1135  0.617829  2.261726  2.7182  0.685714  72.131876      2.662614   \n\n      l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n1131     3.486598    0.496637  2.144327   1.822242  \n1132     1.597251    0.546035  2.232185   1.894171  \n1133     1.027329    0.534169  2.270802   1.854214  \n1134     1.340521    0.569174  2.339334   1.887731  \n1135     2.197339    0.626926  2.570129   1.990144  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1131</th>\n      <td>10025</td>\n      <td>574</td>\n      <td>-2.974832</td>\n      <td>138.462531</td>\n      <td>2006</td>\n      <td>3.1985</td>\n      <td>15.0</td>\n      <td>-0.896731</td>\n      <td>0.092108</td>\n      <td>0.384218</td>\n      <td>-0.009293</td>\n      <td>3.6500</td>\n      <td>29.081776</td>\n      <td>1.206031</td>\n      <td>1.971906</td>\n      <td>1.655145</td>\n      <td>0.772577</td>\n      <td>4.2400</td>\n      <td>1.953144</td>\n      <td>2.076001</td>\n      <td>1.899123</td>\n      <td>0.038270</td>\n      <td>5.407530</td>\n      <td>-0.458862</td>\n      <td>0.058436</td>\n      <td>0.356411</td>\n      <td>-0.027007</td>\n      <td>5.069140</td>\n      <td>1.170735</td>\n      <td>2.8956</td>\n      <td>1.293610</td>\n      <td>1.528294</td>\n      <td>4.0896</td>\n      <td>0.431241</td>\n      <td>1.961437</td>\n      <td>1.8887</td>\n      <td>0.458482</td>\n      <td>2.553807</td>\n      <td>2.8956</td>\n      <td>0.569064</td>\n      <td>32.664685</td>\n      <td>3.995464</td>\n      <td>3.486598</td>\n      <td>0.496637</td>\n      <td>2.144327</td>\n      <td>1.822242</td>\n    </tr>\n    <tr>\n      <th>1132</th>\n      <td>10025</td>\n      <td>575</td>\n      <td>-26.926201</td>\n      <td>141.474082</td>\n      <td>2006</td>\n      <td>22.0297</td>\n      <td>15.0</td>\n      <td>-0.896731</td>\n      <td>0.092108</td>\n      <td>0.384218</td>\n      <td>-0.009293</td>\n      <td>3.1985</td>\n      <td>23.810656</td>\n      <td>1.238849</td>\n      <td>1.932768</td>\n      <td>1.469588</td>\n      <td>0.733751</td>\n      <td>6.8663</td>\n      <td>2.112008</td>\n      <td>2.187022</td>\n      <td>1.887418</td>\n      <td>0.222140</td>\n      <td>5.442536</td>\n      <td>-0.458862</td>\n      <td>0.058436</td>\n      <td>0.356411</td>\n      <td>-0.027007</td>\n      <td>5.148162</td>\n      <td>1.206031</td>\n      <td>4.2400</td>\n      <td>0.038270</td>\n      <td>1.165798</td>\n      <td>2.8000</td>\n      <td>0.617829</td>\n      <td>1.779929</td>\n      <td>1.6955</td>\n      <td>0.244260</td>\n      <td>2.424054</td>\n      <td>4.2400</td>\n      <td>0.440313</td>\n      <td>68.816168</td>\n      <td>1.778135</td>\n      <td>1.597251</td>\n      <td>0.546035</td>\n      <td>2.232185</td>\n      <td>1.894171</td>\n    </tr>\n    <tr>\n      <th>1133</th>\n      <td>10025</td>\n      <td>576</td>\n      <td>-2.145041</td>\n      <td>157.746715</td>\n      <td>2006</td>\n      <td>6.5899</td>\n      <td>15.0</td>\n      <td>-0.896731</td>\n      <td>0.092108</td>\n      <td>0.384218</td>\n      <td>-0.009293</td>\n      <td>22.0297</td>\n      <td>32.262780</td>\n      <td>1.233384</td>\n      <td>1.627409</td>\n      <td>1.481364</td>\n      <td>0.771070</td>\n      <td>5.3763</td>\n      <td>1.761302</td>\n      <td>1.849104</td>\n      <td>1.931074</td>\n      <td>0.121175</td>\n      <td>5.652782</td>\n      <td>-0.458862</td>\n      <td>0.058436</td>\n      <td>0.356411</td>\n      <td>-0.027007</td>\n      <td>5.125570</td>\n      <td>1.238849</td>\n      <td>6.8663</td>\n      <td>0.222140</td>\n      <td>1.170735</td>\n      <td>2.8956</td>\n      <td>1.293610</td>\n      <td>1.718863</td>\n      <td>15.0031</td>\n      <td>0.134831</td>\n      <td>2.330424</td>\n      <td>6.8663</td>\n      <td>0.049975</td>\n      <td>88.399166</td>\n      <td>1.210893</td>\n      <td>1.027329</td>\n      <td>0.534169</td>\n      <td>2.270802</td>\n      <td>1.854214</td>\n    </tr>\n    <tr>\n      <th>1134</th>\n      <td>10025</td>\n      <td>577</td>\n      <td>-6.587080</td>\n      <td>170.270066</td>\n      <td>2006</td>\n      <td>-6.4885</td>\n      <td>15.0</td>\n      <td>-0.896731</td>\n      <td>0.092108</td>\n      <td>0.384218</td>\n      <td>-0.009293</td>\n      <td>6.5899</td>\n      <td>71.854469</td>\n      <td>1.165663</td>\n      <td>0.967349</td>\n      <td>0.836301</td>\n      <td>0.720582</td>\n      <td>2.7182</td>\n      <td>1.024173</td>\n      <td>1.550442</td>\n      <td>1.889576</td>\n      <td>0.344037</td>\n      <td>5.721243</td>\n      <td>-0.458862</td>\n      <td>0.058436</td>\n      <td>0.356411</td>\n      <td>-0.027007</td>\n      <td>5.065979</td>\n      <td>1.233384</td>\n      <td>5.3763</td>\n      <td>0.121175</td>\n      <td>1.206031</td>\n      <td>4.2400</td>\n      <td>0.038270</td>\n      <td>1.528294</td>\n      <td>4.0896</td>\n      <td>0.431241</td>\n      <td>2.285802</td>\n      <td>5.3763</td>\n      <td>0.633276</td>\n      <td>63.216325</td>\n      <td>1.581157</td>\n      <td>1.340521</td>\n      <td>0.569174</td>\n      <td>2.339334</td>\n      <td>1.887731</td>\n    </tr>\n    <tr>\n      <th>1135</th>\n      <td>10025</td>\n      <td>578</td>\n      <td>-13.767670</td>\n      <td>170.270066</td>\n      <td>2006</td>\n      <td>0.5515</td>\n      <td>15.0</td>\n      <td>-2.833924</td>\n      <td>0.138217</td>\n      <td>0.492630</td>\n      <td>-0.230583</td>\n      <td>-6.4885</td>\n      <td>98.151432</td>\n      <td>0.966655</td>\n      <td>1.729306</td>\n      <td>1.656696</td>\n      <td>0.677494</td>\n      <td>5.9039</td>\n      <td>1.766046</td>\n      <td>1.651156</td>\n      <td>1.792183</td>\n      <td>0.151057</td>\n      <td>5.658745</td>\n      <td>-0.458862</td>\n      <td>0.058436</td>\n      <td>0.356411</td>\n      <td>-0.027007</td>\n      <td>4.990124</td>\n      <td>1.165663</td>\n      <td>2.7182</td>\n      <td>0.344037</td>\n      <td>1.238849</td>\n      <td>6.8663</td>\n      <td>0.222140</td>\n      <td>1.165798</td>\n      <td>2.8000</td>\n      <td>0.617829</td>\n      <td>2.261726</td>\n      <td>2.7182</td>\n      <td>0.685714</td>\n      <td>72.131876</td>\n      <td>2.662614</td>\n      <td>2.197339</td>\n      <td>0.626926</td>\n      <td>2.570129</td>\n      <td>1.990144</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    79401.000000\nmean      2007.202554\nstd          0.972074\nmin       2006.000000\n25%       2006.000000\n50%       2007.000000\n75%       2008.000000\nmax       2009.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          79401\nprd             79401\nmom482          71843\nmom242          77707\nyear            79401\nRET             79401\nind             79401\nbm              79401\nop              79401\ngp              79401\ninv             79229\nmom11           79401\nmom122          79401\namhd            77019\nivol_capm       79400\nivol_ff5        79400\nbeta_bw         79401\nMAX             79401\nvol1m           79399\nvol6m           79207\nvol12m          78903\nBAspr           78124\nsize            79401\nlbm             79401\nlop             79401\nlgp             79401\nlinv            79401\nllme            79401\nl1amhd          77037\nl1MAX           79398\nl1BAspr         78035\nl3amhd          77062\nl3MAX           79357\nl3BAspr         77897\nl6amhd          77045\nl6MAX           79325\nl6BAspr         77744\nl12amhd         76876\nl12MAX          79398\nl12BAspr        76893\nl12mom122       79222\nl12ivol_capm    79298\nl12ivol_ff5     79298\nl12beta_bw      79335\nl12vol6m        79138\nl12vol12m       78304\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (74917, 44)\ntime to do feature proprocessing: \nNumber of features after transformation:  (74917, 92)\nmae of a constant model 9.37771448482403\nR2 of a constant model 0.0\nXGB train: 8.760247406031798 0.08801593642949712\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\nXGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.00636599015286049 43.349798917770386\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:16:30,274]\u001b[0m A new study created in memory with name: no-name-5288407e-79e6-40be-95d0-8afa4ee78125\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 8.96426959307641 0.0329700854269932 44.876866579055786\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:16:37,500]\u001b[0m Trial 0 finished with value: -0.01817829058720192 and parameters: {'n_estimators': 948, 'max_depth': 4, 'learning_rate': 0.036810429385138094, 'colsample_bytree': 0.7657108173552764, 'subsample': 0.5531484067987946, 'alpha': 4.10144474526287, 'lambda': 0.40489107646781697, 'gamma': 2.313574522906363e-05, 'min_child_weight': 4.342095520211626}. Best is trial 0 with value: -0.01817829058720192.\u001b[0m\n\u001b[32m[I 2022-08-25 21:16:41,344]\u001b[0m Trial 1 finished with value: 0.0028207286007919164 and parameters: {'n_estimators': 639, 'max_depth': 3, 'learning_rate': 0.04071450093723057, 'colsample_bytree': 0.16672943692574527, 'subsample': 0.8938768214972186, 'alpha': 1.1576882807905784, 'lambda': 0.8280540879257247, 'gamma': 2.7979366423936194e-10, 'min_child_weight': 2.6338992394639837}. Best is trial 1 with value: 0.0028207286007919164.\u001b[0m\n\u001b[32m[I 2022-08-25 21:16:46,318]\u001b[0m Trial 2 finished with value: 0.005772743866480837 and parameters: {'n_estimators': 882, 'max_depth': 3, 'learning_rate': 0.004973145901946558, 'colsample_bytree': 0.9235808068756721, 'subsample': 0.8140837484752359, 'alpha': 0.2055983782654645, 'lambda': 0.9128870812635237, 'gamma': 0.056333159416884215, 'min_child_weight': 0.11908939575405085}. Best is trial 2 with value: 0.005772743866480837.\u001b[0m\n\u001b[32m[I 2022-08-25 21:16:51,535]\u001b[0m Trial 3 finished with value: 0.0009429357572895447 and parameters: {'n_estimators': 951, 'max_depth': 3, 'learning_rate': 0.03379192667555208, 'colsample_bytree': 0.25750228084732407, 'subsample': 0.7898829573399693, 'alpha': 5.90129907134013, 'lambda': 10.307197773681919, 'gamma': 6.840536883566628, 'min_child_weight': 1.2027576163637694}. Best is trial 2 with value: 0.005772743866480837.\u001b[0m\n\u001b[32m[I 2022-08-25 21:16:56,165]\u001b[0m Trial 4 finished with value: -0.009142240987435442 and parameters: {'n_estimators': 608, 'max_depth': 4, 'learning_rate': 0.035728565515394564, 'colsample_bytree': 0.4919615404495107, 'subsample': 0.3054234079264437, 'alpha': 0.30418372714253306, 'lambda': 0.7016006531249444, 'gamma': 1.2037893107155877e-08, 'min_child_weight': 0.10577956507095501}. Best is trial 2 with value: 0.005772743866480837.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:01,104]\u001b[0m Trial 5 finished with value: 0.0038497777358565913 and parameters: {'n_estimators': 898, 'max_depth': 3, 'learning_rate': 0.030750779456005656, 'colsample_bytree': 0.20041358157792338, 'subsample': 0.438752608652067, 'alpha': 0.5185850946979597, 'lambda': 71.86858327538673, 'gamma': 8.721192061348548e-06, 'min_child_weight': 0.34666724996124515}. Best is trial 2 with value: 0.005772743866480837.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:05,150]\u001b[0m Trial 6 finished with value: 0.003541755764755581 and parameters: {'n_estimators': 648, 'max_depth': 3, 'learning_rate': 0.025110047202361187, 'colsample_bytree': 0.7968856737501813, 'subsample': 0.5801276904156176, 'alpha': 0.8518213389057321, 'lambda': 0.30896928069252205, 'gamma': 9.453158183106955e-09, 'min_child_weight': 17.6974043163953}. Best is trial 2 with value: 0.005772743866480837.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:08,691]\u001b[0m Trial 7 finished with value: 0.004491166554808686 and parameters: {'n_estimators': 587, 'max_depth': 3, 'learning_rate': 0.03131490305009212, 'colsample_bytree': 0.5368982531058646, 'subsample': 0.8639858733556602, 'alpha': 8.114409644553962, 'lambda': 11.967671373972596, 'gamma': 0.6776864292802833, 'min_child_weight': 5.539533205995964}. Best is trial 2 with value: 0.005772743866480837.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:16,377]\u001b[0m Trial 8 finished with value: -0.012473708747205627 and parameters: {'n_estimators': 753, 'max_depth': 5, 'learning_rate': 0.04623791949942439, 'colsample_bytree': 0.23109343926546858, 'subsample': 0.7578969047380169, 'alpha': 0.10866696352372084, 'lambda': 61.80318185873707, 'gamma': 0.00140457381989882, 'min_child_weight': 4.6497830678654735}. Best is trial 2 with value: 0.005772743866480837.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:24,054]\u001b[0m Trial 9 finished with value: -0.009913038007882099 and parameters: {'n_estimators': 719, 'max_depth': 5, 'learning_rate': 0.03239731233330132, 'colsample_bytree': 0.6877411833236211, 'subsample': 0.8474112720860034, 'alpha': 0.33949697812196905, 'lambda': 1.280334830756277, 'gamma': 1.5250103162212707e-07, 'min_child_weight': 23.306989212632608}. Best is trial 2 with value: 0.005772743866480837.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:27,974]\u001b[0m Trial 10 finished with value: 0.003531914283355562 and parameters: {'n_estimators': 838, 'max_depth': 2, 'learning_rate': 0.0013639760006768577, 'colsample_bytree': 0.9397991146665237, 'subsample': 0.7194381289565518, 'alpha': 0.15294820744129067, 'lambda': 0.10605857517883044, 'gamma': 0.011854349736545209, 'min_child_weight': 0.12190909565330747}. Best is trial 2 with value: 0.005772743866480837.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:30,651]\u001b[0m Trial 11 finished with value: 0.006700497751842291 and parameters: {'n_estimators': 538, 'max_depth': 2, 'learning_rate': 0.017112114894091986, 'colsample_bytree': 0.47256862651815285, 'subsample': 0.9326240855482896, 'alpha': 18.481735051683643, 'lambda': 6.728876594365553, 'gamma': 9.514726406704579, 'min_child_weight': 0.7482916654508507}. Best is trial 11 with value: 0.006700497751842291.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:33,687]\u001b[0m Trial 12 finished with value: 0.005902855084416336 and parameters: {'n_estimators': 509, 'max_depth': 2, 'learning_rate': 0.009616959099897161, 'colsample_bytree': 0.4570635978140269, 'subsample': 0.9285592223553318, 'alpha': 19.851449631991038, 'lambda': 3.4433156171264345, 'gamma': 0.08599286135933153, 'min_child_weight': 0.6800854805665755}. Best is trial 11 with value: 0.006700497751842291.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:36,409]\u001b[0m Trial 13 finished with value: 0.005969656763631331 and parameters: {'n_estimators': 516, 'max_depth': 2, 'learning_rate': 0.014121117435432647, 'colsample_bytree': 0.4304106709634225, 'subsample': 0.9433786304117018, 'alpha': 27.548981827984704, 'lambda': 4.666187376746909, 'gamma': 9.498047076533192, 'min_child_weight': 0.8474100766759145}. Best is trial 11 with value: 0.006700497751842291.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:38,961]\u001b[0m Trial 14 finished with value: 0.007937796374567296 and parameters: {'n_estimators': 509, 'max_depth': 2, 'learning_rate': 0.017147852308275726, 'colsample_bytree': 0.3735095670847926, 'subsample': 0.6802727435343728, 'alpha': 21.759838932398416, 'lambda': 18.033517505460377, 'gamma': 9.34455689217273, 'min_child_weight': 0.39756461408827354}. Best is trial 14 with value: 0.007937796374567296.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:41,656]\u001b[0m Trial 15 finished with value: 0.005489426557097299 and parameters: {'n_estimators': 543, 'max_depth': 2, 'learning_rate': 0.02015808493546113, 'colsample_bytree': 0.3568913350637907, 'subsample': 0.6292578770766685, 'alpha': 11.4798011568343, 'lambda': 30.10955150577225, 'gamma': 0.0001848410642163475, 'min_child_weight': 0.33588979090202725}. Best is trial 14 with value: 0.007937796374567296.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:45,130]\u001b[0m Trial 16 finished with value: 0.005845353465335506 and parameters: {'n_estimators': 752, 'max_depth': 2, 'learning_rate': 0.017285384967660408, 'colsample_bytree': 0.3182914487123236, 'subsample': 0.6772403046871798, 'alpha': 2.6082943663176583, 'lambda': 152.65777945999494, 'gamma': 0.5948875263295854, 'min_child_weight': 0.3672649914176187}. Best is trial 14 with value: 0.007937796374567296.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:48,183]\u001b[0m Trial 17 finished with value: 0.005791584451909644 and parameters: {'n_estimators': 573, 'max_depth': 2, 'learning_rate': 0.023212583643745663, 'colsample_bytree': 0.5965043439349541, 'subsample': 0.45015143505150856, 'alpha': 14.346945326813406, 'lambda': 17.010144345779775, 'gamma': 0.00354375094219304, 'min_child_weight': 1.4772874487589738}. Best is trial 14 with value: 0.007937796374567296.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:53,229]\u001b[0m Trial 18 finished with value: 0.004660724330899219 and parameters: {'n_estimators': 681, 'max_depth': 4, 'learning_rate': 0.011285788968263126, 'colsample_bytree': 0.37218932610890143, 'subsample': 0.48195242038332703, 'alpha': 2.365075390841853, 'lambda': 3.3257371382495684, 'gamma': 0.6283807650584103, 'min_child_weight': 0.2654888059115737}. Best is trial 14 with value: 0.007937796374567296.\u001b[0m\n\u001b[32m[I 2022-08-25 21:17:57,118]\u001b[0m Trial 19 finished with value: 0.006669281898725273 and parameters: {'n_estimators': 799, 'max_depth': 2, 'learning_rate': 0.01980782591029896, 'colsample_bytree': 0.11085931838774482, 'subsample': 0.7079209302552559, 'alpha': 28.002823888632133, 'lambda': 33.91555380485398, 'gamma': 2.416034645731773e-06, 'min_child_weight': 0.6303537953331356}. Best is trial 14 with value: 0.007937796374567296.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  86.84788966178894\n        n_estimators : 509\n           max_depth : 2\n       learning_rate : 0.017147852308275726\n    colsample_bytree : 0.3735095670847926\n           subsample : 0.6802727435343728\n               alpha : 21.759838932398416\n              lambda : 18.033517505460377\n               gamma : 9.34455689217273\n    min_child_weight : 0.39756461408827354\nbest objective value : 0.007937796374567296\nOptuna XGB train: 9.024606503172446 0.01470599127067962 88.24956822395325\nMin_prd:  575\nConstant guess:  14.023942927689596 0.0\nXGB test: 14.192609780601327 -0.01490470258145593\nXGB GS test: 14.087690210426105 -0.005434828800949587\nOptuna XGB test: 14.097072510523505 -0.008217293847714968\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(75993, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"      PERMNO  prd      mom482     mom242  year      RET   ind        bm  \\\n1156   10025  599  158.189432  -5.022474  2008  -0.4991  15.0 -1.952836   \n1157   10025  600  124.460223 -20.289089  2008  -6.9809  15.0 -1.952836   \n1158   10025  601  135.589552 -21.721917  2008  -7.3709  15.0 -1.952836   \n1159   10025  602  106.971105 -29.424658  2008 -33.8723  15.0 -1.952836   \n1160   10025  603   39.462652 -64.862586  2008   0.2530  15.0 -1.584946   \n\n            op        gp       inv      mom11     mom122      amhd  ivol_capm  \\\n1156  0.208828  0.532784  0.079522   0.833500 -36.267527  0.508400   2.045092   \n1157  0.208828  0.532784  0.079522  -0.499100 -31.960679  0.676040   2.132460   \n1158  0.208828  0.532784  0.079522  -6.980900 -31.294902  0.816429   2.261645   \n1159  0.208828  0.532784  0.079522  -7.370900 -38.829846  1.003851   2.089856   \n1160  0.181465  0.518737 -0.020983 -22.380465 -43.580620  1.113378   3.987491   \n\n      ivol_ff5   beta_bw     MAX     vol1m     vol6m    vol12m     BAspr  \\\n1156  1.564722  1.192492  6.4372  2.924940  2.532906  2.525805  0.553926   \n1157  1.283755  1.261232  9.8376  3.935230  2.800506  2.684324  0.977199   \n1158  1.714087  1.265152  5.5953  2.884987  2.977204  2.772837  0.210011   \n1159  1.745884  1.263638  5.6901  2.598776  2.864899  2.790130  1.175517   \n1160  3.447501  1.263138  3.9483  4.136117  3.263374  3.009246  0.293945   \n\n          size       lbm       lop       lgp      linv      llme    l1amhd  \\\n1156  5.333826 -2.833924  0.138217  0.492630 -0.230583  5.885158  0.313061   \n1157  5.331117 -2.833924  0.138217  0.492630 -0.230583  5.835001  0.508400   \n1158  5.249631 -2.833924  0.138217  0.492630 -0.230583  5.811174  0.676040   \n1159  5.175006 -2.833924  0.138217  0.492630 -0.230583  5.858889  0.816429   \n1160  4.760279 -1.952836  0.208828  0.532784  0.079522  5.828432  1.003851   \n\n       l1MAX   l1BAspr    l3amhd   l3MAX   l3BAspr    l6amhd    l6MAX  \\\n1156  5.7842  0.518303  0.195908  6.7404  0.416791 -0.073123  11.3755   \n1157  6.4372  0.553926  0.215690  2.5582  0.190476 -0.027171   4.2986   \n1158  9.8376  0.977199  0.313061  5.7842  0.518303 -0.013400   4.0330   \n1159  5.5953  0.210011  0.508400  6.4372  0.553926  0.195908   6.7404   \n1160  5.6901  1.175517  0.676040  9.8376  0.977199  0.215690   2.5582   \n\n       l6BAspr   l12amhd  l12MAX  l12BAspr  l12mom122  l12ivol_capm  \\\n1156  0.664894 -0.123588  5.7842  0.385138  65.921853      1.894051   \n1157  0.163934 -0.216606  6.4372  0.476515  31.631842      2.000991   \n1158  0.209974 -0.151384  9.8376  0.215054  16.640814      1.428514   \n1159  0.416791 -0.186485  5.5953  0.287293  22.908957      2.017218   \n1160  0.190476 -0.200377  5.6901  0.416393  27.707530      1.552090   \n\n      l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n1156     1.627898    0.908137  2.089061   2.006254  \n1157     1.969442    0.882032  2.070222   2.027439  \n1158     1.255339    0.926147  1.908736   2.050792  \n1159     1.651721    1.007585  2.083395   2.093771  \n1160     1.325000    1.109816  2.115923   2.128906  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1156</th>\n      <td>10025</td>\n      <td>599</td>\n      <td>158.189432</td>\n      <td>-5.022474</td>\n      <td>2008</td>\n      <td>-0.4991</td>\n      <td>15.0</td>\n      <td>-1.952836</td>\n      <td>0.208828</td>\n      <td>0.532784</td>\n      <td>0.079522</td>\n      <td>0.833500</td>\n      <td>-36.267527</td>\n      <td>0.508400</td>\n      <td>2.045092</td>\n      <td>1.564722</td>\n      <td>1.192492</td>\n      <td>6.4372</td>\n      <td>2.924940</td>\n      <td>2.532906</td>\n      <td>2.525805</td>\n      <td>0.553926</td>\n      <td>5.333826</td>\n      <td>-2.833924</td>\n      <td>0.138217</td>\n      <td>0.492630</td>\n      <td>-0.230583</td>\n      <td>5.885158</td>\n      <td>0.313061</td>\n      <td>5.7842</td>\n      <td>0.518303</td>\n      <td>0.195908</td>\n      <td>6.7404</td>\n      <td>0.416791</td>\n      <td>-0.073123</td>\n      <td>11.3755</td>\n      <td>0.664894</td>\n      <td>-0.123588</td>\n      <td>5.7842</td>\n      <td>0.385138</td>\n      <td>65.921853</td>\n      <td>1.894051</td>\n      <td>1.627898</td>\n      <td>0.908137</td>\n      <td>2.089061</td>\n      <td>2.006254</td>\n    </tr>\n    <tr>\n      <th>1157</th>\n      <td>10025</td>\n      <td>600</td>\n      <td>124.460223</td>\n      <td>-20.289089</td>\n      <td>2008</td>\n      <td>-6.9809</td>\n      <td>15.0</td>\n      <td>-1.952836</td>\n      <td>0.208828</td>\n      <td>0.532784</td>\n      <td>0.079522</td>\n      <td>-0.499100</td>\n      <td>-31.960679</td>\n      <td>0.676040</td>\n      <td>2.132460</td>\n      <td>1.283755</td>\n      <td>1.261232</td>\n      <td>9.8376</td>\n      <td>3.935230</td>\n      <td>2.800506</td>\n      <td>2.684324</td>\n      <td>0.977199</td>\n      <td>5.331117</td>\n      <td>-2.833924</td>\n      <td>0.138217</td>\n      <td>0.492630</td>\n      <td>-0.230583</td>\n      <td>5.835001</td>\n      <td>0.508400</td>\n      <td>6.4372</td>\n      <td>0.553926</td>\n      <td>0.215690</td>\n      <td>2.5582</td>\n      <td>0.190476</td>\n      <td>-0.027171</td>\n      <td>4.2986</td>\n      <td>0.163934</td>\n      <td>-0.216606</td>\n      <td>6.4372</td>\n      <td>0.476515</td>\n      <td>31.631842</td>\n      <td>2.000991</td>\n      <td>1.969442</td>\n      <td>0.882032</td>\n      <td>2.070222</td>\n      <td>2.027439</td>\n    </tr>\n    <tr>\n      <th>1158</th>\n      <td>10025</td>\n      <td>601</td>\n      <td>135.589552</td>\n      <td>-21.721917</td>\n      <td>2008</td>\n      <td>-7.3709</td>\n      <td>15.0</td>\n      <td>-1.952836</td>\n      <td>0.208828</td>\n      <td>0.532784</td>\n      <td>0.079522</td>\n      <td>-6.980900</td>\n      <td>-31.294902</td>\n      <td>0.816429</td>\n      <td>2.261645</td>\n      <td>1.714087</td>\n      <td>1.265152</td>\n      <td>5.5953</td>\n      <td>2.884987</td>\n      <td>2.977204</td>\n      <td>2.772837</td>\n      <td>0.210011</td>\n      <td>5.249631</td>\n      <td>-2.833924</td>\n      <td>0.138217</td>\n      <td>0.492630</td>\n      <td>-0.230583</td>\n      <td>5.811174</td>\n      <td>0.676040</td>\n      <td>9.8376</td>\n      <td>0.977199</td>\n      <td>0.313061</td>\n      <td>5.7842</td>\n      <td>0.518303</td>\n      <td>-0.013400</td>\n      <td>4.0330</td>\n      <td>0.209974</td>\n      <td>-0.151384</td>\n      <td>9.8376</td>\n      <td>0.215054</td>\n      <td>16.640814</td>\n      <td>1.428514</td>\n      <td>1.255339</td>\n      <td>0.926147</td>\n      <td>1.908736</td>\n      <td>2.050792</td>\n    </tr>\n    <tr>\n      <th>1159</th>\n      <td>10025</td>\n      <td>602</td>\n      <td>106.971105</td>\n      <td>-29.424658</td>\n      <td>2008</td>\n      <td>-33.8723</td>\n      <td>15.0</td>\n      <td>-1.952836</td>\n      <td>0.208828</td>\n      <td>0.532784</td>\n      <td>0.079522</td>\n      <td>-7.370900</td>\n      <td>-38.829846</td>\n      <td>1.003851</td>\n      <td>2.089856</td>\n      <td>1.745884</td>\n      <td>1.263638</td>\n      <td>5.6901</td>\n      <td>2.598776</td>\n      <td>2.864899</td>\n      <td>2.790130</td>\n      <td>1.175517</td>\n      <td>5.175006</td>\n      <td>-2.833924</td>\n      <td>0.138217</td>\n      <td>0.492630</td>\n      <td>-0.230583</td>\n      <td>5.858889</td>\n      <td>0.816429</td>\n      <td>5.5953</td>\n      <td>0.210011</td>\n      <td>0.508400</td>\n      <td>6.4372</td>\n      <td>0.553926</td>\n      <td>0.195908</td>\n      <td>6.7404</td>\n      <td>0.416791</td>\n      <td>-0.186485</td>\n      <td>5.5953</td>\n      <td>0.287293</td>\n      <td>22.908957</td>\n      <td>2.017218</td>\n      <td>1.651721</td>\n      <td>1.007585</td>\n      <td>2.083395</td>\n      <td>2.093771</td>\n    </tr>\n    <tr>\n      <th>1160</th>\n      <td>10025</td>\n      <td>603</td>\n      <td>39.462652</td>\n      <td>-64.862586</td>\n      <td>2008</td>\n      <td>0.2530</td>\n      <td>15.0</td>\n      <td>-1.584946</td>\n      <td>0.181465</td>\n      <td>0.518737</td>\n      <td>-0.020983</td>\n      <td>-22.380465</td>\n      <td>-43.580620</td>\n      <td>1.113378</td>\n      <td>3.987491</td>\n      <td>3.447501</td>\n      <td>1.263138</td>\n      <td>3.9483</td>\n      <td>4.136117</td>\n      <td>3.263374</td>\n      <td>3.009246</td>\n      <td>0.293945</td>\n      <td>4.760279</td>\n      <td>-1.952836</td>\n      <td>0.208828</td>\n      <td>0.532784</td>\n      <td>0.079522</td>\n      <td>5.828432</td>\n      <td>1.003851</td>\n      <td>5.6901</td>\n      <td>1.175517</td>\n      <td>0.676040</td>\n      <td>9.8376</td>\n      <td>0.977199</td>\n      <td>0.215690</td>\n      <td>2.5582</td>\n      <td>0.190476</td>\n      <td>-0.200377</td>\n      <td>5.6901</td>\n      <td>0.416393</td>\n      <td>27.707530</td>\n      <td>1.552090</td>\n      <td>1.325000</td>\n      <td>1.109816</td>\n      <td>2.115923</td>\n      <td>2.128906</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    75993.000000\nmean      2009.293435\nstd          0.988989\nmin       2008.000000\n25%       2008.000000\n50%       2009.000000\n75%       2010.000000\nmax       2011.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          75993\nprd             75993\nmom482          66357\nmom242          74466\nyear            75993\nRET             75993\nind             75993\nbm              75993\nop              75993\ngp              75993\ninv             75838\nmom11           75993\nmom122          75993\namhd            73690\nivol_capm       75992\nivol_ff5        75992\nbeta_bw         75993\nMAX             75993\nvol1m           75990\nvol6m           75886\nvol12m          75679\nBAspr           75536\nsize            75993\nlbm             75993\nlop             75993\nlgp             75993\nlinv            75993\nllme            75993\nl1amhd          73692\nl1MAX           75992\nl1BAspr         75518\nl3amhd          73695\nl3MAX           75972\nl3BAspr         75506\nl6amhd          73678\nl6MAX           75956\nl6BAspr         75445\nl12amhd         73578\nl12MAX          75992\nl12BAspr        75332\nl12mom122       75844\nl12ivol_capm    75930\nl12ivol_ff5     75930\nl12beta_bw      75955\nl12vol6m        75811\nl12vol12m       74946\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (71322, 44)\ntime to do feature proprocessing: \nNumber of features after transformation:  (71322, 92)\nmae of a constant model 10.037046635152372\nR2 of a constant model 0.0\nXGB train: 9.760712862590289 0.09358310824487537\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\nXGB {'colsample_bytree': 0.6, 'eta': 0.012, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.011507977762960031 44.789910316467285\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:18:47,956]\u001b[0m A new study created in memory with name: no-name-c333cff7-656e-4e51-951e-b865c60c2fba\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 9.929117147790853 0.05635211483289826 46.126760721206665\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:18:52,233]\u001b[0m Trial 0 finished with value: 0.005322787624741703 and parameters: {'n_estimators': 933, 'max_depth': 2, 'learning_rate': 0.0035504132012419737, 'colsample_bytree': 0.17049506314726862, 'subsample': 0.43025035502262304, 'alpha': 0.48045147834486623, 'lambda': 3.715943603247201, 'gamma': 1.551561268987683, 'min_child_weight': 0.10610909085414198}. Best is trial 0 with value: 0.005322787624741703.\u001b[0m\n\u001b[32m[I 2022-08-25 21:18:57,777]\u001b[0m Trial 1 finished with value: 0.006723857611341455 and parameters: {'n_estimators': 508, 'max_depth': 5, 'learning_rate': 0.029465870298917392, 'colsample_bytree': 0.5967227255707233, 'subsample': 0.7558594578377145, 'alpha': 0.6956784829403881, 'lambda': 167.51717677154733, 'gamma': 3.596485745389904e-10, 'min_child_weight': 1.1914748262851673}. Best is trial 1 with value: 0.006723857611341455.\u001b[0m\n\u001b[32m[I 2022-08-25 21:19:01,606]\u001b[0m Trial 2 finished with value: -0.0005760884478441175 and parameters: {'n_estimators': 673, 'max_depth': 3, 'learning_rate': 0.034804290076523366, 'colsample_bytree': 0.6039911140413914, 'subsample': 0.3028911328464055, 'alpha': 3.7755918014473533, 'lambda': 0.5602158306720418, 'gamma': 2.015043851623179e-10, 'min_child_weight': 6.689090029268675}. Best is trial 1 with value: 0.006723857611341455.\u001b[0m\n\u001b[32m[I 2022-08-25 21:19:04,446]\u001b[0m Trial 3 finished with value: 0.008260985389356768 and parameters: {'n_estimators': 570, 'max_depth': 2, 'learning_rate': 0.016405251789787287, 'colsample_bytree': 0.1811686269537324, 'subsample': 0.4176595727288114, 'alpha': 2.916132692577215, 'lambda': 37.48061229967674, 'gamma': 5.688339172930634e-06, 'min_child_weight': 0.11239227893608673}. Best is trial 3 with value: 0.008260985389356768.\u001b[0m\n\u001b[32m[I 2022-08-25 21:19:07,352]\u001b[0m Trial 4 finished with value: 0.009042236576125743 and parameters: {'n_estimators': 627, 'max_depth': 2, 'learning_rate': 0.03651760127530726, 'colsample_bytree': 0.5882935731786142, 'subsample': 0.39708388762819263, 'alpha': 0.5649334140356664, 'lambda': 72.43986671681832, 'gamma': 0.9187753474140181, 'min_child_weight': 1.0962322331336232}. Best is trial 4 with value: 0.009042236576125743.\u001b[0m\n\u001b[32m[I 2022-08-25 21:19:13,021]\u001b[0m Trial 5 finished with value: 0.00680091187103166 and parameters: {'n_estimators': 589, 'max_depth': 5, 'learning_rate': 0.012284591351500534, 'colsample_bytree': 0.10073645289153133, 'subsample': 0.7532426951831602, 'alpha': 1.7303921476688608, 'lambda': 2.2739418701581426, 'gamma': 6.399005287274239, 'min_child_weight': 1.6637379643625363}. Best is trial 4 with value: 0.009042236576125743.\u001b[0m\n\u001b[32m[I 2022-08-25 21:19:17,029]\u001b[0m Trial 6 finished with value: 0.007223152194278537 and parameters: {'n_estimators': 875, 'max_depth': 2, 'learning_rate': 0.0367917577056681, 'colsample_bytree': 0.9125369800504922, 'subsample': 0.6176122520394198, 'alpha': 4.599502439038343, 'lambda': 37.48818942267104, 'gamma': 0.0014027553880385203, 'min_child_weight': 1.1941627008431956}. Best is trial 4 with value: 0.009042236576125743.\u001b[0m\n\u001b[32m[I 2022-08-25 21:19:19,937]\u001b[0m Trial 7 finished with value: 0.007952708887368527 and parameters: {'n_estimators': 505, 'max_depth': 3, 'learning_rate': 0.03246571502913551, 'colsample_bytree': 0.29934597634596155, 'subsample': 0.6817132319541068, 'alpha': 2.484663970966141, 'lambda': 36.87694550081263, 'gamma': 2.8630795965995347e-08, 'min_child_weight': 9.399769175474322}. Best is trial 4 with value: 0.009042236576125743.\u001b[0m\n\u001b[32m[I 2022-08-25 21:19:23,901]\u001b[0m Trial 8 finished with value: 0.006313233863819128 and parameters: {'n_estimators': 735, 'max_depth': 3, 'learning_rate': 0.016949631808664073, 'colsample_bytree': 0.1163141931671167, 'subsample': 0.8811304416384889, 'alpha': 0.10353436955094003, 'lambda': 0.8768976725633648, 'gamma': 0.013948485655510786, 'min_child_weight': 0.3005751977445096}. Best is trial 4 with value: 0.009042236576125743.\u001b[0m\n\u001b[32m[I 2022-08-25 21:19:32,193]\u001b[0m Trial 9 finished with value: -0.020766250588492262 and parameters: {'n_estimators': 807, 'max_depth': 5, 'learning_rate': 0.04338536961601288, 'colsample_bytree': 0.6741646679722926, 'subsample': 0.6380165935043868, 'alpha': 0.8822888365852912, 'lambda': 8.688555175331995, 'gamma': 6.518831359319805e-09, 'min_child_weight': 19.214380982608706}. Best is trial 4 with value: 0.009042236576125743.\u001b[0m\n\u001b[32m[I 2022-08-25 21:19:40,027]\u001b[0m Trial 10 finished with value: -0.017748466246061138 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.04984461854973099, 'colsample_bytree': 0.43485965495162127, 'subsample': 0.4715961067434896, 'alpha': 23.227208201089567, 'lambda': 0.10833807150375424, 'gamma': 2.0594448588748148e-05, 'min_child_weight': 45.561176934257325}. Best is trial 4 with value: 0.009042236576125743.\u001b[0m\n\u001b[32m[I 2022-08-25 21:19:43,028]\u001b[0m Trial 11 finished with value: 0.008893047275340973 and parameters: {'n_estimators': 645, 'max_depth': 2, 'learning_rate': 0.0206193702222297, 'colsample_bytree': 0.38791762261580576, 'subsample': 0.427058601698111, 'alpha': 0.1371758224866324, 'lambda': 188.45333446458366, 'gamma': 4.333913027694465e-06, 'min_child_weight': 0.33334995601168904}. Best is trial 4 with value: 0.009042236576125743.\u001b[0m\n\u001b[32m[I 2022-08-25 21:19:46,073]\u001b[0m Trial 12 finished with value: 0.007870024687082802 and parameters: {'n_estimators': 665, 'max_depth': 2, 'learning_rate': 0.023349566330627746, 'colsample_bytree': 0.4006128821917054, 'subsample': 0.30629941674273775, 'alpha': 0.11991705846732724, 'lambda': 186.6428581011149, 'gamma': 9.754570795575002e-07, 'min_child_weight': 0.5556580032735632}. Best is trial 4 with value: 0.009042236576125743.\u001b[0m\n\u001b[32m[I 2022-08-25 21:19:51,208]\u001b[0m Trial 13 finished with value: 0.009552537534777548 and parameters: {'n_estimators': 656, 'max_depth': 4, 'learning_rate': 0.023842781044028122, 'colsample_bytree': 0.846786254608283, 'subsample': 0.49735372953457946, 'alpha': 0.2666874782213661, 'lambda': 82.98814139840577, 'gamma': 0.0011233868771867684, 'min_child_weight': 0.38064788283321005}. Best is trial 13 with value: 0.009552537534777548.\u001b[0m\n\u001b[32m[I 2022-08-25 21:19:56,862]\u001b[0m Trial 14 finished with value: -0.010294660338757757 and parameters: {'n_estimators': 754, 'max_depth': 4, 'learning_rate': 0.04146668565540035, 'colsample_bytree': 0.7899558132756058, 'subsample': 0.5336398617499962, 'alpha': 0.30221904833824625, 'lambda': 10.955206223115308, 'gamma': 0.03349370330965764, 'min_child_weight': 2.9696318156208976}. Best is trial 13 with value: 0.009552537534777548.\u001b[0m\n\u001b[32m[I 2022-08-25 21:20:01,746]\u001b[0m Trial 15 finished with value: 0.00528727145559767 and parameters: {'n_estimators': 605, 'max_depth': 4, 'learning_rate': 0.028219255922261315, 'colsample_bytree': 0.948602212156904, 'subsample': 0.5323941261822204, 'alpha': 0.2671510902882706, 'lambda': 68.32684202728605, 'gamma': 0.0009095307512613583, 'min_child_weight': 0.433778844093323}. Best is trial 13 with value: 0.009552537534777548.\u001b[0m\n\u001b[32m[I 2022-08-25 21:20:07,194]\u001b[0m Trial 16 finished with value: 0.008504645034448642 and parameters: {'n_estimators': 730, 'max_depth': 4, 'learning_rate': 0.007513789352739057, 'colsample_bytree': 0.7749381603352202, 'subsample': 0.3689515396393458, 'alpha': 1.094522823643474, 'lambda': 14.316242546918476, 'gamma': 0.2668190900083009, 'min_child_weight': 3.6706821209535496}. Best is trial 13 with value: 0.009552537534777548.\u001b[0m\n\u001b[32m[I 2022-08-25 21:20:11,774]\u001b[0m Trial 17 finished with value: 0.006849918934207069 and parameters: {'n_estimators': 783, 'max_depth': 3, 'learning_rate': 0.0251077058198096, 'colsample_bytree': 0.7952051505079516, 'subsample': 0.5313247691111969, 'alpha': 0.3401198864258122, 'lambda': 74.02851935165978, 'gamma': 0.0004905998806429493, 'min_child_weight': 0.6929427327149483}. Best is trial 13 with value: 0.009552537534777548.\u001b[0m\n\u001b[32m[I 2022-08-25 21:20:15,741]\u001b[0m Trial 18 finished with value: 0.0036788257335203535 and parameters: {'n_estimators': 704, 'max_depth': 3, 'learning_rate': 0.045519773364714626, 'colsample_bytree': 0.5160427652787487, 'subsample': 0.49442909622918163, 'alpha': 10.582154837285287, 'lambda': 17.015193088662837, 'gamma': 0.11811123828365094, 'min_child_weight': 0.2837917863753968}. Best is trial 13 with value: 0.009552537534777548.\u001b[0m\n\u001b[32m[I 2022-08-25 21:20:21,963]\u001b[0m Trial 19 finished with value: 0.0027195229655427025 and parameters: {'n_estimators': 831, 'max_depth': 4, 'learning_rate': 0.038488130002028456, 'colsample_bytree': 0.7024146364835394, 'subsample': 0.6019131860959553, 'alpha': 0.23197540335547334, 'lambda': 64.66384173488413, 'gamma': 0.007533490822756721, 'min_child_weight': 0.21015653240921292}. Best is trial 13 with value: 0.009552537534777548.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  94.00881671905518\n        n_estimators : 656\n           max_depth : 4\n       learning_rate : 0.023842781044028122\n    colsample_bytree : 0.846786254608283\n           subsample : 0.49735372953457946\n               alpha : 0.2666874782213661\n              lambda : 82.98814139840577\n               gamma : 0.0011233868771867684\n    min_child_weight : 0.38064788283321005\nbest objective value : 0.009552537534777548\nOptuna XGB train: 9.860614932384733 0.06916504137619384 96.93542790412903\nMin_prd:  600\nConstant guess:  7.151687740274089 0.0\nXGB test: 7.194567545345738 0.006236133789213394\nXGB GS test: 7.163474458498653 0.00725061280046424\nOptuna XGB test: 7.205065529671993 4.012371960093741e-05\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(72134, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"      PERMNO  prd     mom482     mom242  year      RET   ind        bm  \\\n1181   10025  624 -33.213243  -7.391161  2010   6.1775  15.0 -1.051382   \n1182   10025  625 -20.492828  12.269626  2010  -9.0219  15.0 -1.051382   \n1183   10025  626 -37.557134  31.626169  2010  -5.0219  15.0 -1.051382   \n1184   10025  627 -48.760900  30.254790  2010  21.0118  15.0 -1.100725   \n1185   10025  628 -36.440453  77.120890  2010 -18.1761  15.0 -1.100725   \n\n            op        gp       inv      mom11      mom122      amhd  \\\n1181  0.024348  0.282811  0.187862 -22.380465  105.899232  0.870701   \n1182  0.024348  0.282811  0.187862   6.177500   27.912777  0.496119   \n1183  0.024348  0.282811  0.187862  -9.021900   11.380036  0.417178   \n1184  0.176879  0.498498 -0.078728  -5.021900   -4.803229  0.328364   \n1185  0.176879  0.498498 -0.078728  21.011800  -25.218487  0.339769   \n\n      ivol_capm  ivol_ff5   beta_bw      MAX     vol1m     vol6m    vol12m  \\\n1181   2.884540  2.491471  1.042598   3.0466  3.074331  2.646712  3.088480   \n1182   1.779394  1.283221  0.992666   5.7236  1.997209  2.550382  2.893940   \n1183   2.047126  1.913765  1.126987   7.2128  4.226972  2.894209  2.874546   \n1184   3.347596  2.637752  1.126710  12.1202  3.699867  3.165143  2.899452   \n1185   1.495870  0.993694  1.161303   4.1322  1.798698  3.032113  2.873359   \n\n         BAspr      size       lbm       lop       lgp      linv      llme  \\\n1181  0.076746  5.183114 -1.584946  0.181465  0.518737 -0.020983  4.638982   \n1182  0.141593  5.243151 -1.584946  0.181465  0.518737 -0.020983  4.925337   \n1183  0.641574  5.148709 -1.584946  0.181465  0.518737 -0.020983  5.123680   \n1184  0.126957  5.098020 -1.051382  0.024348  0.282811  0.187862  5.186815   \n1185  0.402414  5.264156 -1.051382  0.024348  0.282811  0.187862  5.382046   \n\n        l1amhd    l1MAX   l1BAspr    l3amhd   l3MAX   l3BAspr    l6amhd  \\\n1181  1.577377   5.7746  0.114155  1.854471  4.6104  0.202224  2.174688   \n1182  0.870701   3.0466  0.076746  1.720513  3.5128  0.179426  1.992475   \n1183  0.496119   5.7236  0.141593  1.577377  5.7746  0.114155  1.954377   \n1184  0.417178   7.2128  0.641574  0.870701  3.0466  0.076746  1.854471   \n1185  0.328364  12.1202  0.126957  0.496119  5.7236  0.141593  1.720513   \n\n       l6MAX   l6BAspr   l12amhd   l12MAX  l12BAspr  l12mom122  l12ivol_capm  \\\n1181  4.5574  0.106752  2.390736   5.7746  0.902778 -57.420339      5.671538   \n1182  6.1459  0.143431  2.428806   3.0466  0.432484 -46.446930      3.140712   \n1183  5.0362  0.522466  2.411381   5.7236  0.555556 -23.033321      4.105175   \n1184  4.6104  0.202224  2.402947   7.2128  1.108647  41.924835      3.267046   \n1185  3.5128  0.179426  2.345499  12.1202  0.209393  50.689511      2.190124   \n\n      l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n1181     3.734227    0.985554  5.641742   4.940010  \n1182     2.651936    0.992760  4.970791   5.028419  \n1183     3.845008    0.986286  5.052746   5.121087  \n1184     2.774924    0.985537  4.931069   5.064231  \n1185     2.024474    0.972879  4.687398   4.996808  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1181</th>\n      <td>10025</td>\n      <td>624</td>\n      <td>-33.213243</td>\n      <td>-7.391161</td>\n      <td>2010</td>\n      <td>6.1775</td>\n      <td>15.0</td>\n      <td>-1.051382</td>\n      <td>0.024348</td>\n      <td>0.282811</td>\n      <td>0.187862</td>\n      <td>-22.380465</td>\n      <td>105.899232</td>\n      <td>0.870701</td>\n      <td>2.884540</td>\n      <td>2.491471</td>\n      <td>1.042598</td>\n      <td>3.0466</td>\n      <td>3.074331</td>\n      <td>2.646712</td>\n      <td>3.088480</td>\n      <td>0.076746</td>\n      <td>5.183114</td>\n      <td>-1.584946</td>\n      <td>0.181465</td>\n      <td>0.518737</td>\n      <td>-0.020983</td>\n      <td>4.638982</td>\n      <td>1.577377</td>\n      <td>5.7746</td>\n      <td>0.114155</td>\n      <td>1.854471</td>\n      <td>4.6104</td>\n      <td>0.202224</td>\n      <td>2.174688</td>\n      <td>4.5574</td>\n      <td>0.106752</td>\n      <td>2.390736</td>\n      <td>5.7746</td>\n      <td>0.902778</td>\n      <td>-57.420339</td>\n      <td>5.671538</td>\n      <td>3.734227</td>\n      <td>0.985554</td>\n      <td>5.641742</td>\n      <td>4.940010</td>\n    </tr>\n    <tr>\n      <th>1182</th>\n      <td>10025</td>\n      <td>625</td>\n      <td>-20.492828</td>\n      <td>12.269626</td>\n      <td>2010</td>\n      <td>-9.0219</td>\n      <td>15.0</td>\n      <td>-1.051382</td>\n      <td>0.024348</td>\n      <td>0.282811</td>\n      <td>0.187862</td>\n      <td>6.177500</td>\n      <td>27.912777</td>\n      <td>0.496119</td>\n      <td>1.779394</td>\n      <td>1.283221</td>\n      <td>0.992666</td>\n      <td>5.7236</td>\n      <td>1.997209</td>\n      <td>2.550382</td>\n      <td>2.893940</td>\n      <td>0.141593</td>\n      <td>5.243151</td>\n      <td>-1.584946</td>\n      <td>0.181465</td>\n      <td>0.518737</td>\n      <td>-0.020983</td>\n      <td>4.925337</td>\n      <td>0.870701</td>\n      <td>3.0466</td>\n      <td>0.076746</td>\n      <td>1.720513</td>\n      <td>3.5128</td>\n      <td>0.179426</td>\n      <td>1.992475</td>\n      <td>6.1459</td>\n      <td>0.143431</td>\n      <td>2.428806</td>\n      <td>3.0466</td>\n      <td>0.432484</td>\n      <td>-46.446930</td>\n      <td>3.140712</td>\n      <td>2.651936</td>\n      <td>0.992760</td>\n      <td>4.970791</td>\n      <td>5.028419</td>\n    </tr>\n    <tr>\n      <th>1183</th>\n      <td>10025</td>\n      <td>626</td>\n      <td>-37.557134</td>\n      <td>31.626169</td>\n      <td>2010</td>\n      <td>-5.0219</td>\n      <td>15.0</td>\n      <td>-1.051382</td>\n      <td>0.024348</td>\n      <td>0.282811</td>\n      <td>0.187862</td>\n      <td>-9.021900</td>\n      <td>11.380036</td>\n      <td>0.417178</td>\n      <td>2.047126</td>\n      <td>1.913765</td>\n      <td>1.126987</td>\n      <td>7.2128</td>\n      <td>4.226972</td>\n      <td>2.894209</td>\n      <td>2.874546</td>\n      <td>0.641574</td>\n      <td>5.148709</td>\n      <td>-1.584946</td>\n      <td>0.181465</td>\n      <td>0.518737</td>\n      <td>-0.020983</td>\n      <td>5.123680</td>\n      <td>0.496119</td>\n      <td>5.7236</td>\n      <td>0.141593</td>\n      <td>1.577377</td>\n      <td>5.7746</td>\n      <td>0.114155</td>\n      <td>1.954377</td>\n      <td>5.0362</td>\n      <td>0.522466</td>\n      <td>2.411381</td>\n      <td>5.7236</td>\n      <td>0.555556</td>\n      <td>-23.033321</td>\n      <td>4.105175</td>\n      <td>3.845008</td>\n      <td>0.986286</td>\n      <td>5.052746</td>\n      <td>5.121087</td>\n    </tr>\n    <tr>\n      <th>1184</th>\n      <td>10025</td>\n      <td>627</td>\n      <td>-48.760900</td>\n      <td>30.254790</td>\n      <td>2010</td>\n      <td>21.0118</td>\n      <td>15.0</td>\n      <td>-1.100725</td>\n      <td>0.176879</td>\n      <td>0.498498</td>\n      <td>-0.078728</td>\n      <td>-5.021900</td>\n      <td>-4.803229</td>\n      <td>0.328364</td>\n      <td>3.347596</td>\n      <td>2.637752</td>\n      <td>1.126710</td>\n      <td>12.1202</td>\n      <td>3.699867</td>\n      <td>3.165143</td>\n      <td>2.899452</td>\n      <td>0.126957</td>\n      <td>5.098020</td>\n      <td>-1.051382</td>\n      <td>0.024348</td>\n      <td>0.282811</td>\n      <td>0.187862</td>\n      <td>5.186815</td>\n      <td>0.417178</td>\n      <td>7.2128</td>\n      <td>0.641574</td>\n      <td>0.870701</td>\n      <td>3.0466</td>\n      <td>0.076746</td>\n      <td>1.854471</td>\n      <td>4.6104</td>\n      <td>0.202224</td>\n      <td>2.402947</td>\n      <td>7.2128</td>\n      <td>1.108647</td>\n      <td>41.924835</td>\n      <td>3.267046</td>\n      <td>2.774924</td>\n      <td>0.985537</td>\n      <td>4.931069</td>\n      <td>5.064231</td>\n    </tr>\n    <tr>\n      <th>1185</th>\n      <td>10025</td>\n      <td>628</td>\n      <td>-36.440453</td>\n      <td>77.120890</td>\n      <td>2010</td>\n      <td>-18.1761</td>\n      <td>15.0</td>\n      <td>-1.100725</td>\n      <td>0.176879</td>\n      <td>0.498498</td>\n      <td>-0.078728</td>\n      <td>21.011800</td>\n      <td>-25.218487</td>\n      <td>0.339769</td>\n      <td>1.495870</td>\n      <td>0.993694</td>\n      <td>1.161303</td>\n      <td>4.1322</td>\n      <td>1.798698</td>\n      <td>3.032113</td>\n      <td>2.873359</td>\n      <td>0.402414</td>\n      <td>5.264156</td>\n      <td>-1.051382</td>\n      <td>0.024348</td>\n      <td>0.282811</td>\n      <td>0.187862</td>\n      <td>5.382046</td>\n      <td>0.328364</td>\n      <td>12.1202</td>\n      <td>0.126957</td>\n      <td>0.496119</td>\n      <td>5.7236</td>\n      <td>0.141593</td>\n      <td>1.720513</td>\n      <td>3.5128</td>\n      <td>0.179426</td>\n      <td>2.345499</td>\n      <td>12.1202</td>\n      <td>0.209393</td>\n      <td>50.689511</td>\n      <td>2.190124</td>\n      <td>2.024474</td>\n      <td>0.972879</td>\n      <td>4.687398</td>\n      <td>4.996808</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    72134.000000\nmean      2011.347118\nstd          1.000128\nmin       2010.000000\n25%       2011.000000\n50%       2011.000000\n75%       2012.000000\nmax       2013.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          72134\nprd             72134\nmom482          64969\nmom242          71280\nyear            72134\nRET             72134\nind             72134\nbm              72134\nop              72134\ngp              72134\ninv             71987\nmom11           72134\nmom122          72134\namhd            70467\nivol_capm       72133\nivol_ff5        72133\nbeta_bw         72134\nMAX             72134\nvol1m           72133\nvol6m           72080\nvol12m          71966\nBAspr           71963\nsize            72134\nlbm             72134\nlop             72134\nlgp             72134\nlinv            72134\nllme            72134\nl1amhd          70471\nl1MAX           72129\nl1BAspr         71947\nl3amhd          70470\nl3MAX           72115\nl3BAspr         71923\nl6amhd          70414\nl6MAX           72101\nl6BAspr         71877\nl12amhd         70264\nl12MAX          72129\nl12BAspr        71683\nl12mom122       72038\nl12ivol_capm    72087\nl12ivol_ff5     72087\nl12beta_bw      72094\nl12vol6m        72054\nl12vol12m       71584\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (68474, 44)\ntime to do feature proprocessing: \nNumber of features after transformation:  (68474, 91)\nmae of a constant model 7.929203557642096\nR2 of a constant model 0.0\nXGB train: 7.614579200435014 0.10740142593489\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\nXGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.007829857361286663 42.7620415687561\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:21:11,970]\u001b[0m A new study created in memory with name: no-name-ba9a56d3-9709-48f9-9c56-f547d7384dae\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 7.828758732420091 0.040164488128036524 43.893948554992676\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:21:21,877]\u001b[0m Trial 0 finished with value: -0.02756818022204511 and parameters: {'n_estimators': 990, 'max_depth': 5, 'learning_rate': 0.03750624270771889, 'colsample_bytree': 0.5606786338927369, 'subsample': 0.7132237014079852, 'alpha': 3.0247723658862555, 'lambda': 0.14515931770000318, 'gamma': 0.00028025061074782835, 'min_child_weight': 8.882808380781123}. Best is trial 0 with value: -0.02756818022204511.\u001b[0m\n\u001b[32m[I 2022-08-25 21:21:28,728]\u001b[0m Trial 1 finished with value: -0.010691635155818094 and parameters: {'n_estimators': 699, 'max_depth': 5, 'learning_rate': 0.035994077505641195, 'colsample_bytree': 0.39485794973622357, 'subsample': 0.7295880981637665, 'alpha': 10.518285007775635, 'lambda': 2.724478265294206, 'gamma': 2.5977902760869326e-10, 'min_child_weight': 38.61082680490899}. Best is trial 1 with value: -0.010691635155818094.\u001b[0m\n\u001b[32m[I 2022-08-25 21:21:33,441]\u001b[0m Trial 2 finished with value: 0.007172902571093585 and parameters: {'n_estimators': 871, 'max_depth': 3, 'learning_rate': 0.017364495683133436, 'colsample_bytree': 0.10828662922137997, 'subsample': 0.6747661078376906, 'alpha': 0.41899947801951026, 'lambda': 0.47882084614696574, 'gamma': 0.004927334580078964, 'min_child_weight': 26.09320780743031}. Best is trial 2 with value: 0.007172902571093585.\u001b[0m\n\u001b[32m[I 2022-08-25 21:21:41,715]\u001b[0m Trial 3 finished with value: -0.007302345426623835 and parameters: {'n_estimators': 748, 'max_depth': 5, 'learning_rate': 0.02908039901453328, 'colsample_bytree': 0.9120922562176733, 'subsample': 0.4784224324601474, 'alpha': 0.19811937541980273, 'lambda': 83.39615895467131, 'gamma': 1.298637059153682e-07, 'min_child_weight': 18.81966913881448}. Best is trial 2 with value: 0.007172902571093585.\u001b[0m\n\u001b[32m[I 2022-08-25 21:21:46,004]\u001b[0m Trial 4 finished with value: 0.001585992215524068 and parameters: {'n_estimators': 973, 'max_depth': 2, 'learning_rate': 0.0471833674654174, 'colsample_bytree': 0.19849222794172244, 'subsample': 0.6420145014214189, 'alpha': 7.473430824171161, 'lambda': 1.0692320172799412, 'gamma': 0.0020639828216493785, 'min_child_weight': 0.5483392901259591}. Best is trial 2 with value: 0.007172902571093585.\u001b[0m\n\u001b[32m[I 2022-08-25 21:21:49,831]\u001b[0m Trial 5 finished with value: 0.003747170844288952 and parameters: {'n_estimators': 593, 'max_depth': 3, 'learning_rate': 0.0441686317556612, 'colsample_bytree': 0.32559803919348795, 'subsample': 0.636631091732552, 'alpha': 24.382838137305704, 'lambda': 5.378243183192765, 'gamma': 1.3611548518269915e-08, 'min_child_weight': 1.6238949459585097}. Best is trial 2 with value: 0.007172902571093585.\u001b[0m\n\u001b[32m[I 2022-08-25 21:21:56,467]\u001b[0m Trial 6 finished with value: -0.00488993989578295 and parameters: {'n_estimators': 940, 'max_depth': 4, 'learning_rate': 0.037848428930545665, 'colsample_bytree': 0.1648229936873058, 'subsample': 0.8712122960248989, 'alpha': 2.3736998329423256, 'lambda': 3.4029170885984095, 'gamma': 8.434178474485181e-10, 'min_child_weight': 0.19036617631396227}. Best is trial 2 with value: 0.007172902571093585.\u001b[0m\n\u001b[32m[I 2022-08-25 21:22:01,765]\u001b[0m Trial 7 finished with value: 0.004573519658395384 and parameters: {'n_estimators': 820, 'max_depth': 3, 'learning_rate': 0.025995632050232517, 'colsample_bytree': 0.9207826295069352, 'subsample': 0.8457401486093326, 'alpha': 0.13380641682469982, 'lambda': 8.412319433500372, 'gamma': 7.091569180178371e-05, 'min_child_weight': 0.8506565153537446}. Best is trial 2 with value: 0.007172902571093585.\u001b[0m\n\u001b[32m[I 2022-08-25 21:22:06,243]\u001b[0m Trial 8 finished with value: -0.0018550598304682775 and parameters: {'n_estimators': 797, 'max_depth': 3, 'learning_rate': 0.04034371826048686, 'colsample_bytree': 0.6212107387070387, 'subsample': 0.6673153281450867, 'alpha': 4.680308384077898, 'lambda': 2.274128473504774, 'gamma': 9.997141885096871, 'min_child_weight': 22.584626521035037}. Best is trial 2 with value: 0.007172902571093585.\u001b[0m\n\u001b[32m[I 2022-08-25 21:22:11,698]\u001b[0m Trial 9 finished with value: -0.004259556528298951 and parameters: {'n_estimators': 956, 'max_depth': 3, 'learning_rate': 0.03845815085735008, 'colsample_bytree': 0.7002608322522763, 'subsample': 0.8202469192005752, 'alpha': 9.015277387535553, 'lambda': 1.1342835643742522, 'gamma': 0.006214869958087151, 'min_child_weight': 40.50512442556087}. Best is trial 2 with value: 0.007172902571093585.\u001b[0m\n\u001b[32m[I 2022-08-25 21:22:15,599]\u001b[0m Trial 10 finished with value: 0.0076659788686680806 and parameters: {'n_estimators': 870, 'max_depth': 2, 'learning_rate': 0.006985963212926305, 'colsample_bytree': 0.10038137216838328, 'subsample': 0.32254145449486127, 'alpha': 0.6370262975147194, 'lambda': 0.10308162852910928, 'gamma': 0.8570827709249433, 'min_child_weight': 5.493333113981677}. Best is trial 10 with value: 0.0076659788686680806.\u001b[0m\n\u001b[32m[I 2022-08-25 21:22:19,505]\u001b[0m Trial 11 finished with value: 0.007795033991139313 and parameters: {'n_estimators': 864, 'max_depth': 2, 'learning_rate': 0.0075310657642956025, 'colsample_bytree': 0.10189185766586617, 'subsample': 0.3067246851081788, 'alpha': 0.6603548319989264, 'lambda': 0.11474147662202144, 'gamma': 0.818402353996119, 'min_child_weight': 6.700773151796079}. Best is trial 11 with value: 0.007795033991139313.\u001b[0m\n\u001b[32m[I 2022-08-25 21:22:23,638]\u001b[0m Trial 12 finished with value: 0.0069799285125894065 and parameters: {'n_estimators': 888, 'max_depth': 2, 'learning_rate': 0.0028796126274381606, 'colsample_bytree': 0.340385895108887, 'subsample': 0.3113032369288312, 'alpha': 0.8243903244495445, 'lambda': 0.10186648500636264, 'gamma': 6.259163872367355, 'min_child_weight': 5.35987251319707}. Best is trial 11 with value: 0.007795033991139313.\u001b[0m\n\u001b[32m[I 2022-08-25 21:22:26,754]\u001b[0m Trial 13 finished with value: 0.007070659530265093 and parameters: {'n_estimators': 667, 'max_depth': 2, 'learning_rate': 0.0035608674308893777, 'colsample_bytree': 0.2515163446078259, 'subsample': 0.3261188894291223, 'alpha': 0.8069871599350484, 'lambda': 0.30696351536476907, 'gamma': 0.15909679867262755, 'min_child_weight': 4.335184555527201}. Best is trial 11 with value: 0.007795033991139313.\u001b[0m\n\u001b[32m[I 2022-08-25 21:22:30,697]\u001b[0m Trial 14 finished with value: 0.009888624410767832 and parameters: {'n_estimators': 868, 'max_depth': 2, 'learning_rate': 0.013868329963668649, 'colsample_bytree': 0.4393040670491829, 'subsample': 0.45423772830872244, 'alpha': 0.7953939799955668, 'lambda': 44.464833772439434, 'gamma': 0.5014330335588163, 'min_child_weight': 2.2100718698548856}. Best is trial 14 with value: 0.009888624410767832.\u001b[0m\n\u001b[32m[I 2022-08-25 21:22:36,446]\u001b[0m Trial 15 finished with value: 0.007297805107398138 and parameters: {'n_estimators': 778, 'max_depth': 4, 'learning_rate': 0.013628261406920618, 'colsample_bytree': 0.4581410273152169, 'subsample': 0.4600555786457716, 'alpha': 1.468291347672091, 'lambda': 27.22781520167121, 'gamma': 1.7524481598196033e-06, 'min_child_weight': 2.0646781279540734}. Best is trial 14 with value: 0.009888624410767832.\u001b[0m\n\u001b[32m[I 2022-08-25 21:22:39,119]\u001b[0m Trial 16 finished with value: 0.0087251554187044 and parameters: {'n_estimators': 535, 'max_depth': 2, 'learning_rate': 0.01542090934418543, 'colsample_bytree': 0.7675023344261473, 'subsample': 0.44967303280133464, 'alpha': 0.34773682014831614, 'lambda': 125.25436752696433, 'gamma': 0.05378032689381343, 'min_child_weight': 0.7889685076126611}. Best is trial 14 with value: 0.009888624410767832.\u001b[0m\n\u001b[32m[I 2022-08-25 21:22:41,739]\u001b[0m Trial 17 finished with value: 0.009309058025769375 and parameters: {'n_estimators': 500, 'max_depth': 2, 'learning_rate': 0.017402915091221546, 'colsample_bytree': 0.7907880019590363, 'subsample': 0.500004867033778, 'alpha': 0.26200515450832434, 'lambda': 186.2632653553358, 'gamma': 0.03335569987620236, 'min_child_weight': 0.2756126236427078}. Best is trial 14 with value: 0.009888624410767832.\u001b[0m\n\u001b[32m[I 2022-08-25 21:22:46,421]\u001b[0m Trial 18 finished with value: 0.007538857786423481 and parameters: {'n_estimators': 516, 'max_depth': 4, 'learning_rate': 0.019710518275302222, 'colsample_bytree': 0.7876006035990333, 'subsample': 0.5440691560659764, 'alpha': 0.10146471861434865, 'lambda': 43.82592327572226, 'gamma': 7.505968713261408e-06, 'min_child_weight': 0.19921895558531674}. Best is trial 14 with value: 0.009888624410767832.\u001b[0m\n\u001b[32m[I 2022-08-25 21:22:49,303]\u001b[0m Trial 19 finished with value: 0.009388493258155935 and parameters: {'n_estimators': 590, 'max_depth': 2, 'learning_rate': 0.021140254690427008, 'colsample_bytree': 0.4942519697090549, 'subsample': 0.5579065545478101, 'alpha': 0.25524614820325675, 'lambda': 180.07137624842736, 'gamma': 0.04076049900733013, 'min_child_weight': 0.3467127271421573}. Best is trial 14 with value: 0.009888624410767832.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  97.3347270488739\n        n_estimators : 868\n           max_depth : 2\n       learning_rate : 0.013868329963668649\n    colsample_bytree : 0.4393040670491829\n           subsample : 0.45423772830872244\n               alpha : 0.7953939799955668\n              lambda : 44.464833772439434\n               gamma : 0.5014330335588163\n    min_child_weight : 2.2100718698548856\nbest objective value : 0.009888624410767832\nOptuna XGB train: 7.876640243138913 0.02196288131081059 99.35954713821411\nMin_prd:  625\nConstant guess:  7.739690600361432 0.0\nXGB test: 7.8125700982203465 -0.02018297952134418\nXGB GS test: 7.772694962113474 -0.013107832891068316\nOptuna XGB test: 7.768919000518592 -0.012510181276847554\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(66111, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"      PERMNO  prd      mom482      mom242  year      RET   ind        bm  \\\n1206   10025  649   30.604529   47.614289  2012  -0.9851  15.0 -0.953163   \n1207   10025  650   97.106725   44.386493  2012  26.1222  15.0 -0.953163   \n1208   10025  651  138.786753   50.502876  2012   7.8760  15.0 -0.899741   \n1209   10025  652  162.913720   87.364374  2012   7.1633  15.0 -0.899741   \n1210   10025  653  174.780357  113.102274  2012  20.3276  15.0 -0.899741   \n\n            op        gp       inv    mom11     mom122      amhd  ivol_capm  \\\n1206  0.060639  0.373348 -0.025756   0.1724  14.759414  1.259688   1.204700   \n1207  0.060639  0.373348 -0.025756  -0.9851  13.571797  1.141539   0.765013   \n1208  0.072943  0.362002  0.184931  26.1222  18.270241  1.103795   1.517394   \n1209  0.072943  0.362002  0.184931   7.8760  60.787559  1.047262   0.937883   \n1210  0.072943  0.362002  0.184931   7.1633  72.766685  0.949094   1.120278   \n\n      ivol_ff5   beta_bw     MAX     vol1m     vol6m    vol12m     BAspr  \\\n1206  0.923609  1.058419  2.5839  1.533648  2.224711  2.413616  0.404975   \n1207  0.647098  1.026432  1.4066  0.866870  1.761031  2.337123  0.579206   \n1208  1.511676  1.007201  5.7938  1.525676  1.485825  2.334760  0.136519   \n1209  0.768468  0.991882  3.1364  0.989203  1.371582  2.299344  0.578902   \n1210  0.963537  1.038772  4.3231  1.269428  1.271617  2.116573  0.335306   \n\n          size       lbm       lop       lgp      linv      llme    l1amhd  \\\n1206  5.260005 -1.100725  0.176879  0.498498 -0.078728  5.226473  1.278464   \n1207  5.250206 -1.100725  0.176879  0.498498 -0.078728  5.238599  1.259688   \n1208  5.482288 -0.953163  0.060639  0.373348 -0.025756  5.188325  1.141539   \n1209  5.558824 -0.953163  0.060639  0.373348 -0.025756  5.001724  1.103795   \n1210  5.628101 -0.953163  0.060639  0.373348 -0.025756  5.005778  1.047262   \n\n       l1MAX   l1BAspr    l3amhd   l3MAX   l3BAspr    l6amhd   l6MAX  \\\n1206  2.9882  0.371854  1.383731  4.1328  0.513906  1.510489  8.7149   \n1207  2.5839  0.404975  1.369098  3.7563  0.490055  1.482684  9.2927   \n1208  1.4066  0.579206  1.278464  2.9882  0.371854  1.460316  8.6057   \n1209  5.7938  0.136519  1.259688  2.5839  0.404975  1.383731  4.1328   \n1210  3.1364  0.578902  1.141539  1.4066  0.579206  1.369098  3.7563   \n\n       l6BAspr   l12amhd  l12MAX  l12BAspr  l12mom122  l12ivol_capm  \\\n1206  0.558214  1.431610  2.9882  0.397878   7.446355      1.532176   \n1207  0.468883  1.488235  2.5839  0.579216  20.525370      1.116961   \n1208  0.567577  1.494722  1.4066  0.307377  28.446093      1.852721   \n1209  0.513906  1.504704  5.7938  0.367918   0.922674      1.208446   \n1210  0.490055  1.523562  3.1364  0.681302  14.425587      2.072178   \n\n      l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n1206     1.429862    1.297452  2.318278   2.736604  \n1207     0.998634    1.245832  2.151214   2.495713  \n1208     1.680914    1.262682  2.178625   2.343239  \n1209     0.908065    1.307383  2.056547   2.325010  \n1210     1.968630    1.081815  2.335976   2.367897  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1206</th>\n      <td>10025</td>\n      <td>649</td>\n      <td>30.604529</td>\n      <td>47.614289</td>\n      <td>2012</td>\n      <td>-0.9851</td>\n      <td>15.0</td>\n      <td>-0.953163</td>\n      <td>0.060639</td>\n      <td>0.373348</td>\n      <td>-0.025756</td>\n      <td>0.1724</td>\n      <td>14.759414</td>\n      <td>1.259688</td>\n      <td>1.204700</td>\n      <td>0.923609</td>\n      <td>1.058419</td>\n      <td>2.5839</td>\n      <td>1.533648</td>\n      <td>2.224711</td>\n      <td>2.413616</td>\n      <td>0.404975</td>\n      <td>5.260005</td>\n      <td>-1.100725</td>\n      <td>0.176879</td>\n      <td>0.498498</td>\n      <td>-0.078728</td>\n      <td>5.226473</td>\n      <td>1.278464</td>\n      <td>2.9882</td>\n      <td>0.371854</td>\n      <td>1.383731</td>\n      <td>4.1328</td>\n      <td>0.513906</td>\n      <td>1.510489</td>\n      <td>8.7149</td>\n      <td>0.558214</td>\n      <td>1.431610</td>\n      <td>2.9882</td>\n      <td>0.397878</td>\n      <td>7.446355</td>\n      <td>1.532176</td>\n      <td>1.429862</td>\n      <td>1.297452</td>\n      <td>2.318278</td>\n      <td>2.736604</td>\n    </tr>\n    <tr>\n      <th>1207</th>\n      <td>10025</td>\n      <td>650</td>\n      <td>97.106725</td>\n      <td>44.386493</td>\n      <td>2012</td>\n      <td>26.1222</td>\n      <td>15.0</td>\n      <td>-0.953163</td>\n      <td>0.060639</td>\n      <td>0.373348</td>\n      <td>-0.025756</td>\n      <td>-0.9851</td>\n      <td>13.571797</td>\n      <td>1.141539</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>1.026432</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>1.761031</td>\n      <td>2.337123</td>\n      <td>0.579206</td>\n      <td>5.250206</td>\n      <td>-1.100725</td>\n      <td>0.176879</td>\n      <td>0.498498</td>\n      <td>-0.078728</td>\n      <td>5.238599</td>\n      <td>1.259688</td>\n      <td>2.5839</td>\n      <td>0.404975</td>\n      <td>1.369098</td>\n      <td>3.7563</td>\n      <td>0.490055</td>\n      <td>1.482684</td>\n      <td>9.2927</td>\n      <td>0.468883</td>\n      <td>1.488235</td>\n      <td>2.5839</td>\n      <td>0.579216</td>\n      <td>20.525370</td>\n      <td>1.116961</td>\n      <td>0.998634</td>\n      <td>1.245832</td>\n      <td>2.151214</td>\n      <td>2.495713</td>\n    </tr>\n    <tr>\n      <th>1208</th>\n      <td>10025</td>\n      <td>651</td>\n      <td>138.786753</td>\n      <td>50.502876</td>\n      <td>2012</td>\n      <td>7.8760</td>\n      <td>15.0</td>\n      <td>-0.899741</td>\n      <td>0.072943</td>\n      <td>0.362002</td>\n      <td>0.184931</td>\n      <td>26.1222</td>\n      <td>18.270241</td>\n      <td>1.103795</td>\n      <td>1.517394</td>\n      <td>1.511676</td>\n      <td>1.007201</td>\n      <td>5.7938</td>\n      <td>1.525676</td>\n      <td>1.485825</td>\n      <td>2.334760</td>\n      <td>0.136519</td>\n      <td>5.482288</td>\n      <td>-0.953163</td>\n      <td>0.060639</td>\n      <td>0.373348</td>\n      <td>-0.025756</td>\n      <td>5.188325</td>\n      <td>1.141539</td>\n      <td>1.4066</td>\n      <td>0.579206</td>\n      <td>1.278464</td>\n      <td>2.9882</td>\n      <td>0.371854</td>\n      <td>1.460316</td>\n      <td>8.6057</td>\n      <td>0.567577</td>\n      <td>1.494722</td>\n      <td>1.4066</td>\n      <td>0.307377</td>\n      <td>28.446093</td>\n      <td>1.852721</td>\n      <td>1.680914</td>\n      <td>1.262682</td>\n      <td>2.178625</td>\n      <td>2.343239</td>\n    </tr>\n    <tr>\n      <th>1209</th>\n      <td>10025</td>\n      <td>652</td>\n      <td>162.913720</td>\n      <td>87.364374</td>\n      <td>2012</td>\n      <td>7.1633</td>\n      <td>15.0</td>\n      <td>-0.899741</td>\n      <td>0.072943</td>\n      <td>0.362002</td>\n      <td>0.184931</td>\n      <td>7.8760</td>\n      <td>60.787559</td>\n      <td>1.047262</td>\n      <td>0.937883</td>\n      <td>0.768468</td>\n      <td>0.991882</td>\n      <td>3.1364</td>\n      <td>0.989203</td>\n      <td>1.371582</td>\n      <td>2.299344</td>\n      <td>0.578902</td>\n      <td>5.558824</td>\n      <td>-0.953163</td>\n      <td>0.060639</td>\n      <td>0.373348</td>\n      <td>-0.025756</td>\n      <td>5.001724</td>\n      <td>1.103795</td>\n      <td>5.7938</td>\n      <td>0.136519</td>\n      <td>1.259688</td>\n      <td>2.5839</td>\n      <td>0.404975</td>\n      <td>1.383731</td>\n      <td>4.1328</td>\n      <td>0.513906</td>\n      <td>1.504704</td>\n      <td>5.7938</td>\n      <td>0.367918</td>\n      <td>0.922674</td>\n      <td>1.208446</td>\n      <td>0.908065</td>\n      <td>1.307383</td>\n      <td>2.056547</td>\n      <td>2.325010</td>\n    </tr>\n    <tr>\n      <th>1210</th>\n      <td>10025</td>\n      <td>653</td>\n      <td>174.780357</td>\n      <td>113.102274</td>\n      <td>2012</td>\n      <td>20.3276</td>\n      <td>15.0</td>\n      <td>-0.899741</td>\n      <td>0.072943</td>\n      <td>0.362002</td>\n      <td>0.184931</td>\n      <td>7.1633</td>\n      <td>72.766685</td>\n      <td>0.949094</td>\n      <td>1.120278</td>\n      <td>0.963537</td>\n      <td>1.038772</td>\n      <td>4.3231</td>\n      <td>1.269428</td>\n      <td>1.271617</td>\n      <td>2.116573</td>\n      <td>0.335306</td>\n      <td>5.628101</td>\n      <td>-0.953163</td>\n      <td>0.060639</td>\n      <td>0.373348</td>\n      <td>-0.025756</td>\n      <td>5.005778</td>\n      <td>1.047262</td>\n      <td>3.1364</td>\n      <td>0.578902</td>\n      <td>1.141539</td>\n      <td>1.4066</td>\n      <td>0.579206</td>\n      <td>1.369098</td>\n      <td>3.7563</td>\n      <td>0.490055</td>\n      <td>1.523562</td>\n      <td>3.1364</td>\n      <td>0.681302</td>\n      <td>14.425587</td>\n      <td>2.072178</td>\n      <td>1.968630</td>\n      <td>1.081815</td>\n      <td>2.335976</td>\n      <td>2.367897</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    66111.000000\nmean      2013.422970\nstd          1.009211\nmin       2012.000000\n25%       2013.000000\n50%       2013.000000\n75%       2014.000000\nmax       2015.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          66111\nprd             66111\nmom482          62388\nmom242          65530\nyear            66111\nRET             66111\nind             66111\nbm              66111\nop              66111\ngp              66111\ninv             66000\nmom11           66111\nmom122          66111\namhd            64693\nivol_capm       66109\nivol_ff5        66109\nbeta_bw         66111\nMAX             66111\nvol1m           66108\nvol6m           66066\nvol12m          65985\nBAspr           66022\nsize            66111\nlbm             66111\nlop             66111\nlgp             66111\nlinv            66111\nllme            66111\nl1amhd          64677\nl1MAX           66107\nl1BAspr         66017\nl3amhd          64655\nl3MAX           66100\nl3BAspr         65998\nl6amhd          64619\nl6MAX           66093\nl6BAspr         65978\nl12amhd         64571\nl12MAX          66107\nl12BAspr        65935\nl12mom122       66049\nl12ivol_capm    66076\nl12ivol_ff5     66076\nl12beta_bw      66081\nl12vol6m        66057\nl12vol12m       65726\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (62745, 44)\ntime to do feature proprocessing: \nNumber of features after transformation:  (62745, 92)\nmae of a constant model 7.4311450540111785\nR2 of a constant model 0.0\nXGB train: 7.102998486516917 0.11496400870943368\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.8s\nXGB {'colsample_bytree': 0.6, 'eta': 0.012, 'max_depth': 4, 'n_estimators': 400, 'subsample': 0.6} 0.010883872969200015 41.69571256637573\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:23:36,984]\u001b[0m A new study created in memory with name: no-name-6a78c6b3-c4c3-4944-821b-b3267daab7f2\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 7.285970160193694 0.04909639497219265 42.33363389968872\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:23:41,820]\u001b[0m Trial 0 finished with value: 0.005934044239519656 and parameters: {'n_estimators': 898, 'max_depth': 3, 'learning_rate': 0.013970707160544726, 'colsample_bytree': 0.8448742919963662, 'subsample': 0.3896946637885105, 'alpha': 0.4208552572168877, 'lambda': 79.98885655352393, 'gamma': 1.5171802297443182e-06, 'min_child_weight': 0.7178420046803845}. Best is trial 0 with value: 0.005934044239519656.\u001b[0m\n\u001b[32m[I 2022-08-25 21:23:47,359]\u001b[0m Trial 1 finished with value: 0.004510653682763724 and parameters: {'n_estimators': 937, 'max_depth': 3, 'learning_rate': 0.019082538960682405, 'colsample_bytree': 0.9063572459045574, 'subsample': 0.34944577971150903, 'alpha': 0.24312218987902928, 'lambda': 37.06873922960986, 'gamma': 2.0386676291445407, 'min_child_weight': 4.32935086765049}. Best is trial 0 with value: 0.005934044239519656.\u001b[0m\n\u001b[32m[I 2022-08-25 21:23:49,997]\u001b[0m Trial 2 finished with value: 0.007682508625491711 and parameters: {'n_estimators': 512, 'max_depth': 2, 'learning_rate': 0.02355465336124448, 'colsample_bytree': 0.18846806868936156, 'subsample': 0.6390724731644855, 'alpha': 0.49434609192819373, 'lambda': 6.315117033205517, 'gamma': 1.771242911412047e-05, 'min_child_weight': 18.90655487448263}. Best is trial 2 with value: 0.007682508625491711.\u001b[0m\n\u001b[32m[I 2022-08-25 21:23:59,021]\u001b[0m Trial 3 finished with value: -0.0015905290697734806 and parameters: {'n_estimators': 954, 'max_depth': 5, 'learning_rate': 0.024801245789294202, 'colsample_bytree': 0.5434329356782491, 'subsample': 0.5830273298672656, 'alpha': 0.3089590072391867, 'lambda': 113.25981094915991, 'gamma': 0.007151473670973936, 'min_child_weight': 0.45894809559011335}. Best is trial 2 with value: 0.007682508625491711.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:04,066]\u001b[0m Trial 4 finished with value: -0.010796253011051752 and parameters: {'n_estimators': 970, 'max_depth': 3, 'learning_rate': 0.049959047329594025, 'colsample_bytree': 0.6111247720093924, 'subsample': 0.9101863134387038, 'alpha': 2.3140542481337563, 'lambda': 4.377946624934059, 'gamma': 0.0011966207185847794, 'min_child_weight': 0.1453400448197522}. Best is trial 2 with value: 0.007682508625491711.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:11,258]\u001b[0m Trial 5 finished with value: 0.007280087367237705 and parameters: {'n_estimators': 675, 'max_depth': 5, 'learning_rate': 0.006685698584848828, 'colsample_bytree': 0.7109982219468034, 'subsample': 0.7235323418021058, 'alpha': 0.428218312066363, 'lambda': 1.1131067598881312, 'gamma': 8.579146401299426e-06, 'min_child_weight': 0.825025404055102}. Best is trial 2 with value: 0.007682508625491711.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:14,387]\u001b[0m Trial 6 finished with value: 0.006129942538408463 and parameters: {'n_estimators': 726, 'max_depth': 2, 'learning_rate': 0.03562195194689199, 'colsample_bytree': 0.7353218593578998, 'subsample': 0.8991510332367436, 'alpha': 0.2636463662312138, 'lambda': 1.4309347098137883, 'gamma': 5.505408281834819e-07, 'min_child_weight': 4.244262725369623}. Best is trial 2 with value: 0.007682508625491711.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:19,525]\u001b[0m Trial 7 finished with value: 0.008020749423278458 and parameters: {'n_estimators': 725, 'max_depth': 4, 'learning_rate': 0.005917886008591802, 'colsample_bytree': 0.8383921323236418, 'subsample': 0.596051956198635, 'alpha': 1.206756651523015, 'lambda': 0.11477974950988616, 'gamma': 5.4941699653719436e-05, 'min_child_weight': 9.888423257026068}. Best is trial 7 with value: 0.008020749423278458.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:25,509]\u001b[0m Trial 8 finished with value: 0.0031061794007688427 and parameters: {'n_estimators': 844, 'max_depth': 4, 'learning_rate': 0.009392587005711404, 'colsample_bytree': 0.7730483977266644, 'subsample': 0.35609937028935446, 'alpha': 0.10017149206316724, 'lambda': 0.1850746824665275, 'gamma': 2.9184708754882664, 'min_child_weight': 1.5773863361073566}. Best is trial 7 with value: 0.008020749423278458.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:28,804]\u001b[0m Trial 9 finished with value: 0.004328942537517125 and parameters: {'n_estimators': 777, 'max_depth': 2, 'learning_rate': 0.035674031474060945, 'colsample_bytree': 0.6864010337850052, 'subsample': 0.5401065555544133, 'alpha': 18.14297877028838, 'lambda': 2.503928052008436, 'gamma': 1.7103940601795637, 'min_child_weight': 0.47789692156323704}. Best is trial 7 with value: 0.008020749423278458.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:33,207]\u001b[0m Trial 10 finished with value: 0.005163796679411193 and parameters: {'n_estimators': 604, 'max_depth': 4, 'learning_rate': 0.0012720838621175087, 'colsample_bytree': 0.3511110820980935, 'subsample': 0.7646412115661501, 'alpha': 3.538746241515016, 'lambda': 0.12073586055916034, 'gamma': 1.1837067256628842e-09, 'min_child_weight': 42.53552185339476}. Best is trial 7 with value: 0.008020749423278458.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:36,640]\u001b[0m Trial 11 finished with value: 0.003709421509684456 and parameters: {'n_estimators': 507, 'max_depth': 4, 'learning_rate': 0.03226681270110511, 'colsample_bytree': 0.12960151728500774, 'subsample': 0.48956030468460787, 'alpha': 1.037572582964651, 'lambda': 16.346933697927604, 'gamma': 1.0998601097400611e-08, 'min_child_weight': 18.949322669554903}. Best is trial 7 with value: 0.008020749423278458.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:38,991]\u001b[0m Trial 12 finished with value: 0.008443010429265136 and parameters: {'n_estimators': 510, 'max_depth': 2, 'learning_rate': 0.021162238896934037, 'colsample_bytree': 0.36530353194811915, 'subsample': 0.7321694071209546, 'alpha': 6.6075932487546725, 'lambda': 0.415654343377241, 'gamma': 0.0005586194310638386, 'min_child_weight': 13.071590336522696}. Best is trial 12 with value: 0.008443010429265136.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:43,188]\u001b[0m Trial 13 finished with value: 0.0037272399836576764 and parameters: {'n_estimators': 598, 'max_depth': 4, 'learning_rate': 0.016181808979187372, 'colsample_bytree': 0.42415456243971916, 'subsample': 0.7244330515929962, 'alpha': 8.362344160013176, 'lambda': 0.30952654453621853, 'gamma': 0.001096556935762985, 'min_child_weight': 9.096374393031237}. Best is trial 12 with value: 0.008443010429265136.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:47,052]\u001b[0m Trial 14 finished with value: 0.008382291796847926 and parameters: {'n_estimators': 595, 'max_depth': 3, 'learning_rate': 0.004720445390254036, 'colsample_bytree': 0.2787025503384495, 'subsample': 0.8182277364610779, 'alpha': 6.68794370278391, 'lambda': 0.45891383710227945, 'gamma': 0.03023424161917935, 'min_child_weight': 9.406085886478957}. Best is trial 12 with value: 0.008443010429265136.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:49,711]\u001b[0m Trial 15 finished with value: 0.006326628650009228 and parameters: {'n_estimators': 596, 'max_depth': 2, 'learning_rate': 0.04485642567258348, 'colsample_bytree': 0.30731347196154785, 'subsample': 0.8163826809436976, 'alpha': 6.747821184107125, 'lambda': 0.5208532978398769, 'gamma': 0.08882430138612557, 'min_child_weight': 49.001090262186615}. Best is trial 12 with value: 0.008443010429265136.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:53,136]\u001b[0m Trial 16 finished with value: 0.008893848798401294 and parameters: {'n_estimators': 647, 'max_depth': 3, 'learning_rate': 0.012450448458307003, 'colsample_bytree': 0.24137118054832493, 'subsample': 0.8316929767773923, 'alpha': 29.93291444686363, 'lambda': 0.5837812878112858, 'gamma': 0.04927291921313879, 'min_child_weight': 3.72748330467612}. Best is trial 16 with value: 0.008893848798401294.\u001b[0m\n\u001b[32m[I 2022-08-25 21:24:56,373]\u001b[0m Trial 17 finished with value: 0.007070284595860903 and parameters: {'n_estimators': 658, 'max_depth': 2, 'learning_rate': 0.012010272770373314, 'colsample_bytree': 0.43193402753016347, 'subsample': 0.6731182370258946, 'alpha': 26.78710988096989, 'lambda': 0.8880401298508471, 'gamma': 0.0004800520045978346, 'min_child_weight': 2.7578500064819487}. Best is trial 16 with value: 0.008893848798401294.\u001b[0m\n\u001b[32m[I 2022-08-25 21:25:00,395]\u001b[0m Trial 18 finished with value: 0.0037073897785783252 and parameters: {'n_estimators': 788, 'max_depth': 3, 'learning_rate': 0.029486704168953073, 'colsample_bytree': 0.20047122292641156, 'subsample': 0.8526577556417476, 'alpha': 14.68131628348842, 'lambda': 11.698737070600957, 'gamma': 0.1641896545268369, 'min_child_weight': 1.8545722892421794}. Best is trial 16 with value: 0.008893848798401294.\u001b[0m\n\u001b[32m[I 2022-08-25 21:25:02,861]\u001b[0m Trial 19 finished with value: 0.006382431907946266 and parameters: {'n_estimators': 545, 'max_depth': 2, 'learning_rate': 0.01985476177318022, 'colsample_bytree': 0.42233601697961043, 'subsample': 0.9367194252763914, 'alpha': 28.311807275084522, 'lambda': 0.26575454614334615, 'gamma': 3.205938777457568e-08, 'min_child_weight': 23.759304323946125}. Best is trial 16 with value: 0.008893848798401294.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  85.87788891792297\n        n_estimators : 647\n           max_depth : 3\n       learning_rate : 0.012450448458307003\n    colsample_bytree : 0.24137118054832493\n           subsample : 0.8316929767773923\n               alpha : 29.93291444686363\n              lambda : 0.5837812878112858\n               gamma : 0.04927291921313879\n    min_child_weight : 3.72748330467612\nbest objective value : 0.008893848798401294\nOptuna XGB train: 7.32321188261344 0.03272832722748553 87.77718997001648\nMin_prd:  650\nConstant guess:  6.455628673143056 0.0\nXGB test: 6.3659382164190115 0.04702019993165385\nXGB GS test: 6.3439868155999255 0.04081648160705098\nOptuna XGB test: 6.321963503175968 0.04786719426337405\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(60932, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"      PERMNO  prd     mom482     mom242  year      RET   ind        bm  \\\n1231   10025  674  27.416551 -18.319600  2014   9.4132  15.0 -1.270650   \n1232   10025  675  28.555097 -19.497988  2014  16.8626  15.0 -0.980287   \n1233   10025  676  68.314359 -15.979361  2014   3.9264  15.0 -0.980287   \n1234   10025  677  80.406968 -28.051947  2014 -10.5785  15.0 -0.980287   \n1235   10025  678  58.245350 -41.759961  2014  21.4418  15.0 -0.980287   \n\n            op        gp       inv    mom11     mom122      amhd  ivol_capm  \\\n1231  0.139710  0.476473  0.037948 -10.5278 -57.331083 -0.453503   1.169023   \n1232  0.091844  0.388207  0.092990   9.4132 -57.158226 -0.219798   3.222446   \n1233  0.091844  0.388207  0.092990  16.8626 -56.790596 -0.112437   2.092630   \n1234  0.091844  0.388207  0.092990   3.9264 -47.916712 -0.058889   0.850280   \n1235  0.091844  0.388207  0.092990 -10.5785 -43.009059  0.128252   2.112572   \n\n      ivol_ff5   beta_bw      MAX     vol1m     vol6m    vol12m     BAspr  \\\n1231  0.920656  0.869967   1.4066  1.272945  2.137565  2.669958  0.550875   \n1232  2.820006  1.011708  10.1363  3.617839  2.391608  2.532018  0.622463   \n1233  1.927199  1.034622   5.9650  2.230764  2.446523  2.631069  0.768849   \n1234  0.806903  1.000746   2.4426  0.866870  2.346222  2.599881  0.383401   \n1235  1.657760  0.983134   4.6989  2.239950  2.203089  2.253126  0.189343   \n\n          size       lbm       lop       lgp      linv      llme    l1amhd  \\\n1231  5.087173 -0.899741  0.072943  0.362002  0.184931  6.146838 -0.530406   \n1232  5.177135 -1.270650  0.139710  0.476473  0.037948  6.031552 -0.453503   \n1233  5.332964 -1.270650  0.139710  0.476473  0.037948  6.113684 -0.219798   \n1234  5.371477 -1.270650  0.139710  0.476473  0.037948  6.082726 -0.112437   \n1235  5.259667 -1.270650  0.139710  0.476473  0.037948  6.031191 -0.058889   \n\n        l1MAX   l1BAspr    l3amhd    l3MAX   l3BAspr    l6amhd   l6MAX  \\\n1231   2.3184  0.462161 -0.798248   3.9944  0.182274 -0.646577  2.3122   \n1232   1.4066  0.550875 -0.613690   2.9798  0.450450 -0.782280  6.1561   \n1233  10.1363  0.622463 -0.530406   2.3184  0.462161 -0.793291  3.5475   \n1234   5.9650  0.768849 -0.453503   1.4066  0.550875 -0.798248  3.9944   \n1235   2.4426  0.383401 -0.219798  10.1363  0.622463 -0.613690  2.9798   \n\n       l6BAspr   l12amhd   l12MAX  l12BAspr   l12mom122  l12ivol_capm  \\\n1231  0.342742 -0.354324   2.3184  0.047699  105.899232      1.154988   \n1232  0.245098 -0.396455   1.4066  0.040102   91.596131      4.875088   \n1233  0.454002 -0.403102  10.1363  0.394964   58.268392      0.765013   \n1234  0.182274 -0.466285   5.9650  0.064045   60.216410      1.443863   \n1235  0.450450 -0.538077   2.4426  0.139451   29.091358      5.116995   \n\n      l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n1231     1.042161    0.759380  1.379997   1.399697  \n1232     4.522004    0.821775  2.256988   1.924399  \n1233     0.654865    0.827337  2.210333   1.880524  \n1234     1.275272    0.847987  2.247112   1.909812  \n1235     4.540554    0.901574  3.008285   2.369508  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1231</th>\n      <td>10025</td>\n      <td>674</td>\n      <td>27.416551</td>\n      <td>-18.319600</td>\n      <td>2014</td>\n      <td>9.4132</td>\n      <td>15.0</td>\n      <td>-1.270650</td>\n      <td>0.139710</td>\n      <td>0.476473</td>\n      <td>0.037948</td>\n      <td>-10.5278</td>\n      <td>-57.331083</td>\n      <td>-0.453503</td>\n      <td>1.169023</td>\n      <td>0.920656</td>\n      <td>0.869967</td>\n      <td>1.4066</td>\n      <td>1.272945</td>\n      <td>2.137565</td>\n      <td>2.669958</td>\n      <td>0.550875</td>\n      <td>5.087173</td>\n      <td>-0.899741</td>\n      <td>0.072943</td>\n      <td>0.362002</td>\n      <td>0.184931</td>\n      <td>6.146838</td>\n      <td>-0.530406</td>\n      <td>2.3184</td>\n      <td>0.462161</td>\n      <td>-0.798248</td>\n      <td>3.9944</td>\n      <td>0.182274</td>\n      <td>-0.646577</td>\n      <td>2.3122</td>\n      <td>0.342742</td>\n      <td>-0.354324</td>\n      <td>2.3184</td>\n      <td>0.047699</td>\n      <td>105.899232</td>\n      <td>1.154988</td>\n      <td>1.042161</td>\n      <td>0.759380</td>\n      <td>1.379997</td>\n      <td>1.399697</td>\n    </tr>\n    <tr>\n      <th>1232</th>\n      <td>10025</td>\n      <td>675</td>\n      <td>28.555097</td>\n      <td>-19.497988</td>\n      <td>2014</td>\n      <td>16.8626</td>\n      <td>15.0</td>\n      <td>-0.980287</td>\n      <td>0.091844</td>\n      <td>0.388207</td>\n      <td>0.092990</td>\n      <td>9.4132</td>\n      <td>-57.158226</td>\n      <td>-0.219798</td>\n      <td>3.222446</td>\n      <td>2.820006</td>\n      <td>1.011708</td>\n      <td>10.1363</td>\n      <td>3.617839</td>\n      <td>2.391608</td>\n      <td>2.532018</td>\n      <td>0.622463</td>\n      <td>5.177135</td>\n      <td>-1.270650</td>\n      <td>0.139710</td>\n      <td>0.476473</td>\n      <td>0.037948</td>\n      <td>6.031552</td>\n      <td>-0.453503</td>\n      <td>1.4066</td>\n      <td>0.550875</td>\n      <td>-0.613690</td>\n      <td>2.9798</td>\n      <td>0.450450</td>\n      <td>-0.782280</td>\n      <td>6.1561</td>\n      <td>0.245098</td>\n      <td>-0.396455</td>\n      <td>1.4066</td>\n      <td>0.040102</td>\n      <td>91.596131</td>\n      <td>4.875088</td>\n      <td>4.522004</td>\n      <td>0.821775</td>\n      <td>2.256988</td>\n      <td>1.924399</td>\n    </tr>\n    <tr>\n      <th>1233</th>\n      <td>10025</td>\n      <td>676</td>\n      <td>68.314359</td>\n      <td>-15.979361</td>\n      <td>2014</td>\n      <td>3.9264</td>\n      <td>15.0</td>\n      <td>-0.980287</td>\n      <td>0.091844</td>\n      <td>0.388207</td>\n      <td>0.092990</td>\n      <td>16.8626</td>\n      <td>-56.790596</td>\n      <td>-0.112437</td>\n      <td>2.092630</td>\n      <td>1.927199</td>\n      <td>1.034622</td>\n      <td>5.9650</td>\n      <td>2.230764</td>\n      <td>2.446523</td>\n      <td>2.631069</td>\n      <td>0.768849</td>\n      <td>5.332964</td>\n      <td>-1.270650</td>\n      <td>0.139710</td>\n      <td>0.476473</td>\n      <td>0.037948</td>\n      <td>6.113684</td>\n      <td>-0.219798</td>\n      <td>10.1363</td>\n      <td>0.622463</td>\n      <td>-0.530406</td>\n      <td>2.3184</td>\n      <td>0.462161</td>\n      <td>-0.793291</td>\n      <td>3.5475</td>\n      <td>0.454002</td>\n      <td>-0.403102</td>\n      <td>10.1363</td>\n      <td>0.394964</td>\n      <td>58.268392</td>\n      <td>0.765013</td>\n      <td>0.654865</td>\n      <td>0.827337</td>\n      <td>2.210333</td>\n      <td>1.880524</td>\n    </tr>\n    <tr>\n      <th>1234</th>\n      <td>10025</td>\n      <td>677</td>\n      <td>80.406968</td>\n      <td>-28.051947</td>\n      <td>2014</td>\n      <td>-10.5785</td>\n      <td>15.0</td>\n      <td>-0.980287</td>\n      <td>0.091844</td>\n      <td>0.388207</td>\n      <td>0.092990</td>\n      <td>3.9264</td>\n      <td>-47.916712</td>\n      <td>-0.058889</td>\n      <td>0.850280</td>\n      <td>0.806903</td>\n      <td>1.000746</td>\n      <td>2.4426</td>\n      <td>0.866870</td>\n      <td>2.346222</td>\n      <td>2.599881</td>\n      <td>0.383401</td>\n      <td>5.371477</td>\n      <td>-1.270650</td>\n      <td>0.139710</td>\n      <td>0.476473</td>\n      <td>0.037948</td>\n      <td>6.082726</td>\n      <td>-0.112437</td>\n      <td>5.9650</td>\n      <td>0.768849</td>\n      <td>-0.453503</td>\n      <td>1.4066</td>\n      <td>0.550875</td>\n      <td>-0.798248</td>\n      <td>3.9944</td>\n      <td>0.182274</td>\n      <td>-0.466285</td>\n      <td>5.9650</td>\n      <td>0.064045</td>\n      <td>60.216410</td>\n      <td>1.443863</td>\n      <td>1.275272</td>\n      <td>0.847987</td>\n      <td>2.247112</td>\n      <td>1.909812</td>\n    </tr>\n    <tr>\n      <th>1235</th>\n      <td>10025</td>\n      <td>678</td>\n      <td>58.245350</td>\n      <td>-41.759961</td>\n      <td>2014</td>\n      <td>21.4418</td>\n      <td>15.0</td>\n      <td>-0.980287</td>\n      <td>0.091844</td>\n      <td>0.388207</td>\n      <td>0.092990</td>\n      <td>-10.5785</td>\n      <td>-43.009059</td>\n      <td>0.128252</td>\n      <td>2.112572</td>\n      <td>1.657760</td>\n      <td>0.983134</td>\n      <td>4.6989</td>\n      <td>2.239950</td>\n      <td>2.203089</td>\n      <td>2.253126</td>\n      <td>0.189343</td>\n      <td>5.259667</td>\n      <td>-1.270650</td>\n      <td>0.139710</td>\n      <td>0.476473</td>\n      <td>0.037948</td>\n      <td>6.031191</td>\n      <td>-0.058889</td>\n      <td>2.4426</td>\n      <td>0.383401</td>\n      <td>-0.219798</td>\n      <td>10.1363</td>\n      <td>0.622463</td>\n      <td>-0.613690</td>\n      <td>2.9798</td>\n      <td>0.450450</td>\n      <td>-0.538077</td>\n      <td>2.4426</td>\n      <td>0.139451</td>\n      <td>29.091358</td>\n      <td>5.116995</td>\n      <td>4.540554</td>\n      <td>0.901574</td>\n      <td>3.008285</td>\n      <td>2.369508</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    60932.000000\nmean      2015.503381\nstd          1.010979\nmin       2014.000000\n25%       2015.000000\n50%       2015.000000\n75%       2016.000000\nmax       2017.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          60932\nprd             60932\nmom482          57428\nmom242          60392\nyear            60932\nRET             60932\nind             60932\nbm              60932\nop              60932\ngp              60932\ninv             60785\nmom11           60932\nmom122          60932\namhd            59954\nivol_capm       60931\nivol_ff5        60931\nbeta_bw         60932\nMAX             60932\nvol1m           60930\nvol6m           60881\nvol12m          60786\nBAspr           60867\nsize            60932\nlbm             60932\nlop             60932\nlgp             60932\nlinv            60932\nllme            60932\nl1amhd          59947\nl1MAX           60931\nl1BAspr         60866\nl3amhd          59929\nl3MAX           60920\nl3BAspr         60857\nl6amhd          59887\nl6MAX           60915\nl6BAspr         60850\nl12amhd         59810\nl12MAX          60931\nl12BAspr        60810\nl12mom122       60888\nl12ivol_capm    60916\nl12ivol_ff5     60916\nl12beta_bw      60919\nl12vol6m        60896\nl12vol12m       60618\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"Number of features before transformation:  (57612, 44)\ntime to do feature proprocessing: \nNumber of features after transformation:  (57612, 92)\nmae of a constant model 7.844483176058157\nR2 of a constant model 0.0\nXGB train: 7.463082080313984 0.12777261074441615\nFitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.7s\nXGB {'colsample_bytree': 0.6, 'eta': 0.006, 'max_depth': 4, 'n_estimators': 700, 'subsample': 0.6} 0.011422581980888358 40.05857849121094\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:25:49,601]\u001b[0m A new study created in memory with name: no-name-03400079-7a3f-44ca-8908-de03a1096848\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"XGB train: 7.698325588684248 0.05027393848590822 41.73289680480957\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-08-25 21:25:58,855]\u001b[0m Trial 0 finished with value: -0.017507152426829303 and parameters: {'n_estimators': 944, 'max_depth': 5, 'learning_rate': 0.02173842376668825, 'colsample_bytree': 0.7059334365524941, 'subsample': 0.4516252398816166, 'alpha': 19.95713097370607, 'lambda': 0.4772871198201621, 'gamma': 9.308233133556265e-05, 'min_child_weight': 6.005904061507015}. Best is trial 0 with value: -0.017507152426829303.\u001b[0m\n\u001b[32m[I 2022-08-25 21:26:05,029]\u001b[0m Trial 1 finished with value: 0.004789122681059692 and parameters: {'n_estimators': 932, 'max_depth': 4, 'learning_rate': 0.019002484298095177, 'colsample_bytree': 0.5365596807266103, 'subsample': 0.6844164371402591, 'alpha': 23.59544126090816, 'lambda': 38.07860697981912, 'gamma': 1.6254762635028171e-07, 'min_child_weight': 4.237638540528578}. Best is trial 1 with value: 0.004789122681059692.\u001b[0m\n\u001b[32m[I 2022-08-25 21:26:11,215]\u001b[0m Trial 2 finished with value: 0.0010626717378536907 and parameters: {'n_estimators': 652, 'max_depth': 5, 'learning_rate': 0.027169484039709153, 'colsample_bytree': 0.7081160585251017, 'subsample': 0.5550755602955626, 'alpha': 0.462287462088571, 'lambda': 142.15944056739343, 'gamma': 7.612276125171508e-05, 'min_child_weight': 34.006566437171436}. Best is trial 1 with value: 0.004789122681059692.\u001b[0m\n\u001b[32m[I 2022-08-25 21:26:17,733]\u001b[0m Trial 3 finished with value: -0.024495303479829346 and parameters: {'n_estimators': 970, 'max_depth': 4, 'learning_rate': 0.03774518557435947, 'colsample_bytree': 0.5920763480342962, 'subsample': 0.37276832077670924, 'alpha': 4.373862409350456, 'lambda': 5.3112845592527576, 'gamma': 0.13823306106944772, 'min_child_weight': 0.18855754871013505}. Best is trial 1 with value: 0.004789122681059692.\u001b[0m\n\u001b[32m[I 2022-08-25 21:26:22,267]\u001b[0m Trial 4 finished with value: 0.00957319463777004 and parameters: {'n_estimators': 702, 'max_depth': 4, 'learning_rate': 0.009773996926948619, 'colsample_bytree': 0.28548806487990236, 'subsample': 0.39371314521362294, 'alpha': 2.333391932609493, 'lambda': 7.697614969256187, 'gamma': 3.601869207919838e-08, 'min_child_weight': 0.21120230888788397}. Best is trial 4 with value: 0.00957319463777004.\u001b[0m\n\u001b[32m[I 2022-08-25 21:26:25,227]\u001b[0m Trial 5 finished with value: 0.003552738739744119 and parameters: {'n_estimators': 536, 'max_depth': 3, 'learning_rate': 0.03607027944155595, 'colsample_bytree': 0.21719309735276215, 'subsample': 0.41245925068242206, 'alpha': 5.013018810714203, 'lambda': 0.18477594172476255, 'gamma': 5.776735833210497e-06, 'min_child_weight': 10.017694804100994}. Best is trial 4 with value: 0.00957319463777004.\u001b[0m\n\u001b[32m[I 2022-08-25 21:26:29,990]\u001b[0m Trial 6 finished with value: 0.004691064023246288 and parameters: {'n_estimators': 985, 'max_depth': 3, 'learning_rate': 0.028777673761537642, 'colsample_bytree': 0.534833505384314, 'subsample': 0.8120384422834308, 'alpha': 0.9797845536479598, 'lambda': 11.364982303169537, 'gamma': 6.425725315443229e-08, 'min_child_weight': 1.1821063874422995}. Best is trial 4 with value: 0.00957319463777004.\u001b[0m\n\u001b[32m[I 2022-08-25 21:26:38,502]\u001b[0m Trial 7 finished with value: -0.0415385894161204 and parameters: {'n_estimators': 866, 'max_depth': 5, 'learning_rate': 0.03634507560752237, 'colsample_bytree': 0.6233721410329139, 'subsample': 0.45311091349327376, 'alpha': 8.038851506088694, 'lambda': 0.19184615199099048, 'gamma': 0.011507629224016977, 'min_child_weight': 0.28629155973731873}. Best is trial 4 with value: 0.00957319463777004.\u001b[0m\n\u001b[32m[I 2022-08-25 21:26:42,222]\u001b[0m Trial 8 finished with value: 0.0048715421836549025 and parameters: {'n_estimators': 930, 'max_depth': 2, 'learning_rate': 0.034786626536694336, 'colsample_bytree': 0.8687212511293769, 'subsample': 0.692497867113415, 'alpha': 5.17435278602513, 'lambda': 46.172735728741806, 'gamma': 1.1071226930523469e-06, 'min_child_weight': 0.5798279223586894}. Best is trial 4 with value: 0.00957319463777004.\u001b[0m\n\u001b[32m[I 2022-08-25 21:26:46,469]\u001b[0m Trial 9 finished with value: 0.00798587796162117 and parameters: {'n_estimators': 798, 'max_depth': 3, 'learning_rate': 0.013859317401148423, 'colsample_bytree': 0.6921406621757347, 'subsample': 0.5088044830887437, 'alpha': 0.20414502050721026, 'lambda': 2.387696197913827, 'gamma': 8.25800524501939, 'min_child_weight': 0.11205576845095148}. Best is trial 4 with value: 0.00957319463777004.\u001b[0m\n\u001b[32m[I 2022-08-25 21:26:49,317]\u001b[0m Trial 10 finished with value: 0.005964568211797677 and parameters: {'n_estimators': 687, 'max_depth': 2, 'learning_rate': 0.0017844584435304477, 'colsample_bytree': 0.2600131151467831, 'subsample': 0.30044582091040234, 'alpha': 1.5283872830978062, 'lambda': 0.918228281416255, 'gamma': 1.5089441429555805e-10, 'min_child_weight': 1.2350289261453657}. Best is trial 4 with value: 0.00957319463777004.\u001b[0m\n\u001b[32m[I 2022-08-25 21:26:53,435]\u001b[0m Trial 11 finished with value: 0.009907753561876325 and parameters: {'n_estimators': 793, 'max_depth': 3, 'learning_rate': 0.010300627820434713, 'colsample_bytree': 0.33457590209840554, 'subsample': 0.5718802927973824, 'alpha': 0.1358392575022072, 'lambda': 2.1362520528108684, 'gamma': 9.423764187408858, 'min_child_weight': 0.10825190782765673}. Best is trial 11 with value: 0.009907753561876325.\u001b[0m\n\u001b[32m[I 2022-08-25 21:26:58,652]\u001b[0m Trial 12 finished with value: 0.009150636584316515 and parameters: {'n_estimators': 753, 'max_depth': 4, 'learning_rate': 0.007345363658071324, 'colsample_bytree': 0.3329164729242362, 'subsample': 0.5962371924886186, 'alpha': 0.10624683195623882, 'lambda': 1.9433251106711096, 'gamma': 6.978303172026209e-10, 'min_child_weight': 0.1047134208488779}. Best is trial 11 with value: 0.009907753561876325.\u001b[0m\n\u001b[32m[I 2022-08-25 21:27:01,811]\u001b[0m Trial 13 finished with value: 0.009769024069006479 and parameters: {'n_estimators': 613, 'max_depth': 3, 'learning_rate': 0.011723202333668106, 'colsample_bytree': 0.3976236290889235, 'subsample': 0.8986838657018781, 'alpha': 0.5030576080890209, 'lambda': 10.645270815073799, 'gamma': 8.725840263721447e-09, 'min_child_weight': 0.3944210673070814}. Best is trial 11 with value: 0.009907753561876325.\u001b[0m\n\u001b[32m[I 2022-08-25 21:27:04,221]\u001b[0m Trial 14 finished with value: 0.007041223625971057 and parameters: {'n_estimators': 563, 'max_depth': 2, 'learning_rate': 0.04702387729948142, 'colsample_bytree': 0.10566675152473165, 'subsample': 0.8795428642862848, 'alpha': 0.37542854377992363, 'lambda': 14.182334824859126, 'gamma': 0.0036087302172136512, 'min_child_weight': 0.49688963013819054}. Best is trial 11 with value: 0.009907753561876325.\u001b[0m\n\u001b[32m[I 2022-08-25 21:27:08,584]\u001b[0m Trial 15 finished with value: 0.0070503406373908515 and parameters: {'n_estimators': 825, 'max_depth': 3, 'learning_rate': 0.0012316346569618518, 'colsample_bytree': 0.3850311572614793, 'subsample': 0.9407469611532292, 'alpha': 0.1004276033758638, 'lambda': 1.6747743704516438, 'gamma': 9.378026015045295, 'min_child_weight': 0.5318987795683937}. Best is trial 11 with value: 0.009907753561876325.\u001b[0m\n\u001b[32m[I 2022-08-25 21:27:11,688]\u001b[0m Trial 16 finished with value: 0.011918020633176344 and parameters: {'n_estimators': 601, 'max_depth': 3, 'learning_rate': 0.015196251991589521, 'colsample_bytree': 0.41612524983927524, 'subsample': 0.764846491142368, 'alpha': 0.5476846156741678, 'lambda': 25.534537192933342, 'gamma': 2.2101698854530036e-09, 'min_child_weight': 1.540181610474194}. Best is trial 16 with value: 0.011918020633176344.\u001b[0m\n\u001b[32m[I 2022-08-25 21:27:13,887]\u001b[0m Trial 17 finished with value: 0.00923616849435402 and parameters: {'n_estimators': 500, 'max_depth': 2, 'learning_rate': 0.01618167161803438, 'colsample_bytree': 0.45478989055711194, 'subsample': 0.7541225824470876, 'alpha': 0.22668385426158774, 'lambda': 34.249690939408474, 'gamma': 0.001093980177587329, 'min_child_weight': 15.576279194767038}. Best is trial 16 with value: 0.011918020633176344.\u001b[0m\n\u001b[32m[I 2022-08-25 21:27:17,694]\u001b[0m Trial 18 finished with value: 0.008149707895147677 and parameters: {'n_estimators': 738, 'max_depth': 3, 'learning_rate': 0.022332696980980674, 'colsample_bytree': 0.1430229855738126, 'subsample': 0.6602959488775321, 'alpha': 0.9271376765734434, 'lambda': 149.67843065091753, 'gamma': 0.21248391931850572, 'min_child_weight': 2.5102376029243287}. Best is trial 16 with value: 0.011918020633176344.\u001b[0m\n\u001b[32m[I 2022-08-25 21:27:21,869]\u001b[0m Trial 19 finished with value: 0.011155758668312888 and parameters: {'n_estimators': 592, 'max_depth': 4, 'learning_rate': 0.005528077437686357, 'colsample_bytree': 0.4482652208308458, 'subsample': 0.7862690385626024, 'alpha': 0.2051846894362773, 'lambda': 0.6322509543543927, 'gamma': 4.066732170103544e-09, 'min_child_weight': 1.4250058123789575}. Best is trial 16 with value: 0.011918020633176344.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  92.27102971076965\n        n_estimators : 601\n           max_depth : 3\n       learning_rate : 0.015196251991589521\n    colsample_bytree : 0.41612524983927524\n           subsample : 0.764846491142368\n               alpha : 0.5476846156741678\n              lambda : 25.534537192933342\n               gamma : 2.2101698854530036e-09\n    min_child_weight : 1.540181610474194\nbest objective value : 0.011918020633176344\nOptuna XGB train: 7.7165973749988765 0.04007504337618861 93.96981620788574\nMin_prd:  675\nConstant guess:  6.559515936576189 0.0\nXGB test: 6.606500270058161 -0.025128448860597175\nXGB GS test: 6.587640379139121 -0.010631009835597505\nOptuna XGB test: 6.5926129951965695 -0.008785808551218466\n3660.1989362239838     min_prd      xgbf     xgbgs      xgbo\n0       100 -0.033926 -0.019374 -0.024648\n1       125  0.001887  0.006944  0.004293\n2       150  0.009361  0.018258  0.019385\n3       175 -0.008671 -0.002783  -0.00082\n4       200  0.012099   0.01089  0.007637\n5       225  0.024659  0.024404  0.024533\n6       250 -0.004759  0.003918  0.005939\n7       275  0.013317  0.017266  0.022634\n8       300 -0.009404 -0.000589 -0.001855\n9       325  -0.00607  0.004755  0.006592\n10      350 -0.014595  -0.00526 -0.003356\n11      375  0.001776  0.006979  0.008173\n12      400  0.006133  0.007229  0.004855\n13      425  0.009275  0.007466  0.007931\n14      450  0.012836  0.009185  0.008157\n15      475  0.016533  0.018099  0.017725\n16      500  0.049542  0.054596  0.055387\n17      525  0.026679  0.028794  0.031473\n18      550 -0.002261  0.001317 -0.000434\n19      575 -0.014905 -0.005435 -0.008217\n20      600  0.006236  0.007251   0.00004\n21      625 -0.020183 -0.013108  -0.01251\n22      650   0.04702  0.040816  0.047867\n23      675 -0.025128 -0.010631 -0.008786\n","output_type":"stream"}]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2022-08-25T21:27:47.613972Z","iopub.execute_input":"2022-08-25T21:27:47.614381Z","iopub.status.idle":"2022-08-25T21:27:47.627296Z","shell.execute_reply.started":"2022-08-25T21:27:47.614346Z","shell.execute_reply":"2022-08-25T21:27:47.626226Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"    min_prd      xgbf     xgbgs      xgbo\n0       100 -0.033926 -0.019374 -0.024648\n1       125  0.001887  0.006944  0.004293\n2       150  0.009361  0.018258  0.019385\n3       175 -0.008671 -0.002783  -0.00082\n4       200  0.012099   0.01089  0.007637\n5       225  0.024659  0.024404  0.024533\n6       250 -0.004759  0.003918  0.005939\n7       275  0.013317  0.017266  0.022634\n8       300 -0.009404 -0.000589 -0.001855\n9       325  -0.00607  0.004755  0.006592\n10      350 -0.014595  -0.00526 -0.003356\n11      375  0.001776  0.006979  0.008173\n12      400  0.006133  0.007229  0.004855\n13      425  0.009275  0.007466  0.007931\n14      450  0.012836  0.009185  0.008157\n15      475  0.016533  0.018099  0.017725\n16      500  0.049542  0.054596  0.055387\n17      525  0.026679  0.028794  0.031473\n18      550 -0.002261  0.001317 -0.000434\n19      575 -0.014905 -0.005435 -0.008217\n20      600  0.006236  0.007251   0.00004\n21      625 -0.020183 -0.013108  -0.01251\n22      650   0.04702  0.040816  0.047867\n23      675 -0.025128 -0.010631 -0.008786","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>min_prd</th>\n      <th>xgbf</th>\n      <th>xgbgs</th>\n      <th>xgbo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>-0.033926</td>\n      <td>-0.019374</td>\n      <td>-0.024648</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>125</td>\n      <td>0.001887</td>\n      <td>0.006944</td>\n      <td>0.004293</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150</td>\n      <td>0.009361</td>\n      <td>0.018258</td>\n      <td>0.019385</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>175</td>\n      <td>-0.008671</td>\n      <td>-0.002783</td>\n      <td>-0.00082</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>200</td>\n      <td>0.012099</td>\n      <td>0.01089</td>\n      <td>0.007637</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>225</td>\n      <td>0.024659</td>\n      <td>0.024404</td>\n      <td>0.024533</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>250</td>\n      <td>-0.004759</td>\n      <td>0.003918</td>\n      <td>0.005939</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>275</td>\n      <td>0.013317</td>\n      <td>0.017266</td>\n      <td>0.022634</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>300</td>\n      <td>-0.009404</td>\n      <td>-0.000589</td>\n      <td>-0.001855</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>325</td>\n      <td>-0.00607</td>\n      <td>0.004755</td>\n      <td>0.006592</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>350</td>\n      <td>-0.014595</td>\n      <td>-0.00526</td>\n      <td>-0.003356</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>375</td>\n      <td>0.001776</td>\n      <td>0.006979</td>\n      <td>0.008173</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>400</td>\n      <td>0.006133</td>\n      <td>0.007229</td>\n      <td>0.004855</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>425</td>\n      <td>0.009275</td>\n      <td>0.007466</td>\n      <td>0.007931</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>450</td>\n      <td>0.012836</td>\n      <td>0.009185</td>\n      <td>0.008157</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>475</td>\n      <td>0.016533</td>\n      <td>0.018099</td>\n      <td>0.017725</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>500</td>\n      <td>0.049542</td>\n      <td>0.054596</td>\n      <td>0.055387</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>525</td>\n      <td>0.026679</td>\n      <td>0.028794</td>\n      <td>0.031473</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>550</td>\n      <td>-0.002261</td>\n      <td>0.001317</td>\n      <td>-0.000434</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>575</td>\n      <td>-0.014905</td>\n      <td>-0.005435</td>\n      <td>-0.008217</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>600</td>\n      <td>0.006236</td>\n      <td>0.007251</td>\n      <td>0.00004</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>625</td>\n      <td>-0.020183</td>\n      <td>-0.013108</td>\n      <td>-0.01251</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>650</td>\n      <td>0.04702</td>\n      <td>0.040816</td>\n      <td>0.047867</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>675</td>\n      <td>-0.025128</td>\n      <td>-0.010631</td>\n      <td>-0.008786</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print('Total time for a script: ', time.time()-time0)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T21:27:23.671309Z","iopub.execute_input":"2022-08-25T21:27:23.673328Z","iopub.status.idle":"2022-08-25T21:27:23.678403Z","shell.execute_reply.started":"2022-08-25T21:27:23.673272Z","shell.execute_reply":"2022-08-25T21:27:23.677384Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Total time for a script:  3660.214448451996\n","output_type":"stream"}]},{"cell_type":"code","source":"results.iloc[:,1:].mean()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T21:27:55.284281Z","iopub.execute_input":"2022-08-25T21:27:55.284871Z","iopub.status.idle":"2022-08-25T21:27:55.295547Z","shell.execute_reply.started":"2022-08-25T21:27:55.284836Z","shell.execute_reply":"2022-08-25T21:27:55.294336Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"xgbf     0.004061\nxgbgs    0.008791\nxgbo     0.008833\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# 3yr window, trials=20, cv_reg=0.03: 0.88%. runs 1 hr.\n","metadata":{},"execution_count":null,"outputs":[]}]}
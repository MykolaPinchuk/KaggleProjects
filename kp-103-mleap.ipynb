{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This is a new version of MLEAP scripts, started in late Aug 2022.\nIt will combine IProject_MLEAP_ANN and IP_MLEAP script, while improving them.","metadata":{}},{"cell_type":"markdown","source":"#### Outline\n\n1. Load libraries and data.\n2. pEDA. Look at feature distribution, fix them if they do not look right.\n3. Train-test split. Most likely couple years into test set. 2015-2018?. Impute missing values.\n4. Transform numerical features, add ohe for inds.\n5. Fit classic models: ols as a baseline, then xgb.\n6. Fir DL.\n\n\nNotes:\nideally, I want to use time-based cross-validation.\nsince I have panel data, it is not a trivial task.\nneed to find some solution online.\ne.g., https://towardsdatascience.com/time-based-cross-validation-d259b13d42b8.\n\nfor now, will try to do siple for loop.\n","metadata":{}},{"cell_type":"code","source":"# 0. Import libraries #\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, time, math, re, warnings, random, gc, dill, optuna, pickle\nimport statsmodels.api as sm\nfrom random import sample\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNetCV\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn.inspection import permutation_importance\nfrom category_encoders import MEstimateEncoder\nfrom xgboost import XGBRegressor\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nplt.style.use('seaborn-white')\nwarnings.simplefilter(action='ignore')\npd.set_option('display.max_columns', 110)\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:16.666279Z","iopub.execute_input":"2022-08-25T00:24:16.666894Z","iopub.status.idle":"2022-08-25T00:24:16.684137Z","shell.execute_reply.started":"2022-08-25T00:24:16.666860Z","shell.execute_reply":"2022-08-25T00:24:16.682621Z"},"trusted":true},"execution_count":226,"outputs":[]},{"cell_type":"code","source":"### target encoding ###\n# source: https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices/notebook\n\nclass CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=4)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:16.686413Z","iopub.execute_input":"2022-08-25T00:24:16.687371Z","iopub.status.idle":"2022-08-25T00:24:16.702697Z","shell.execute_reply.started":"2022-08-25T00:24:16.687333Z","shell.execute_reply":"2022-08-25T00:24:16.700655Z"},"trusted":true},"execution_count":227,"outputs":[]},{"cell_type":"code","source":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:16.708225Z","iopub.execute_input":"2022-08-25T00:24:16.709150Z","iopub.status.idle":"2022-08-25T00:24:16.723321Z","shell.execute_reply.started":"2022-08-25T00:24:16.709112Z","shell.execute_reply":"2022-08-25T00:24:16.722031Z"},"trusted":true},"execution_count":228,"outputs":[{"name":"stdout","text":"REPLICAS:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"# 1. Import data #\n\nmin_prd = 384\n\ntime0 = time.time()\n#df = pd.read_csv('../input/cpcrsp-46/IMLEAP_v4.csv')\nwith open('../input/kaggle-46pkl/IMLEAP_v4.pkl', 'rb') as pickled_one:\n    df = pickle.load(pickled_one)\ndf = df[df.prd.isin(range(min_prd-1, min_prd+62))]\ndisplay(df.shape, df.head(), df.count())","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:16.728904Z","iopub.execute_input":"2022-08-25T00:24:16.730110Z","iopub.status.idle":"2022-08-25T00:24:17.530027Z","shell.execute_reply.started":"2022-08-25T00:24:16.730072Z","shell.execute_reply":"2022-08-25T00:24:17.529033Z"},"trusted":true},"execution_count":229,"outputs":[{"output_type":"display_data","data":{"text/plain":"(159567, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    PERMNO  prd  mom482     mom242  year   RET   ind        bm        op   gp  \\\n8    10005  383     NaN -72.706514  1990 -0.64  30.0  0.490174 -0.214332  0.0   \n9    10005  384     NaN -67.514581  1990 -0.69  30.0  0.490174 -0.214332  0.0   \n10   10005  385     NaN -62.951924  1990 -0.68  30.0  0.490174 -0.214332  0.0   \n11   10005  386     NaN -63.021898  1990 -0.63  30.0  0.490174 -0.214332  0.0   \n12   10005  387     NaN -71.270748  1990 -0.68  30.0  0.667021 -0.123134  0.0   \n\n         inv      mom11     mom122  amhd  ivol_capm  ivol_ff5   beta_bw  \\\n8  -0.230583 -22.380465 -38.380158   NaN   5.732938  5.391287  0.492262   \n9  -0.230583  -0.640000 -53.826992   NaN   0.765013  0.647098  0.493277   \n10 -0.230583  -0.690000 -44.500763   NaN   0.765013  0.647098  0.538328   \n11 -0.230583  -0.680000 -44.444822   NaN   0.765013  0.647098  0.538359   \n12 -0.220930  -0.630000 -44.428036   NaN   0.765013  0.647098  0.539508   \n\n       MAX     vol1m     vol6m    vol12m  BAspr      size       lbm       lop  \\\n8   1.4066  5.455535  4.690786  3.473044    NaN -0.934794  0.750140 -0.084639   \n9   1.4066  0.866870  3.725968  3.473051    NaN -0.934794  0.750140 -0.084639   \n10  1.4066  0.866870  3.725977  3.313428    NaN -0.934794  0.750140 -0.084639   \n11  1.4066  0.866870  2.227182  3.313446    NaN -0.934794  0.750140 -0.084639   \n12  1.4066  0.866870  2.227184  3.313454    NaN -0.934794  0.490174 -0.214332   \n\n         lgp      linv      llme  l1amhd   l1MAX  l1BAspr  l3amhd      l3MAX  \\\n8   0.015282  0.306039 -0.241753     NaN  1.4066      NaN     NaN  21.135115   \n9   0.015282  0.306039 -0.241753     NaN  1.4066      NaN     NaN   1.406600   \n10  0.015282  0.306039 -0.424011     NaN  1.4066      NaN     NaN   1.406600   \n11  0.015282  0.306039 -0.424011     NaN  1.4066      NaN     NaN   1.406600   \n12  0.000000 -0.230583 -0.424011     NaN  1.4066      NaN     NaN   1.406600   \n\n    l3BAspr  l6amhd      l6MAX  l6BAspr  l12amhd  l12MAX  l12BAspr  l12mom122  \\\n8       NaN     NaN   1.406600      NaN      NaN  1.4066       NaN -43.710657   \n9       NaN     NaN   1.406600      NaN      NaN  1.4066       NaN -43.806772   \n10      NaN     NaN   1.406600      NaN      NaN  1.4066       NaN -29.825580   \n11      NaN     NaN  21.135115      NaN      NaN  1.4066       NaN -33.315908   \n12      NaN     NaN   1.406600      NaN      NaN  1.4066       NaN -33.516946   \n\n    l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n8       0.765013     0.647098    0.741531  3.367760   3.336121  \n9       0.765013     0.647098    0.750895  2.328417   3.336079  \n10      3.624354     3.579437    0.776122  1.485171   3.263052  \n11      0.765013     0.647098    0.837432  1.485034   3.167953  \n12      0.765013     0.647098    0.843440  1.485001   3.167929  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>10005</td>\n      <td>383</td>\n      <td>NaN</td>\n      <td>-72.706514</td>\n      <td>1990</td>\n      <td>-0.64</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-22.380465</td>\n      <td>-38.380158</td>\n      <td>NaN</td>\n      <td>5.732938</td>\n      <td>5.391287</td>\n      <td>0.492262</td>\n      <td>1.4066</td>\n      <td>5.455535</td>\n      <td>4.690786</td>\n      <td>3.473044</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.750140</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>-43.710657</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.741531</td>\n      <td>3.367760</td>\n      <td>3.336121</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10005</td>\n      <td>384</td>\n      <td>NaN</td>\n      <td>-67.514581</td>\n      <td>1990</td>\n      <td>-0.69</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.640000</td>\n      <td>-53.826992</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.493277</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>3.725968</td>\n      <td>3.473051</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.750140</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>-43.806772</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.750895</td>\n      <td>2.328417</td>\n      <td>3.336079</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10005</td>\n      <td>385</td>\n      <td>NaN</td>\n      <td>-62.951924</td>\n      <td>1990</td>\n      <td>-0.68</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.690000</td>\n      <td>-44.500763</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.538328</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>3.725977</td>\n      <td>3.313428</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.750140</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.424011</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>-29.825580</td>\n      <td>3.624354</td>\n      <td>3.579437</td>\n      <td>0.776122</td>\n      <td>1.485171</td>\n      <td>3.263052</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10005</td>\n      <td>386</td>\n      <td>NaN</td>\n      <td>-63.021898</td>\n      <td>1990</td>\n      <td>-0.63</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.680000</td>\n      <td>-44.444822</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.538359</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>2.227182</td>\n      <td>3.313446</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.750140</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.424011</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>-33.315908</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.837432</td>\n      <td>1.485034</td>\n      <td>3.167953</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>10005</td>\n      <td>387</td>\n      <td>NaN</td>\n      <td>-71.270748</td>\n      <td>1990</td>\n      <td>-0.68</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.220930</td>\n      <td>-0.630000</td>\n      <td>-44.428036</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.539508</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>2.227184</td>\n      <td>3.313454</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.000000</td>\n      <td>-0.230583</td>\n      <td>-0.424011</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>-33.516946</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.843440</td>\n      <td>1.485001</td>\n      <td>3.167929</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          159567\nprd             159567\nmom482          137496\nmom242          157726\nyear            159567\nRET             159567\nind             159567\nbm              159567\nop              159567\ngp              159567\ninv             159474\nmom11           159567\nmom122          159567\namhd            121257\nivol_capm       159562\nivol_ff5        159562\nbeta_bw         159567\nMAX             159567\nvol1m           159552\nvol6m           159462\nvol12m          159264\nBAspr           108565\nsize            159567\nlbm             159567\nlop             159567\nlgp             159567\nlinv            159567\nllme            159567\nl1amhd          121269\nl1MAX           159564\nl1BAspr         107155\nl3amhd          121320\nl3MAX           159544\nl3BAspr         104235\nl6amhd          121323\nl6MAX           159524\nl6BAspr          99863\nl12amhd         121058\nl12MAX          159564\nl12BAspr         91204\nl12mom122       159005\nl12ivol_capm    159462\nl12ivol_ff5     159462\nl12beta_bw      159499\nl12vol6m        159215\nl12vol12m       158071\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# 2. pEDA #\n\ndf.RET.hist()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:17.531422Z","iopub.execute_input":"2022-08-25T00:24:17.532035Z","iopub.status.idle":"2022-08-25T00:24:17.729341Z","shell.execute_reply.started":"2022-08-25T00:24:17.531991Z","shell.execute_reply":"2022-08-25T00:24:17.728366Z"},"trusted":true},"execution_count":230,"outputs":[{"execution_count":230,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"# explore feature distibution, adjust if seems unreasonable","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:17.731807Z","iopub.execute_input":"2022-08-25T00:24:17.732444Z","iopub.status.idle":"2022-08-25T00:24:17.737042Z","shell.execute_reply.started":"2022-08-25T00:24:17.732404Z","shell.execute_reply":"2022-08-25T00:24:17.736028Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"code","source":"# add dummies for some missing features\n\nfeatures_miss_dummies = ['amhd', 'BAspr']\n\nfor col in features_miss_dummies:\n    df[col+'_miss'] = df[col].isnull().astype(int)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:17.738739Z","iopub.execute_input":"2022-08-25T00:24:17.739811Z","iopub.status.idle":"2022-08-25T00:24:17.785461Z","shell.execute_reply.started":"2022-08-25T00:24:17.739774Z","shell.execute_reply":"2022-08-25T00:24:17.784308Z"},"trusted":true},"execution_count":232,"outputs":[{"execution_count":232,"output_type":"execute_result","data":{"text/plain":"    PERMNO  prd  mom482     mom242  year   RET   ind        bm        op   gp  \\\n8    10005  383     NaN -72.706514  1990 -0.64  30.0  0.490174 -0.214332  0.0   \n9    10005  384     NaN -67.514581  1990 -0.69  30.0  0.490174 -0.214332  0.0   \n10   10005  385     NaN -62.951924  1990 -0.68  30.0  0.490174 -0.214332  0.0   \n11   10005  386     NaN -63.021898  1990 -0.63  30.0  0.490174 -0.214332  0.0   \n12   10005  387     NaN -71.270748  1990 -0.68  30.0  0.667021 -0.123134  0.0   \n\n         inv      mom11     mom122  amhd  ivol_capm  ivol_ff5   beta_bw  \\\n8  -0.230583 -22.380465 -38.380158   NaN   5.732938  5.391287  0.492262   \n9  -0.230583  -0.640000 -53.826992   NaN   0.765013  0.647098  0.493277   \n10 -0.230583  -0.690000 -44.500763   NaN   0.765013  0.647098  0.538328   \n11 -0.230583  -0.680000 -44.444822   NaN   0.765013  0.647098  0.538359   \n12 -0.220930  -0.630000 -44.428036   NaN   0.765013  0.647098  0.539508   \n\n       MAX     vol1m     vol6m    vol12m  BAspr      size       lbm       lop  \\\n8   1.4066  5.455535  4.690786  3.473044    NaN -0.934794  0.750140 -0.084639   \n9   1.4066  0.866870  3.725968  3.473051    NaN -0.934794  0.750140 -0.084639   \n10  1.4066  0.866870  3.725977  3.313428    NaN -0.934794  0.750140 -0.084639   \n11  1.4066  0.866870  2.227182  3.313446    NaN -0.934794  0.750140 -0.084639   \n12  1.4066  0.866870  2.227184  3.313454    NaN -0.934794  0.490174 -0.214332   \n\n         lgp      linv      llme  l1amhd   l1MAX  l1BAspr  l3amhd      l3MAX  \\\n8   0.015282  0.306039 -0.241753     NaN  1.4066      NaN     NaN  21.135115   \n9   0.015282  0.306039 -0.241753     NaN  1.4066      NaN     NaN   1.406600   \n10  0.015282  0.306039 -0.424011     NaN  1.4066      NaN     NaN   1.406600   \n11  0.015282  0.306039 -0.424011     NaN  1.4066      NaN     NaN   1.406600   \n12  0.000000 -0.230583 -0.424011     NaN  1.4066      NaN     NaN   1.406600   \n\n    l3BAspr  l6amhd      l6MAX  l6BAspr  l12amhd  l12MAX  l12BAspr  l12mom122  \\\n8       NaN     NaN   1.406600      NaN      NaN  1.4066       NaN -43.710657   \n9       NaN     NaN   1.406600      NaN      NaN  1.4066       NaN -43.806772   \n10      NaN     NaN   1.406600      NaN      NaN  1.4066       NaN -29.825580   \n11      NaN     NaN  21.135115      NaN      NaN  1.4066       NaN -33.315908   \n12      NaN     NaN   1.406600      NaN      NaN  1.4066       NaN -33.516946   \n\n    l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  amhd_miss  \\\n8       0.765013     0.647098    0.741531  3.367760   3.336121          1   \n9       0.765013     0.647098    0.750895  2.328417   3.336079          1   \n10      3.624354     3.579437    0.776122  1.485171   3.263052          1   \n11      0.765013     0.647098    0.837432  1.485034   3.167953          1   \n12      0.765013     0.647098    0.843440  1.485001   3.167929          1   \n\n    BAspr_miss  \n8            1  \n9            1  \n10           1  \n11           1  \n12           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>amhd_miss</th>\n      <th>BAspr_miss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>10005</td>\n      <td>383</td>\n      <td>NaN</td>\n      <td>-72.706514</td>\n      <td>1990</td>\n      <td>-0.64</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-22.380465</td>\n      <td>-38.380158</td>\n      <td>NaN</td>\n      <td>5.732938</td>\n      <td>5.391287</td>\n      <td>0.492262</td>\n      <td>1.4066</td>\n      <td>5.455535</td>\n      <td>4.690786</td>\n      <td>3.473044</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.750140</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>-43.710657</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.741531</td>\n      <td>3.367760</td>\n      <td>3.336121</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10005</td>\n      <td>384</td>\n      <td>NaN</td>\n      <td>-67.514581</td>\n      <td>1990</td>\n      <td>-0.69</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.640000</td>\n      <td>-53.826992</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.493277</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>3.725968</td>\n      <td>3.473051</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.750140</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>-43.806772</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.750895</td>\n      <td>2.328417</td>\n      <td>3.336079</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10005</td>\n      <td>385</td>\n      <td>NaN</td>\n      <td>-62.951924</td>\n      <td>1990</td>\n      <td>-0.68</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.690000</td>\n      <td>-44.500763</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.538328</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>3.725977</td>\n      <td>3.313428</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.750140</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.424011</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>-29.825580</td>\n      <td>3.624354</td>\n      <td>3.579437</td>\n      <td>0.776122</td>\n      <td>1.485171</td>\n      <td>3.263052</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10005</td>\n      <td>386</td>\n      <td>NaN</td>\n      <td>-63.021898</td>\n      <td>1990</td>\n      <td>-0.63</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.680000</td>\n      <td>-44.444822</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.538359</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>2.227182</td>\n      <td>3.313446</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.750140</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.424011</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>-33.315908</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.837432</td>\n      <td>1.485034</td>\n      <td>3.167953</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>10005</td>\n      <td>387</td>\n      <td>NaN</td>\n      <td>-71.270748</td>\n      <td>1990</td>\n      <td>-0.68</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.220930</td>\n      <td>-0.630000</td>\n      <td>-44.428036</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.539508</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>2.227184</td>\n      <td>3.313454</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.000000</td>\n      <td>-0.230583</td>\n      <td>-0.424011</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>-33.516946</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.843440</td>\n      <td>1.485001</td>\n      <td>3.167929</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 3. Train-test split #\n\ntemp_cols = ['PERMNO', 'prd', 'year']\n\ntrain = df[df.prd<(min_prd+60)]\ntest = df[df.prd==(min_prd+60)]\ntrain.drop(columns=temp_cols, inplace=True)\ntest.drop(columns=temp_cols, inplace=True)\ndisplay(train.shape, test.shape, train.head(3), test.head(3))","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:17.787060Z","iopub.execute_input":"2022-08-25T00:24:17.787687Z","iopub.status.idle":"2022-08-25T00:24:17.917202Z","shell.execute_reply.started":"2022-08-25T00:24:17.787650Z","shell.execute_reply":"2022-08-25T00:24:17.915851Z"},"trusted":true},"execution_count":233,"outputs":[{"output_type":"display_data","data":{"text/plain":"(154591, 45)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(2497, 45)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    mom482     mom242   RET   ind        bm        op   gp       inv  \\\n8      NaN -72.706514 -0.64  30.0  0.490174 -0.214332  0.0 -0.230583   \n9      NaN -67.514581 -0.69  30.0  0.490174 -0.214332  0.0 -0.230583   \n10     NaN -62.951924 -0.68  30.0  0.490174 -0.214332  0.0 -0.230583   \n\n        mom11     mom122  amhd  ivol_capm  ivol_ff5   beta_bw     MAX  \\\n8  -22.380465 -38.380158   NaN   5.732938  5.391287  0.492262  1.4066   \n9   -0.640000 -53.826992   NaN   0.765013  0.647098  0.493277  1.4066   \n10  -0.690000 -44.500763   NaN   0.765013  0.647098  0.538328  1.4066   \n\n       vol1m     vol6m    vol12m  BAspr      size      lbm       lop  \\\n8   5.455535  4.690786  3.473044    NaN -0.934794  0.75014 -0.084639   \n9   0.866870  3.725968  3.473051    NaN -0.934794  0.75014 -0.084639   \n10  0.866870  3.725977  3.313428    NaN -0.934794  0.75014 -0.084639   \n\n         lgp      linv      llme  l1amhd   l1MAX  l1BAspr  l3amhd      l3MAX  \\\n8   0.015282  0.306039 -0.241753     NaN  1.4066      NaN     NaN  21.135115   \n9   0.015282  0.306039 -0.241753     NaN  1.4066      NaN     NaN   1.406600   \n10  0.015282  0.306039 -0.424011     NaN  1.4066      NaN     NaN   1.406600   \n\n    l3BAspr  l6amhd   l6MAX  l6BAspr  l12amhd  l12MAX  l12BAspr  l12mom122  \\\n8       NaN     NaN  1.4066      NaN      NaN  1.4066       NaN -43.710657   \n9       NaN     NaN  1.4066      NaN      NaN  1.4066       NaN -43.806772   \n10      NaN     NaN  1.4066      NaN      NaN  1.4066       NaN -29.825580   \n\n    l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  amhd_miss  \\\n8       0.765013     0.647098    0.741531  3.367760   3.336121          1   \n9       0.765013     0.647098    0.750895  2.328417   3.336079          1   \n10      3.624354     3.579437    0.776122  1.485171   3.263052          1   \n\n    BAspr_miss  \n8            1  \n9            1  \n10           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>amhd_miss</th>\n      <th>BAspr_miss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>-72.706514</td>\n      <td>-0.64</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-22.380465</td>\n      <td>-38.380158</td>\n      <td>NaN</td>\n      <td>5.732938</td>\n      <td>5.391287</td>\n      <td>0.492262</td>\n      <td>1.4066</td>\n      <td>5.455535</td>\n      <td>4.690786</td>\n      <td>3.473044</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>-43.710657</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.741531</td>\n      <td>3.367760</td>\n      <td>3.336121</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>-67.514581</td>\n      <td>-0.69</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.640000</td>\n      <td>-53.826992</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.493277</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>3.725968</td>\n      <td>3.473051</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.241753</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>-43.806772</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.750895</td>\n      <td>2.328417</td>\n      <td>3.336079</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NaN</td>\n      <td>-62.951924</td>\n      <td>-0.68</td>\n      <td>30.0</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.690000</td>\n      <td>-44.500763</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.538328</td>\n      <td>1.4066</td>\n      <td>0.866870</td>\n      <td>3.725977</td>\n      <td>3.313428</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.75014</td>\n      <td>-0.084639</td>\n      <td>0.015282</td>\n      <td>0.306039</td>\n      <td>-0.424011</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>-29.825580</td>\n      <td>3.624354</td>\n      <td>3.579437</td>\n      <td>0.776122</td>\n      <td>1.485171</td>\n      <td>3.263052</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"         mom482      mom242      RET   ind        bm        op        gp  \\\n308  -71.666115  -50.199564  83.4310  12.0 -1.896125  0.081622  0.510535   \n345  102.462626  170.270066  22.5689  34.0 -1.862198  0.132619  0.757579   \n577  -47.308239  -54.110858  -4.6067  21.0  0.177905 -0.082748  0.119668   \n\n          inv    mom11     mom122      amhd  ivol_capm  ivol_ff5   beta_bw  \\\n308 -0.101827 -14.3489 -42.430472  3.182400   3.363124  2.941161  0.861234   \n345  0.335288   6.1438  50.020912  2.295714   6.735740  6.005222  0.647692   \n577 -0.103007   7.0027 -16.399859  2.401087   2.019339  1.878105  1.023677   \n\n         MAX     vol1m     vol6m    vol12m     BAspr      size       lbm  \\\n308   5.5356  3.228927  3.324761  3.442898  6.250000  3.692401 -1.623669   \n345  11.8848  7.065670  4.022678  3.439909  2.564103  4.395057 -1.567054   \n577   4.5954  2.036277  3.990957  3.484678  2.666667  4.811550  0.670110   \n\n          lop       lgp      linv      llme    l1amhd    l1MAX   l1BAspr  \\\n308  0.013844  0.291257  0.800300  4.345376  3.097367   4.8570  5.263158   \n345  0.019597  0.839508 -0.112930  3.808339  2.492715   3.4878  0.934579   \n577  0.063815  0.291788  0.003223  4.881979  2.403057  11.2693  3.076923   \n\n       l3amhd    l3MAX   l3BAspr    l6amhd   l6MAX   l6BAspr   l12amhd  \\\n308  2.778245   7.4790  4.651163  2.800786  6.6497  2.040816  2.673470   \n345  3.248493   7.5420  1.538462  3.981594  5.2462  2.380952  4.731040   \n577  2.239765  10.7633  5.769231  1.872630  2.7999  2.816901  2.423493   \n\n      l12MAX  l12BAspr  l12mom122  l12ivol_capm  l12ivol_ff5  l12beta_bw  \\\n308   4.8570  1.538462 -18.575370      3.142974     2.825022    1.048256   \n345   3.4878  4.081633  81.804988      2.942629     2.429158    0.503468   \n577  11.2693  1.333333 -53.126659      6.610402     5.952957    0.353690   \n\n     l12vol6m  l12vol12m  amhd_miss  BAspr_miss  \n308  3.929775   3.548225          0           0  \n345  3.131319   3.703239          0           0  \n577  4.399474   3.494552          0           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>amhd_miss</th>\n      <th>BAspr_miss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>308</th>\n      <td>-71.666115</td>\n      <td>-50.199564</td>\n      <td>83.4310</td>\n      <td>12.0</td>\n      <td>-1.896125</td>\n      <td>0.081622</td>\n      <td>0.510535</td>\n      <td>-0.101827</td>\n      <td>-14.3489</td>\n      <td>-42.430472</td>\n      <td>3.182400</td>\n      <td>3.363124</td>\n      <td>2.941161</td>\n      <td>0.861234</td>\n      <td>5.5356</td>\n      <td>3.228927</td>\n      <td>3.324761</td>\n      <td>3.442898</td>\n      <td>6.250000</td>\n      <td>3.692401</td>\n      <td>-1.623669</td>\n      <td>0.013844</td>\n      <td>0.291257</td>\n      <td>0.800300</td>\n      <td>4.345376</td>\n      <td>3.097367</td>\n      <td>4.8570</td>\n      <td>5.263158</td>\n      <td>2.778245</td>\n      <td>7.4790</td>\n      <td>4.651163</td>\n      <td>2.800786</td>\n      <td>6.6497</td>\n      <td>2.040816</td>\n      <td>2.673470</td>\n      <td>4.8570</td>\n      <td>1.538462</td>\n      <td>-18.575370</td>\n      <td>3.142974</td>\n      <td>2.825022</td>\n      <td>1.048256</td>\n      <td>3.929775</td>\n      <td>3.548225</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>345</th>\n      <td>102.462626</td>\n      <td>170.270066</td>\n      <td>22.5689</td>\n      <td>34.0</td>\n      <td>-1.862198</td>\n      <td>0.132619</td>\n      <td>0.757579</td>\n      <td>0.335288</td>\n      <td>6.1438</td>\n      <td>50.020912</td>\n      <td>2.295714</td>\n      <td>6.735740</td>\n      <td>6.005222</td>\n      <td>0.647692</td>\n      <td>11.8848</td>\n      <td>7.065670</td>\n      <td>4.022678</td>\n      <td>3.439909</td>\n      <td>2.564103</td>\n      <td>4.395057</td>\n      <td>-1.567054</td>\n      <td>0.019597</td>\n      <td>0.839508</td>\n      <td>-0.112930</td>\n      <td>3.808339</td>\n      <td>2.492715</td>\n      <td>3.4878</td>\n      <td>0.934579</td>\n      <td>3.248493</td>\n      <td>7.5420</td>\n      <td>1.538462</td>\n      <td>3.981594</td>\n      <td>5.2462</td>\n      <td>2.380952</td>\n      <td>4.731040</td>\n      <td>3.4878</td>\n      <td>4.081633</td>\n      <td>81.804988</td>\n      <td>2.942629</td>\n      <td>2.429158</td>\n      <td>0.503468</td>\n      <td>3.131319</td>\n      <td>3.703239</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>577</th>\n      <td>-47.308239</td>\n      <td>-54.110858</td>\n      <td>-4.6067</td>\n      <td>21.0</td>\n      <td>0.177905</td>\n      <td>-0.082748</td>\n      <td>0.119668</td>\n      <td>-0.103007</td>\n      <td>7.0027</td>\n      <td>-16.399859</td>\n      <td>2.401087</td>\n      <td>2.019339</td>\n      <td>1.878105</td>\n      <td>1.023677</td>\n      <td>4.5954</td>\n      <td>2.036277</td>\n      <td>3.990957</td>\n      <td>3.484678</td>\n      <td>2.666667</td>\n      <td>4.811550</td>\n      <td>0.670110</td>\n      <td>0.063815</td>\n      <td>0.291788</td>\n      <td>0.003223</td>\n      <td>4.881979</td>\n      <td>2.403057</td>\n      <td>11.2693</td>\n      <td>3.076923</td>\n      <td>2.239765</td>\n      <td>10.7633</td>\n      <td>5.769231</td>\n      <td>1.872630</td>\n      <td>2.7999</td>\n      <td>2.816901</td>\n      <td>2.423493</td>\n      <td>11.2693</td>\n      <td>1.333333</td>\n      <td>-53.126659</td>\n      <td>6.610402</td>\n      <td>5.952957</td>\n      <td>0.353690</td>\n      <td>4.399474</td>\n      <td>3.494552</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 4. Missing values #\n\ncol_ignore = ['RET']\ncol_cat = ['ind']\ncol_num = [x for x in train.columns if x not in col_ignore+col_cat]\n\nfor col in col_num:\n    train[col] = train[col].fillna(train[col].median())\n    test[col] = test[col].fillna(train[col].median())\n\nfor col in col_cat:\n    train[col] = train[col].fillna(value=-1000)\n    test[col] = test[col].fillna(value=-1000)\n    \ndisplay(train.count())","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:17.919112Z","iopub.execute_input":"2022-08-25T00:24:17.920071Z","iopub.status.idle":"2022-08-25T00:24:18.163576Z","shell.execute_reply.started":"2022-08-25T00:24:17.920031Z","shell.execute_reply":"2022-08-25T00:24:18.162698Z"},"trusted":true},"execution_count":234,"outputs":[{"output_type":"display_data","data":{"text/plain":"mom482          154591\nmom242          154591\nRET             154591\nind             154591\nbm              154591\nop              154591\ngp              154591\ninv             154591\nmom11           154591\nmom122          154591\namhd            154591\nivol_capm       154591\nivol_ff5        154591\nbeta_bw         154591\nMAX             154591\nvol1m           154591\nvol6m           154591\nvol12m          154591\nBAspr           154591\nsize            154591\nlbm             154591\nlop             154591\nlgp             154591\nlinv            154591\nllme            154591\nl1amhd          154591\nl1MAX           154591\nl1BAspr         154591\nl3amhd          154591\nl3MAX           154591\nl3BAspr         154591\nl6amhd          154591\nl6MAX           154591\nl6BAspr         154591\nl12amhd         154591\nl12MAX          154591\nl12BAspr        154591\nl12mom122       154591\nl12ivol_capm    154591\nl12ivol_ff5     154591\nl12beta_bw      154591\nl12vol6m        154591\nl12vol12m       154591\namhd_miss       154591\nBAspr_miss      154591\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# [optional] Target Encoding\n","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:18.164884Z","iopub.execute_input":"2022-08-25T00:24:18.165269Z","iopub.status.idle":"2022-08-25T00:24:18.172228Z","shell.execute_reply.started":"2022-08-25T00:24:18.165233Z","shell.execute_reply":"2022-08-25T00:24:18.171348Z"},"trusted":true},"execution_count":235,"outputs":[]},{"cell_type":"code","source":"X_train = train.copy()\ny_train = X_train.pop('RET')\n\nX_test = test.copy()\ny_test = X_test.pop('RET')","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:18.175913Z","iopub.execute_input":"2022-08-25T00:24:18.176261Z","iopub.status.idle":"2022-08-25T00:24:18.206756Z","shell.execute_reply.started":"2022-08-25T00:24:18.176235Z","shell.execute_reply":"2022-08-25T00:24:18.205861Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"# 5. Feature engineering #\n\ntime1 = time.time()\n\nfeature_transformer = ColumnTransformer([\n    (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\", drop='if_binary'), col_cat),\n    ('num', StandardScaler(), col_num)])\n\nprint('Number of features before transformation: ', X_train.shape)\nX_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\nX_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\nprint('time to do feature proprocessing: ', time.time()-time1)\nprint('Number of features after transformation: ', X_train.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:18.208244Z","iopub.execute_input":"2022-08-25T00:24:18.208887Z","iopub.status.idle":"2022-08-25T00:24:18.543644Z","shell.execute_reply.started":"2022-08-25T00:24:18.208851Z","shell.execute_reply":"2022-08-25T00:24:18.542646Z"},"trusted":true},"execution_count":237,"outputs":[{"name":"stdout","text":"Number of features before transformation:  (154591, 44)\ntime to do feature proprocessing:  0.3267397880554199\nNumber of features after transformation:  (154591, 92)\n","output_type":"stream"}]},{"cell_type":"code","source":"# 6. Model fitting #\n\n# first, some trivial baselines:\nprint('mae of a constant model', mean_absolute_error(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\nprint('R2 of a constant model', r2_score(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\n\ntime1 = time.time()\nxgb1 = XGBRegressor(tree_method = 'gpu_hist', n_estimators=300, max_depth=6, eta=0.05, colsample_bytree=0.6)\nxgb1.fit(X_train, y_train)\nprint('XGB train:', mean_absolute_error(y_train, xgb1.predict(X_train)), r2_score(y_train, xgb1.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:18.545253Z","iopub.execute_input":"2022-08-25T00:24:18.545625Z","iopub.status.idle":"2022-08-25T00:24:22.790314Z","shell.execute_reply.started":"2022-08-25T00:24:18.545588Z","shell.execute_reply":"2022-08-25T00:24:22.789490Z"},"trusted":true},"execution_count":238,"outputs":[{"name":"stdout","text":"mae of a constant model 10.890287712726742\nR2 of a constant model 0.0\nXGB train: 10.39120989936875 0.1579073139409377 4.229769468307495\n","output_type":"stream"}]},{"cell_type":"code","source":"time1 = time.time()\nxgb = XGBRegressor(tree_method = 'gpu_hist')\nparam_grid = {'n_estimators':[300, 500], 'max_depth':[2,3,4], 'eta':[0.015, 0.3, 0.05],\n             'subsample':[0.6], 'colsample_bytree':[0.6]}\nxgbm = GridSearchCV(xgb, param_grid, cv=2, verbose=2, scoring='neg_mean_absolute_error')\nxgbm.fit(X_train, y_train)\nprint('XGB', xgbm.best_params_, xgbm.best_score_, time.time()-time1)\n# this runs for 40 min and finds \n# 'eta': 0.02, 'max_depth': 6, 'n_estimators': 500, 0.01095415380877135\nprint('XGB train:', mean_absolute_error(y_train, xgbm.predict(X_train)), r2_score(y_train, xgbm.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:24:22.793757Z","iopub.execute_input":"2022-08-25T00:24:22.795542Z","iopub.status.idle":"2022-08-25T00:25:12.522847Z","shell.execute_reply.started":"2022-08-25T00:24:22.795508Z","shell.execute_reply":"2022-08-25T00:25:12.522037Z"},"trusted":true},"execution_count":239,"outputs":[{"name":"stdout","text":"Fitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.015, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.015, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.015, max_depth=2, n_estimators=500, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.015, max_depth=2, n_estimators=500, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.015, max_depth=3, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.015, max_depth=3, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.015, max_depth=3, n_estimators=500, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.015, max_depth=3, n_estimators=500, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.015, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.015, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.015, max_depth=4, n_estimators=500, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.015, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.3, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.3, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.3, max_depth=2, n_estimators=500, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.3, max_depth=2, n_estimators=500, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.3, max_depth=3, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.3, max_depth=3, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.3, max_depth=3, n_estimators=500, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.3, max_depth=3, n_estimators=500, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.3, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.3, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.3, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.3, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=2, n_estimators=500, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=2, n_estimators=500, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=3, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=3, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=3, n_estimators=500, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=3, n_estimators=500, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=4, n_estimators=500, subsample=0.6; total time=   2.0s\nXGB {'colsample_bytree': 0.6, 'eta': 0.015, 'max_depth': 3, 'n_estimators': 500, 'subsample': 0.6} -10.927707707849091 48.286598205566406\nXGB train: 10.8717219634902 0.02347348450652409 49.717132329940796\n","output_type":"stream"}]},{"cell_type":"code","source":"# time1 = time.time()\n\n# def objective(trial, cv_runs=1, n_splits=2, n_jobs=-1):\n\n#     cv_regularizer=0.01\n#     # Usually values between 0.1 and 0.2 work fine.\n\n#     params = {\n#         \"tree_method\": 'gpu_hist',\n#         \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n#         \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n#         \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n#         \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.005, 0.2),\n#         \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.1, 0.95),\n#         \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 0.95),\n#         \"alpha\": trial.suggest_loguniform(\"alpha\", 0.1, 20.0),\n#         \"lambda\": trial.suggest_loguniform(\"lambda\", 0.1, 150.0),\n#         \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-10, 10.0),\n#         \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 0.1, 10)    }\n#     # usually it makes sense to resrtict hyperparameter space from some solutions which Optuna will find\n#     # e.g., for tmx-joined data only (downsampled tmx), optuna keeps selecting depths of 2 and 3.\n#     # for my purposes (smooth left side of prc, close to 1), those solutions are no good.\n\n#     temp_out = []\n\n#     for i in range(cv_runs):\n\n#         X = X_train\n#         y = y_train\n\n#         model = XGBRegressor(**params, njobs=-1)\n#         rkf = KFold(n_splits=n_splits, shuffle=True)\n#         X_values = X.values\n#         y_values = y.values\n#         y_pred = np.zeros_like(y_values)\n#         y_pred_train = np.zeros_like(y_values)\n#         for train_index, test_index in rkf.split(X_values):\n#             X_A, X_B = X_values[train_index, :], X_values[test_index, :]\n#             y_A, y_B = y_values[train_index], y_values[test_index]\n#             model.fit(X_A, y_A, eval_set=[(X_B, y_B)], verbose = False)\n#             y_pred[test_index] += model.predict(X_B)\n                      \n            \n#         #score_train = roc_auc_score(y_train, y_pred_train)\n#         score_test = mean_absolute_error(y_train, y_pred) \n#         #overfit = score_train-score_test\n#         #temp_out.append(score_test-cv_regularizer*overfit)\n#         temp_out.append(score_test)\n\n#     return (np.mean(temp_out))\n\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(objective, n_trials=30)\n\n# print('Total time for hypermarameter optimization ', time.time()-time1)\n# hp = study.best_params\n# for key, value in hp.items():\n#     print(f\"{key:>20s} : {value}\")\n# print(f\"{'best objective value':>20s} : {study.best_value}\")\n\n# optuna_hyperpars = study.best_params\n# optuna_hyperpars['tree_method']='gpu_hist'\n\n# optuna_xgb = XGBRegressor(**optuna_hyperpars)\n# optuna_xgb.fit(X_train, y_train)\n# print('Optuna XGB train:', \n#       mean_absolute_error(y_train, optuna_xgb.predict(X_train)), r2_score(y_train, optuna_xgb.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:25:12.526449Z","iopub.execute_input":"2022-08-25T00:25:12.528288Z","iopub.status.idle":"2022-08-25T00:25:12.535491Z","shell.execute_reply.started":"2022-08-25T00:25:12.528254Z","shell.execute_reply":"2022-08-25T00:25:12.534483Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"code","source":"# Evaluate performance of XGB models:\n\nprint('XGB test:', mean_absolute_error(y_test, xgb1.predict(X_test)), r2_score(y_test, xgb1.predict(X_test)))\nprint('XGB GS test:', mean_absolute_error(y_test, xgbm.predict(X_test)), r2_score(y_test, xgbm.predict(X_test)))\n#print('Optuna XGB test:', mean_absolute_error(y_test, optuna_xgb.predict(X_test)), r2_score(y_test, optuna_xgb.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:25:12.536997Z","iopub.execute_input":"2022-08-25T00:25:12.537366Z","iopub.status.idle":"2022-08-25T00:25:12.623580Z","shell.execute_reply.started":"2022-08-25T00:25:12.537329Z","shell.execute_reply":"2022-08-25T00:25:12.622851Z"},"trusted":true},"execution_count":241,"outputs":[{"name":"stdout","text":"XGB test: 9.431713072469499 0.0035976181956411946\nXGB GS test: 9.371976466451265 0.00966110890471683\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total time for a script: ', time.time()-time0)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:25:12.626824Z","iopub.execute_input":"2022-08-25T00:25:12.628939Z","iopub.status.idle":"2022-08-25T00:25:12.637135Z","shell.execute_reply.started":"2022-08-25T00:25:12.628906Z","shell.execute_reply":"2022-08-25T00:25:12.636014Z"},"trusted":true},"execution_count":242,"outputs":[{"name":"stdout","text":"Total time for a script:  55.89503788948059\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_size = 0.1\n# df.reset_index(inplace=True, drop=True)\n# #random.seed(2)\n# test_index = random.sample(list(df.index), int(test_size*df.shape[0]))\n# train = df.iloc[list(set(df.index)-set(test_index))]\n# test = df.iloc[test_index]\n# train.reset_index(drop=True, inplace=True)\n# test.reset_index(drop=True, inplace=True)\n# display(train.shape, test.shape, train.head(3), test.head(3))","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:25:12.641179Z","iopub.execute_input":"2022-08-25T00:25:12.641447Z","iopub.status.idle":"2022-08-25T00:25:12.649122Z","shell.execute_reply.started":"2022-08-25T00:25:12.641424Z","shell.execute_reply":"2022-08-25T00:25:12.647851Z"},"trusted":true},"execution_count":243,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This is a new version of MLEAP scripts, started in late Aug 2022.\nIt will combine IProject_MLEAP_ANN and IP_MLEAP script, while improving them.","metadata":{}},{"cell_type":"markdown","source":"#### Outline\n\n1. Load libraries and data.\n2. pEDA. Look at feature distribution, fix them if they do not look right.\n3. Train-test split. Most likely couple years into test set. 2015-2018?. Impute missing values.\n4. Transform numerical features, add ohe for inds.\n5. Fit classic models: ols as a baseline, then xgb.\n6. Fir DL.\n\n\nNotes:\nideally, I want to use time-based cross-validation.\nsince I have panel data, it is not a trivial task.\nneed to find some solution online.\ne.g., https://towardsdatascience.com/time-based-cross-validation-d259b13d42b8.\n\nfor now, will try to do siple for loop.\n","metadata":{}},{"cell_type":"code","source":"# 0. Import libraries #\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, time, math, re, warnings, random, gc, dill, optuna, pickle\nimport statsmodels.api as sm\nfrom random import sample\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNetCV\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn.inspection import permutation_importance\nfrom category_encoders import MEstimateEncoder\nfrom xgboost import XGBRegressor\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nplt.style.use('seaborn-white')\nwarnings.simplefilter(action='ignore')\npd.set_option('display.max_columns', 110)\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:42.821479Z","iopub.execute_input":"2022-08-25T19:41:42.821898Z","iopub.status.idle":"2022-08-25T19:41:42.831793Z","shell.execute_reply.started":"2022-08-25T19:41:42.821866Z","shell.execute_reply":"2022-08-25T19:41:42.830627Z"},"trusted":true},"execution_count":299,"outputs":[]},{"cell_type":"code","source":"### target encoding ###\n# source: https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices/notebook\n\nclass CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=4)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:42.849632Z","iopub.execute_input":"2022-08-25T19:41:42.850350Z","iopub.status.idle":"2022-08-25T19:41:42.861383Z","shell.execute_reply.started":"2022-08-25T19:41:42.850307Z","shell.execute_reply":"2022-08-25T19:41:42.860411Z"},"trusted":true},"execution_count":300,"outputs":[]},{"cell_type":"code","source":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:42.881496Z","iopub.execute_input":"2022-08-25T19:41:42.882322Z","iopub.status.idle":"2022-08-25T19:41:42.889263Z","shell.execute_reply.started":"2022-08-25T19:41:42.882294Z","shell.execute_reply":"2022-08-25T19:41:42.888146Z"},"trusted":true},"execution_count":301,"outputs":[{"name":"stdout","text":"REPLICAS:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"# 1. Import data #\n\n# window: 3y seems good?\n\nmin_prd = 300\nwindows_width = 3*12\n\nresults = pd.DataFrame(columns = ['min_prd', 'xgbf', 'xgbgs', 'xgbo'])\n\ntime0 = time.time()\n#df = pd.read_csv('../input/cpcrsp-46/IMLEAP_v4.csv')\nwith open('../input/kaggle-46pkl/IMLEAP_v4.pkl', 'rb') as pickled_one:\n    df = pickle.load(pickled_one)\ndf = df[df.prd.isin(range(min_prd-1, min_prd+windows_width+2))]\ndisplay(df.shape, df.head(), df.year.describe(), df.count())","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:42.941063Z","iopub.execute_input":"2022-08-25T19:41:42.943010Z","iopub.status.idle":"2022-08-25T19:41:43.713494Z","shell.execute_reply.started":"2022-08-25T19:41:42.942965Z","shell.execute_reply":"2022-08-25T19:41:43.712327Z"},"trusted":true},"execution_count":302,"outputs":[{"output_type":"display_data","data":{"text/plain":"(89414, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd     mom482     mom242  year     RET   ind        bm  \\\n224   10006  299 -19.434584 -38.390360  1983  0.1605  25.0  0.467418   \n225   10006  300 -21.388149 -35.843377  1983  5.9567  25.0  0.467418   \n226   10006  301 -13.964189 -34.528211  1983 -1.4988  25.0  0.467418   \n227   10006  302 -17.681530 -29.776396  1983  2.7008  25.0  0.467418   \n228   10006  303 -18.595559 -22.961625  1983 -2.1893  25.0  0.784207   \n\n           op        gp       inv   mom11     mom122      amhd  ivol_capm  \\\n224  0.097309  0.220497  0.118136 -4.5159  -9.790204  1.628314   1.033030   \n225  0.097309  0.220497  0.118136  0.1605  -7.157811  1.598340   1.063466   \n226  0.097309  0.220497  0.118136  5.9567 -12.456541  1.521537   1.313733   \n227  0.097309  0.220497  0.118136 -1.4988   0.904921  1.485340   2.426025   \n228  0.088427  0.222761 -0.032575  2.7008   8.156360  1.298865   1.393089   \n\n     ivol_ff5   beta_bw     MAX     vol1m     vol6m    vol12m  BAspr  \\\n224  0.727775  0.814121  1.4386  1.157497  1.825477  1.691859    NaN   \n225  0.936522  0.799767  2.3259  1.152686  1.614224  1.667907    NaN   \n226  1.155573  0.808885  4.1307  1.433440  1.474423  1.647114    NaN   \n227  2.027979  0.825450  4.3466  2.604619  1.663623  1.780087    NaN   \n228  1.343269  0.796333  3.7153  1.412173  1.616113  1.743533    NaN   \n\n         size       lbm       lop       lgp      linv      llme    l1amhd  \\\n224  5.560153  0.274945  0.118348  0.237469  0.091161  5.825327  1.626665   \n225  5.568027  0.274945  0.118348  0.237469  0.091161  5.740770  1.628314   \n226  5.632566  0.274945  0.118348  0.237469  0.091161  5.811722  1.598340   \n227  5.621046  0.274945  0.118348  0.237469  0.091161  5.718464  1.521537   \n228  5.654198  0.467418  0.097309  0.220497  0.118136  5.650019  1.485340   \n\n      l1MAX  l1BAspr    l3amhd   l3MAX  l3BAspr    l6amhd   l6MAX  l6BAspr  \\\n224  4.1337      NaN  1.715833  4.1367      NaN  1.781569  5.0932      NaN   \n225  1.4386      NaN  1.671621  4.0013      NaN  1.786906  4.5785      NaN   \n226  2.3259      NaN  1.626665  4.1337      NaN  1.762098  3.9561      NaN   \n227  4.1307      NaN  1.628314  1.4386      NaN  1.715833  4.1367      NaN   \n228  4.3466      NaN  1.598340  2.3259      NaN  1.671621  4.0013      NaN   \n\n      l12amhd  l12MAX  l12BAspr  l12mom122  l12ivol_capm  l12ivol_ff5  \\\n224  1.422049  4.1337       NaN -30.659974      0.986262     0.964204   \n225  1.440860  1.4386       NaN -30.101733      1.193522     1.015454   \n226  1.526839  2.3259       NaN -29.730986      1.645750     1.498313   \n227  1.559589  4.1307       NaN -29.282674      0.983334     0.916348   \n228  1.691079  4.3466       NaN -28.654955      1.557424     1.486731   \n\n     l12beta_bw  l12vol6m  l12vol12m  \n224    0.843484  1.687154   1.437885  \n225    0.852702  1.554393   1.440870  \n226    0.865615  1.602011   1.493237  \n227    0.864828  1.585183   1.486680  \n228    0.901204  1.618876   1.559004  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>224</th>\n      <td>10006</td>\n      <td>299</td>\n      <td>-19.434584</td>\n      <td>-38.390360</td>\n      <td>1983</td>\n      <td>0.1605</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>-4.5159</td>\n      <td>-9.790204</td>\n      <td>1.628314</td>\n      <td>1.033030</td>\n      <td>0.727775</td>\n      <td>0.814121</td>\n      <td>1.4386</td>\n      <td>1.157497</td>\n      <td>1.825477</td>\n      <td>1.691859</td>\n      <td>NaN</td>\n      <td>5.560153</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.825327</td>\n      <td>1.626665</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>1.715833</td>\n      <td>4.1367</td>\n      <td>NaN</td>\n      <td>1.781569</td>\n      <td>5.0932</td>\n      <td>NaN</td>\n      <td>1.422049</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>-30.659974</td>\n      <td>0.986262</td>\n      <td>0.964204</td>\n      <td>0.843484</td>\n      <td>1.687154</td>\n      <td>1.437885</td>\n    </tr>\n    <tr>\n      <th>225</th>\n      <td>10006</td>\n      <td>300</td>\n      <td>-21.388149</td>\n      <td>-35.843377</td>\n      <td>1983</td>\n      <td>5.9567</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>0.1605</td>\n      <td>-7.157811</td>\n      <td>1.598340</td>\n      <td>1.063466</td>\n      <td>0.936522</td>\n      <td>0.799767</td>\n      <td>2.3259</td>\n      <td>1.152686</td>\n      <td>1.614224</td>\n      <td>1.667907</td>\n      <td>NaN</td>\n      <td>5.568027</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.740770</td>\n      <td>1.628314</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>1.671621</td>\n      <td>4.0013</td>\n      <td>NaN</td>\n      <td>1.786906</td>\n      <td>4.5785</td>\n      <td>NaN</td>\n      <td>1.440860</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>-30.101733</td>\n      <td>1.193522</td>\n      <td>1.015454</td>\n      <td>0.852702</td>\n      <td>1.554393</td>\n      <td>1.440870</td>\n    </tr>\n    <tr>\n      <th>226</th>\n      <td>10006</td>\n      <td>301</td>\n      <td>-13.964189</td>\n      <td>-34.528211</td>\n      <td>1983</td>\n      <td>-1.4988</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>5.9567</td>\n      <td>-12.456541</td>\n      <td>1.521537</td>\n      <td>1.313733</td>\n      <td>1.155573</td>\n      <td>0.808885</td>\n      <td>4.1307</td>\n      <td>1.433440</td>\n      <td>1.474423</td>\n      <td>1.647114</td>\n      <td>NaN</td>\n      <td>5.632566</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.811722</td>\n      <td>1.598340</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>1.626665</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>1.762098</td>\n      <td>3.9561</td>\n      <td>NaN</td>\n      <td>1.526839</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>-29.730986</td>\n      <td>1.645750</td>\n      <td>1.498313</td>\n      <td>0.865615</td>\n      <td>1.602011</td>\n      <td>1.493237</td>\n    </tr>\n    <tr>\n      <th>227</th>\n      <td>10006</td>\n      <td>302</td>\n      <td>-17.681530</td>\n      <td>-29.776396</td>\n      <td>1983</td>\n      <td>2.7008</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>-1.4988</td>\n      <td>0.904921</td>\n      <td>1.485340</td>\n      <td>2.426025</td>\n      <td>2.027979</td>\n      <td>0.825450</td>\n      <td>4.3466</td>\n      <td>2.604619</td>\n      <td>1.663623</td>\n      <td>1.780087</td>\n      <td>NaN</td>\n      <td>5.621046</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.718464</td>\n      <td>1.521537</td>\n      <td>4.1307</td>\n      <td>NaN</td>\n      <td>1.628314</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>1.715833</td>\n      <td>4.1367</td>\n      <td>NaN</td>\n      <td>1.559589</td>\n      <td>4.1307</td>\n      <td>NaN</td>\n      <td>-29.282674</td>\n      <td>0.983334</td>\n      <td>0.916348</td>\n      <td>0.864828</td>\n      <td>1.585183</td>\n      <td>1.486680</td>\n    </tr>\n    <tr>\n      <th>228</th>\n      <td>10006</td>\n      <td>303</td>\n      <td>-18.595559</td>\n      <td>-22.961625</td>\n      <td>1983</td>\n      <td>-2.1893</td>\n      <td>25.0</td>\n      <td>0.784207</td>\n      <td>0.088427</td>\n      <td>0.222761</td>\n      <td>-0.032575</td>\n      <td>2.7008</td>\n      <td>8.156360</td>\n      <td>1.298865</td>\n      <td>1.393089</td>\n      <td>1.343269</td>\n      <td>0.796333</td>\n      <td>3.7153</td>\n      <td>1.412173</td>\n      <td>1.616113</td>\n      <td>1.743533</td>\n      <td>NaN</td>\n      <td>5.654198</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>5.650019</td>\n      <td>1.485340</td>\n      <td>4.3466</td>\n      <td>NaN</td>\n      <td>1.598340</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>1.671621</td>\n      <td>4.0013</td>\n      <td>NaN</td>\n      <td>1.691079</td>\n      <td>4.3466</td>\n      <td>NaN</td>\n      <td>-28.654955</td>\n      <td>1.557424</td>\n      <td>1.486731</td>\n      <td>0.901204</td>\n      <td>1.618876</td>\n      <td>1.559004</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"count    89414.000000\nmean      1984.326616\nstd          0.986718\nmin       1983.000000\n25%       1984.000000\n50%       1984.000000\n75%       1985.000000\nmax       1986.000000\nName: year, dtype: float64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          89414\nprd             89414\nmom482          77366\nmom242          87910\nyear            89414\nRET             89414\nind             89414\nbm              89414\nop              89414\ngp              89414\ninv             89384\nmom11           89414\nmom122          89414\namhd            67483\nivol_capm       89406\nivol_ff5        89406\nbeta_bw         89414\nMAX             89414\nvol1m           89392\nvol6m           89332\nvol12m          89193\nBAspr           15086\nsize            89414\nlbm             89414\nlop             89414\nlgp             89414\nlinv            89414\nllme            89414\nl1amhd          66888\nl1MAX           89409\nl1BAspr         14548\nl3amhd          65668\nl3MAX           89393\nl3BAspr         13462\nl6amhd          63736\nl6MAX           89361\nl6BAspr         12365\nl12amhd         59151\nl12MAX          89409\nl12BAspr         8683\nl12mom122       88531\nl12ivol_capm    89301\nl12ivol_ff5     89301\nl12beta_bw      89339\nl12vol6m        89013\nl12vol12m       88279\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# 2. pEDA #\n\nprint(df.shape)\ndf = df[(df.RET>-50)&(df.RET<75)]\nprint(df.shape)\ndf.RET.hist()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:43.715430Z","iopub.execute_input":"2022-08-25T19:41:43.715896Z","iopub.status.idle":"2022-08-25T19:41:43.941324Z","shell.execute_reply.started":"2022-08-25T19:41:43.715857Z","shell.execute_reply":"2022-08-25T19:41:43.940325Z"},"trusted":true},"execution_count":303,"outputs":[{"name":"stdout","text":"(89414, 46)\n(89142, 46)\n","output_type":"stream"},{"execution_count":303,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"meanret = df.groupby('prd').RET.mean().to_frame().reset_index().rename(columns={'RET':'mRET'})\ndf = pd.merge(df, meanret, on='prd', how='left')\ndisplay(df, df[['RET', 'mRET']].describe())\ndf.RET = df.RET-df.mRET\ndf.drop(columns='mRET', inplace=True)\ndisplay(df, df[['RET']].describe())","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:43.942933Z","iopub.execute_input":"2022-08-25T19:41:43.943298Z","iopub.status.idle":"2022-08-25T19:41:44.144643Z","shell.execute_reply.started":"2022-08-25T19:41:43.943261Z","shell.execute_reply":"2022-08-25T19:41:44.143686Z"},"trusted":true},"execution_count":304,"outputs":[{"output_type":"display_data","data":{"text/plain":"       PERMNO  prd     mom482      mom242  year      RET   ind        bm  \\\n0       10006  299 -19.434584  -38.390360  1983   0.1605  25.0  0.467418   \n1       10006  300 -21.388149  -35.843377  1983   5.9567  25.0  0.467418   \n2       10006  301 -13.964189  -34.528211  1983  -1.4988  25.0  0.467418   \n3       10006  302 -17.681530  -29.776396  1983   2.7008  25.0  0.467418   \n4       10006  303 -18.595559  -22.961625  1983  -2.1893  25.0  0.784207   \n...       ...  ...        ...         ...   ...      ...   ...       ...   \n89137   92946  333        NaN  -19.587939  1986  17.4400  47.0  0.120154   \n89138   92946  334        NaN    3.876358  1986  33.3683  47.0  0.120154   \n89139   92946  335        NaN   49.044398  1986  13.3241  47.0  0.120154   \n89140   92946  336        NaN   75.282209  1986  15.0356  47.0  0.120154   \n89141   92946  337        NaN  105.207709  1986 -12.0285  47.0  0.120154   \n\n             op        gp       inv      mom11     mom122      amhd  \\\n0      0.097309  0.220497  0.118136  -4.515900  -9.790204  1.628314   \n1      0.097309  0.220497  0.118136   0.160500  -7.157811  1.598340   \n2      0.097309  0.220497  0.118136   5.956700 -12.456541  1.521537   \n3      0.097309  0.220497  0.118136  -1.498800   0.904921  1.485340   \n4      0.088427  0.222761 -0.032575   2.700800   8.156360  1.298865   \n...         ...       ...       ...        ...        ...       ...   \n89137  0.177305  0.308133  0.215016  -1.640100  12.397723  5.125374   \n89138  0.177305  0.308133  0.215016  17.440000 -22.258250  5.232350   \n89139  0.177305  0.308133  0.215016  26.592465  -6.601710  5.196593   \n89140  0.177305  0.308133  0.215016  13.324100  29.767114  5.052953   \n89141  0.177305  0.308133  0.215016  15.035600  52.157112  4.967777   \n\n       ivol_capm  ivol_ff5   beta_bw      MAX     vol1m     vol6m    vol12m  \\\n0       1.033030  0.727775  0.814121   1.4386  1.157497  1.825477  1.691859   \n1       1.063466  0.936522  0.799767   2.3259  1.152686  1.614224  1.667907   \n2       1.313733  1.155573  0.808885   4.1307  1.433440  1.474423  1.647114   \n3       2.426025  2.027979  0.825450   4.3466  2.604619  1.663623  1.780087   \n4       1.393089  1.343269  0.796333   3.7153  1.412173  1.616113  1.743533   \n...          ...       ...       ...      ...       ...       ...       ...   \n89137   2.127734  1.928188  0.285266   4.1357  2.127804  1.798316  2.172438   \n89138   3.703064  3.313591  0.228219   7.8181  3.827562  2.166532  2.131927   \n89139   4.419921  3.534160  0.206141  14.9720  4.455543  2.815415  2.413931   \n89140   3.271774  2.861851  0.266392  12.4700  3.330529  2.964701  2.473126   \n89141   4.085311  3.321355  0.381156  15.8851  4.217792  3.391053  2.719966   \n\n       BAspr      size       lbm       lop       lgp      linv      llme  \\\n0        NaN  5.560153  0.274945  0.118348  0.237469  0.091161  5.825327   \n1        NaN  5.568027  0.274945  0.118348  0.237469  0.091161  5.740770   \n2        NaN  5.632566  0.274945  0.118348  0.237469  0.091161  5.811722   \n3        NaN  5.621046  0.274945  0.118348  0.237469  0.091161  5.718464   \n4        NaN  5.654198  0.467418  0.097309  0.220497  0.118136  5.650019   \n...      ...       ...       ...       ...       ...       ...       ...   \n89137    NaN  3.177533 -1.039216  0.136978  0.206441  0.752757  3.003179   \n89138    NaN  3.343047 -1.039216  0.136978  0.206441  0.752757  3.359854   \n89139    NaN  3.634958 -1.039216  0.136978  0.206441  0.752757  3.342787   \n89140    NaN  3.765320 -1.039216  0.136978  0.206441  0.752757  3.308301   \n89141    NaN  3.909901 -1.039216  0.136978  0.206441  0.752757  3.281632   \n\n         l1amhd    l1MAX  l1BAspr    l3amhd   l3MAX  l3BAspr    l6amhd  \\\n0      1.626665   4.1337      NaN  1.715833  4.1367      NaN  1.781569   \n1      1.628314   1.4386      NaN  1.671621  4.0013      NaN  1.786906   \n2      1.598340   2.3259      NaN  1.626665  4.1337      NaN  1.762098   \n3      1.521537   4.1307      NaN  1.628314  1.4386      NaN  1.715833   \n4      1.485340   4.3466      NaN  1.598340  2.3259      NaN  1.671621   \n...         ...      ...      ...       ...     ...      ...       ...   \n89137  5.068573   4.0516      NaN  5.102019  3.8142      NaN  4.845562   \n89138  5.125374   4.1357      NaN  5.039274  1.4066      NaN  4.861569   \n89139  5.232350   7.8181      NaN  5.068573  4.0516      NaN  4.932019   \n89140  5.196593  14.9720      NaN  5.125374  4.1357      NaN  5.102019   \n89141  5.052953  12.4700      NaN  5.232350  7.8181      NaN  5.039274   \n\n        l6MAX   l6BAspr   l12amhd   l12MAX  l12BAspr  l12mom122  l12ivol_capm  \\\n0      5.0932       NaN  1.422049   4.1337       NaN -30.659974      0.986262   \n1      4.5785       NaN  1.440860   1.4386       NaN -30.101733      1.193522   \n2      3.9561       NaN  1.526839   2.3259       NaN -29.730986      1.645750   \n3      4.1367       NaN  1.559589   4.1307       NaN -29.282674      0.983334   \n4      4.0013       NaN  1.691079   4.3466       NaN -28.654955      1.557424   \n...       ...       ...       ...      ...       ...        ...           ...   \n89137  3.8182  1.923077  4.476104   4.0516       NaN -19.103995      0.935040   \n89138  7.6643  3.703704  4.530583   4.1357  4.687500 -28.851974      3.685578   \n89139  1.8618  5.882353  4.562731   7.8181  3.448276  19.771892      2.575444   \n89140  3.8142       NaN  4.731638  14.9720  1.739130  16.664484      2.531351   \n89141  1.4066       NaN  4.786683  12.4700  1.818182  23.622024      1.557420   \n\n       l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m      mRET  \n0         0.964204    0.843484  1.687154   1.437885  4.471928  \n1         1.015454    0.852702  1.554393   1.440870  6.058939  \n2         1.498313    0.865615  1.602011   1.493237  7.356716  \n3         0.916348    0.864828  1.585183   1.486680  4.342518  \n4         1.486731    0.901204  1.618876   1.559004 -3.073421  \n...            ...         ...       ...        ...       ...  \n89137     0.851318    0.280058  2.178122   1.817845  1.581326  \n89138     3.236819    0.378143  2.712262   2.107456  4.917725  \n89139     2.382566    0.336538  2.290062   2.150948  4.068921  \n89140     2.460838    0.288472  2.293766   2.247671  0.110681  \n89141     1.046288    0.272410  2.343698   2.276872  3.328243  \n\n[89142 rows x 47 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>mRET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10006</td>\n      <td>299</td>\n      <td>-19.434584</td>\n      <td>-38.390360</td>\n      <td>1983</td>\n      <td>0.1605</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>-4.515900</td>\n      <td>-9.790204</td>\n      <td>1.628314</td>\n      <td>1.033030</td>\n      <td>0.727775</td>\n      <td>0.814121</td>\n      <td>1.4386</td>\n      <td>1.157497</td>\n      <td>1.825477</td>\n      <td>1.691859</td>\n      <td>NaN</td>\n      <td>5.560153</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.825327</td>\n      <td>1.626665</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>1.715833</td>\n      <td>4.1367</td>\n      <td>NaN</td>\n      <td>1.781569</td>\n      <td>5.0932</td>\n      <td>NaN</td>\n      <td>1.422049</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>-30.659974</td>\n      <td>0.986262</td>\n      <td>0.964204</td>\n      <td>0.843484</td>\n      <td>1.687154</td>\n      <td>1.437885</td>\n      <td>4.471928</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10006</td>\n      <td>300</td>\n      <td>-21.388149</td>\n      <td>-35.843377</td>\n      <td>1983</td>\n      <td>5.9567</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>0.160500</td>\n      <td>-7.157811</td>\n      <td>1.598340</td>\n      <td>1.063466</td>\n      <td>0.936522</td>\n      <td>0.799767</td>\n      <td>2.3259</td>\n      <td>1.152686</td>\n      <td>1.614224</td>\n      <td>1.667907</td>\n      <td>NaN</td>\n      <td>5.568027</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.740770</td>\n      <td>1.628314</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>1.671621</td>\n      <td>4.0013</td>\n      <td>NaN</td>\n      <td>1.786906</td>\n      <td>4.5785</td>\n      <td>NaN</td>\n      <td>1.440860</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>-30.101733</td>\n      <td>1.193522</td>\n      <td>1.015454</td>\n      <td>0.852702</td>\n      <td>1.554393</td>\n      <td>1.440870</td>\n      <td>6.058939</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10006</td>\n      <td>301</td>\n      <td>-13.964189</td>\n      <td>-34.528211</td>\n      <td>1983</td>\n      <td>-1.4988</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>5.956700</td>\n      <td>-12.456541</td>\n      <td>1.521537</td>\n      <td>1.313733</td>\n      <td>1.155573</td>\n      <td>0.808885</td>\n      <td>4.1307</td>\n      <td>1.433440</td>\n      <td>1.474423</td>\n      <td>1.647114</td>\n      <td>NaN</td>\n      <td>5.632566</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.811722</td>\n      <td>1.598340</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>1.626665</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>1.762098</td>\n      <td>3.9561</td>\n      <td>NaN</td>\n      <td>1.526839</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>-29.730986</td>\n      <td>1.645750</td>\n      <td>1.498313</td>\n      <td>0.865615</td>\n      <td>1.602011</td>\n      <td>1.493237</td>\n      <td>7.356716</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10006</td>\n      <td>302</td>\n      <td>-17.681530</td>\n      <td>-29.776396</td>\n      <td>1983</td>\n      <td>2.7008</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>-1.498800</td>\n      <td>0.904921</td>\n      <td>1.485340</td>\n      <td>2.426025</td>\n      <td>2.027979</td>\n      <td>0.825450</td>\n      <td>4.3466</td>\n      <td>2.604619</td>\n      <td>1.663623</td>\n      <td>1.780087</td>\n      <td>NaN</td>\n      <td>5.621046</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.718464</td>\n      <td>1.521537</td>\n      <td>4.1307</td>\n      <td>NaN</td>\n      <td>1.628314</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>1.715833</td>\n      <td>4.1367</td>\n      <td>NaN</td>\n      <td>1.559589</td>\n      <td>4.1307</td>\n      <td>NaN</td>\n      <td>-29.282674</td>\n      <td>0.983334</td>\n      <td>0.916348</td>\n      <td>0.864828</td>\n      <td>1.585183</td>\n      <td>1.486680</td>\n      <td>4.342518</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10006</td>\n      <td>303</td>\n      <td>-18.595559</td>\n      <td>-22.961625</td>\n      <td>1983</td>\n      <td>-2.1893</td>\n      <td>25.0</td>\n      <td>0.784207</td>\n      <td>0.088427</td>\n      <td>0.222761</td>\n      <td>-0.032575</td>\n      <td>2.700800</td>\n      <td>8.156360</td>\n      <td>1.298865</td>\n      <td>1.393089</td>\n      <td>1.343269</td>\n      <td>0.796333</td>\n      <td>3.7153</td>\n      <td>1.412173</td>\n      <td>1.616113</td>\n      <td>1.743533</td>\n      <td>NaN</td>\n      <td>5.654198</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>5.650019</td>\n      <td>1.485340</td>\n      <td>4.3466</td>\n      <td>NaN</td>\n      <td>1.598340</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>1.671621</td>\n      <td>4.0013</td>\n      <td>NaN</td>\n      <td>1.691079</td>\n      <td>4.3466</td>\n      <td>NaN</td>\n      <td>-28.654955</td>\n      <td>1.557424</td>\n      <td>1.486731</td>\n      <td>0.901204</td>\n      <td>1.618876</td>\n      <td>1.559004</td>\n      <td>-3.073421</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>89137</th>\n      <td>92946</td>\n      <td>333</td>\n      <td>NaN</td>\n      <td>-19.587939</td>\n      <td>1986</td>\n      <td>17.4400</td>\n      <td>47.0</td>\n      <td>0.120154</td>\n      <td>0.177305</td>\n      <td>0.308133</td>\n      <td>0.215016</td>\n      <td>-1.640100</td>\n      <td>12.397723</td>\n      <td>5.125374</td>\n      <td>2.127734</td>\n      <td>1.928188</td>\n      <td>0.285266</td>\n      <td>4.1357</td>\n      <td>2.127804</td>\n      <td>1.798316</td>\n      <td>2.172438</td>\n      <td>NaN</td>\n      <td>3.177533</td>\n      <td>-1.039216</td>\n      <td>0.136978</td>\n      <td>0.206441</td>\n      <td>0.752757</td>\n      <td>3.003179</td>\n      <td>5.068573</td>\n      <td>4.0516</td>\n      <td>NaN</td>\n      <td>5.102019</td>\n      <td>3.8142</td>\n      <td>NaN</td>\n      <td>4.845562</td>\n      <td>3.8182</td>\n      <td>1.923077</td>\n      <td>4.476104</td>\n      <td>4.0516</td>\n      <td>NaN</td>\n      <td>-19.103995</td>\n      <td>0.935040</td>\n      <td>0.851318</td>\n      <td>0.280058</td>\n      <td>2.178122</td>\n      <td>1.817845</td>\n      <td>1.581326</td>\n    </tr>\n    <tr>\n      <th>89138</th>\n      <td>92946</td>\n      <td>334</td>\n      <td>NaN</td>\n      <td>3.876358</td>\n      <td>1986</td>\n      <td>33.3683</td>\n      <td>47.0</td>\n      <td>0.120154</td>\n      <td>0.177305</td>\n      <td>0.308133</td>\n      <td>0.215016</td>\n      <td>17.440000</td>\n      <td>-22.258250</td>\n      <td>5.232350</td>\n      <td>3.703064</td>\n      <td>3.313591</td>\n      <td>0.228219</td>\n      <td>7.8181</td>\n      <td>3.827562</td>\n      <td>2.166532</td>\n      <td>2.131927</td>\n      <td>NaN</td>\n      <td>3.343047</td>\n      <td>-1.039216</td>\n      <td>0.136978</td>\n      <td>0.206441</td>\n      <td>0.752757</td>\n      <td>3.359854</td>\n      <td>5.125374</td>\n      <td>4.1357</td>\n      <td>NaN</td>\n      <td>5.039274</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>4.861569</td>\n      <td>7.6643</td>\n      <td>3.703704</td>\n      <td>4.530583</td>\n      <td>4.1357</td>\n      <td>4.687500</td>\n      <td>-28.851974</td>\n      <td>3.685578</td>\n      <td>3.236819</td>\n      <td>0.378143</td>\n      <td>2.712262</td>\n      <td>2.107456</td>\n      <td>4.917725</td>\n    </tr>\n    <tr>\n      <th>89139</th>\n      <td>92946</td>\n      <td>335</td>\n      <td>NaN</td>\n      <td>49.044398</td>\n      <td>1986</td>\n      <td>13.3241</td>\n      <td>47.0</td>\n      <td>0.120154</td>\n      <td>0.177305</td>\n      <td>0.308133</td>\n      <td>0.215016</td>\n      <td>26.592465</td>\n      <td>-6.601710</td>\n      <td>5.196593</td>\n      <td>4.419921</td>\n      <td>3.534160</td>\n      <td>0.206141</td>\n      <td>14.9720</td>\n      <td>4.455543</td>\n      <td>2.815415</td>\n      <td>2.413931</td>\n      <td>NaN</td>\n      <td>3.634958</td>\n      <td>-1.039216</td>\n      <td>0.136978</td>\n      <td>0.206441</td>\n      <td>0.752757</td>\n      <td>3.342787</td>\n      <td>5.232350</td>\n      <td>7.8181</td>\n      <td>NaN</td>\n      <td>5.068573</td>\n      <td>4.0516</td>\n      <td>NaN</td>\n      <td>4.932019</td>\n      <td>1.8618</td>\n      <td>5.882353</td>\n      <td>4.562731</td>\n      <td>7.8181</td>\n      <td>3.448276</td>\n      <td>19.771892</td>\n      <td>2.575444</td>\n      <td>2.382566</td>\n      <td>0.336538</td>\n      <td>2.290062</td>\n      <td>2.150948</td>\n      <td>4.068921</td>\n    </tr>\n    <tr>\n      <th>89140</th>\n      <td>92946</td>\n      <td>336</td>\n      <td>NaN</td>\n      <td>75.282209</td>\n      <td>1986</td>\n      <td>15.0356</td>\n      <td>47.0</td>\n      <td>0.120154</td>\n      <td>0.177305</td>\n      <td>0.308133</td>\n      <td>0.215016</td>\n      <td>13.324100</td>\n      <td>29.767114</td>\n      <td>5.052953</td>\n      <td>3.271774</td>\n      <td>2.861851</td>\n      <td>0.266392</td>\n      <td>12.4700</td>\n      <td>3.330529</td>\n      <td>2.964701</td>\n      <td>2.473126</td>\n      <td>NaN</td>\n      <td>3.765320</td>\n      <td>-1.039216</td>\n      <td>0.136978</td>\n      <td>0.206441</td>\n      <td>0.752757</td>\n      <td>3.308301</td>\n      <td>5.196593</td>\n      <td>14.9720</td>\n      <td>NaN</td>\n      <td>5.125374</td>\n      <td>4.1357</td>\n      <td>NaN</td>\n      <td>5.102019</td>\n      <td>3.8142</td>\n      <td>NaN</td>\n      <td>4.731638</td>\n      <td>14.9720</td>\n      <td>1.739130</td>\n      <td>16.664484</td>\n      <td>2.531351</td>\n      <td>2.460838</td>\n      <td>0.288472</td>\n      <td>2.293766</td>\n      <td>2.247671</td>\n      <td>0.110681</td>\n    </tr>\n    <tr>\n      <th>89141</th>\n      <td>92946</td>\n      <td>337</td>\n      <td>NaN</td>\n      <td>105.207709</td>\n      <td>1986</td>\n      <td>-12.0285</td>\n      <td>47.0</td>\n      <td>0.120154</td>\n      <td>0.177305</td>\n      <td>0.308133</td>\n      <td>0.215016</td>\n      <td>15.035600</td>\n      <td>52.157112</td>\n      <td>4.967777</td>\n      <td>4.085311</td>\n      <td>3.321355</td>\n      <td>0.381156</td>\n      <td>15.8851</td>\n      <td>4.217792</td>\n      <td>3.391053</td>\n      <td>2.719966</td>\n      <td>NaN</td>\n      <td>3.909901</td>\n      <td>-1.039216</td>\n      <td>0.136978</td>\n      <td>0.206441</td>\n      <td>0.752757</td>\n      <td>3.281632</td>\n      <td>5.052953</td>\n      <td>12.4700</td>\n      <td>NaN</td>\n      <td>5.232350</td>\n      <td>7.8181</td>\n      <td>NaN</td>\n      <td>5.039274</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>4.786683</td>\n      <td>12.4700</td>\n      <td>1.818182</td>\n      <td>23.622024</td>\n      <td>1.557420</td>\n      <td>1.046288</td>\n      <td>0.272410</td>\n      <td>2.343698</td>\n      <td>2.276872</td>\n      <td>3.328243</td>\n    </tr>\n  </tbody>\n</table>\n<p>89142 rows × 47 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                RET          mRET\ncount  89142.000000  89142.000000\nmean       0.429392      0.429392\nstd       12.537315      4.229241\nmin      -49.447900     -6.515949\n25%       -6.542400     -2.635541\n50%       -0.600000      0.110681\n75%        6.392300      3.408678\nmax       74.380000     11.035232","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RET</th>\n      <th>mRET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>89142.000000</td>\n      <td>89142.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.429392</td>\n      <td>0.429392</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>12.537315</td>\n      <td>4.229241</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-49.447900</td>\n      <td>-6.515949</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-6.542400</td>\n      <td>-2.635541</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-0.600000</td>\n      <td>0.110681</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.392300</td>\n      <td>3.408678</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>74.380000</td>\n      <td>11.035232</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"       PERMNO  prd     mom482      mom242  year        RET   ind        bm  \\\n0       10006  299 -19.434584  -38.390360  1983  -4.311428  25.0  0.467418   \n1       10006  300 -21.388149  -35.843377  1983  -0.102239  25.0  0.467418   \n2       10006  301 -13.964189  -34.528211  1983  -8.855516  25.0  0.467418   \n3       10006  302 -17.681530  -29.776396  1983  -1.641718  25.0  0.467418   \n4       10006  303 -18.595559  -22.961625  1983   0.884121  25.0  0.784207   \n...       ...  ...        ...         ...   ...        ...   ...       ...   \n89137   92946  333        NaN  -19.587939  1986  15.858674  47.0  0.120154   \n89138   92946  334        NaN    3.876358  1986  28.450575  47.0  0.120154   \n89139   92946  335        NaN   49.044398  1986   9.255179  47.0  0.120154   \n89140   92946  336        NaN   75.282209  1986  14.924919  47.0  0.120154   \n89141   92946  337        NaN  105.207709  1986 -15.356743  47.0  0.120154   \n\n             op        gp       inv      mom11     mom122      amhd  \\\n0      0.097309  0.220497  0.118136  -4.515900  -9.790204  1.628314   \n1      0.097309  0.220497  0.118136   0.160500  -7.157811  1.598340   \n2      0.097309  0.220497  0.118136   5.956700 -12.456541  1.521537   \n3      0.097309  0.220497  0.118136  -1.498800   0.904921  1.485340   \n4      0.088427  0.222761 -0.032575   2.700800   8.156360  1.298865   \n...         ...       ...       ...        ...        ...       ...   \n89137  0.177305  0.308133  0.215016  -1.640100  12.397723  5.125374   \n89138  0.177305  0.308133  0.215016  17.440000 -22.258250  5.232350   \n89139  0.177305  0.308133  0.215016  26.592465  -6.601710  5.196593   \n89140  0.177305  0.308133  0.215016  13.324100  29.767114  5.052953   \n89141  0.177305  0.308133  0.215016  15.035600  52.157112  4.967777   \n\n       ivol_capm  ivol_ff5   beta_bw      MAX     vol1m     vol6m    vol12m  \\\n0       1.033030  0.727775  0.814121   1.4386  1.157497  1.825477  1.691859   \n1       1.063466  0.936522  0.799767   2.3259  1.152686  1.614224  1.667907   \n2       1.313733  1.155573  0.808885   4.1307  1.433440  1.474423  1.647114   \n3       2.426025  2.027979  0.825450   4.3466  2.604619  1.663623  1.780087   \n4       1.393089  1.343269  0.796333   3.7153  1.412173  1.616113  1.743533   \n...          ...       ...       ...      ...       ...       ...       ...   \n89137   2.127734  1.928188  0.285266   4.1357  2.127804  1.798316  2.172438   \n89138   3.703064  3.313591  0.228219   7.8181  3.827562  2.166532  2.131927   \n89139   4.419921  3.534160  0.206141  14.9720  4.455543  2.815415  2.413931   \n89140   3.271774  2.861851  0.266392  12.4700  3.330529  2.964701  2.473126   \n89141   4.085311  3.321355  0.381156  15.8851  4.217792  3.391053  2.719966   \n\n       BAspr      size       lbm       lop       lgp      linv      llme  \\\n0        NaN  5.560153  0.274945  0.118348  0.237469  0.091161  5.825327   \n1        NaN  5.568027  0.274945  0.118348  0.237469  0.091161  5.740770   \n2        NaN  5.632566  0.274945  0.118348  0.237469  0.091161  5.811722   \n3        NaN  5.621046  0.274945  0.118348  0.237469  0.091161  5.718464   \n4        NaN  5.654198  0.467418  0.097309  0.220497  0.118136  5.650019   \n...      ...       ...       ...       ...       ...       ...       ...   \n89137    NaN  3.177533 -1.039216  0.136978  0.206441  0.752757  3.003179   \n89138    NaN  3.343047 -1.039216  0.136978  0.206441  0.752757  3.359854   \n89139    NaN  3.634958 -1.039216  0.136978  0.206441  0.752757  3.342787   \n89140    NaN  3.765320 -1.039216  0.136978  0.206441  0.752757  3.308301   \n89141    NaN  3.909901 -1.039216  0.136978  0.206441  0.752757  3.281632   \n\n         l1amhd    l1MAX  l1BAspr    l3amhd   l3MAX  l3BAspr    l6amhd  \\\n0      1.626665   4.1337      NaN  1.715833  4.1367      NaN  1.781569   \n1      1.628314   1.4386      NaN  1.671621  4.0013      NaN  1.786906   \n2      1.598340   2.3259      NaN  1.626665  4.1337      NaN  1.762098   \n3      1.521537   4.1307      NaN  1.628314  1.4386      NaN  1.715833   \n4      1.485340   4.3466      NaN  1.598340  2.3259      NaN  1.671621   \n...         ...      ...      ...       ...     ...      ...       ...   \n89137  5.068573   4.0516      NaN  5.102019  3.8142      NaN  4.845562   \n89138  5.125374   4.1357      NaN  5.039274  1.4066      NaN  4.861569   \n89139  5.232350   7.8181      NaN  5.068573  4.0516      NaN  4.932019   \n89140  5.196593  14.9720      NaN  5.125374  4.1357      NaN  5.102019   \n89141  5.052953  12.4700      NaN  5.232350  7.8181      NaN  5.039274   \n\n        l6MAX   l6BAspr   l12amhd   l12MAX  l12BAspr  l12mom122  l12ivol_capm  \\\n0      5.0932       NaN  1.422049   4.1337       NaN -30.659974      0.986262   \n1      4.5785       NaN  1.440860   1.4386       NaN -30.101733      1.193522   \n2      3.9561       NaN  1.526839   2.3259       NaN -29.730986      1.645750   \n3      4.1367       NaN  1.559589   4.1307       NaN -29.282674      0.983334   \n4      4.0013       NaN  1.691079   4.3466       NaN -28.654955      1.557424   \n...       ...       ...       ...      ...       ...        ...           ...   \n89137  3.8182  1.923077  4.476104   4.0516       NaN -19.103995      0.935040   \n89138  7.6643  3.703704  4.530583   4.1357  4.687500 -28.851974      3.685578   \n89139  1.8618  5.882353  4.562731   7.8181  3.448276  19.771892      2.575444   \n89140  3.8142       NaN  4.731638  14.9720  1.739130  16.664484      2.531351   \n89141  1.4066       NaN  4.786683  12.4700  1.818182  23.622024      1.557420   \n\n       l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n0         0.964204    0.843484  1.687154   1.437885  \n1         1.015454    0.852702  1.554393   1.440870  \n2         1.498313    0.865615  1.602011   1.493237  \n3         0.916348    0.864828  1.585183   1.486680  \n4         1.486731    0.901204  1.618876   1.559004  \n...            ...         ...       ...        ...  \n89137     0.851318    0.280058  2.178122   1.817845  \n89138     3.236819    0.378143  2.712262   2.107456  \n89139     2.382566    0.336538  2.290062   2.150948  \n89140     2.460838    0.288472  2.293766   2.247671  \n89141     1.046288    0.272410  2.343698   2.276872  \n\n[89142 rows x 46 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10006</td>\n      <td>299</td>\n      <td>-19.434584</td>\n      <td>-38.390360</td>\n      <td>1983</td>\n      <td>-4.311428</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>-4.515900</td>\n      <td>-9.790204</td>\n      <td>1.628314</td>\n      <td>1.033030</td>\n      <td>0.727775</td>\n      <td>0.814121</td>\n      <td>1.4386</td>\n      <td>1.157497</td>\n      <td>1.825477</td>\n      <td>1.691859</td>\n      <td>NaN</td>\n      <td>5.560153</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.825327</td>\n      <td>1.626665</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>1.715833</td>\n      <td>4.1367</td>\n      <td>NaN</td>\n      <td>1.781569</td>\n      <td>5.0932</td>\n      <td>NaN</td>\n      <td>1.422049</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>-30.659974</td>\n      <td>0.986262</td>\n      <td>0.964204</td>\n      <td>0.843484</td>\n      <td>1.687154</td>\n      <td>1.437885</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10006</td>\n      <td>300</td>\n      <td>-21.388149</td>\n      <td>-35.843377</td>\n      <td>1983</td>\n      <td>-0.102239</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>0.160500</td>\n      <td>-7.157811</td>\n      <td>1.598340</td>\n      <td>1.063466</td>\n      <td>0.936522</td>\n      <td>0.799767</td>\n      <td>2.3259</td>\n      <td>1.152686</td>\n      <td>1.614224</td>\n      <td>1.667907</td>\n      <td>NaN</td>\n      <td>5.568027</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.740770</td>\n      <td>1.628314</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>1.671621</td>\n      <td>4.0013</td>\n      <td>NaN</td>\n      <td>1.786906</td>\n      <td>4.5785</td>\n      <td>NaN</td>\n      <td>1.440860</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>-30.101733</td>\n      <td>1.193522</td>\n      <td>1.015454</td>\n      <td>0.852702</td>\n      <td>1.554393</td>\n      <td>1.440870</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10006</td>\n      <td>301</td>\n      <td>-13.964189</td>\n      <td>-34.528211</td>\n      <td>1983</td>\n      <td>-8.855516</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>5.956700</td>\n      <td>-12.456541</td>\n      <td>1.521537</td>\n      <td>1.313733</td>\n      <td>1.155573</td>\n      <td>0.808885</td>\n      <td>4.1307</td>\n      <td>1.433440</td>\n      <td>1.474423</td>\n      <td>1.647114</td>\n      <td>NaN</td>\n      <td>5.632566</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.811722</td>\n      <td>1.598340</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>1.626665</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>1.762098</td>\n      <td>3.9561</td>\n      <td>NaN</td>\n      <td>1.526839</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>-29.730986</td>\n      <td>1.645750</td>\n      <td>1.498313</td>\n      <td>0.865615</td>\n      <td>1.602011</td>\n      <td>1.493237</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10006</td>\n      <td>302</td>\n      <td>-17.681530</td>\n      <td>-29.776396</td>\n      <td>1983</td>\n      <td>-1.641718</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>-1.498800</td>\n      <td>0.904921</td>\n      <td>1.485340</td>\n      <td>2.426025</td>\n      <td>2.027979</td>\n      <td>0.825450</td>\n      <td>4.3466</td>\n      <td>2.604619</td>\n      <td>1.663623</td>\n      <td>1.780087</td>\n      <td>NaN</td>\n      <td>5.621046</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.718464</td>\n      <td>1.521537</td>\n      <td>4.1307</td>\n      <td>NaN</td>\n      <td>1.628314</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>1.715833</td>\n      <td>4.1367</td>\n      <td>NaN</td>\n      <td>1.559589</td>\n      <td>4.1307</td>\n      <td>NaN</td>\n      <td>-29.282674</td>\n      <td>0.983334</td>\n      <td>0.916348</td>\n      <td>0.864828</td>\n      <td>1.585183</td>\n      <td>1.486680</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10006</td>\n      <td>303</td>\n      <td>-18.595559</td>\n      <td>-22.961625</td>\n      <td>1983</td>\n      <td>0.884121</td>\n      <td>25.0</td>\n      <td>0.784207</td>\n      <td>0.088427</td>\n      <td>0.222761</td>\n      <td>-0.032575</td>\n      <td>2.700800</td>\n      <td>8.156360</td>\n      <td>1.298865</td>\n      <td>1.393089</td>\n      <td>1.343269</td>\n      <td>0.796333</td>\n      <td>3.7153</td>\n      <td>1.412173</td>\n      <td>1.616113</td>\n      <td>1.743533</td>\n      <td>NaN</td>\n      <td>5.654198</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>5.650019</td>\n      <td>1.485340</td>\n      <td>4.3466</td>\n      <td>NaN</td>\n      <td>1.598340</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>1.671621</td>\n      <td>4.0013</td>\n      <td>NaN</td>\n      <td>1.691079</td>\n      <td>4.3466</td>\n      <td>NaN</td>\n      <td>-28.654955</td>\n      <td>1.557424</td>\n      <td>1.486731</td>\n      <td>0.901204</td>\n      <td>1.618876</td>\n      <td>1.559004</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>89137</th>\n      <td>92946</td>\n      <td>333</td>\n      <td>NaN</td>\n      <td>-19.587939</td>\n      <td>1986</td>\n      <td>15.858674</td>\n      <td>47.0</td>\n      <td>0.120154</td>\n      <td>0.177305</td>\n      <td>0.308133</td>\n      <td>0.215016</td>\n      <td>-1.640100</td>\n      <td>12.397723</td>\n      <td>5.125374</td>\n      <td>2.127734</td>\n      <td>1.928188</td>\n      <td>0.285266</td>\n      <td>4.1357</td>\n      <td>2.127804</td>\n      <td>1.798316</td>\n      <td>2.172438</td>\n      <td>NaN</td>\n      <td>3.177533</td>\n      <td>-1.039216</td>\n      <td>0.136978</td>\n      <td>0.206441</td>\n      <td>0.752757</td>\n      <td>3.003179</td>\n      <td>5.068573</td>\n      <td>4.0516</td>\n      <td>NaN</td>\n      <td>5.102019</td>\n      <td>3.8142</td>\n      <td>NaN</td>\n      <td>4.845562</td>\n      <td>3.8182</td>\n      <td>1.923077</td>\n      <td>4.476104</td>\n      <td>4.0516</td>\n      <td>NaN</td>\n      <td>-19.103995</td>\n      <td>0.935040</td>\n      <td>0.851318</td>\n      <td>0.280058</td>\n      <td>2.178122</td>\n      <td>1.817845</td>\n    </tr>\n    <tr>\n      <th>89138</th>\n      <td>92946</td>\n      <td>334</td>\n      <td>NaN</td>\n      <td>3.876358</td>\n      <td>1986</td>\n      <td>28.450575</td>\n      <td>47.0</td>\n      <td>0.120154</td>\n      <td>0.177305</td>\n      <td>0.308133</td>\n      <td>0.215016</td>\n      <td>17.440000</td>\n      <td>-22.258250</td>\n      <td>5.232350</td>\n      <td>3.703064</td>\n      <td>3.313591</td>\n      <td>0.228219</td>\n      <td>7.8181</td>\n      <td>3.827562</td>\n      <td>2.166532</td>\n      <td>2.131927</td>\n      <td>NaN</td>\n      <td>3.343047</td>\n      <td>-1.039216</td>\n      <td>0.136978</td>\n      <td>0.206441</td>\n      <td>0.752757</td>\n      <td>3.359854</td>\n      <td>5.125374</td>\n      <td>4.1357</td>\n      <td>NaN</td>\n      <td>5.039274</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>4.861569</td>\n      <td>7.6643</td>\n      <td>3.703704</td>\n      <td>4.530583</td>\n      <td>4.1357</td>\n      <td>4.687500</td>\n      <td>-28.851974</td>\n      <td>3.685578</td>\n      <td>3.236819</td>\n      <td>0.378143</td>\n      <td>2.712262</td>\n      <td>2.107456</td>\n    </tr>\n    <tr>\n      <th>89139</th>\n      <td>92946</td>\n      <td>335</td>\n      <td>NaN</td>\n      <td>49.044398</td>\n      <td>1986</td>\n      <td>9.255179</td>\n      <td>47.0</td>\n      <td>0.120154</td>\n      <td>0.177305</td>\n      <td>0.308133</td>\n      <td>0.215016</td>\n      <td>26.592465</td>\n      <td>-6.601710</td>\n      <td>5.196593</td>\n      <td>4.419921</td>\n      <td>3.534160</td>\n      <td>0.206141</td>\n      <td>14.9720</td>\n      <td>4.455543</td>\n      <td>2.815415</td>\n      <td>2.413931</td>\n      <td>NaN</td>\n      <td>3.634958</td>\n      <td>-1.039216</td>\n      <td>0.136978</td>\n      <td>0.206441</td>\n      <td>0.752757</td>\n      <td>3.342787</td>\n      <td>5.232350</td>\n      <td>7.8181</td>\n      <td>NaN</td>\n      <td>5.068573</td>\n      <td>4.0516</td>\n      <td>NaN</td>\n      <td>4.932019</td>\n      <td>1.8618</td>\n      <td>5.882353</td>\n      <td>4.562731</td>\n      <td>7.8181</td>\n      <td>3.448276</td>\n      <td>19.771892</td>\n      <td>2.575444</td>\n      <td>2.382566</td>\n      <td>0.336538</td>\n      <td>2.290062</td>\n      <td>2.150948</td>\n    </tr>\n    <tr>\n      <th>89140</th>\n      <td>92946</td>\n      <td>336</td>\n      <td>NaN</td>\n      <td>75.282209</td>\n      <td>1986</td>\n      <td>14.924919</td>\n      <td>47.0</td>\n      <td>0.120154</td>\n      <td>0.177305</td>\n      <td>0.308133</td>\n      <td>0.215016</td>\n      <td>13.324100</td>\n      <td>29.767114</td>\n      <td>5.052953</td>\n      <td>3.271774</td>\n      <td>2.861851</td>\n      <td>0.266392</td>\n      <td>12.4700</td>\n      <td>3.330529</td>\n      <td>2.964701</td>\n      <td>2.473126</td>\n      <td>NaN</td>\n      <td>3.765320</td>\n      <td>-1.039216</td>\n      <td>0.136978</td>\n      <td>0.206441</td>\n      <td>0.752757</td>\n      <td>3.308301</td>\n      <td>5.196593</td>\n      <td>14.9720</td>\n      <td>NaN</td>\n      <td>5.125374</td>\n      <td>4.1357</td>\n      <td>NaN</td>\n      <td>5.102019</td>\n      <td>3.8142</td>\n      <td>NaN</td>\n      <td>4.731638</td>\n      <td>14.9720</td>\n      <td>1.739130</td>\n      <td>16.664484</td>\n      <td>2.531351</td>\n      <td>2.460838</td>\n      <td>0.288472</td>\n      <td>2.293766</td>\n      <td>2.247671</td>\n    </tr>\n    <tr>\n      <th>89141</th>\n      <td>92946</td>\n      <td>337</td>\n      <td>NaN</td>\n      <td>105.207709</td>\n      <td>1986</td>\n      <td>-15.356743</td>\n      <td>47.0</td>\n      <td>0.120154</td>\n      <td>0.177305</td>\n      <td>0.308133</td>\n      <td>0.215016</td>\n      <td>15.035600</td>\n      <td>52.157112</td>\n      <td>4.967777</td>\n      <td>4.085311</td>\n      <td>3.321355</td>\n      <td>0.381156</td>\n      <td>15.8851</td>\n      <td>4.217792</td>\n      <td>3.391053</td>\n      <td>2.719966</td>\n      <td>NaN</td>\n      <td>3.909901</td>\n      <td>-1.039216</td>\n      <td>0.136978</td>\n      <td>0.206441</td>\n      <td>0.752757</td>\n      <td>3.281632</td>\n      <td>5.052953</td>\n      <td>12.4700</td>\n      <td>NaN</td>\n      <td>5.232350</td>\n      <td>7.8181</td>\n      <td>NaN</td>\n      <td>5.039274</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>4.786683</td>\n      <td>12.4700</td>\n      <td>1.818182</td>\n      <td>23.622024</td>\n      <td>1.557420</td>\n      <td>1.046288</td>\n      <td>0.272410</td>\n      <td>2.343698</td>\n      <td>2.276872</td>\n    </tr>\n  </tbody>\n</table>\n<p>89142 rows × 46 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                RET\ncount  8.914200e+04\nmean   2.550691e-17\nstd    1.180245e+01\nmin   -6.007233e+01\n25%   -6.412001e+00\n50%   -4.024439e-01\n75%    5.585002e+00\nmax    7.860422e+01","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8.914200e+04</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.550691e-17</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.180245e+01</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-6.007233e+01</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-6.412001e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-4.024439e-01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5.585002e+00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.860422e+01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# explore feature distibution, adjust if seems unreasonable","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:44.147309Z","iopub.execute_input":"2022-08-25T19:41:44.148542Z","iopub.status.idle":"2022-08-25T19:41:44.153313Z","shell.execute_reply.started":"2022-08-25T19:41:44.148503Z","shell.execute_reply":"2022-08-25T19:41:44.152342Z"},"trusted":true},"execution_count":305,"outputs":[]},{"cell_type":"code","source":"# add dummies for some missing features\n\nfeatures_miss_dummies = ['amhd', 'BAspr']\n\nfor col in features_miss_dummies:\n    df[col+'_miss'] = df[col].isnull().astype(int)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:44.154972Z","iopub.execute_input":"2022-08-25T19:41:44.155422Z","iopub.status.idle":"2022-08-25T19:41:44.200520Z","shell.execute_reply.started":"2022-08-25T19:41:44.155386Z","shell.execute_reply":"2022-08-25T19:41:44.199261Z"},"trusted":true},"execution_count":306,"outputs":[{"execution_count":306,"output_type":"execute_result","data":{"text/plain":"   PERMNO  prd     mom482     mom242  year       RET   ind        bm  \\\n0   10006  299 -19.434584 -38.390360  1983 -4.311428  25.0  0.467418   \n1   10006  300 -21.388149 -35.843377  1983 -0.102239  25.0  0.467418   \n2   10006  301 -13.964189 -34.528211  1983 -8.855516  25.0  0.467418   \n3   10006  302 -17.681530 -29.776396  1983 -1.641718  25.0  0.467418   \n4   10006  303 -18.595559 -22.961625  1983  0.884121  25.0  0.784207   \n\n         op        gp       inv   mom11     mom122      amhd  ivol_capm  \\\n0  0.097309  0.220497  0.118136 -4.5159  -9.790204  1.628314   1.033030   \n1  0.097309  0.220497  0.118136  0.1605  -7.157811  1.598340   1.063466   \n2  0.097309  0.220497  0.118136  5.9567 -12.456541  1.521537   1.313733   \n3  0.097309  0.220497  0.118136 -1.4988   0.904921  1.485340   2.426025   \n4  0.088427  0.222761 -0.032575  2.7008   8.156360  1.298865   1.393089   \n\n   ivol_ff5   beta_bw     MAX     vol1m     vol6m    vol12m  BAspr      size  \\\n0  0.727775  0.814121  1.4386  1.157497  1.825477  1.691859    NaN  5.560153   \n1  0.936522  0.799767  2.3259  1.152686  1.614224  1.667907    NaN  5.568027   \n2  1.155573  0.808885  4.1307  1.433440  1.474423  1.647114    NaN  5.632566   \n3  2.027979  0.825450  4.3466  2.604619  1.663623  1.780087    NaN  5.621046   \n4  1.343269  0.796333  3.7153  1.412173  1.616113  1.743533    NaN  5.654198   \n\n        lbm       lop       lgp      linv      llme    l1amhd   l1MAX  \\\n0  0.274945  0.118348  0.237469  0.091161  5.825327  1.626665  4.1337   \n1  0.274945  0.118348  0.237469  0.091161  5.740770  1.628314  1.4386   \n2  0.274945  0.118348  0.237469  0.091161  5.811722  1.598340  2.3259   \n3  0.274945  0.118348  0.237469  0.091161  5.718464  1.521537  4.1307   \n4  0.467418  0.097309  0.220497  0.118136  5.650019  1.485340  4.3466   \n\n   l1BAspr    l3amhd   l3MAX  l3BAspr    l6amhd   l6MAX  l6BAspr   l12amhd  \\\n0      NaN  1.715833  4.1367      NaN  1.781569  5.0932      NaN  1.422049   \n1      NaN  1.671621  4.0013      NaN  1.786906  4.5785      NaN  1.440860   \n2      NaN  1.626665  4.1337      NaN  1.762098  3.9561      NaN  1.526839   \n3      NaN  1.628314  1.4386      NaN  1.715833  4.1367      NaN  1.559589   \n4      NaN  1.598340  2.3259      NaN  1.671621  4.0013      NaN  1.691079   \n\n   l12MAX  l12BAspr  l12mom122  l12ivol_capm  l12ivol_ff5  l12beta_bw  \\\n0  4.1337       NaN -30.659974      0.986262     0.964204    0.843484   \n1  1.4386       NaN -30.101733      1.193522     1.015454    0.852702   \n2  2.3259       NaN -29.730986      1.645750     1.498313    0.865615   \n3  4.1307       NaN -29.282674      0.983334     0.916348    0.864828   \n4  4.3466       NaN -28.654955      1.557424     1.486731    0.901204   \n\n   l12vol6m  l12vol12m  amhd_miss  BAspr_miss  \n0  1.687154   1.437885          0           1  \n1  1.554393   1.440870          0           1  \n2  1.602011   1.493237          0           1  \n3  1.585183   1.486680          0           1  \n4  1.618876   1.559004          0           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>amhd_miss</th>\n      <th>BAspr_miss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10006</td>\n      <td>299</td>\n      <td>-19.434584</td>\n      <td>-38.390360</td>\n      <td>1983</td>\n      <td>-4.311428</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>-4.5159</td>\n      <td>-9.790204</td>\n      <td>1.628314</td>\n      <td>1.033030</td>\n      <td>0.727775</td>\n      <td>0.814121</td>\n      <td>1.4386</td>\n      <td>1.157497</td>\n      <td>1.825477</td>\n      <td>1.691859</td>\n      <td>NaN</td>\n      <td>5.560153</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.825327</td>\n      <td>1.626665</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>1.715833</td>\n      <td>4.1367</td>\n      <td>NaN</td>\n      <td>1.781569</td>\n      <td>5.0932</td>\n      <td>NaN</td>\n      <td>1.422049</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>-30.659974</td>\n      <td>0.986262</td>\n      <td>0.964204</td>\n      <td>0.843484</td>\n      <td>1.687154</td>\n      <td>1.437885</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10006</td>\n      <td>300</td>\n      <td>-21.388149</td>\n      <td>-35.843377</td>\n      <td>1983</td>\n      <td>-0.102239</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>0.1605</td>\n      <td>-7.157811</td>\n      <td>1.598340</td>\n      <td>1.063466</td>\n      <td>0.936522</td>\n      <td>0.799767</td>\n      <td>2.3259</td>\n      <td>1.152686</td>\n      <td>1.614224</td>\n      <td>1.667907</td>\n      <td>NaN</td>\n      <td>5.568027</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.740770</td>\n      <td>1.628314</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>1.671621</td>\n      <td>4.0013</td>\n      <td>NaN</td>\n      <td>1.786906</td>\n      <td>4.5785</td>\n      <td>NaN</td>\n      <td>1.440860</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>-30.101733</td>\n      <td>1.193522</td>\n      <td>1.015454</td>\n      <td>0.852702</td>\n      <td>1.554393</td>\n      <td>1.440870</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10006</td>\n      <td>301</td>\n      <td>-13.964189</td>\n      <td>-34.528211</td>\n      <td>1983</td>\n      <td>-8.855516</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>5.9567</td>\n      <td>-12.456541</td>\n      <td>1.521537</td>\n      <td>1.313733</td>\n      <td>1.155573</td>\n      <td>0.808885</td>\n      <td>4.1307</td>\n      <td>1.433440</td>\n      <td>1.474423</td>\n      <td>1.647114</td>\n      <td>NaN</td>\n      <td>5.632566</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.811722</td>\n      <td>1.598340</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>1.626665</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>1.762098</td>\n      <td>3.9561</td>\n      <td>NaN</td>\n      <td>1.526839</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>-29.730986</td>\n      <td>1.645750</td>\n      <td>1.498313</td>\n      <td>0.865615</td>\n      <td>1.602011</td>\n      <td>1.493237</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10006</td>\n      <td>302</td>\n      <td>-17.681530</td>\n      <td>-29.776396</td>\n      <td>1983</td>\n      <td>-1.641718</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>-1.4988</td>\n      <td>0.904921</td>\n      <td>1.485340</td>\n      <td>2.426025</td>\n      <td>2.027979</td>\n      <td>0.825450</td>\n      <td>4.3466</td>\n      <td>2.604619</td>\n      <td>1.663623</td>\n      <td>1.780087</td>\n      <td>NaN</td>\n      <td>5.621046</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.718464</td>\n      <td>1.521537</td>\n      <td>4.1307</td>\n      <td>NaN</td>\n      <td>1.628314</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>1.715833</td>\n      <td>4.1367</td>\n      <td>NaN</td>\n      <td>1.559589</td>\n      <td>4.1307</td>\n      <td>NaN</td>\n      <td>-29.282674</td>\n      <td>0.983334</td>\n      <td>0.916348</td>\n      <td>0.864828</td>\n      <td>1.585183</td>\n      <td>1.486680</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10006</td>\n      <td>303</td>\n      <td>-18.595559</td>\n      <td>-22.961625</td>\n      <td>1983</td>\n      <td>0.884121</td>\n      <td>25.0</td>\n      <td>0.784207</td>\n      <td>0.088427</td>\n      <td>0.222761</td>\n      <td>-0.032575</td>\n      <td>2.7008</td>\n      <td>8.156360</td>\n      <td>1.298865</td>\n      <td>1.393089</td>\n      <td>1.343269</td>\n      <td>0.796333</td>\n      <td>3.7153</td>\n      <td>1.412173</td>\n      <td>1.616113</td>\n      <td>1.743533</td>\n      <td>NaN</td>\n      <td>5.654198</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>5.650019</td>\n      <td>1.485340</td>\n      <td>4.3466</td>\n      <td>NaN</td>\n      <td>1.598340</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>1.671621</td>\n      <td>4.0013</td>\n      <td>NaN</td>\n      <td>1.691079</td>\n      <td>4.3466</td>\n      <td>NaN</td>\n      <td>-28.654955</td>\n      <td>1.557424</td>\n      <td>1.486731</td>\n      <td>0.901204</td>\n      <td>1.618876</td>\n      <td>1.559004</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 3. Train-test split #\n\ntemp_cols = ['PERMNO', 'prd', 'year']\n\ntrain = df[df.prd<(min_prd+windows_width)]\ntest = df[df.prd==(min_prd+windows_width)]\ndisplay(train.shape, test.shape, train.head(3), test.head(3))\ntrain.drop(columns=temp_cols, inplace=True)\ntest.drop(columns=temp_cols, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:44.202248Z","iopub.execute_input":"2022-08-25T19:41:44.202590Z","iopub.status.idle":"2022-08-25T19:41:44.307546Z","shell.execute_reply.started":"2022-08-25T19:41:44.202556Z","shell.execute_reply":"2022-08-25T19:41:44.306600Z"},"trusted":true},"execution_count":307,"outputs":[{"output_type":"display_data","data":{"text/plain":"(84583, 48)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(2290, 48)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   PERMNO  prd     mom482     mom242  year       RET   ind        bm  \\\n0   10006  299 -19.434584 -38.390360  1983 -4.311428  25.0  0.467418   \n1   10006  300 -21.388149 -35.843377  1983 -0.102239  25.0  0.467418   \n2   10006  301 -13.964189 -34.528211  1983 -8.855516  25.0  0.467418   \n\n         op        gp       inv   mom11     mom122      amhd  ivol_capm  \\\n0  0.097309  0.220497  0.118136 -4.5159  -9.790204  1.628314   1.033030   \n1  0.097309  0.220497  0.118136  0.1605  -7.157811  1.598340   1.063466   \n2  0.097309  0.220497  0.118136  5.9567 -12.456541  1.521537   1.313733   \n\n   ivol_ff5   beta_bw     MAX     vol1m     vol6m    vol12m  BAspr      size  \\\n0  0.727775  0.814121  1.4386  1.157497  1.825477  1.691859    NaN  5.560153   \n1  0.936522  0.799767  2.3259  1.152686  1.614224  1.667907    NaN  5.568027   \n2  1.155573  0.808885  4.1307  1.433440  1.474423  1.647114    NaN  5.632566   \n\n        lbm       lop       lgp      linv      llme    l1amhd   l1MAX  \\\n0  0.274945  0.118348  0.237469  0.091161  5.825327  1.626665  4.1337   \n1  0.274945  0.118348  0.237469  0.091161  5.740770  1.628314  1.4386   \n2  0.274945  0.118348  0.237469  0.091161  5.811722  1.598340  2.3259   \n\n   l1BAspr    l3amhd   l3MAX  l3BAspr    l6amhd   l6MAX  l6BAspr   l12amhd  \\\n0      NaN  1.715833  4.1367      NaN  1.781569  5.0932      NaN  1.422049   \n1      NaN  1.671621  4.0013      NaN  1.786906  4.5785      NaN  1.440860   \n2      NaN  1.626665  4.1337      NaN  1.762098  3.9561      NaN  1.526839   \n\n   l12MAX  l12BAspr  l12mom122  l12ivol_capm  l12ivol_ff5  l12beta_bw  \\\n0  4.1337       NaN -30.659974      0.986262     0.964204    0.843484   \n1  1.4386       NaN -30.101733      1.193522     1.015454    0.852702   \n2  2.3259       NaN -29.730986      1.645750     1.498313    0.865615   \n\n   l12vol6m  l12vol12m  amhd_miss  BAspr_miss  \n0  1.687154   1.437885          0           1  \n1  1.554393   1.440870          0           1  \n2  1.602011   1.493237          0           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>amhd_miss</th>\n      <th>BAspr_miss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10006</td>\n      <td>299</td>\n      <td>-19.434584</td>\n      <td>-38.390360</td>\n      <td>1983</td>\n      <td>-4.311428</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>-4.5159</td>\n      <td>-9.790204</td>\n      <td>1.628314</td>\n      <td>1.033030</td>\n      <td>0.727775</td>\n      <td>0.814121</td>\n      <td>1.4386</td>\n      <td>1.157497</td>\n      <td>1.825477</td>\n      <td>1.691859</td>\n      <td>NaN</td>\n      <td>5.560153</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.825327</td>\n      <td>1.626665</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>1.715833</td>\n      <td>4.1367</td>\n      <td>NaN</td>\n      <td>1.781569</td>\n      <td>5.0932</td>\n      <td>NaN</td>\n      <td>1.422049</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>-30.659974</td>\n      <td>0.986262</td>\n      <td>0.964204</td>\n      <td>0.843484</td>\n      <td>1.687154</td>\n      <td>1.437885</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10006</td>\n      <td>300</td>\n      <td>-21.388149</td>\n      <td>-35.843377</td>\n      <td>1983</td>\n      <td>-0.102239</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>0.1605</td>\n      <td>-7.157811</td>\n      <td>1.598340</td>\n      <td>1.063466</td>\n      <td>0.936522</td>\n      <td>0.799767</td>\n      <td>2.3259</td>\n      <td>1.152686</td>\n      <td>1.614224</td>\n      <td>1.667907</td>\n      <td>NaN</td>\n      <td>5.568027</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.740770</td>\n      <td>1.628314</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>1.671621</td>\n      <td>4.0013</td>\n      <td>NaN</td>\n      <td>1.786906</td>\n      <td>4.5785</td>\n      <td>NaN</td>\n      <td>1.440860</td>\n      <td>1.4386</td>\n      <td>NaN</td>\n      <td>-30.101733</td>\n      <td>1.193522</td>\n      <td>1.015454</td>\n      <td>0.852702</td>\n      <td>1.554393</td>\n      <td>1.440870</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10006</td>\n      <td>301</td>\n      <td>-13.964189</td>\n      <td>-34.528211</td>\n      <td>1983</td>\n      <td>-8.855516</td>\n      <td>25.0</td>\n      <td>0.467418</td>\n      <td>0.097309</td>\n      <td>0.220497</td>\n      <td>0.118136</td>\n      <td>5.9567</td>\n      <td>-12.456541</td>\n      <td>1.521537</td>\n      <td>1.313733</td>\n      <td>1.155573</td>\n      <td>0.808885</td>\n      <td>4.1307</td>\n      <td>1.433440</td>\n      <td>1.474423</td>\n      <td>1.647114</td>\n      <td>NaN</td>\n      <td>5.632566</td>\n      <td>0.274945</td>\n      <td>0.118348</td>\n      <td>0.237469</td>\n      <td>0.091161</td>\n      <td>5.811722</td>\n      <td>1.598340</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>1.626665</td>\n      <td>4.1337</td>\n      <td>NaN</td>\n      <td>1.762098</td>\n      <td>3.9561</td>\n      <td>NaN</td>\n      <td>1.526839</td>\n      <td>2.3259</td>\n      <td>NaN</td>\n      <td>-29.730986</td>\n      <td>1.645750</td>\n      <td>1.498313</td>\n      <td>0.865615</td>\n      <td>1.602011</td>\n      <td>1.493237</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     PERMNO  prd     mom482     mom242  year        RET   ind        bm  \\\n52    10057  336 -49.521013 -41.162606  1986  -6.166381  21.0  0.359048   \n108   10103  336  31.358459  27.448509  1986  11.869319  19.0  1.026441   \n147   10145  336  97.259488  33.682313  1986   0.097519  30.0  0.013006   \n\n           op        gp       inv    mom11     mom122      amhd  ivol_capm  \\\n52  -0.046435  0.175019  0.171881  13.6857 -24.058754  2.931516   2.337379   \n108  0.041895  0.269995  0.144567  13.6857 -12.783167       NaN   1.821956   \n147  0.185981  0.369886  0.070877  -0.1122  32.383299 -2.912560   0.880505   \n\n     ivol_ff5   beta_bw     MAX     vol1m     vol6m    vol12m  BAspr  \\\n52   2.079664  0.955897  7.3384  2.734031  3.018834  2.755937    NaN   \n108  1.643456  0.436024  7.1129  1.783183  1.301326  1.922222    NaN   \n147  0.793993  0.859177  2.2144  1.160101  1.324462  1.500313    NaN   \n\n         size       lbm       lop       lgp      linv      llme    l1amhd  \\\n52   4.476268 -0.145511 -0.077896  0.215811 -0.177229  4.550767  3.028739   \n108  1.583505  0.917254  0.128636  0.371166  0.028616  1.518966       NaN   \n147  9.107476 -0.135373  0.174447  0.360926  0.219228  8.050175 -2.783153   \n\n      l1MAX  l1BAspr    l3amhd   l3MAX  l3BAspr    l6amhd   l6MAX  l6BAspr  \\\n52   3.0332      NaN  2.990925  6.3520      NaN  3.119337  2.7717      NaN   \n108  1.4066      NaN       NaN  3.4173      NaN       NaN  1.4066      NaN   \n147  2.6880      NaN -2.544408  1.9081      NaN -2.146272  2.3279      NaN   \n\n      l12amhd  l12MAX  l12BAspr  l12mom122  l12ivol_capm  l12ivol_ff5  \\\n52   2.843837  3.0332       NaN -17.885489      2.613949     1.793321   \n108       NaN  1.4066       NaN  59.997120      3.754783     1.864018   \n147 -1.433116  2.6880       NaN   8.843444      0.995126     0.924633   \n\n     l12beta_bw  l12vol6m  l12vol12m  amhd_miss  BAspr_miss  \n52     0.686819  2.394339   2.259529          0           1  \n108    0.361274  5.351636   3.949111          1           1  \n147    1.211169  1.375794   1.593098          0           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>amhd_miss</th>\n      <th>BAspr_miss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>52</th>\n      <td>10057</td>\n      <td>336</td>\n      <td>-49.521013</td>\n      <td>-41.162606</td>\n      <td>1986</td>\n      <td>-6.166381</td>\n      <td>21.0</td>\n      <td>0.359048</td>\n      <td>-0.046435</td>\n      <td>0.175019</td>\n      <td>0.171881</td>\n      <td>13.6857</td>\n      <td>-24.058754</td>\n      <td>2.931516</td>\n      <td>2.337379</td>\n      <td>2.079664</td>\n      <td>0.955897</td>\n      <td>7.3384</td>\n      <td>2.734031</td>\n      <td>3.018834</td>\n      <td>2.755937</td>\n      <td>NaN</td>\n      <td>4.476268</td>\n      <td>-0.145511</td>\n      <td>-0.077896</td>\n      <td>0.215811</td>\n      <td>-0.177229</td>\n      <td>4.550767</td>\n      <td>3.028739</td>\n      <td>3.0332</td>\n      <td>NaN</td>\n      <td>2.990925</td>\n      <td>6.3520</td>\n      <td>NaN</td>\n      <td>3.119337</td>\n      <td>2.7717</td>\n      <td>NaN</td>\n      <td>2.843837</td>\n      <td>3.0332</td>\n      <td>NaN</td>\n      <td>-17.885489</td>\n      <td>2.613949</td>\n      <td>1.793321</td>\n      <td>0.686819</td>\n      <td>2.394339</td>\n      <td>2.259529</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>10103</td>\n      <td>336</td>\n      <td>31.358459</td>\n      <td>27.448509</td>\n      <td>1986</td>\n      <td>11.869319</td>\n      <td>19.0</td>\n      <td>1.026441</td>\n      <td>0.041895</td>\n      <td>0.269995</td>\n      <td>0.144567</td>\n      <td>13.6857</td>\n      <td>-12.783167</td>\n      <td>NaN</td>\n      <td>1.821956</td>\n      <td>1.643456</td>\n      <td>0.436024</td>\n      <td>7.1129</td>\n      <td>1.783183</td>\n      <td>1.301326</td>\n      <td>1.922222</td>\n      <td>NaN</td>\n      <td>1.583505</td>\n      <td>0.917254</td>\n      <td>0.128636</td>\n      <td>0.371166</td>\n      <td>0.028616</td>\n      <td>1.518966</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.4173</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>59.997120</td>\n      <td>3.754783</td>\n      <td>1.864018</td>\n      <td>0.361274</td>\n      <td>5.351636</td>\n      <td>3.949111</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>10145</td>\n      <td>336</td>\n      <td>97.259488</td>\n      <td>33.682313</td>\n      <td>1986</td>\n      <td>0.097519</td>\n      <td>30.0</td>\n      <td>0.013006</td>\n      <td>0.185981</td>\n      <td>0.369886</td>\n      <td>0.070877</td>\n      <td>-0.1122</td>\n      <td>32.383299</td>\n      <td>-2.912560</td>\n      <td>0.880505</td>\n      <td>0.793993</td>\n      <td>0.859177</td>\n      <td>2.2144</td>\n      <td>1.160101</td>\n      <td>1.324462</td>\n      <td>1.500313</td>\n      <td>NaN</td>\n      <td>9.107476</td>\n      <td>-0.135373</td>\n      <td>0.174447</td>\n      <td>0.360926</td>\n      <td>0.219228</td>\n      <td>8.050175</td>\n      <td>-2.783153</td>\n      <td>2.6880</td>\n      <td>NaN</td>\n      <td>-2.544408</td>\n      <td>1.9081</td>\n      <td>NaN</td>\n      <td>-2.146272</td>\n      <td>2.3279</td>\n      <td>NaN</td>\n      <td>-1.433116</td>\n      <td>2.6880</td>\n      <td>NaN</td>\n      <td>8.843444</td>\n      <td>0.995126</td>\n      <td>0.924633</td>\n      <td>1.211169</td>\n      <td>1.375794</td>\n      <td>1.593098</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 4. Missing values #\n\ncol_ignore = ['RET']\ncol_cat = ['ind']\ncol_num = [x for x in train.columns if x not in col_ignore+col_cat]\n\nfor col in col_num:\n    train[col] = train[col].fillna(train[col].median())\n    test[col] = test[col].fillna(train[col].median())\n\nfor col in col_cat:\n    train[col] = train[col].fillna(value=-1000)\n    test[col] = test[col].fillna(value=-1000)\n    \ndisplay(train.count())","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:44.308994Z","iopub.execute_input":"2022-08-25T19:41:44.309566Z","iopub.status.idle":"2022-08-25T19:41:44.466869Z","shell.execute_reply.started":"2022-08-25T19:41:44.309525Z","shell.execute_reply":"2022-08-25T19:41:44.465836Z"},"trusted":true},"execution_count":308,"outputs":[{"output_type":"display_data","data":{"text/plain":"mom482          84583\nmom242          84583\nRET             84583\nind             84583\nbm              84583\nop              84583\ngp              84583\ninv             84583\nmom11           84583\nmom122          84583\namhd            84583\nivol_capm       84583\nivol_ff5        84583\nbeta_bw         84583\nMAX             84583\nvol1m           84583\nvol6m           84583\nvol12m          84583\nBAspr           84583\nsize            84583\nlbm             84583\nlop             84583\nlgp             84583\nlinv            84583\nllme            84583\nl1amhd          84583\nl1MAX           84583\nl1BAspr         84583\nl3amhd          84583\nl3MAX           84583\nl3BAspr         84583\nl6amhd          84583\nl6MAX           84583\nl6BAspr         84583\nl12amhd         84583\nl12MAX          84583\nl12BAspr        84583\nl12mom122       84583\nl12ivol_capm    84583\nl12ivol_ff5     84583\nl12beta_bw      84583\nl12vol6m        84583\nl12vol12m       84583\namhd_miss       84583\nBAspr_miss      84583\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# # [optional] Target Encoding\n\n# # first, do frequency encoding\n# freq_enc = (train.groupby('ind').size()) / len(train)\n# train['ind_fencoded'] = train['ind'].apply(lambda x : freq_enc[x])\n# test['ind_fencoded'] = test['ind'].apply(lambda x : freq_enc[x])\n\n# time1 = time.time()\n# encoder = CrossFoldEncoder(MEstimateEncoder, m=10)\n# train_encoded = encoder.fit_transform(train, train.RET, cols=col_cat)\n# test_encoded = encoder.transform(test)\n\n# train.drop(columns=col_cat, inplace=True)\n# test.drop(columns=col_cat,  inplace=True)\n# train = pd.concat([train, train_encoded], axis = 1)\n# test = pd.concat([test, test_encoded], axis = 1)\n\n# display(time.time()-time0, time.time()-time1)\n# display(train.shape, train.head(), train.count())\n# train0 = train.copy()\n# test0 = test.copy()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:44.468192Z","iopub.execute_input":"2022-08-25T19:41:44.468926Z","iopub.status.idle":"2022-08-25T19:41:44.476122Z","shell.execute_reply.started":"2022-08-25T19:41:44.468878Z","shell.execute_reply":"2022-08-25T19:41:44.475070Z"},"trusted":true},"execution_count":309,"outputs":[]},{"cell_type":"code","source":"X_train = train.copy()\ny_train = X_train.pop('RET')\n\nX_test = test.copy()\ny_test = X_test.pop('RET')","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:44.479298Z","iopub.execute_input":"2022-08-25T19:41:44.479568Z","iopub.status.idle":"2022-08-25T19:41:44.497243Z","shell.execute_reply.started":"2022-08-25T19:41:44.479542Z","shell.execute_reply":"2022-08-25T19:41:44.496369Z"},"trusted":true},"execution_count":310,"outputs":[]},{"cell_type":"code","source":"# 5. Feature engineering #\n\ntime1 = time.time()\n\n# (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\", drop='if_binary'), col_cat),\n\nfeature_transformer = ColumnTransformer([('num', StandardScaler(), col_num),\n                                        (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\", drop='if_binary'), col_cat)], \n                                        remainder=\"passthrough\")\n\nprint('Number of features before transformation: ', X_train.shape)\nX_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\nX_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\nprint('time to do feature proprocessing: ', time.time()-time1)\nprint('Number of features after transformation: ', X_train.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:44.500698Z","iopub.execute_input":"2022-08-25T19:41:44.501035Z","iopub.status.idle":"2022-08-25T19:41:44.692954Z","shell.execute_reply.started":"2022-08-25T19:41:44.501007Z","shell.execute_reply":"2022-08-25T19:41:44.691835Z"},"trusted":true},"execution_count":311,"outputs":[{"name":"stdout","text":"Number of features before transformation:  (84583, 44)\ntime to do feature proprocessing:  0.18500423431396484\nNumber of features after transformation:  (84583, 91)\n","output_type":"stream"}]},{"cell_type":"code","source":"# 6. Model fitting #\n\n# first, some trivial baselines:\nprint('mae of a constant model', mean_absolute_error(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\nprint('R2 of a constant model', r2_score(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\n\ntime1 = time.time()\nxgb1 = XGBRegressor(tree_method = 'gpu_hist', n_estimators=300, max_depth=5, eta=0.03, colsample_bytree=0.6)\nxgb1.fit(X_train, y_train)\nprint('XGB train:', mean_absolute_error(y_train, xgb1.predict(X_train)), r2_score(y_train, xgb1.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:44.694300Z","iopub.execute_input":"2022-08-25T19:41:44.695399Z","iopub.status.idle":"2022-08-25T19:41:46.972048Z","shell.execute_reply.started":"2022-08-25T19:41:44.695359Z","shell.execute_reply":"2022-08-25T19:41:46.971176Z"},"trusted":true},"execution_count":312,"outputs":[{"name":"stdout","text":"mae of a constant model 8.393769117304654\nR2 of a constant model 0.0\nXGB train: 8.005444411283628 0.09517217915634713 2.262685775756836\n","output_type":"stream"}]},{"cell_type":"code","source":"time1 = time.time()\nxgb = XGBRegressor(tree_method = 'gpu_hist')\nparam_grid = {'n_estimators':[400, 700], 'max_depth':[2,3,4], 'eta':[0.006, 0.012, 0.02],\n             'subsample':[0.6], 'colsample_bytree':[0.6]}\nxgbm = GridSearchCV(xgb, param_grid, cv=2, verbose=2, scoring='r2')\nxgbm.fit(X_train, y_train)\nprint('XGB', xgbm.best_params_, xgbm.best_score_, time.time()-time1)\n# this runs for 40 min and finds \n# 'eta': 0.02, 'max_depth': 6, 'n_estimators': 500, 0.01095415380877135\nprint('XGB train:', mean_absolute_error(y_train, xgbm.predict(X_train)), r2_score(y_train, xgbm.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:41:46.975756Z","iopub.execute_input":"2022-08-25T19:41:46.977855Z","iopub.status.idle":"2022-08-25T19:42:33.994859Z","shell.execute_reply.started":"2022-08-25T19:41:46.977822Z","shell.execute_reply":"2022-08-25T19:42:33.993965Z"},"trusted":true},"execution_count":313,"outputs":[{"name":"stdout","text":"Fitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.006, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=400, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.012, max_depth=4, n_estimators=700, subsample=0.6; total time=   1.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=2, n_estimators=700, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=400, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=3, n_estimators=700, subsample=0.6; total time=   1.4s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=400, subsample=0.6; total time=   1.2s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\n[CV] END colsample_bytree=0.6, eta=0.02, max_depth=4, n_estimators=700, subsample=0.6; total time=   2.0s\nXGB {'colsample_bytree': 0.6, 'eta': 0.012, 'max_depth': 4, 'n_estimators': 400, 'subsample': 0.6} 0.018222181773355606 46.18161392211914\nXGB train: 8.165715234962578 0.04471946403473803 47.005911350250244\n","output_type":"stream"}]},{"cell_type":"code","source":"time1 = time.time()\n\ndef objective(trial, cv_runs=1, n_splits=2, n_jobs=-1):\n\n    cv_regularizer=0.03\n    # Usually values between 0.1 and 0.2 work fine.\n\n    params = {\n        \"tree_method\": 'gpu_hist',\n        \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 1000),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 5),\n        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.001, 0.05),\n        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.1, 0.95),\n        \"subsample\": trial.suggest_uniform(\"subsample\", 0.3, 0.95),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 0.1, 30.0),\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 0.1, 200.0),\n        \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-10, 10.0),\n        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 0.1, 50)    }\n    # usually it makes sense to resrtict hyperparameter space from some solutions which Optuna will find\n    # e.g., for tmx-joined data only (downsampled tmx), optuna keeps selecting depths of 2 and 3.\n    # for my purposes (smooth left side of prc, close to 1), those solutions are no good.\n\n    temp_out = []\n\n    for i in range(cv_runs):\n\n        X = X_train\n        y = y_train\n\n        model = XGBRegressor(**params, njobs=-1)\n        rkf = KFold(n_splits=n_splits, shuffle=True)\n        X_values = X.values\n        y_values = y.values\n        y_pred = np.zeros_like(y_values)\n        y_pred_train = np.zeros_like(y_values)\n        for train_index, test_index in rkf.split(X_values):\n            X_A, X_B = X_values[train_index, :], X_values[test_index, :]\n            y_A, y_B = y_values[train_index], y_values[test_index]\n            model.fit(X_A, y_A, eval_set=[(X_B, y_B)], verbose = False)\n            y_pred[test_index] = model.predict(X_B)\n            y_pred_train[train_index] = model.predict(X_A)\n                      \n            \n        score_train = r2_score(y_train, y_pred_train)\n        score_test = r2_score(y_train, y_pred) \n        overfit = (score_train-score_test)\n        temp_out.append(score_test-cv_regularizer*overfit)\n        #temp_out.append(score_test)\n\n    return (np.mean(temp_out))\n\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=10)\n\nprint('Total time for hypermarameter optimization ', time.time()-time1)\nhp = study.best_params\nfor key, value in hp.items():\n    print(f\"{key:>20s} : {value}\")\nprint(f\"{'best objective value':>20s} : {study.best_value}\")\n\noptuna_hyperpars = study.best_params\noptuna_hyperpars['tree_method']='gpu_hist'\n\noptuna_xgb = XGBRegressor(**optuna_hyperpars)\noptuna_xgb.fit(X_train, y_train)\nprint('Optuna XGB train:', \n      mean_absolute_error(y_train, optuna_xgb.predict(X_train)), r2_score(y_train, optuna_xgb.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:42:33.998509Z","iopub.execute_input":"2022-08-25T19:42:34.000326Z","iopub.status.idle":"2022-08-25T19:43:33.883243Z","shell.execute_reply.started":"2022-08-25T19:42:34.000291Z","shell.execute_reply":"2022-08-25T19:43:33.882353Z"},"trusted":true},"execution_count":314,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-08-25 19:42:34,012]\u001b[0m A new study created in memory with name: no-name-7412bf84-ec50-4566-a1f1-866d5475b847\u001b[0m\n\u001b[32m[I 2022-08-25 19:42:41,767]\u001b[0m Trial 0 finished with value: -0.006441945209520411 and parameters: {'n_estimators': 990, 'max_depth': 4, 'learning_rate': 0.047373651706199484, 'colsample_bytree': 0.3245715435679861, 'subsample': 0.7413268339862242, 'alpha': 0.7304650334808365, 'lambda': 6.761931922618051, 'gamma': 0.027449459340483793, 'min_child_weight': 0.11404650676014563}. Best is trial 0 with value: -0.006441945209520411.\u001b[0m\n\u001b[32m[I 2022-08-25 19:42:46,757]\u001b[0m Trial 1 finished with value: 0.007208145360881263 and parameters: {'n_estimators': 596, 'max_depth': 4, 'learning_rate': 0.03227952516648879, 'colsample_bytree': 0.8247968999279774, 'subsample': 0.5599805929467533, 'alpha': 0.3973563200089628, 'lambda': 0.4064706238098478, 'gamma': 2.365582098874825, 'min_child_weight': 2.159506202888462}. Best is trial 1 with value: 0.007208145360881263.\u001b[0m\n\u001b[32m[I 2022-08-25 19:42:55,961]\u001b[0m Trial 2 finished with value: 0.015666143100600938 and parameters: {'n_estimators': 813, 'max_depth': 5, 'learning_rate': 0.011302810761729225, 'colsample_bytree': 0.5012625488788005, 'subsample': 0.786662313703054, 'alpha': 0.6283538602263444, 'lambda': 117.07268984573518, 'gamma': 1.6326905475263394e-10, 'min_child_weight': 0.11959259988100061}. Best is trial 2 with value: 0.015666143100600938.\u001b[0m\n\u001b[32m[I 2022-08-25 19:43:01,686]\u001b[0m Trial 3 finished with value: 0.014631782267417522 and parameters: {'n_estimators': 960, 'max_depth': 3, 'learning_rate': 0.018871851943296287, 'colsample_bytree': 0.2739380267560708, 'subsample': 0.638882710347298, 'alpha': 1.0743942853128043, 'lambda': 1.92591744801408, 'gamma': 1.6478136077055713e-07, 'min_child_weight': 0.2774973108741427}. Best is trial 2 with value: 0.015666143100600938.\u001b[0m\n\u001b[32m[I 2022-08-25 19:43:06,683]\u001b[0m Trial 4 finished with value: 0.016369401484487237 and parameters: {'n_estimators': 878, 'max_depth': 2, 'learning_rate': 0.03029274397097526, 'colsample_bytree': 0.6434204793534474, 'subsample': 0.8126511003287133, 'alpha': 0.11947535909225333, 'lambda': 1.0419870674703051, 'gamma': 1.396060656923731e-07, 'min_child_weight': 0.2531785949525317}. Best is trial 4 with value: 0.016369401484487237.\u001b[0m\n\u001b[32m[I 2022-08-25 19:43:10,625]\u001b[0m Trial 5 finished with value: 0.01563651575824325 and parameters: {'n_estimators': 759, 'max_depth': 2, 'learning_rate': 0.02359163214529018, 'colsample_bytree': 0.6839390342417325, 'subsample': 0.6103287950237459, 'alpha': 21.742797851134863, 'lambda': 6.775516615572457, 'gamma': 7.300696545611832e-09, 'min_child_weight': 1.2808478003690975}. Best is trial 4 with value: 0.016369401484487237.\u001b[0m\n\u001b[32m[I 2022-08-25 19:43:15,107]\u001b[0m Trial 6 finished with value: 0.016527246650237 and parameters: {'n_estimators': 877, 'max_depth': 2, 'learning_rate': 0.04284586300194715, 'colsample_bytree': 0.17562766396928103, 'subsample': 0.7328961560166636, 'alpha': 0.3432954720106906, 'lambda': 17.217106184505674, 'gamma': 1.0038482274679952e-06, 'min_child_weight': 8.772176043209315}. Best is trial 6 with value: 0.016527246650237.\u001b[0m\n\u001b[32m[I 2022-08-25 19:43:19,546]\u001b[0m Trial 7 finished with value: 0.017897087440093554 and parameters: {'n_estimators': 714, 'max_depth': 3, 'learning_rate': 0.018535772826360604, 'colsample_bytree': 0.3322582892062964, 'subsample': 0.4465066189512473, 'alpha': 0.44577039283562325, 'lambda': 42.239931172836506, 'gamma': 2.6260679925447078e-08, 'min_child_weight': 29.108784856459792}. Best is trial 7 with value: 0.017897087440093554.\u001b[0m\n\u001b[32m[I 2022-08-25 19:43:26,543]\u001b[0m Trial 8 finished with value: 0.005446106630857919 and parameters: {'n_estimators': 871, 'max_depth': 4, 'learning_rate': 0.02911252116962182, 'colsample_bytree': 0.5682874659589812, 'subsample': 0.6626849547728444, 'alpha': 0.11756615451558078, 'lambda': 27.0137423083958, 'gamma': 1.2663286885750437e-05, 'min_child_weight': 3.894408662948924}. Best is trial 7 with value: 0.017897087440093554.\u001b[0m\n\u001b[32m[I 2022-08-25 19:43:31,381]\u001b[0m Trial 9 finished with value: 0.006240090002059232 and parameters: {'n_estimators': 767, 'max_depth': 3, 'learning_rate': 0.04082937734358475, 'colsample_bytree': 0.6684696651989087, 'subsample': 0.6832406326276619, 'alpha': 4.921929842591556, 'lambda': 0.10460596805823438, 'gamma': 0.004169199967059792, 'min_child_weight': 4.633687740974168}. Best is trial 7 with value: 0.017897087440093554.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  57.37122821807861\n        n_estimators : 714\n           max_depth : 3\n       learning_rate : 0.018535772826360604\n    colsample_bytree : 0.3322582892062964\n           subsample : 0.4465066189512473\n               alpha : 0.44577039283562325\n              lambda : 42.239931172836506\n               gamma : 2.6260679925447078e-08\n    min_child_weight : 29.108784856459792\nbest objective value : 0.017897087440093554\nOptuna XGB train: 8.171230590075561 0.04107862129969675 59.86653208732605\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate performance of XGB models:\n\nprint('Constant guess: ', mean_absolute_error(y_test, np.ones(len(y_test))*y_test.mean()), \n      r2_score(y_test, np.ones(len(y_test))*y_test.mean()))\n\nprint('XGB test:', mean_absolute_error(y_test, xgb1.predict(X_test)), r2_score(y_test, xgb1.predict(X_test)))\nprint('XGB GS test:', mean_absolute_error(y_test, xgbm.predict(X_test)), r2_score(y_test, xgbm.predict(X_test)))\nprint('Optuna XGB test:', mean_absolute_error(y_test, optuna_xgb.predict(X_test)), r2_score(y_test, optuna_xgb.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:43:33.886824Z","iopub.execute_input":"2022-08-25T19:43:33.888712Z","iopub.status.idle":"2022-08-25T19:43:34.005559Z","shell.execute_reply.started":"2022-08-25T19:43:33.888675Z","shell.execute_reply":"2022-08-25T19:43:34.004799Z"},"trusted":true},"execution_count":315,"outputs":[{"name":"stdout","text":"Constant guess:  9.021598745386575 0.0\nXGB test: 9.099873026086465 -0.009254169874327145\nXGB GS test: 9.040259427737732 -2.9032783836591136e-05\nOptuna XGB test: 9.05336356697449 -0.001729996364225439\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total time for a script: ', time.time()-time0)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:43:34.009685Z","iopub.execute_input":"2022-08-25T19:43:34.011751Z","iopub.status.idle":"2022-08-25T19:43:34.019342Z","shell.execute_reply.started":"2022-08-25T19:43:34.011719Z","shell.execute_reply":"2022-08-25T19:43:34.017885Z"},"trusted":true},"execution_count":316,"outputs":[{"name":"stdout","text":"Total time for a script:  111.06930112838745\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_size = 0.1\n# df.reset_index(inplace=True, drop=True)\n# #random.seed(2)\n# test_index = random.sample(list(df.index), int(test_size*df.shape[0]))\n# train = df.iloc[list(set(df.index)-set(test_index))]\n# test = df.iloc[test_index]\n# train.reset_index(drop=True, inplace=True)\n# test.reset_index(drop=True, inplace=True)\n# display(train.shape, test.shape, train.head(3), test.head(3))","metadata":{"execution":{"iopub.status.busy":"2022-08-25T19:43:34.021390Z","iopub.execute_input":"2022-08-25T19:43:34.021939Z","iopub.status.idle":"2022-08-25T19:43:34.027812Z","shell.execute_reply.started":"2022-08-25T19:43:34.021898Z","shell.execute_reply":"2022-08-25T19:43:34.026594Z"},"trusted":true},"execution_count":317,"outputs":[]}]}
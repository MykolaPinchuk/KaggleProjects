{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This is a new version of MLEAP scripts, started in late Aug 2022.\nIt will combine IProject_MLEAP_ANN and IP_MLEAP script, while improving them.","metadata":{}},{"cell_type":"markdown","source":"#### Outline\n\n1. Load libraries and data.\n2. pEDA. Look at feature distribution, fix them if they do not look right.\n3. Train-test split. Most likely couple years into test set. 2015-2018?. Impute missing values.\n4. Transform numerical features, add ohe for inds.\n5. Fit classic models: ols as a baseline, then xgb.\n6. Fir DL.\n\n\nNotes:\nideally, I want to use time-based cross-validation.\nsince I have panel data, it is not a trivial task.\nneed to find some solution online.\ne.g., https://towardsdatascience.com/time-based-cross-validation-d259b13d42b8.\n\nfor now, will try to do siple for loop.\n","metadata":{}},{"cell_type":"code","source":"# 0. Import libraries #\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, time, math, re, warnings, random, gc, dill, optuna, pickle\nimport statsmodels.api as sm\nfrom random import sample\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNetCV\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn.inspection import permutation_importance\nfrom category_encoders import MEstimateEncoder\nfrom xgboost import XGBRegressor\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nplt.style.use('seaborn-white')\nwarnings.simplefilter(action='ignore')\npd.set_option('display.max_columns', 110)\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:34.512536Z","iopub.execute_input":"2022-08-25T00:45:34.512921Z","iopub.status.idle":"2022-08-25T00:45:34.522373Z","shell.execute_reply.started":"2022-08-25T00:45:34.512890Z","shell.execute_reply":"2022-08-25T00:45:34.521396Z"},"trusted":true},"execution_count":333,"outputs":[]},{"cell_type":"code","source":"### target encoding ###\n# source: https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices/notebook\n\nclass CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=4)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:34.524087Z","iopub.execute_input":"2022-08-25T00:45:34.525060Z","iopub.status.idle":"2022-08-25T00:45:34.538052Z","shell.execute_reply.started":"2022-08-25T00:45:34.524995Z","shell.execute_reply":"2022-08-25T00:45:34.536996Z"},"trusted":true},"execution_count":334,"outputs":[]},{"cell_type":"code","source":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:34.541726Z","iopub.execute_input":"2022-08-25T00:45:34.542022Z","iopub.status.idle":"2022-08-25T00:45:34.552792Z","shell.execute_reply.started":"2022-08-25T00:45:34.541991Z","shell.execute_reply":"2022-08-25T00:45:34.551714Z"},"trusted":true},"execution_count":335,"outputs":[{"name":"stdout","text":"REPLICAS:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"# 1. Import data #\n\nmin_prd = 391\n\ntime0 = time.time()\n#df = pd.read_csv('../input/cpcrsp-46/IMLEAP_v4.csv')\nwith open('../input/kaggle-46pkl/IMLEAP_v4.pkl', 'rb') as pickled_one:\n    df = pickle.load(pickled_one)\ndf = df[df.prd.isin(range(min_prd-1, min_prd+62))]\ndisplay(df.shape, df.head(), df.count())","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:34.555319Z","iopub.execute_input":"2022-08-25T00:45:34.556012Z","iopub.status.idle":"2022-08-25T00:45:35.455525Z","shell.execute_reply.started":"2022-08-25T00:45:34.555950Z","shell.execute_reply":"2022-08-25T00:45:35.454683Z"},"trusted":true},"execution_count":336,"outputs":[{"output_type":"display_data","data":{"text/plain":"(161139, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    PERMNO  prd  mom482     mom242  year      RET   ind        bm        op  \\\n15   10005  390     NaN -56.974664  1990 -40.6800  30.0  0.667021 -0.123134   \n16   10005  391     NaN -57.000479  1990  -0.5700  30.0  0.667021 -0.123134   \n17   10005  392     NaN -56.974664  1990  -0.6000  30.0  0.667021 -0.123134   \n18   10005  393     NaN -57.005640  1991  66.1467  30.0  0.667021 -0.123134   \n19   10005  394     NaN -28.214878  1991  -0.4800  30.0  0.667021 -0.123134   \n\n     gp      inv      mom11     mom122  amhd  ivol_capm  ivol_ff5   beta_bw  \\\n15  0.0 -0.22093  26.592465  -6.891869   NaN   7.874195  6.946893  0.093336   \n16  0.0 -0.22093 -22.380465  55.680226   NaN   7.404275  6.612712 -0.150509   \n17  0.0 -0.22093  -0.570000 -30.377554   NaN   0.765013  0.647098 -0.156073   \n18  0.0 -0.22093  -0.600000 -30.349534   NaN   0.765013  0.647098 -0.197082   \n19  0.0 -0.22093  26.592465 -30.370549   NaN   7.874195  6.946893 -0.127235   \n\n          MAX     vol1m     vol6m    vol12m  BAspr      size       lbm  \\\n15  21.135115  8.239788  7.983689  7.756113    NaN -0.424011  0.490174   \n16   1.406600  0.866870  7.983689  7.756113    NaN -0.934794  0.490174   \n17   1.406600  0.866870  7.983689  7.756113    NaN -0.934794  0.490174   \n18   1.406600  0.866870  7.983689  7.756113    NaN -0.938262  0.490174   \n19  21.135115  8.239788  7.983689  7.756113    NaN -0.427479  0.490174   \n\n         lop  lgp      linv      llme  l1amhd      l1MAX  l1BAspr  l3amhd  \\\n15 -0.214332  0.0 -0.230583 -0.934794     NaN   1.406600      NaN     NaN   \n16 -0.214332  0.0 -0.230583 -0.934794     NaN  21.135115      NaN     NaN   \n17 -0.214332  0.0 -0.230583 -0.647218     NaN   1.406600      NaN     NaN   \n18 -0.214332  0.0 -0.230583 -0.647218     NaN   1.406600      NaN     NaN   \n19 -0.214332  0.0 -0.230583 -0.647218     NaN   1.406600      NaN     NaN   \n\n        l3MAX  l3BAspr  l6amhd   l6MAX  l6BAspr  l12amhd     l12MAX  l12BAspr  \\\n15   1.406600      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n16   1.406600      NaN     NaN  1.4066      NaN      NaN  21.135115       NaN   \n17   1.406600      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n18  21.135115      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n19   1.406600      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n\n    l12mom122  l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \n15 -38.209694      5.565847     5.250996    0.663164  3.190628   2.799597  \n16 -53.776947      0.765013     0.647098    0.372045  2.840962   2.265160  \n17 -53.828083      6.739834     4.518291    0.526334  4.132793   3.099129  \n18 -38.367763      0.765013     0.647098    0.522012  4.132801   3.099129  \n19 -38.404947      0.765013     0.647098    0.499827  4.132835   3.099130  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>10005</td>\n      <td>390</td>\n      <td>NaN</td>\n      <td>-56.974664</td>\n      <td>1990</td>\n      <td>-40.6800</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>26.592465</td>\n      <td>-6.891869</td>\n      <td>NaN</td>\n      <td>7.874195</td>\n      <td>6.946893</td>\n      <td>0.093336</td>\n      <td>21.135115</td>\n      <td>8.239788</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>NaN</td>\n      <td>-0.424011</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.934794</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-38.209694</td>\n      <td>5.565847</td>\n      <td>5.250996</td>\n      <td>0.663164</td>\n      <td>3.190628</td>\n      <td>2.799597</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>10005</td>\n      <td>391</td>\n      <td>NaN</td>\n      <td>-57.000479</td>\n      <td>1990</td>\n      <td>-0.5700</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>-22.380465</td>\n      <td>55.680226</td>\n      <td>NaN</td>\n      <td>7.404275</td>\n      <td>6.612712</td>\n      <td>-0.150509</td>\n      <td>1.406600</td>\n      <td>0.866870</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.934794</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>-53.776947</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.372045</td>\n      <td>2.840962</td>\n      <td>2.265160</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>10005</td>\n      <td>392</td>\n      <td>NaN</td>\n      <td>-56.974664</td>\n      <td>1990</td>\n      <td>-0.6000</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>-0.570000</td>\n      <td>-30.377554</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>-0.156073</td>\n      <td>1.406600</td>\n      <td>0.866870</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.647218</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-53.828083</td>\n      <td>6.739834</td>\n      <td>4.518291</td>\n      <td>0.526334</td>\n      <td>4.132793</td>\n      <td>3.099129</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10005</td>\n      <td>393</td>\n      <td>NaN</td>\n      <td>-57.005640</td>\n      <td>1991</td>\n      <td>66.1467</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>-0.600000</td>\n      <td>-30.349534</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>-0.197082</td>\n      <td>1.406600</td>\n      <td>0.866870</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>NaN</td>\n      <td>-0.938262</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.647218</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-38.367763</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.522012</td>\n      <td>4.132801</td>\n      <td>3.099129</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>10005</td>\n      <td>394</td>\n      <td>NaN</td>\n      <td>-28.214878</td>\n      <td>1991</td>\n      <td>-0.4800</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>26.592465</td>\n      <td>-30.370549</td>\n      <td>NaN</td>\n      <td>7.874195</td>\n      <td>6.946893</td>\n      <td>-0.127235</td>\n      <td>21.135115</td>\n      <td>8.239788</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>NaN</td>\n      <td>-0.427479</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.647218</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-38.404947</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.499827</td>\n      <td>4.132835</td>\n      <td>3.099130</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"PERMNO          161139\nprd             161139\nmom482          139045\nmom242          159125\nyear            161139\nRET             161139\nind             161139\nbm              161139\nop              161139\ngp              161139\ninv             161045\nmom11           161139\nmom122          161139\namhd            124600\nivol_capm       161134\nivol_ff5        161134\nbeta_bw         161139\nMAX             161139\nvol1m           161123\nvol6m           161039\nvol12m          160822\nBAspr           120393\nsize            161139\nlbm             161139\nlop             161139\nlgp             161139\nlinv            161139\nllme            161139\nl1amhd          124489\nl1MAX           161134\nl1BAspr         118923\nl3amhd          124312\nl3MAX           161106\nl3BAspr         115926\nl6amhd          124095\nl6MAX           161084\nl6BAspr         111495\nl12amhd         124082\nl12MAX          161134\nl12BAspr        102815\nl12mom122       160515\nl12ivol_capm    161029\nl12ivol_ff5     161029\nl12beta_bw      161070\nl12vol6m        160761\nl12vol12m       159526\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# 2. pEDA #\n\ndf.RET.hist()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:35.460367Z","iopub.execute_input":"2022-08-25T00:45:35.462300Z","iopub.status.idle":"2022-08-25T00:45:35.670792Z","shell.execute_reply.started":"2022-08-25T00:45:35.462260Z","shell.execute_reply":"2022-08-25T00:45:35.669892Z"},"trusted":true},"execution_count":337,"outputs":[{"execution_count":337,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"# explore feature distibution, adjust if seems unreasonable","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:35.673915Z","iopub.execute_input":"2022-08-25T00:45:35.674247Z","iopub.status.idle":"2022-08-25T00:45:35.678298Z","shell.execute_reply.started":"2022-08-25T00:45:35.674219Z","shell.execute_reply":"2022-08-25T00:45:35.677108Z"},"trusted":true},"execution_count":338,"outputs":[]},{"cell_type":"code","source":"# add dummies for some missing features\n\nfeatures_miss_dummies = ['amhd', 'BAspr']\n\nfor col in features_miss_dummies:\n    df[col+'_miss'] = df[col].isnull().astype(int)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:35.679997Z","iopub.execute_input":"2022-08-25T00:45:35.680612Z","iopub.status.idle":"2022-08-25T00:45:35.725492Z","shell.execute_reply.started":"2022-08-25T00:45:35.680575Z","shell.execute_reply":"2022-08-25T00:45:35.724356Z"},"trusted":true},"execution_count":339,"outputs":[{"execution_count":339,"output_type":"execute_result","data":{"text/plain":"    PERMNO  prd  mom482     mom242  year      RET   ind        bm        op  \\\n15   10005  390     NaN -56.974664  1990 -40.6800  30.0  0.667021 -0.123134   \n16   10005  391     NaN -57.000479  1990  -0.5700  30.0  0.667021 -0.123134   \n17   10005  392     NaN -56.974664  1990  -0.6000  30.0  0.667021 -0.123134   \n18   10005  393     NaN -57.005640  1991  66.1467  30.0  0.667021 -0.123134   \n19   10005  394     NaN -28.214878  1991  -0.4800  30.0  0.667021 -0.123134   \n\n     gp      inv      mom11     mom122  amhd  ivol_capm  ivol_ff5   beta_bw  \\\n15  0.0 -0.22093  26.592465  -6.891869   NaN   7.874195  6.946893  0.093336   \n16  0.0 -0.22093 -22.380465  55.680226   NaN   7.404275  6.612712 -0.150509   \n17  0.0 -0.22093  -0.570000 -30.377554   NaN   0.765013  0.647098 -0.156073   \n18  0.0 -0.22093  -0.600000 -30.349534   NaN   0.765013  0.647098 -0.197082   \n19  0.0 -0.22093  26.592465 -30.370549   NaN   7.874195  6.946893 -0.127235   \n\n          MAX     vol1m     vol6m    vol12m  BAspr      size       lbm  \\\n15  21.135115  8.239788  7.983689  7.756113    NaN -0.424011  0.490174   \n16   1.406600  0.866870  7.983689  7.756113    NaN -0.934794  0.490174   \n17   1.406600  0.866870  7.983689  7.756113    NaN -0.934794  0.490174   \n18   1.406600  0.866870  7.983689  7.756113    NaN -0.938262  0.490174   \n19  21.135115  8.239788  7.983689  7.756113    NaN -0.427479  0.490174   \n\n         lop  lgp      linv      llme  l1amhd      l1MAX  l1BAspr  l3amhd  \\\n15 -0.214332  0.0 -0.230583 -0.934794     NaN   1.406600      NaN     NaN   \n16 -0.214332  0.0 -0.230583 -0.934794     NaN  21.135115      NaN     NaN   \n17 -0.214332  0.0 -0.230583 -0.647218     NaN   1.406600      NaN     NaN   \n18 -0.214332  0.0 -0.230583 -0.647218     NaN   1.406600      NaN     NaN   \n19 -0.214332  0.0 -0.230583 -0.647218     NaN   1.406600      NaN     NaN   \n\n        l3MAX  l3BAspr  l6amhd   l6MAX  l6BAspr  l12amhd     l12MAX  l12BAspr  \\\n15   1.406600      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n16   1.406600      NaN     NaN  1.4066      NaN      NaN  21.135115       NaN   \n17   1.406600      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n18  21.135115      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n19   1.406600      NaN     NaN  1.4066      NaN      NaN   1.406600       NaN   \n\n    l12mom122  l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  \\\n15 -38.209694      5.565847     5.250996    0.663164  3.190628   2.799597   \n16 -53.776947      0.765013     0.647098    0.372045  2.840962   2.265160   \n17 -53.828083      6.739834     4.518291    0.526334  4.132793   3.099129   \n18 -38.367763      0.765013     0.647098    0.522012  4.132801   3.099129   \n19 -38.404947      0.765013     0.647098    0.499827  4.132835   3.099130   \n\n    amhd_miss  BAspr_miss  \n15          1           1  \n16          1           1  \n17          1           1  \n18          1           1  \n19          1           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PERMNO</th>\n      <th>prd</th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>year</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>amhd_miss</th>\n      <th>BAspr_miss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>10005</td>\n      <td>390</td>\n      <td>NaN</td>\n      <td>-56.974664</td>\n      <td>1990</td>\n      <td>-40.6800</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>26.592465</td>\n      <td>-6.891869</td>\n      <td>NaN</td>\n      <td>7.874195</td>\n      <td>6.946893</td>\n      <td>0.093336</td>\n      <td>21.135115</td>\n      <td>8.239788</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>NaN</td>\n      <td>-0.424011</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.934794</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-38.209694</td>\n      <td>5.565847</td>\n      <td>5.250996</td>\n      <td>0.663164</td>\n      <td>3.190628</td>\n      <td>2.799597</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>10005</td>\n      <td>391</td>\n      <td>NaN</td>\n      <td>-57.000479</td>\n      <td>1990</td>\n      <td>-0.5700</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>-22.380465</td>\n      <td>55.680226</td>\n      <td>NaN</td>\n      <td>7.404275</td>\n      <td>6.612712</td>\n      <td>-0.150509</td>\n      <td>1.406600</td>\n      <td>0.866870</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.934794</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>-53.776947</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.372045</td>\n      <td>2.840962</td>\n      <td>2.265160</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>10005</td>\n      <td>392</td>\n      <td>NaN</td>\n      <td>-56.974664</td>\n      <td>1990</td>\n      <td>-0.6000</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>-0.570000</td>\n      <td>-30.377554</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>-0.156073</td>\n      <td>1.406600</td>\n      <td>0.866870</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.647218</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-53.828083</td>\n      <td>6.739834</td>\n      <td>4.518291</td>\n      <td>0.526334</td>\n      <td>4.132793</td>\n      <td>3.099129</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10005</td>\n      <td>393</td>\n      <td>NaN</td>\n      <td>-57.005640</td>\n      <td>1991</td>\n      <td>66.1467</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>-0.600000</td>\n      <td>-30.349534</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>-0.197082</td>\n      <td>1.406600</td>\n      <td>0.866870</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>NaN</td>\n      <td>-0.938262</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.647218</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-38.367763</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.522012</td>\n      <td>4.132801</td>\n      <td>3.099129</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>10005</td>\n      <td>394</td>\n      <td>NaN</td>\n      <td>-28.214878</td>\n      <td>1991</td>\n      <td>-0.4800</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>26.592465</td>\n      <td>-30.370549</td>\n      <td>NaN</td>\n      <td>7.874195</td>\n      <td>6.946893</td>\n      <td>-0.127235</td>\n      <td>21.135115</td>\n      <td>8.239788</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>NaN</td>\n      <td>-0.427479</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.647218</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-38.404947</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.499827</td>\n      <td>4.132835</td>\n      <td>3.099130</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 3. Train-test split #\n\ntemp_cols = ['PERMNO', 'prd', 'year']\n\ntrain = df[df.prd<(min_prd+60)]\ntest = df[df.prd==(min_prd+60)]\ntrain.drop(columns=temp_cols, inplace=True)\ntest.drop(columns=temp_cols, inplace=True)\ndisplay(train.shape, test.shape, train.head(3), test.head(3))","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:35.727099Z","iopub.execute_input":"2022-08-25T00:45:35.727455Z","iopub.status.idle":"2022-08-25T00:45:35.836981Z","shell.execute_reply.started":"2022-08-25T00:45:35.727419Z","shell.execute_reply":"2022-08-25T00:45:35.836031Z"},"trusted":true},"execution_count":340,"outputs":[{"output_type":"display_data","data":{"text/plain":"(155745, 45)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(2704, 45)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    mom482     mom242    RET   ind        bm        op   gp      inv  \\\n15     NaN -56.974664 -40.68  30.0  0.667021 -0.123134  0.0 -0.22093   \n16     NaN -57.000479  -0.57  30.0  0.667021 -0.123134  0.0 -0.22093   \n17     NaN -56.974664  -0.60  30.0  0.667021 -0.123134  0.0 -0.22093   \n\n        mom11     mom122  amhd  ivol_capm  ivol_ff5   beta_bw        MAX  \\\n15  26.592465  -6.891869   NaN   7.874195  6.946893  0.093336  21.135115   \n16 -22.380465  55.680226   NaN   7.404275  6.612712 -0.150509   1.406600   \n17  -0.570000 -30.377554   NaN   0.765013  0.647098 -0.156073   1.406600   \n\n       vol1m     vol6m    vol12m  BAspr      size       lbm       lop  lgp  \\\n15  8.239788  7.983689  7.756113    NaN -0.424011  0.490174 -0.214332  0.0   \n16  0.866870  7.983689  7.756113    NaN -0.934794  0.490174 -0.214332  0.0   \n17  0.866870  7.983689  7.756113    NaN -0.934794  0.490174 -0.214332  0.0   \n\n        linv      llme  l1amhd      l1MAX  l1BAspr  l3amhd   l3MAX  l3BAspr  \\\n15 -0.230583 -0.934794     NaN   1.406600      NaN     NaN  1.4066      NaN   \n16 -0.230583 -0.934794     NaN  21.135115      NaN     NaN  1.4066      NaN   \n17 -0.230583 -0.647218     NaN   1.406600      NaN     NaN  1.4066      NaN   \n\n    l6amhd   l6MAX  l6BAspr  l12amhd     l12MAX  l12BAspr  l12mom122  \\\n15     NaN  1.4066      NaN      NaN   1.406600       NaN -38.209694   \n16     NaN  1.4066      NaN      NaN  21.135115       NaN -53.776947   \n17     NaN  1.4066      NaN      NaN   1.406600       NaN -53.828083   \n\n    l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  amhd_miss  \\\n15      5.565847     5.250996    0.663164  3.190628   2.799597          1   \n16      0.765013     0.647098    0.372045  2.840962   2.265160          1   \n17      6.739834     4.518291    0.526334  4.132793   3.099129          1   \n\n    BAspr_miss  \n15           1  \n16           1  \n17           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>amhd_miss</th>\n      <th>BAspr_miss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>NaN</td>\n      <td>-56.974664</td>\n      <td>-40.68</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>26.592465</td>\n      <td>-6.891869</td>\n      <td>NaN</td>\n      <td>7.874195</td>\n      <td>6.946893</td>\n      <td>0.093336</td>\n      <td>21.135115</td>\n      <td>8.239788</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>NaN</td>\n      <td>-0.424011</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.934794</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-38.209694</td>\n      <td>5.565847</td>\n      <td>5.250996</td>\n      <td>0.663164</td>\n      <td>3.190628</td>\n      <td>2.799597</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>NaN</td>\n      <td>-57.000479</td>\n      <td>-0.57</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>-22.380465</td>\n      <td>55.680226</td>\n      <td>NaN</td>\n      <td>7.404275</td>\n      <td>6.612712</td>\n      <td>-0.150509</td>\n      <td>1.406600</td>\n      <td>0.866870</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.934794</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.135115</td>\n      <td>NaN</td>\n      <td>-53.776947</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.372045</td>\n      <td>2.840962</td>\n      <td>2.265160</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>NaN</td>\n      <td>-56.974664</td>\n      <td>-0.60</td>\n      <td>30.0</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>-0.570000</td>\n      <td>-30.377554</td>\n      <td>NaN</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>-0.156073</td>\n      <td>1.406600</td>\n      <td>0.866870</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>NaN</td>\n      <td>-0.934794</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.647218</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.4066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.406600</td>\n      <td>NaN</td>\n      <td>-53.828083</td>\n      <td>6.739834</td>\n      <td>4.518291</td>\n      <td>0.526334</td>\n      <td>4.132793</td>\n      <td>3.099129</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"         mom482     mom242     RET   ind        bm        op        gp  \\\n352  221.036390  71.141338 -9.5109  34.0 -2.486223  0.258106  0.875338   \n584  -20.644388 -14.451079 -3.5450  21.0 -0.251613 -0.024900  0.176579   \n802   14.774473   0.128066  5.1356  22.0 -0.350772  0.080204  0.514015   \n\n          inv    mom11     mom122      amhd  ivol_capm  ivol_ff5   beta_bw  \\\n352  0.516551  -8.8033   4.809002  1.994961   4.082701  3.614374  0.889628   \n584 -0.230583  -9.9040  65.805395  2.268093   1.479970  1.147467  0.836054   \n802  0.044549 -12.6651  26.020433  3.902367   2.958742  2.530542  0.667538   \n\n        MAX     vol1m     vol6m    vol12m     BAspr      size       lbm  \\\n352  8.0435  4.223638  2.857356  3.429300  1.886792  4.388676 -1.862198   \n584  2.1067  1.480002  2.175121  3.150615  2.105263  5.098719  0.177905   \n802  4.9790  3.030023  3.543060  3.745831  2.702703  3.900517 -0.174981   \n\n          lop       lgp      linv      llme    l1amhd   l1MAX   l1BAspr  \\\n352  0.132619  0.757579  0.335288  4.334673  2.055711  3.4263  1.680672   \n584 -0.082748  0.119668 -0.103007  4.646416  2.330593  5.2920  1.923077   \n802  0.079414  0.476869  0.132045  3.709154  4.167721  4.3258  4.819277   \n\n       l3amhd    l3MAX   l3BAspr    l6amhd    l6MAX   l6BAspr   l12amhd  \\\n352  2.158299  11.8414  3.816794  2.282986  17.0710  1.481481  3.937745   \n584  2.493890  11.7417  2.439024  2.455719   4.1437  2.898551  1.945916   \n802  4.980164   3.7745  7.228916  5.256542   9.4110  4.081633  5.583447   \n\n     l12MAX  l12BAspr  l12mom122  l12ivol_capm  l12ivol_ff5  l12beta_bw  \\\n352  3.4263  1.550388  43.713086      2.723997     2.325965    0.670790   \n584  5.2920  4.918033 -44.221641      2.446662     1.955686    0.806892   \n802  4.3258  7.812500 -20.978555      4.569170     4.275598    1.398619   \n\n     l12vol6m  l12vol12m  amhd_miss  BAspr_miss  \n352  2.191232   2.755011          0           0  \n584  2.414122   3.739985          0           0  \n802  5.172389   5.055447          0           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>RET</th>\n      <th>ind</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>amhd_miss</th>\n      <th>BAspr_miss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>352</th>\n      <td>221.036390</td>\n      <td>71.141338</td>\n      <td>-9.5109</td>\n      <td>34.0</td>\n      <td>-2.486223</td>\n      <td>0.258106</td>\n      <td>0.875338</td>\n      <td>0.516551</td>\n      <td>-8.8033</td>\n      <td>4.809002</td>\n      <td>1.994961</td>\n      <td>4.082701</td>\n      <td>3.614374</td>\n      <td>0.889628</td>\n      <td>8.0435</td>\n      <td>4.223638</td>\n      <td>2.857356</td>\n      <td>3.429300</td>\n      <td>1.886792</td>\n      <td>4.388676</td>\n      <td>-1.862198</td>\n      <td>0.132619</td>\n      <td>0.757579</td>\n      <td>0.335288</td>\n      <td>4.334673</td>\n      <td>2.055711</td>\n      <td>3.4263</td>\n      <td>1.680672</td>\n      <td>2.158299</td>\n      <td>11.8414</td>\n      <td>3.816794</td>\n      <td>2.282986</td>\n      <td>17.0710</td>\n      <td>1.481481</td>\n      <td>3.937745</td>\n      <td>3.4263</td>\n      <td>1.550388</td>\n      <td>43.713086</td>\n      <td>2.723997</td>\n      <td>2.325965</td>\n      <td>0.670790</td>\n      <td>2.191232</td>\n      <td>2.755011</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>584</th>\n      <td>-20.644388</td>\n      <td>-14.451079</td>\n      <td>-3.5450</td>\n      <td>21.0</td>\n      <td>-0.251613</td>\n      <td>-0.024900</td>\n      <td>0.176579</td>\n      <td>-0.230583</td>\n      <td>-9.9040</td>\n      <td>65.805395</td>\n      <td>2.268093</td>\n      <td>1.479970</td>\n      <td>1.147467</td>\n      <td>0.836054</td>\n      <td>2.1067</td>\n      <td>1.480002</td>\n      <td>2.175121</td>\n      <td>3.150615</td>\n      <td>2.105263</td>\n      <td>5.098719</td>\n      <td>0.177905</td>\n      <td>-0.082748</td>\n      <td>0.119668</td>\n      <td>-0.103007</td>\n      <td>4.646416</td>\n      <td>2.330593</td>\n      <td>5.2920</td>\n      <td>1.923077</td>\n      <td>2.493890</td>\n      <td>11.7417</td>\n      <td>2.439024</td>\n      <td>2.455719</td>\n      <td>4.1437</td>\n      <td>2.898551</td>\n      <td>1.945916</td>\n      <td>5.2920</td>\n      <td>4.918033</td>\n      <td>-44.221641</td>\n      <td>2.446662</td>\n      <td>1.955686</td>\n      <td>0.806892</td>\n      <td>2.414122</td>\n      <td>3.739985</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>802</th>\n      <td>14.774473</td>\n      <td>0.128066</td>\n      <td>5.1356</td>\n      <td>22.0</td>\n      <td>-0.350772</td>\n      <td>0.080204</td>\n      <td>0.514015</td>\n      <td>0.044549</td>\n      <td>-12.6651</td>\n      <td>26.020433</td>\n      <td>3.902367</td>\n      <td>2.958742</td>\n      <td>2.530542</td>\n      <td>0.667538</td>\n      <td>4.9790</td>\n      <td>3.030023</td>\n      <td>3.543060</td>\n      <td>3.745831</td>\n      <td>2.702703</td>\n      <td>3.900517</td>\n      <td>-0.174981</td>\n      <td>0.079414</td>\n      <td>0.476869</td>\n      <td>0.132045</td>\n      <td>3.709154</td>\n      <td>4.167721</td>\n      <td>4.3258</td>\n      <td>4.819277</td>\n      <td>4.980164</td>\n      <td>3.7745</td>\n      <td>7.228916</td>\n      <td>5.256542</td>\n      <td>9.4110</td>\n      <td>4.081633</td>\n      <td>5.583447</td>\n      <td>4.3258</td>\n      <td>7.812500</td>\n      <td>-20.978555</td>\n      <td>4.569170</td>\n      <td>4.275598</td>\n      <td>1.398619</td>\n      <td>5.172389</td>\n      <td>5.055447</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 4. Missing values #\n\ncol_ignore = ['RET']\ncol_cat = ['ind']\ncol_num = [x for x in train.columns if x not in col_ignore+col_cat]\n\nfor col in col_num:\n    train[col] = train[col].fillna(train[col].median())\n    test[col] = test[col].fillna(train[col].median())\n\nfor col in col_cat:\n    train[col] = train[col].fillna(value=-1000)\n    test[col] = test[col].fillna(value=-1000)\n    \ndisplay(train.count())","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:35.838528Z","iopub.execute_input":"2022-08-25T00:45:35.839136Z","iopub.status.idle":"2022-08-25T00:45:36.080592Z","shell.execute_reply.started":"2022-08-25T00:45:35.839099Z","shell.execute_reply":"2022-08-25T00:45:36.079481Z"},"trusted":true},"execution_count":341,"outputs":[{"output_type":"display_data","data":{"text/plain":"mom482          155745\nmom242          155745\nRET             155745\nind             155745\nbm              155745\nop              155745\ngp              155745\ninv             155745\nmom11           155745\nmom122          155745\namhd            155745\nivol_capm       155745\nivol_ff5        155745\nbeta_bw         155745\nMAX             155745\nvol1m           155745\nvol6m           155745\nvol12m          155745\nBAspr           155745\nsize            155745\nlbm             155745\nlop             155745\nlgp             155745\nlinv            155745\nllme            155745\nl1amhd          155745\nl1MAX           155745\nl1BAspr         155745\nl3amhd          155745\nl3MAX           155745\nl3BAspr         155745\nl6amhd          155745\nl6MAX           155745\nl6BAspr         155745\nl12amhd         155745\nl12MAX          155745\nl12BAspr        155745\nl12mom122       155745\nl12ivol_capm    155745\nl12ivol_ff5     155745\nl12beta_bw      155745\nl12vol6m        155745\nl12vol12m       155745\namhd_miss       155745\nBAspr_miss      155745\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# [optional] Target Encoding\n\n# first, do frequency encoding\nfreq_enc = (train.groupby('ind').size()) / len(train)\ntrain['ind_fencoded'] = train['ind'].apply(lambda x : freq_enc[x])\ntest['ind_fencoded'] = test['ind'].apply(lambda x : freq_enc[x])\n\ntime1 = time.time()\nencoder = CrossFoldEncoder(MEstimateEncoder, m=10)\ntrain_encoded = encoder.fit_transform(train, train.RET, cols=col_cat)\ntest_encoded = encoder.transform(test)\n\ntrain.drop(columns=col_cat, inplace=True)\ntest.drop(columns=col_cat,  inplace=True)\ntrain = pd.concat([train, train_encoded], axis = 1)\ntest = pd.concat([test, test_encoded], axis = 1)\n\ndisplay(time.time()-time0, time.time()-time1)\ndisplay(train.shape, train.head(), train.count())\ntrain0 = train.copy()\ntest0 = test.copy()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:36.082387Z","iopub.execute_input":"2022-08-25T00:45:36.082765Z","iopub.status.idle":"2022-08-25T00:45:37.879736Z","shell.execute_reply.started":"2022-08-25T00:45:36.082728Z","shell.execute_reply":"2022-08-25T00:45:37.878578Z"},"trusted":true},"execution_count":342,"outputs":[{"output_type":"display_data","data":{"text/plain":"3.176252603530884"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1.099823236465454"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(155745, 46)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"      mom482     mom242      RET        bm        op   gp      inv      mom11  \\\n15 -1.431704 -56.974664 -40.6800  0.667021 -0.123134  0.0 -0.22093  26.592465   \n16 -1.431704 -57.000479  -0.5700  0.667021 -0.123134  0.0 -0.22093 -22.380465   \n17 -1.431704 -56.974664  -0.6000  0.667021 -0.123134  0.0 -0.22093  -0.570000   \n18 -1.431704 -57.005640  66.1467  0.667021 -0.123134  0.0 -0.22093  -0.600000   \n19 -1.431704 -28.214878  -0.4800  0.667021 -0.123134  0.0 -0.22093  26.592465   \n\n       mom122      amhd  ivol_capm  ivol_ff5   beta_bw        MAX     vol1m  \\\n15  -6.891869  2.954248   7.874195  6.946893  0.093336  21.135115  8.239788   \n16  55.680226  2.954248   7.404275  6.612712 -0.150509   1.406600  0.866870   \n17 -30.377554  2.954248   0.765013  0.647098 -0.156073   1.406600  0.866870   \n18 -30.349534  2.954248   0.765013  0.647098 -0.197082   1.406600  0.866870   \n19 -30.370549  2.954248   7.874195  6.946893 -0.127235  21.135115  8.239788   \n\n       vol6m    vol12m     BAspr      size       lbm       lop  lgp      linv  \\\n15  7.983689  7.756113  3.921569 -0.424011  0.490174 -0.214332  0.0 -0.230583   \n16  7.983689  7.756113  3.921569 -0.934794  0.490174 -0.214332  0.0 -0.230583   \n17  7.983689  7.756113  3.921569 -0.934794  0.490174 -0.214332  0.0 -0.230583   \n18  7.983689  7.756113  3.921569 -0.938262  0.490174 -0.214332  0.0 -0.230583   \n19  7.983689  7.756113  3.921569 -0.427479  0.490174 -0.214332  0.0 -0.230583   \n\n        llme    l1amhd      l1MAX   l1BAspr    l3amhd      l3MAX  l3BAspr  \\\n15 -0.934794  2.965253   1.406600  3.947368  2.986047   1.406600      4.0   \n16 -0.934794  2.965253  21.135115  3.947368  2.986047   1.406600      4.0   \n17 -0.647218  2.965253   1.406600  3.947368  2.986047   1.406600      4.0   \n18 -0.647218  2.965253   1.406600  3.947368  2.986047  21.135115      4.0   \n19 -0.647218  2.965253   1.406600  3.947368  2.986047   1.406600      4.0   \n\n      l6amhd   l6MAX   l6BAspr   l12amhd     l12MAX  l12BAspr  l12mom122  \\\n15  3.009939  1.4066  4.054054  3.048352   1.406600  4.123711 -38.209694   \n16  3.009939  1.4066  4.054054  3.048352  21.135115  4.123711 -53.776947   \n17  3.009939  1.4066  4.054054  3.048352   1.406600  4.123711 -53.828083   \n18  3.009939  1.4066  4.054054  3.048352   1.406600  4.123711 -38.367763   \n19  3.009939  1.4066  4.054054  3.048352   1.406600  4.123711 -38.404947   \n\n    l12ivol_capm  l12ivol_ff5  l12beta_bw  l12vol6m  l12vol12m  amhd_miss  \\\n15      5.565847     5.250996    0.663164  3.190628   2.799597          1   \n16      0.765013     0.647098    0.372045  2.840962   2.265160          1   \n17      6.739834     4.518291    0.526334  4.132793   3.099129          1   \n18      0.765013     0.647098    0.522012  4.132801   3.099129          1   \n19      0.765013     0.647098    0.499827  4.132835   3.099130          1   \n\n    BAspr_miss  ind_fencoded  ind_encoded  \n15           1      0.063527     0.063301  \n16           1      0.063527     0.063301  \n17           1      0.063527     0.063301  \n18           1      0.063527     0.063301  \n19           1      0.063527     0.063301  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mom482</th>\n      <th>mom242</th>\n      <th>RET</th>\n      <th>bm</th>\n      <th>op</th>\n      <th>gp</th>\n      <th>inv</th>\n      <th>mom11</th>\n      <th>mom122</th>\n      <th>amhd</th>\n      <th>ivol_capm</th>\n      <th>ivol_ff5</th>\n      <th>beta_bw</th>\n      <th>MAX</th>\n      <th>vol1m</th>\n      <th>vol6m</th>\n      <th>vol12m</th>\n      <th>BAspr</th>\n      <th>size</th>\n      <th>lbm</th>\n      <th>lop</th>\n      <th>lgp</th>\n      <th>linv</th>\n      <th>llme</th>\n      <th>l1amhd</th>\n      <th>l1MAX</th>\n      <th>l1BAspr</th>\n      <th>l3amhd</th>\n      <th>l3MAX</th>\n      <th>l3BAspr</th>\n      <th>l6amhd</th>\n      <th>l6MAX</th>\n      <th>l6BAspr</th>\n      <th>l12amhd</th>\n      <th>l12MAX</th>\n      <th>l12BAspr</th>\n      <th>l12mom122</th>\n      <th>l12ivol_capm</th>\n      <th>l12ivol_ff5</th>\n      <th>l12beta_bw</th>\n      <th>l12vol6m</th>\n      <th>l12vol12m</th>\n      <th>amhd_miss</th>\n      <th>BAspr_miss</th>\n      <th>ind_fencoded</th>\n      <th>ind_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>-1.431704</td>\n      <td>-56.974664</td>\n      <td>-40.6800</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>26.592465</td>\n      <td>-6.891869</td>\n      <td>2.954248</td>\n      <td>7.874195</td>\n      <td>6.946893</td>\n      <td>0.093336</td>\n      <td>21.135115</td>\n      <td>8.239788</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>3.921569</td>\n      <td>-0.424011</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.934794</td>\n      <td>2.965253</td>\n      <td>1.406600</td>\n      <td>3.947368</td>\n      <td>2.986047</td>\n      <td>1.406600</td>\n      <td>4.0</td>\n      <td>3.009939</td>\n      <td>1.4066</td>\n      <td>4.054054</td>\n      <td>3.048352</td>\n      <td>1.406600</td>\n      <td>4.123711</td>\n      <td>-38.209694</td>\n      <td>5.565847</td>\n      <td>5.250996</td>\n      <td>0.663164</td>\n      <td>3.190628</td>\n      <td>2.799597</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.063527</td>\n      <td>0.063301</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>-1.431704</td>\n      <td>-57.000479</td>\n      <td>-0.5700</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>-22.380465</td>\n      <td>55.680226</td>\n      <td>2.954248</td>\n      <td>7.404275</td>\n      <td>6.612712</td>\n      <td>-0.150509</td>\n      <td>1.406600</td>\n      <td>0.866870</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>3.921569</td>\n      <td>-0.934794</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.934794</td>\n      <td>2.965253</td>\n      <td>21.135115</td>\n      <td>3.947368</td>\n      <td>2.986047</td>\n      <td>1.406600</td>\n      <td>4.0</td>\n      <td>3.009939</td>\n      <td>1.4066</td>\n      <td>4.054054</td>\n      <td>3.048352</td>\n      <td>21.135115</td>\n      <td>4.123711</td>\n      <td>-53.776947</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.372045</td>\n      <td>2.840962</td>\n      <td>2.265160</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.063527</td>\n      <td>0.063301</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>-1.431704</td>\n      <td>-56.974664</td>\n      <td>-0.6000</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>-0.570000</td>\n      <td>-30.377554</td>\n      <td>2.954248</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>-0.156073</td>\n      <td>1.406600</td>\n      <td>0.866870</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>3.921569</td>\n      <td>-0.934794</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.647218</td>\n      <td>2.965253</td>\n      <td>1.406600</td>\n      <td>3.947368</td>\n      <td>2.986047</td>\n      <td>1.406600</td>\n      <td>4.0</td>\n      <td>3.009939</td>\n      <td>1.4066</td>\n      <td>4.054054</td>\n      <td>3.048352</td>\n      <td>1.406600</td>\n      <td>4.123711</td>\n      <td>-53.828083</td>\n      <td>6.739834</td>\n      <td>4.518291</td>\n      <td>0.526334</td>\n      <td>4.132793</td>\n      <td>3.099129</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.063527</td>\n      <td>0.063301</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>-1.431704</td>\n      <td>-57.005640</td>\n      <td>66.1467</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>-0.600000</td>\n      <td>-30.349534</td>\n      <td>2.954248</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>-0.197082</td>\n      <td>1.406600</td>\n      <td>0.866870</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>3.921569</td>\n      <td>-0.938262</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.647218</td>\n      <td>2.965253</td>\n      <td>1.406600</td>\n      <td>3.947368</td>\n      <td>2.986047</td>\n      <td>21.135115</td>\n      <td>4.0</td>\n      <td>3.009939</td>\n      <td>1.4066</td>\n      <td>4.054054</td>\n      <td>3.048352</td>\n      <td>1.406600</td>\n      <td>4.123711</td>\n      <td>-38.367763</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.522012</td>\n      <td>4.132801</td>\n      <td>3.099129</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.063527</td>\n      <td>0.063301</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>-1.431704</td>\n      <td>-28.214878</td>\n      <td>-0.4800</td>\n      <td>0.667021</td>\n      <td>-0.123134</td>\n      <td>0.0</td>\n      <td>-0.22093</td>\n      <td>26.592465</td>\n      <td>-30.370549</td>\n      <td>2.954248</td>\n      <td>7.874195</td>\n      <td>6.946893</td>\n      <td>-0.127235</td>\n      <td>21.135115</td>\n      <td>8.239788</td>\n      <td>7.983689</td>\n      <td>7.756113</td>\n      <td>3.921569</td>\n      <td>-0.427479</td>\n      <td>0.490174</td>\n      <td>-0.214332</td>\n      <td>0.0</td>\n      <td>-0.230583</td>\n      <td>-0.647218</td>\n      <td>2.965253</td>\n      <td>1.406600</td>\n      <td>3.947368</td>\n      <td>2.986047</td>\n      <td>1.406600</td>\n      <td>4.0</td>\n      <td>3.009939</td>\n      <td>1.4066</td>\n      <td>4.054054</td>\n      <td>3.048352</td>\n      <td>1.406600</td>\n      <td>4.123711</td>\n      <td>-38.404947</td>\n      <td>0.765013</td>\n      <td>0.647098</td>\n      <td>0.499827</td>\n      <td>4.132835</td>\n      <td>3.099130</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.063527</td>\n      <td>0.063301</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"mom482          155745\nmom242          155745\nRET             155745\nbm              155745\nop              155745\ngp              155745\ninv             155745\nmom11           155745\nmom122          155745\namhd            155745\nivol_capm       155745\nivol_ff5        155745\nbeta_bw         155745\nMAX             155745\nvol1m           155745\nvol6m           155745\nvol12m          155745\nBAspr           155745\nsize            155745\nlbm             155745\nlop             155745\nlgp             155745\nlinv            155745\nllme            155745\nl1amhd          155745\nl1MAX           155745\nl1BAspr         155745\nl3amhd          155745\nl3MAX           155745\nl3BAspr         155745\nl6amhd          155745\nl6MAX           155745\nl6BAspr         155745\nl12amhd         155745\nl12MAX          155745\nl12BAspr        155745\nl12mom122       155745\nl12ivol_capm    155745\nl12ivol_ff5     155745\nl12beta_bw      155745\nl12vol6m        155745\nl12vol12m       155745\namhd_miss       155745\nBAspr_miss      155745\nind_fencoded    155745\nind_encoded     155745\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"X_train = train.copy()\ny_train = X_train.pop('RET')\n\nX_test = test.copy()\ny_test = X_test.pop('RET')","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:37.883577Z","iopub.execute_input":"2022-08-25T00:45:37.883948Z","iopub.status.idle":"2022-08-25T00:45:37.929142Z","shell.execute_reply.started":"2022-08-25T00:45:37.883914Z","shell.execute_reply":"2022-08-25T00:45:37.927949Z"},"trusted":true},"execution_count":343,"outputs":[]},{"cell_type":"code","source":"# 5. Feature engineering #\n\ntime1 = time.time()\n\n# (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\", drop='if_binary'), col_cat),\n\nfeature_transformer = ColumnTransformer([('num', StandardScaler(), col_num)], remainder=\"passthrough\")\n\nprint('Number of features before transformation: ', X_train.shape)\nX_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\nX_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\nprint('time to do feature proprocessing: ', time.time()-time1)\nprint('Number of features after transformation: ', X_train.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:37.930429Z","iopub.execute_input":"2022-08-25T00:45:37.931029Z","iopub.status.idle":"2022-08-25T00:45:38.109412Z","shell.execute_reply.started":"2022-08-25T00:45:37.930975Z","shell.execute_reply":"2022-08-25T00:45:38.108286Z"},"trusted":true},"execution_count":344,"outputs":[{"name":"stdout","text":"Number of features before transformation:  (155745, 45)\ntime to do feature proprocessing:  0.17090606689453125\nNumber of features after transformation:  (155745, 45)\n","output_type":"stream"}]},{"cell_type":"code","source":"# 6. Model fitting #\n\n# first, some trivial baselines:\nprint('mae of a constant model', mean_absolute_error(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\nprint('R2 of a constant model', r2_score(df.RET, np.ones(df.shape[0])*(df.RET.mean())))\n\ntime1 = time.time()\nxgb1 = XGBRegressor(tree_method = 'gpu_hist', n_estimators=300, max_depth=5, eta=0.04, colsample_bytree=0.6)\nxgb1.fit(X_train, y_train)\nprint('XGB train:', mean_absolute_error(y_train, xgb1.predict(X_train)), r2_score(y_train, xgb1.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:38.111303Z","iopub.execute_input":"2022-08-25T00:45:38.111647Z","iopub.status.idle":"2022-08-25T00:45:41.029093Z","shell.execute_reply.started":"2022-08-25T00:45:38.111612Z","shell.execute_reply":"2022-08-25T00:45:41.028337Z"},"trusted":true},"execution_count":345,"outputs":[{"name":"stdout","text":"mae of a constant model 10.795447332475286\nR2 of a constant model 0.0\nXGB train: 10.524598947835688 0.09155861878129534 2.899041175842285\n","output_type":"stream"}]},{"cell_type":"code","source":"time1 = time.time()\nxgb = XGBRegressor(tree_method = 'gpu_hist')\nparam_grid = {'n_estimators':[300, 500], 'max_depth':[2,3,4], 'eta':[0.01, 0.03, 0.05],\n             'subsample':[0.6], 'colsample_bytree':[0.6]}\nxgbm = GridSearchCV(xgb, param_grid, cv=2, verbose=2, scoring='neg_mean_absolute_error')\nxgbm.fit(X_train, y_train)\nprint('XGB', xgbm.best_params_, xgbm.best_score_, time.time()-time1)\n# this runs for 40 min and finds \n# 'eta': 0.02, 'max_depth': 6, 'n_estimators': 500, 0.01095415380877135\nprint('XGB train:', mean_absolute_error(y_train, xgbm.predict(X_train)), r2_score(y_train, xgbm.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:45:41.030255Z","iopub.execute_input":"2022-08-25T00:45:41.030803Z","iopub.status.idle":"2022-08-25T00:46:18.578960Z","shell.execute_reply.started":"2022-08-25T00:45:41.030766Z","shell.execute_reply":"2022-08-25T00:46:18.578203Z"},"trusted":true},"execution_count":346,"outputs":[{"name":"stdout","text":"Fitting 2 folds for each of 18 candidates, totalling 36 fits\n[CV] END colsample_bytree=0.6, eta=0.01, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.01, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.01, max_depth=2, n_estimators=500, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.01, max_depth=2, n_estimators=500, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.01, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.01, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   1.3s\n[CV] END colsample_bytree=0.6, eta=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.01, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.01, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.01, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.01, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.03, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.03, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.03, max_depth=2, n_estimators=500, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.03, max_depth=2, n_estimators=500, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.03, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.8s\n[CV] END colsample_bytree=0.6, eta=0.03, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.03, max_depth=3, n_estimators=500, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.03, max_depth=3, n_estimators=500, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.03, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.03, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.03, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.03, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=2, n_estimators=300, subsample=0.6; total time=   0.6s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=2, n_estimators=500, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=2, n_estimators=500, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.9s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.7s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=3, n_estimators=500, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=3, n_estimators=500, subsample=0.6; total time=   1.1s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=4, n_estimators=300, subsample=0.6; total time=   1.0s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.5s\n[CV] END colsample_bytree=0.6, eta=0.05, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.5s\nXGB {'colsample_bytree': 0.6, 'eta': 0.01, 'max_depth': 4, 'n_estimators': 300, 'subsample': 0.6} -10.80209208550507 36.44972896575928\nXGB train: 10.751439746247739 0.023483696094606543 37.538378953933716\n","output_type":"stream"}]},{"cell_type":"code","source":"# time1 = time.time()\n\n# def objective(trial, cv_runs=1, n_splits=2, n_jobs=-1):\n\n#     cv_regularizer=0.01\n#     # Usually values between 0.1 and 0.2 work fine.\n\n#     params = {\n#         \"tree_method\": 'gpu_hist',\n#         \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n#         \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n#         \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n#         \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.005, 0.2),\n#         \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.1, 0.95),\n#         \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 0.95),\n#         \"alpha\": trial.suggest_loguniform(\"alpha\", 0.1, 20.0),\n#         \"lambda\": trial.suggest_loguniform(\"lambda\", 0.1, 150.0),\n#         \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-10, 10.0),\n#         \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 0.1, 10)    }\n#     # usually it makes sense to resrtict hyperparameter space from some solutions which Optuna will find\n#     # e.g., for tmx-joined data only (downsampled tmx), optuna keeps selecting depths of 2 and 3.\n#     # for my purposes (smooth left side of prc, close to 1), those solutions are no good.\n\n#     temp_out = []\n\n#     for i in range(cv_runs):\n\n#         X = X_train\n#         y = y_train\n\n#         model = XGBRegressor(**params, njobs=-1)\n#         rkf = KFold(n_splits=n_splits, shuffle=True)\n#         X_values = X.values\n#         y_values = y.values\n#         y_pred = np.zeros_like(y_values)\n#         y_pred_train = np.zeros_like(y_values)\n#         for train_index, test_index in rkf.split(X_values):\n#             X_A, X_B = X_values[train_index, :], X_values[test_index, :]\n#             y_A, y_B = y_values[train_index], y_values[test_index]\n#             model.fit(X_A, y_A, eval_set=[(X_B, y_B)], verbose = False)\n#             y_pred[test_index] += model.predict(X_B)\n                      \n            \n#         #score_train = roc_auc_score(y_train, y_pred_train)\n#         score_test = mean_absolute_error(y_train, y_pred) \n#         #overfit = score_train-score_test\n#         #temp_out.append(score_test-cv_regularizer*overfit)\n#         temp_out.append(score_test)\n\n#     return (np.mean(temp_out))\n\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(objective, n_trials=30)\n\n# print('Total time for hypermarameter optimization ', time.time()-time1)\n# hp = study.best_params\n# for key, value in hp.items():\n#     print(f\"{key:>20s} : {value}\")\n# print(f\"{'best objective value':>20s} : {study.best_value}\")\n\n# optuna_hyperpars = study.best_params\n# optuna_hyperpars['tree_method']='gpu_hist'\n\n# optuna_xgb = XGBRegressor(**optuna_hyperpars)\n# optuna_xgb.fit(X_train, y_train)\n# print('Optuna XGB train:', \n#       mean_absolute_error(y_train, optuna_xgb.predict(X_train)), r2_score(y_train, optuna_xgb.predict(X_train)), time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:46:18.582604Z","iopub.execute_input":"2022-08-25T00:46:18.584424Z","iopub.status.idle":"2022-08-25T00:46:18.591514Z","shell.execute_reply.started":"2022-08-25T00:46:18.584391Z","shell.execute_reply":"2022-08-25T00:46:18.590528Z"},"trusted":true},"execution_count":347,"outputs":[]},{"cell_type":"code","source":"# Evaluate performance of XGB models:\n\nprint('XGB test:', mean_absolute_error(y_test, xgb1.predict(X_test)), r2_score(y_test, xgb1.predict(X_test)))\nprint('XGB GS test:', mean_absolute_error(y_test, xgbm.predict(X_test)), r2_score(y_test, xgbm.predict(X_test)))\n#print('Optuna XGB test:', mean_absolute_error(y_test, optuna_xgb.predict(X_test)), r2_score(y_test, optuna_xgb.predict(X_test)))","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:46:18.592718Z","iopub.execute_input":"2022-08-25T00:46:18.593272Z","iopub.status.idle":"2022-08-25T00:46:18.680245Z","shell.execute_reply.started":"2022-08-25T00:46:18.593235Z","shell.execute_reply":"2022-08-25T00:46:18.677686Z"},"trusted":true},"execution_count":348,"outputs":[{"name":"stdout","text":"XGB test: 10.135926009525937 -0.028100875477757414\nXGB GS test: 10.067216374248824 -0.013144079657394503\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total time for a script: ', time.time()-time0)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:46:18.681630Z","iopub.execute_input":"2022-08-25T00:46:18.681982Z","iopub.status.idle":"2022-08-25T00:46:18.692325Z","shell.execute_reply.started":"2022-08-25T00:46:18.681930Z","shell.execute_reply":"2022-08-25T00:46:18.691019Z"},"trusted":true},"execution_count":349,"outputs":[{"name":"stdout","text":"Total time for a script:  44.12144064903259\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_size = 0.1\n# df.reset_index(inplace=True, drop=True)\n# #random.seed(2)\n# test_index = random.sample(list(df.index), int(test_size*df.shape[0]))\n# train = df.iloc[list(set(df.index)-set(test_index))]\n# test = df.iloc[test_index]\n# train.reset_index(drop=True, inplace=True)\n# test.reset_index(drop=True, inplace=True)\n# display(train.shape, test.shape, train.head(3), test.head(3))","metadata":{"execution":{"iopub.status.busy":"2022-08-25T00:46:18.693914Z","iopub.execute_input":"2022-08-25T00:46:18.695317Z","iopub.status.idle":"2022-08-25T00:46:18.709954Z","shell.execute_reply.started":"2022-08-25T00:46:18.695281Z","shell.execute_reply":"2022-08-25T00:46:18.707533Z"},"trusted":true},"execution_count":350,"outputs":[]}]}
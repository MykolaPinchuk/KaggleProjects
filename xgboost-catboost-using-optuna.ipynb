{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Optuna: A hyperparameter optimization framework","metadata":{}},{"cell_type":"markdown","source":"### This is modified public notebook from Kaggle, showing how to use Optuna.\n### I have modified it to do cross-validation within Optuna.","metadata":{"execution":{"iopub.status.busy":"2022-06-04T19:50:29.687081Z","iopub.execute_input":"2022-06-04T19:50:29.687439Z","iopub.status.idle":"2022-06-04T19:50:29.691828Z","shell.execute_reply.started":"2022-06-04T19:50:29.687407Z","shell.execute_reply":"2022-06-04T19:50:29.690941Z"}}},{"cell_type":"markdown","source":"* [1.Basic Concepts](#chapter1)\n* [2. Let's build our optimization function using optuna](#chapter2)\n* [3. XGBoost using Optuna](#chapter3)\n* [5. Submission](#chapter5)","metadata":{}},{"cell_type":"markdown","source":"* <h4> In This Kernel I will use an amazing framework called <b>Optuna</b> to find the best hyparameters of our XGBoost and CatBoost </h4>","metadata":{}},{"cell_type":"markdown","source":"**So, Optuna is an automatic hyperparameter optimization software framework, particularly designed for machine learning. It features an imperative, define-by-run style user API.<br> The code written with Optuna enjoys high modularity, and the user of Optuna can dynamically construct the search spaces for the hyperparameters.** \n* To learn more about Optuna check this [link](https://optuna.org/)","metadata":{}},{"cell_type":"markdown","source":"MP: Good fast introduction to Optuna: https://towardsdatascience.com/why-is-everyone-at-kaggle-obsessed-with-optuna-for-hyperparameter-tuning-7608fdca337c","metadata":{}},{"cell_type":"markdown","source":"# 1. Basic Concepts <a class=\"anchor\" id=\"chapter1\"></a>\nSo, We use the terms study and trial as follows:\n* <b>Study</b> : optimization based on an objective function\n* <b>Trial</b> : a single execution of the objective function","metadata":{}},{"cell_type":"code","source":"#import optuna \nimport optuna\n\nfrom xgboost import XGBRegressor\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold, GridSearchCV, KFold, RepeatedKFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport time, warnings\n#from optuna.visualization.matplotlib import plot_param_importances\n\nwarnings.filterwarnings('ignore')\n\ntrain = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')\ntest  = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv')\nsub = pd.read_csv('../input/tabular-playground-series-jan-2021/sample_submission.csv')\n\ntrain.head()\n\nprint(train.shape)\ncolumns = [col for col in train.columns.to_list() if col not in ['id','target']]\n\ndata=train[columns]\ntarget=train['target']\n\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.15,random_state=4)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:49:50.383256Z","iopub.execute_input":"2022-06-04T20:49:50.384231Z","iopub.status.idle":"2022-06-04T20:49:58.988060Z","shell.execute_reply.started":"2022-06-04T20:49:50.384168Z","shell.execute_reply":"2022-06-04T20:49:58.986782Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"(300000, 16)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. Let's build our optimization function using optuna <a class=\"anchor\" id=\"chapter2\"></a>","metadata":{}},{"cell_type":"markdown","source":"### The following optimization function uses XGBoostRegressor model, so it takes the following arguments:\n* the data\n* the target\n* trial (How many executions we will do)  \n### and returns\n* RMSE (Root Mean Squared Rrror)","metadata":{}},{"cell_type":"markdown","source":"## Notes:\n* Note that I used some XGBoostRegressor hyperparameters from Xgboost official site. \n* So if you like to add more parameters or change them, check this [link](https://xgboost.readthedocs.io/en/latest/parameter.html) \n* Also I used early_stopping_rounds to avoid overfiting\n* to speedup the training process we can use the GPU or you can comment the first param argument (the training process will takes a lot of time by only using the cpu ðŸ˜©) ","metadata":{}},{"cell_type":"markdown","source":"# 3. XGBoost using Optuna <a class=\"anchor\" id=\"chapter3\"></a>","metadata":{}},{"cell_type":"code","source":"def evaluate_model_rkf(model, X_df, y_df, n_splits=4, random_state=3):\n    X_values = X_df.values\n    y_values = y_df.values\n    rkf = KFold(n_splits=n_splits, random_state=random_state)\n    y_pred = np.zeros_like(y_values)\n    for train_index, test_index in rkf.split(X_values):\n        X_t, X_v = X_values[train_index, :], X_values[test_index, :]\n        y_t = y_values[train_index]\n        model.fit(\n            X_t, y_t,\n        )\n        y_pred[test_index] += model.predict(X_v)\n    y_pred\n    return np.sqrt(mean_squared_error(y_train, y_pred))\n\n\n# First, try raw XGBoost to make sure that evaluate_model_rkf works:\n\nmodel = XGBRegressor(tree_method = 'gpu_hist', gpu_id=0, max_depth=8, eta=0.03, n_estimators=200)\nevaluate_model_rkf(model, X_train, y_train, n_splits=4, random_state=2)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:50:05.201833Z","iopub.execute_input":"2022-06-04T20:50:05.202160Z","iopub.status.idle":"2022-06-04T20:50:18.915896Z","shell.execute_reply.started":"2022-06-04T20:50:05.202131Z","shell.execute_reply":"2022-06-04T20:50:18.914672Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"0.703764751179221"},"metadata":{}}]},{"cell_type":"code","source":"def objective(trial, random_state=1, n_splits=4, n_jobs=-1, early_stopping_rounds=50):\n    params = {\n        \"tree_method\": 'gpu_hist',\n        \"gpu_id\": 0,\n        \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n        \"objective\": \"reg:squarederror\",\n        \"n_estimators\": 400,\n        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 15),\n        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.01, 0.09),\n        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.2, 1),\n        \"subsample\": trial.suggest_uniform(\"subsample\", 0.3, 1),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 0.01, 10.0),\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 10.0),\n        \"gamma\": trial.suggest_loguniform(\"lambda\", 1e-8, 10.0),\n        \"min_child_weight\": trial.suggest_uniform(\"min_child_weight\", 10, 1000),\n        \"seed\": random_state,\n        \"n_jobs\": n_jobs,\n    }\n\n    X = X_train\n    y = y_train\n    \n    model = XGBRegressor(**params)\n    rkf = KFold(n_splits=n_splits, random_state=random_state)\n    X_values = X.values\n    y_values = y.values\n    y_pred = np.zeros_like(y_values)\n    for train_index, test_index in rkf.split(X_values):\n        X_A, X_B = X_values[train_index, :], X_values[test_index, :]\n        y_A, y_B = y_values[train_index], y_values[test_index]\n        model.fit(X_A, y_A, eval_set=[(X_B, y_B)],\n            eval_metric=\"rmse\", early_stopping_rounds=early_stopping_rounds, verbose = False)\n        y_pred[test_index] += model.predict(X_B)\n    return (mean_squared_error(y_train, y_pred, squared=False))\n\n\n\ntime1 = time.time()\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=20)\nprint('Total time ', time.time()-time1)\n\n# display params\nhp = study.best_params\nfor key, value in hp.items():\n    print(f\"{key:>20s} : {value}\")\nprint(f\"{'best objective value':>20s} : {study.best_value}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:50:49.376256Z","iopub.execute_input":"2022-06-04T20:50:49.376638Z","iopub.status.idle":"2022-06-04T20:59:38.610895Z","shell.execute_reply.started":"2022-06-04T20:50:49.376608Z","shell.execute_reply":"2022-06-04T20:59:38.609908Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-06-04 20:50:49,390]\u001b[0m A new study created in memory with name: no-name-45ec484e-d2d9-4b46-a25d-467e9ffb5c37\u001b[0m\n\u001b[32m[I 2022-06-04 20:51:11,948]\u001b[0m Trial 0 finished with value: 0.6988289305582124 and parameters: {'max_depth': 8, 'learning_rate': 0.050063088418425904, 'colsample_bytree': 0.923988893216138, 'subsample': 0.7318991246605181, 'alpha': 2.8301777069291516, 'lambda': 3.036489613239245e-05, 'min_child_weight': 282.04926545776914}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:51:26,108]\u001b[0m Trial 1 finished with value: 0.6998709618170263 and parameters: {'max_depth': 6, 'learning_rate': 0.07869120023858178, 'colsample_bytree': 0.5141833134360554, 'subsample': 0.9438518356701528, 'alpha': 0.032726657699866726, 'lambda': 0.0014445901126299574, 'min_child_weight': 815.5820917327338}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:51:40,528]\u001b[0m Trial 2 finished with value: 0.7022471471647614 and parameters: {'max_depth': 6, 'learning_rate': 0.0362161417987386, 'colsample_bytree': 0.4066183941007129, 'subsample': 0.7606105663166298, 'alpha': 3.8575085908238065, 'lambda': 5.994034500740225e-05, 'min_child_weight': 684.7113044413934}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:52:25,988]\u001b[0m Trial 3 finished with value: 0.6993598283064969 and parameters: {'max_depth': 10, 'learning_rate': 0.04714697205988587, 'colsample_bytree': 0.21572495872195516, 'subsample': 0.9578177450779863, 'alpha': 1.6503197092071815, 'lambda': 3.717117006083358e-08, 'min_child_weight': 111.88296599223376}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:52:44,053]\u001b[0m Trial 4 finished with value: 0.6995952106701017 and parameters: {'max_depth': 8, 'learning_rate': 0.06068572695952109, 'colsample_bytree': 0.7820072963540292, 'subsample': 0.5225289398750987, 'alpha': 0.12831554586143418, 'lambda': 0.02143879267668824, 'min_child_weight': 894.7008319690955}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:52:58,577]\u001b[0m Trial 5 finished with value: 0.7021236844146814 and parameters: {'max_depth': 6, 'learning_rate': 0.039445064236273066, 'colsample_bytree': 0.34931410399203716, 'subsample': 0.6275976549201093, 'alpha': 0.1318159596466247, 'lambda': 1.5217007944616058e-08, 'min_child_weight': 657.5906229293603}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:53:03,484]\u001b[0m Trial 6 finished with value: 0.7051259411435297 and parameters: {'max_depth': 13, 'learning_rate': 0.07806039311227791, 'colsample_bytree': 0.44815596557914533, 'subsample': 0.962353504941426, 'alpha': 4.060901712180294, 'lambda': 7.231855642539445, 'min_child_weight': 565.458701244032}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:53:11,333]\u001b[0m Trial 7 finished with value: 0.7030092354285522 and parameters: {'max_depth': 4, 'learning_rate': 0.07137674723423648, 'colsample_bytree': 0.6115872623631331, 'subsample': 0.5592181218930999, 'alpha': 0.234006183314622, 'lambda': 2.7438037025961073, 'min_child_weight': 12.058179628510189}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:53:16,151]\u001b[0m Trial 8 finished with value: 0.7149062698801708 and parameters: {'max_depth': 2, 'learning_rate': 0.03209296642674406, 'colsample_bytree': 0.7845645354862092, 'subsample': 0.8104153507605432, 'alpha': 0.10363692698460598, 'lambda': 3.759356245496757, 'min_child_weight': 256.38793970417623}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:53:20,991]\u001b[0m Trial 9 finished with value: 0.7183267094978557 and parameters: {'max_depth': 2, 'learning_rate': 0.01717195764878643, 'colsample_bytree': 0.7965226251642445, 'subsample': 0.9731946262937465, 'alpha': 0.22277576968150242, 'lambda': 0.010517193984331352, 'min_child_weight': 628.4348394618148}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:53:48,986]\u001b[0m Trial 10 finished with value: 0.7000739796972348 and parameters: {'max_depth': 15, 'learning_rate': 0.055494619185079114, 'colsample_bytree': 0.9788745593963976, 'subsample': 0.33688601947967645, 'alpha': 1.2794788619173174, 'lambda': 3.061799635141603e-06, 'min_child_weight': 333.0075704018417}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:54:53,119]\u001b[0m Trial 11 finished with value: 0.7012298466553503 and parameters: {'max_depth': 12, 'learning_rate': 0.05199631105392095, 'colsample_bytree': 0.2319250778125089, 'subsample': 0.8019102704557273, 'alpha': 1.0554647248379767, 'lambda': 1.1899817551631147e-08, 'min_child_weight': 48.17614897547412}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:55:23,209]\u001b[0m Trial 12 finished with value: 0.6993540989126494 and parameters: {'max_depth': 10, 'learning_rate': 0.0496520045737909, 'colsample_bytree': 0.9965335342683475, 'subsample': 0.3998448026222787, 'alpha': 8.418941561727845, 'lambda': 4.6740011278499043e-07, 'min_child_weight': 231.52339223392158}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:55:46,223]\u001b[0m Trial 13 finished with value: 0.6999477846388018 and parameters: {'max_depth': 10, 'learning_rate': 0.06415370526210126, 'colsample_bytree': 0.9966149463071737, 'subsample': 0.30086293777279055, 'alpha': 9.695920829970984, 'lambda': 1.0418432929327623e-06, 'min_child_weight': 388.02368541648895}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:56:09,077]\u001b[0m Trial 14 finished with value: 0.7006047633285013 and parameters: {'max_depth': 8, 'learning_rate': 0.026129329041638675, 'colsample_bytree': 0.891079523989408, 'subsample': 0.4563990921358813, 'alpha': 9.197413142979554, 'lambda': 1.389583152443111e-06, 'min_child_weight': 218.46750440490302}. Best is trial 0 with value: 0.6988289305582124.\u001b[0m\n\u001b[32m[I 2022-06-04 20:56:41,772]\u001b[0m Trial 15 finished with value: 0.698503296507512 and parameters: {'max_depth': 11, 'learning_rate': 0.04433532691752662, 'colsample_bytree': 0.9138440633519979, 'subsample': 0.6915598853469267, 'alpha': 3.7039571123898996, 'lambda': 2.7419870907663816e-05, 'min_child_weight': 448.23252055337673}. Best is trial 15 with value: 0.698503296507512.\u001b[0m\n\u001b[32m[I 2022-06-04 20:57:21,644]\u001b[0m Trial 16 finished with value: 0.6983901604840934 and parameters: {'max_depth': 13, 'learning_rate': 0.04235724944611368, 'colsample_bytree': 0.6246010458210072, 'subsample': 0.6747538113353361, 'alpha': 0.6269390451666313, 'lambda': 1.7410031402729705e-05, 'min_child_weight': 452.38917430661263}. Best is trial 16 with value: 0.6983901604840934.\u001b[0m\n\u001b[32m[I 2022-06-04 20:58:07,937]\u001b[0m Trial 17 finished with value: 0.6985150392984493 and parameters: {'max_depth': 14, 'learning_rate': 0.02472296420018876, 'colsample_bytree': 0.6783987004635197, 'subsample': 0.6812909487107744, 'alpha': 0.6853848909608312, 'lambda': 0.00023928809129558724, 'min_child_weight': 458.15520988046575}. Best is trial 16 with value: 0.6983901604840934.\u001b[0m\n\u001b[32m[I 2022-06-04 20:58:55,278]\u001b[0m Trial 18 finished with value: 0.7074871625232494 and parameters: {'max_depth': 12, 'learning_rate': 0.011019435070067508, 'colsample_bytree': 0.6797818910134342, 'subsample': 0.8513313905502132, 'alpha': 0.5082096533615321, 'lambda': 8.69156897242086e-06, 'min_child_weight': 455.3354717455018}. Best is trial 16 with value: 0.6983901604840934.\u001b[0m\n\u001b[32m[I 2022-06-04 20:59:38,601]\u001b[0m Trial 19 finished with value: 0.6983776513576055 and parameters: {'max_depth': 15, 'learning_rate': 0.04192502207851453, 'colsample_bytree': 0.557020876933197, 'subsample': 0.6312356746524119, 'alpha': 2.486571722519996, 'lambda': 1.1823471520888105e-07, 'min_child_weight': 517.5475000809336}. Best is trial 19 with value: 0.6983776513576055.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time  529.2130689620972\n           max_depth : 15\n       learning_rate : 0.04192502207851453\n    colsample_bytree : 0.557020876933197\n           subsample : 0.6312356746524119\n               alpha : 2.486571722519996\n              lambda : 1.1823471520888105e-07\n    min_child_weight : 517.5475000809336\nbest objective value : 0.6983776513576055\n","output_type":"stream"}]},{"cell_type":"code","source":"optuna_hyperpars = study.best_params\noptuna_hyperpars['tree_method']='gpu_hist'\noptuna_hyperpars['gpu_id']=0\noptuna_hyperpars['n_estimators']=400\n#optuna_hyperpars\noptuna_xgb = XGBRegressor(**optuna_hyperpars)\noptuna_xgb.fit(X_train, y_train)\noptuna_xgb.predict(X_test)\nprint('Optuna model:', mean_squared_error(optuna_xgb.predict(X_test), y_test, squared = False))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T21:08:29.357945Z","iopub.execute_input":"2022-06-04T21:08:29.358318Z","iopub.status.idle":"2022-06-04T21:08:44.021840Z","shell.execute_reply.started":"2022-06-04T21:08:29.358264Z","shell.execute_reply":"2022-06-04T21:08:44.020556Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Optuna model: 0.6963909629721695\n","output_type":"stream"}]},{"cell_type":"code","source":"# compare timing with GridSearchCV on XGBoost:\n\ntime1 = time.time()\nxgbb = XGBRegressor(tree_method='gpu_hist', gpu_id=0)\nparam_grid = {'n_estimators':[400], 'eta':[0.02, 0.04, 0.06], 'max_depth':[4,7,10,12,15]}\nxgbm = GridSearchCV(xgbb, param_grid, cv=4, scoring='neg_root_mean_squared_error')\nxgbm.fit(X_train, y_train)\nprint('XGB ', xgbm.best_params_, xgbm.best_score_, time.time()-time1)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:11:42.260258Z","iopub.execute_input":"2022-06-04T20:11:42.260604Z","iopub.status.idle":"2022-06-04T20:15:10.69839Z","shell.execute_reply.started":"2022-06-04T20:11:42.260571Z","shell.execute_reply":"2022-06-04T20:15:10.697619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna_hyperpars = study.best_params\noptuna_hyperpars['tree_method']='gpu_hist'\noptuna_hyperpars['gpu_id']=0\noptuna_hyperpars['n_estimators']=400\n#optuna_hyperpars\noptuna_xgb = XGBRegressor(**optuna_hyperpars)\noptuna_xgb.fit(X_train, y_train)\n\nprint('Optuna model:', mean_squared_error(optuna_xgb.predict(X_test), y_test, squared = False))\nprint('GS model:', mean_squared_error(xgbm.predict(X_test), y_test, squared = False))","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:15:28.841807Z","iopub.execute_input":"2022-06-04T20:15:28.842171Z","iopub.status.idle":"2022-06-04T20:15:35.468779Z","shell.execute_reply.started":"2022-06-04T20:15:28.842138Z","shell.execute_reply":"2022-06-04T20:15:35.4679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.trials_dataframe()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:16:26.913158Z","iopub.execute_input":"2022-06-04T20:16:26.913524Z","iopub.status.idle":"2022-06-04T20:16:26.948824Z","shell.execute_reply.started":"2022-06-04T20:16:26.913489Z","shell.execute_reply":"2022-06-04T20:16:26.947944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's do some Quick Visualization for Hyperparameter Optimization Analysis\n#### Optuna provides various visualization features in optuna.visualization to analyze optimization results visually","metadata":{}},{"cell_type":"code","source":"#plot_optimization_histor: shows the scores from all trials as well as the best score so far at each point.\noptuna.visualization.plot_optimization_history(study)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:16:31.375421Z","iopub.execute_input":"2022-06-04T20:16:31.375756Z","iopub.status.idle":"2022-06-04T20:16:31.392602Z","shell.execute_reply.started":"2022-06-04T20:16:31.375724Z","shell.execute_reply":"2022-06-04T20:16:31.39173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot_parallel_coordinate: interactively visualizes the hyperparameters and scores\noptuna.visualization.plot_parallel_coordinate(study)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:16:47.472943Z","iopub.execute_input":"2022-06-04T20:16:47.473263Z","iopub.status.idle":"2022-06-04T20:16:47.495435Z","shell.execute_reply.started":"2022-06-04T20:16:47.473231Z","shell.execute_reply":"2022-06-04T20:16:47.494582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''plot_slice: shows the evolution of the search. You can see where in the hyperparameter space your search\nwent and which parts of the space were explored more.'''\noptuna.visualization.plot_slice(study)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:16:53.209594Z","iopub.execute_input":"2022-06-04T20:16:53.20995Z","iopub.status.idle":"2022-06-04T20:16:53.352417Z","shell.execute_reply.started":"2022-06-04T20:16:53.209916Z","shell.execute_reply":"2022-06-04T20:16:53.35148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot_contour: plots parameter interactions on an interactive chart. You can choose which hyperparameters you would like to explore.\noptuna.visualization.plot_contour(study, params=['alpha',\n                            #'max_depth',\n                            'lambda',\n                            'subsample',\n                            'learning_rate',\n                            'subsample'])","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:17:59.627232Z","iopub.execute_input":"2022-06-04T20:17:59.62762Z","iopub.status.idle":"2022-06-04T20:18:00.095186Z","shell.execute_reply.started":"2022-06-04T20:17:59.627584Z","shell.execute_reply":"2022-06-04T20:18:00.094127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize parameter importances.\noptuna.visualization.plot_param_importances(study)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:17:02.488316Z","iopub.execute_input":"2022-06-04T20:17:02.488654Z","iopub.status.idle":"2022-06-04T20:17:03.02045Z","shell.execute_reply.started":"2022-06-04T20:17:02.488618Z","shell.execute_reply":"2022-06-04T20:17:03.019618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize empirical distribution function\noptuna.visualization.plot_edf(study)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:20:00.025263Z","iopub.execute_input":"2022-06-04T20:20:00.025605Z","iopub.status.idle":"2022-06-04T20:20:00.042305Z","shell.execute_reply.started":"2022-06-04T20:20:00.025575Z","shell.execute_reply":"2022-06-04T20:20:00.041457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Optuna with cross-validation code was developed using this: https://aetperf.github.io/2021/02/16/Optuna-+-XGBoost-on-a-tabular-dataset.html","metadata":{}},{"cell_type":"markdown","source":"# Let's create an XGBoostRegressor model with the best hyperparameters","metadata":{}},{"cell_type":"code","source":"#Best_trial = study.best_trial.params\n#Best_trial[\"n_estimators\"], Best_trial[\"tree_method\"] = 10000, 'gpu_hist'\n#Best_trial","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:22:57.599067Z","iopub.execute_input":"2022-05-01T17:22:57.599424Z","iopub.status.idle":"2022-05-01T17:22:57.607725Z","shell.execute_reply.started":"2022-05-01T17:22:57.599389Z","shell.execute_reply":"2022-05-01T17:22:57.606328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preds = np.zeros(test.shape[0])\n#kf = KFold(n_splits=5,random_state=48,shuffle=True)\n#rmse=[]  # list contains rmse for each fold\n#n=0\n#for trn_idx, test_idx in kf.split(train[columns],train['target']):\n#    X_tr,X_val=train[columns].iloc[trn_idx],train[columns].iloc[test_idx]\n#    y_tr,y_val=train['target'].iloc[trn_idx],train['target'].iloc[test_idx]\n#    model = xgb.XGBRegressor(**Best_trial)\n#    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n#    preds+=model.predict(test[columns])/kf.n_splits\n#    rmse.append(mean_squared_error(y_val, model.predict(X_val), squared=False))\n#    print(f\"fold: {n+1} ==> rmse: {rmse[n]}\")\n#    n+=1","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:23:22.067063Z","iopub.execute_input":"2022-05-01T17:23:22.067421Z","iopub.status.idle":"2022-05-01T17:33:56.126107Z","shell.execute_reply.started":"2022-05-01T17:23:22.067386Z","shell.execute_reply":"2022-05-01T17:33:56.125245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#np.mean(rmse)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:33:56.130458Z","iopub.execute_input":"2022-05-01T17:33:56.132428Z","iopub.status.idle":"2022-05-01T17:33:56.141059Z","shell.execute_reply.started":"2022-05-01T17:33:56.132385Z","shell.execute_reply":"2022-05-01T17:33:56.139714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Submission <a class=\"anchor\" id=\"chapter5\"></a>","metadata":{}},{"cell_type":"code","source":"#sub['target']=preds\n#sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T18:57:00.127002Z","iopub.execute_input":"2022-05-01T18:57:00.127699Z","iopub.status.idle":"2022-05-01T18:57:01.445149Z","shell.execute_reply.started":"2022-05-01T18:57:00.12764Z","shell.execute_reply":"2022-05-01T18:57:01.443677Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
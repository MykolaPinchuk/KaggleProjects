{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is December 2021 Tabulat Playground series","metadata":{}},{"cell_type":"markdown","source":"### Outline:\n0. Load libraries and custom functions.\n1. Load data.\n2. Preliminary data analysis: explore features and a target, delete unneeded features, create new features.\n3. Train-test split.\n4. Missing values. In some cases it may be useful to explore skew and perform log-transform before imputing missing values.\n5. Feature engineering. Transform skewed variables, do OHC and scaling.\n6. Fit models.\n7. Evaluate models.\n8. Feature importance, error analysis. Based on the results, go to 2. and iterate.\n9. Make predictions.","metadata":{}},{"cell_type":"code","source":"import pynvml\npynvml.nvmlInit()\ndeviceCount = pynvml.nvmlDeviceGetCount()\nfor i in range(deviceCount):\n    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n    print(f\"Device {i} {pynvml.nvmlDeviceGetName(handle).decode()}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:20:56.285477Z","iopub.execute_input":"2022-06-05T20:20:56.285859Z","iopub.status.idle":"2022-06-05T20:20:56.315547Z","shell.execute_reply.started":"2022-06-05T20:20:56.285824Z","shell.execute_reply":"2022-06-05T20:20:56.314341Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Device 0 Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"# 0. Load libraries #\n\nimport numpy as np\nimport pandas as pd\nimport os, time, warnings, optuna, gc\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.svm import SVC, SVR\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split, KFold\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, r2_score, mean_squared_error, make_scorer\nfrom sklearn.inspection import permutation_importance\nfrom scipy.special import inv_boxcox\nfrom xgboost import XGBClassifier, XGBRegressor\nimport lightgbm as lgb\n\npd.set_option('display.max_columns', 20)\npd.set_option('mode.chained_assignment', None)\npd.set_option('display.expand_frame_repr', False)\nwarnings.filterwarnings('ignore')\n\ndef draw_histograms(df, variables, n_rows, n_cols):\n    # stolen from https://stackoverflow.com/questions/29530355/plotting-multiple-histograms-in-grid\n    fig=plt.figure()\n    for i, var_name in enumerate(variables):\n        ax=fig.add_subplot(n_rows,n_cols,i+1)\n        df[var_name].hist(bins=10,ax=ax)\n        ax.set_title(var_name+\" Distribution\")\n    fig.tight_layout()  \n    plt.show()\n\n\ndef fillna_mp_i1(df_train, df_test, df_pred, num_features, cat_features, num_fill='median', cat_fill='mode'):\n    \"\"\"This function speeds up filling missing values for 3 main datasets using different imputation methods.\n    Later may replace it with some subclass.\n    Example: \n    fillna_mp_i1(X_train, X_test, X_pred, num_cols, cat_cols)\"\"\"\n    \n    # set df_pred to None if it does not exist\n    if (cat_features is not None):\n        if (cat_fill=='mode'):\n\n            df_train[cat_features] = df_train[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n            df_test[cat_features] = df_test[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n            if (df_pred is not None):\n                df_pred[cat_features] = df_pred[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n\n        if (cat_fill=='missing'):\n\n            df_train[cat_features] = df_train[cat_features].fillna(value='missing')\n            df_test[cat_features] = df_test[cat_features].fillna(value='missing')\n            if (df_pred is not None):\n                df_pred[cat_features] = df_pred[cat_features].fillna(value='missing')\n        \n    if (num_fill=='median'):\n        df_train[num_features] = df_train[num_features].fillna(value=df_train[num_features].median())\n        df_test[num_features] = df_test[num_features].fillna(value=df_train[num_features].median())\n        if (df_pred is not None):\n            df_pred[num_features] = df_pred[num_features].fillna(value=df_train[num_features].median())    \n    \n    if (cat_features is not None):\n        all_good = (\n        (np.prod(df_train[num_features+cat_features].shape)==df_train[num_features+cat_features].count().sum()) and \n        (np.prod(df_test[num_features+cat_features].shape) == df_test[num_features+cat_features].count().sum()))\n        if (all_good):\n            print('Missing values imputed successfully')\n        else:\n            print('There are still some missing values...')\n    else:\n        all_good = (\n        (np.prod(df_train[num_features].shape)==df_train[num_features].count().sum()) and \n        (np.prod(df_test[num_features].shape) == df_test[num_features].count().sum()))\n        if (all_good):\n            print('Missing values imputed successfully')\n        else:\n            print('There are still some missing values...')\n# END\n\n    \ndef add_misDummy_mp_i1(df_train, df_test, df_pred, features):\n    \"\"\"This function creates new dummy columns for missing features.\n    Example: add_misDummy_mp_i1(X_train, X_test, X_pred, ['Age'])\"\"\"\n    # set df_pred to None if it does not exist\n    \n    columns_before = df_train.shape[1]\n    \n    for feature_name in features:\n        \n        if df_train[feature_name].count()==df_train.shape[0]:\n            continue\n        \n        misColName = 'mis'+feature_name\n        df_train.loc[df_train[feature_name].isnull(), misColName]=1\n        df_train.loc[df_train[feature_name].notnull(), misColName]=0\n        df_test.loc[df_test[feature_name].isnull(), misColName]=1\n        df_test.loc[df_test[feature_name].notnull(), misColName]=0\n        if (df_pred is not None):\n            df_pred.loc[df_pred[feature_name].isnull(), misColName]=1\n            df_pred.loc[df_pred[feature_name].notnull(), misColName]=0\n            \n        columns_after = df_train.shape[1]\n            \n    print(columns_after-columns_before, ' dummy features added')\n# END\n   \n\ndef discretize_mp_i1(df_train, df_test, df_pred, feature, ntiles, delete_feature=False):\n    \"\"\"This function divides a continuous feature into quantile groups.\n    Example: discretize_mp_i1(X_train, X_test, X_pred, 'Age', 15)\"\"\"\n    # set df_pred to None if it does not exist\n    _,bin = pd.qcut(df_train[feature], ntiles, retbins = True, labels = False, duplicates = 'drop')\n    df_train[feature+'Ntile'] = pd.cut(df_train[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    df_test[feature+'Ntile'] = pd.cut(df_test[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    if (df_pred is not None):\n        df_pred[feature+'Ntile'] = pd.cut(df_pred[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    if (delete_feature==True):\n        df_train.drop(columns=[feature], inplace=True)\n        df_test.drop(columns=[feature], inplace=True)\n        df_pred.drop(columns=[feature], inplace=True)\n    print('Discretized ',feature, ' into ', len(bin)-1, ' bins')\n# END\n\n\ndef log_transformer_mp_i1(df_train, df_test, df_pred=None, feature_subset=False, max_skew=3):\n    \"\"\"This function divides a continuous feature into quantile groups.\n    Example: log_transformer_mp_i1(X_train, X_test, X_pred, feature_subset=num_cols)\"\"\"\n    # set df_pred to None if it does not exist\n    if (feature_subset==False):\n        features_totransform = df_train.columns\n    else:\n        features_totransform = feature_subset.copy()\n    skewed_vars = list(df_train.skew()[(df_train.skew())>max_skew].index)\n    for col in list(set(skewed_vars)&set(features_totransform)):\n        df_train[col] = np.log1p(df_train[col])\n        df_test[col] = np.log1p(df_test[col])\n        if (df_pred is not None):\n            df_pred[col] = np.log1p(df_pred[col])\n    print('Skewed columns log-transformed: ', list(set(skewed_vars)&set(features_totransform)))\n# END\n    \n    \ndef add_dummyfeatures(df_train, df_test, df_pred, feature_dict):\n    \"\"\"This function adds dummy feature when some feature is equal to value, specified in a dictionary.\n    Example: add_dummyfeatures(X_train, X_test, X_pred, {'RoomService':0, 'Spa':0, 'VRDeck':0, 'ShoppingMall':0})\"\"\"\n    input_dimensions = np.array([df_train.shape[1], df_test.shape[1], df_pred.shape[1]])\n    for i in range(len(list(feature_dict.items()))):\n        feature,value = list(feature_dict.keys())[i], list(feature_dict.values())[i]\n        df_train.loc[df_train[feature]==value,(str(feature)+str(value))]=1\n        df_train.loc[df_train[feature]!=value,(str(feature)+str(value))]=0\n        df_test.loc[df_test[feature]==value,(str(feature)+str(value))]=1\n        df_test.loc[df_test[feature]!=value,(str(feature)+str(value))]=0\n        df_pred.loc[df_pred[feature]==value,(str(feature)+str(value))]=1\n        df_pred.loc[df_pred[feature]!=value,(str(feature)+str(value))]=0\n    output_dimensions = np.array([df_train.shape[1], df_test.shape[1], df_pred.shape[1]])\n    print(output_dimensions-input_dimensions, ' variables created') \n# END\n\n\n\ntime0 = time.time()\n\n\n#1. Load data #\n\ndf = pd.read_csv('../input/tabular-playground-series-dec-2021/train.csv')\npred = pd.read_csv('../input/tabular-playground-series-dec-2021/test.csv')\npred0 = pred.copy()\nprint(df.shape, pred.shape)\n\n# 2. pEDA #\n\ndf = df.sample(200000, random_state=2)\n\ndf.drop(columns = ['Id'], inplace = True)\npred.drop(columns = ['Id'], inplace = True)\nprint(df.Cover_Type.value_counts())\n#df.head()\n\n#[[col, df[col].nunique()] for col in df.columns]\n#df.count()\ndf.Cover_Type.value_counts()\n#df.skew()\n\n# 3. Train-test split #\n\ntrain_y = df[['Cover_Type']]\ntrain_y.replace([1, 2, 3, 4, 6, 7], [0,1,2,3,4,5], inplace = True)\ntrain_x = df.drop(columns = ['Cover_Type'])\n\nX_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.05, random_state = 1)\n\nprint(X_train.shape, X_test.shape, y_train.shape, pred.shape)\n\n\n# 4. Missing values #\n\n#X_train.count()\n\n#X_train.skew()\n\n# 5. Feature engineering #\n\n#log_transformer_mp_i1(X_train, X_test, pred)\n#X_train.skew()\n# all skewed variables are already ohc-ed, so their skew does not matter.\n\nss = StandardScaler()\n\nfor col in X_train.columns:\n    X_train[[col]] = ss.fit_transform(X_train[[col]])\n    X_test[[col]] = ss.transform(X_test[[col]])\n    pred[[col]] = ss.transform(pred[[col]])\n    \ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:32:02.926169Z","iopub.execute_input":"2022-06-05T20:32:02.926560Z","iopub.status.idle":"2022-06-05T20:32:27.458551Z","shell.execute_reply.started":"2022-06-05T20:32:02.926530Z","shell.execute_reply":"2022-06-05T20:32:27.457646Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(4000000, 56) (1000000, 55)\n2    112641\n1     74007\n3      9804\n7      2986\n6       537\n4        25\nName: Cover_Type, dtype: int64\n(190000, 54) (10000, 54) (190000, 1) (1000000, 55)\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"118"},"metadata":{}}]},{"cell_type":"code","source":"# 6. Model fitting #\n\nf1w = make_scorer(f1_score , average='weighted')\n\ntime1 = time.time()\nlr = LogisticRegression()\nparam_grid = {'C':[1, 10, 100]}\nlrm = GridSearchCV(lr, param_grid, cv=2, scoring=f1w)\nlrm.fit(X_train, y_train)\nprint('Logistic', lrm.best_params_, lrm.best_score_, time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:32:30.874637Z","iopub.execute_input":"2022-06-05T20:32:30.875001Z","iopub.status.idle":"2022-06-05T20:33:19.806219Z","shell.execute_reply.started":"2022-06-05T20:32:30.874970Z","shell.execute_reply":"2022-06-05T20:33:19.805323Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Logistic {'C': 100} 0.913665263032583 48.924094676971436\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fit XGBoost using Optuna\n\ntime1 = time.time()\n\ndef objective(trial, n_splits=2, n_jobs=-1, early_stopping_rounds=50):\n    params = {\n        \"tree_method\": 'gpu_hist',\n        \"gpu_id\": 0,\n        \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n        \"n_estimators\": 500,\n        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.02, 0.3),\n        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.2, 1),\n        \"subsample\": trial.suggest_uniform(\"subsample\", 0.3, 1),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 0.001, 10.0),\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 10.0),\n        \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-8, 10.0),\n        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 0.1, 200),\n        \"n_jobs\": n_jobs,\n    }\n\n    X = X_train\n    y = y_train\n    \n    model = XGBClassifier(**params)\n    rkf = KFold(n_splits=n_splits)\n    X_values = X.values\n    y_values = y.values\n    y_pred = np.zeros_like(y_values)\n    for train_index, test_index in rkf.split(X_values):\n        X_A, X_B = X_values[train_index, :], X_values[test_index, :]\n        y_A, y_B = y_values[train_index], y_values[test_index]\n        model.fit(X_A, y_A, eval_set=[(X_B, y_B)],\n                  early_stopping_rounds=early_stopping_rounds, verbose = False)\n        y_pred[test_index] += model.predict(X_B).reshape(-1,1)\n    return (f1_score(y_train, y_pred, average='weighted'))\n\ntime1 = time.time()\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=50)\nprint('Total time ', time.time()-time1)\nhp = study.best_params\nfor key, value in hp.items():\n    print(f\"{key:>20s} : {value}\")\nprint(f\"{'best objective value':>20s} : {study.best_value}\")\n\noptuna_hyperpars = study.best_params\noptuna_hyperpars['tree_method']='gpu_hist'\noptuna_hyperpars['gpu_id']=0\noptuna_hyperpars['n_estimators']=300\n#optuna_hyperpars\noptuna_xgb = XGBClassifier(**optuna_hyperpars)\noptuna_xgb.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:33:27.194847Z","iopub.execute_input":"2022-06-05T20:33:27.195193Z","iopub.status.idle":"2022-06-05T20:45:52.225373Z","shell.execute_reply.started":"2022-06-05T20:33:27.195165Z","shell.execute_reply":"2022-06-05T20:45:52.224526Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-06-05 20:33:27,205]\u001b[0m A new study created in memory with name: no-name-a9755574-f713-41ef-bd1e-ee0a92fd656e\u001b[0m\n\u001b[32m[I 2022-06-05 20:33:46,631]\u001b[0m Trial 0 finished with value: 0.9534767545048135 and parameters: {'max_depth': 7, 'learning_rate': 0.21113722551112757, 'colsample_bytree': 0.3881817595458446, 'subsample': 0.8992526390885487, 'alpha': 0.001535245335376505, 'lambda': 1.9252771105793597e-07, 'gamma': 2.783201019807266e-08, 'min_child_weight': 2.2352379352482075}. Best is trial 0 with value: 0.9534767545048135.\u001b[0m\n\u001b[32m[I 2022-06-05 20:34:02,537]\u001b[0m Trial 1 finished with value: 0.9534240422814795 and parameters: {'max_depth': 9, 'learning_rate': 0.2592985787854512, 'colsample_bytree': 0.8847198282339721, 'subsample': 0.929956252160677, 'alpha': 5.189437529672751, 'lambda': 1.2162035137454986e-08, 'gamma': 1.8976802726507724e-08, 'min_child_weight': 1.2957745949902637}. Best is trial 0 with value: 0.9534767545048135.\u001b[0m\n\u001b[32m[I 2022-06-05 20:34:15,614]\u001b[0m Trial 2 finished with value: 0.9314161500214528 and parameters: {'max_depth': 3, 'learning_rate': 0.036901846358216514, 'colsample_bytree': 0.45891630310340575, 'subsample': 0.8676997467130305, 'alpha': 0.02021388728836253, 'lambda': 9.157457585177313e-06, 'gamma': 0.03447488575913547, 'min_child_weight': 2.1883072647227233}. Best is trial 0 with value: 0.9534767545048135.\u001b[0m\n\u001b[32m[I 2022-06-05 20:34:31,269]\u001b[0m Trial 3 finished with value: 0.947716692649121 and parameters: {'max_depth': 8, 'learning_rate': 0.17735346663256532, 'colsample_bytree': 0.5741303541826406, 'subsample': 0.49213088127250815, 'alpha': 0.556461032205982, 'lambda': 0.21287853000768225, 'gamma': 2.9337868505564164e-07, 'min_child_weight': 21.90380757857727}. Best is trial 0 with value: 0.9534767545048135.\u001b[0m\n\u001b[32m[I 2022-06-05 20:35:08,795]\u001b[0m Trial 4 finished with value: 0.9532645147402714 and parameters: {'max_depth': 10, 'learning_rate': 0.12140427607515852, 'colsample_bytree': 0.7624673467550223, 'subsample': 0.620797231804602, 'alpha': 0.12087383001893671, 'lambda': 6.50515433728164e-05, 'gamma': 3.973985454602106e-08, 'min_child_weight': 0.10642886767342423}. Best is trial 0 with value: 0.9534767545048135.\u001b[0m\n\u001b[32m[I 2022-06-05 20:35:23,722]\u001b[0m Trial 5 finished with value: 0.9450859786942782 and parameters: {'max_depth': 4, 'learning_rate': 0.1223071270993597, 'colsample_bytree': 0.8772076688566859, 'subsample': 0.30768472649012657, 'alpha': 0.01403771700902894, 'lambda': 0.3894786442173849, 'gamma': 0.009325652965605594, 'min_child_weight': 18.176800489803593}. Best is trial 0 with value: 0.9534767545048135.\u001b[0m\n\u001b[32m[I 2022-06-05 20:35:39,378]\u001b[0m Trial 6 finished with value: 0.9547140636022007 and parameters: {'max_depth': 4, 'learning_rate': 0.22847375857589186, 'colsample_bytree': 0.7401068761227074, 'subsample': 0.7974938184689351, 'alpha': 0.033244657220662444, 'lambda': 0.13410961530738041, 'gamma': 4.6915419484414456e-05, 'min_child_weight': 1.3572199676808427}. Best is trial 6 with value: 0.9547140636022007.\u001b[0m\n\u001b[32m[I 2022-06-05 20:35:50,352]\u001b[0m Trial 7 finished with value: 0.9494443303521669 and parameters: {'max_depth': 8, 'learning_rate': 0.28425561800080756, 'colsample_bytree': 0.5425937659098279, 'subsample': 0.31241232437531924, 'alpha': 0.3471574321109624, 'lambda': 9.16855521460947e-08, 'gamma': 0.0007350803083025099, 'min_child_weight': 1.9538789568586135}. Best is trial 6 with value: 0.9547140636022007.\u001b[0m\n\u001b[32m[I 2022-06-05 20:36:00,134]\u001b[0m Trial 8 finished with value: 0.9384525246223663 and parameters: {'max_depth': 2, 'learning_rate': 0.10206912455269036, 'colsample_bytree': 0.5841184759176725, 'subsample': 0.7830961862125971, 'alpha': 0.002622442033343443, 'lambda': 3.435518719440789e-08, 'gamma': 1.1473830864729926, 'min_child_weight': 3.0650713188570053}. Best is trial 6 with value: 0.9547140636022007.\u001b[0m\n\u001b[32m[I 2022-06-05 20:36:10,091]\u001b[0m Trial 9 finished with value: 0.9256765573471485 and parameters: {'max_depth': 2, 'learning_rate': 0.06128825084648783, 'colsample_bytree': 0.42412145748781394, 'subsample': 0.682418848000875, 'alpha': 0.24654510271171223, 'lambda': 5.586295772008387, 'gamma': 6.243719475282239e-07, 'min_child_weight': 22.164067513313956}. Best is trial 6 with value: 0.9547140636022007.\u001b[0m\n\u001b[32m[I 2022-06-05 20:36:21,429]\u001b[0m Trial 10 finished with value: 0.9127940700362634 and parameters: {'max_depth': 5, 'learning_rate': 0.22861381103614026, 'colsample_bytree': 0.20550811700287097, 'subsample': 0.5358391592710682, 'alpha': 0.01584204525383366, 'lambda': 0.0016864791431664599, 'gamma': 1.8894313697985505e-05, 'min_child_weight': 170.3409475838971}. Best is trial 6 with value: 0.9547140636022007.\u001b[0m\n\u001b[32m[I 2022-06-05 20:36:43,036]\u001b[0m Trial 11 finished with value: 0.9533978250964418 and parameters: {'max_depth': 6, 'learning_rate': 0.1859965674261777, 'colsample_bytree': 0.3384663435801252, 'subsample': 0.966153028330296, 'alpha': 0.0015343551302128536, 'lambda': 0.0019381219527672864, 'gamma': 2.2682640624513846e-05, 'min_child_weight': 0.4033120413541364}. Best is trial 6 with value: 0.9547140636022007.\u001b[0m\n\u001b[32m[I 2022-06-05 20:36:56,974]\u001b[0m Trial 12 finished with value: 0.9548122864455161 and parameters: {'max_depth': 6, 'learning_rate': 0.226230822959955, 'colsample_bytree': 0.726009159055024, 'subsample': 0.8186719638426829, 'alpha': 0.004940582703759946, 'lambda': 2.618443178726498e-06, 'gamma': 1.1771652823541784e-05, 'min_child_weight': 0.6340711076524884}. Best is trial 12 with value: 0.9548122864455161.\u001b[0m\n\u001b[32m[I 2022-06-05 20:37:10,685]\u001b[0m Trial 13 finished with value: 0.9546995694860951 and parameters: {'max_depth': 5, 'learning_rate': 0.23717138908220362, 'colsample_bytree': 0.7303086792497103, 'subsample': 0.7680113505322372, 'alpha': 0.03742594711638949, 'lambda': 2.577083076035249e-06, 'gamma': 3.0211061903152935e-05, 'min_child_weight': 0.4032251246617983}. Best is trial 12 with value: 0.9548122864455161.\u001b[0m\n\u001b[32m[I 2022-06-05 20:37:22,226]\u001b[0m Trial 14 finished with value: 0.9543011699109761 and parameters: {'max_depth': 4, 'learning_rate': 0.2970448666979578, 'colsample_bytree': 0.7270669296843782, 'subsample': 0.7926325234043964, 'alpha': 0.005307062125970442, 'lambda': 0.030117273558917558, 'gamma': 0.0007188231870225274, 'min_child_weight': 0.3956569039577608}. Best is trial 12 with value: 0.9548122864455161.\u001b[0m\n\u001b[32m[I 2022-06-05 20:37:35,526]\u001b[0m Trial 15 finished with value: 0.9545700994015216 and parameters: {'max_depth': 6, 'learning_rate': 0.1990078585355649, 'colsample_bytree': 0.9955885989731067, 'subsample': 0.6879032872279442, 'alpha': 0.060625752316097126, 'lambda': 0.00019131189026272508, 'gamma': 2.553490101582861e-06, 'min_child_weight': 8.117131303384364}. Best is trial 12 with value: 0.9548122864455161.\u001b[0m\n\u001b[32m[I 2022-06-05 20:37:53,106]\u001b[0m Trial 16 finished with value: 0.9545570393980257 and parameters: {'max_depth': 4, 'learning_rate': 0.1506461936152839, 'colsample_bytree': 0.6777271865712612, 'subsample': 0.7894406053060857, 'alpha': 0.006075704749187378, 'lambda': 1.992660614559372e-06, 'gamma': 0.00015303834512646013, 'min_child_weight': 0.10799592465742298}. Best is trial 12 with value: 0.9548122864455161.\u001b[0m\n\u001b[32m[I 2022-06-05 20:38:06,039]\u001b[0m Trial 17 finished with value: 0.9543693404159285 and parameters: {'max_depth': 7, 'learning_rate': 0.26360030948798796, 'colsample_bytree': 0.8765682456860037, 'subsample': 0.8590230266520061, 'alpha': 1.0706759587829922, 'lambda': 0.010194714788388886, 'gamma': 0.014583638324181568, 'min_child_weight': 0.7758953055442316}. Best is trial 12 with value: 0.9548122864455161.\u001b[0m\n\u001b[32m[I 2022-06-05 20:38:26,586]\u001b[0m Trial 18 finished with value: 0.9546098164674078 and parameters: {'max_depth': 5, 'learning_rate': 0.1587150783941667, 'colsample_bytree': 0.7978370236914567, 'subsample': 0.9914598413900433, 'alpha': 0.005613958664358653, 'lambda': 7.305178716972353, 'gamma': 2.3811156865452443e-06, 'min_child_weight': 6.8842789400507725}. Best is trial 12 with value: 0.9548122864455161.\u001b[0m\n\u001b[32m[I 2022-06-05 20:38:37,521]\u001b[0m Trial 19 finished with value: 0.9527103672861618 and parameters: {'max_depth': 3, 'learning_rate': 0.24025647945957893, 'colsample_bytree': 0.6457341255130533, 'subsample': 0.5845691991940827, 'alpha': 0.10741687509756345, 'lambda': 2.0701428923134e-05, 'gamma': 1.329163524942204, 'min_child_weight': 0.2283600661019934}. Best is trial 12 with value: 0.9548122864455161.\u001b[0m\n\u001b[32m[I 2022-06-05 20:38:51,814]\u001b[0m Trial 20 finished with value: 0.9545560808164846 and parameters: {'max_depth': 6, 'learning_rate': 0.21263481927541575, 'colsample_bytree': 0.9933985237099452, 'subsample': 0.7252659852176102, 'alpha': 2.6053314829483725, 'lambda': 5.941168531686571e-07, 'gamma': 0.003205842083188014, 'min_child_weight': 0.7909914173014825}. Best is trial 12 with value: 0.9548122864455161.\u001b[0m\n\u001b[32m[I 2022-06-05 20:39:03,695]\u001b[0m Trial 21 finished with value: 0.954840709128878 and parameters: {'max_depth': 5, 'learning_rate': 0.24822675929806454, 'colsample_bytree': 0.8159858028636691, 'subsample': 0.7506375725744188, 'alpha': 0.03631364099832812, 'lambda': 3.840611479395879e-06, 'gamma': 3.110139575248076e-05, 'min_child_weight': 0.30917425822615074}. Best is trial 21 with value: 0.954840709128878.\u001b[0m\n\u001b[32m[I 2022-06-05 20:39:15,368]\u001b[0m Trial 22 finished with value: 0.9547454288231608 and parameters: {'max_depth': 5, 'learning_rate': 0.2691678308190393, 'colsample_bytree': 0.8216767209620164, 'subsample': 0.8409414715979493, 'alpha': 0.032015078671994726, 'lambda': 0.0006729483389188649, 'gamma': 0.00013067424924522242, 'min_child_weight': 0.803863988278684}. Best is trial 21 with value: 0.954840709128878.\u001b[0m\n\u001b[32m[I 2022-06-05 20:39:27,282]\u001b[0m Trial 23 finished with value: 0.9542727586066214 and parameters: {'max_depth': 7, 'learning_rate': 0.26868206857164145, 'colsample_bytree': 0.8257884062032947, 'subsample': 0.8391202103861709, 'alpha': 0.010116474857327896, 'lambda': 0.0005644055417923352, 'gamma': 5.128662532526361e-06, 'min_child_weight': 0.24999233183518466}. Best is trial 21 with value: 0.954840709128878.\u001b[0m\n\u001b[32m[I 2022-06-05 20:39:36,923]\u001b[0m Trial 24 finished with value: 0.9544242557647371 and parameters: {'max_depth': 5, 'learning_rate': 0.2996328288944644, 'colsample_bytree': 0.9321631925319682, 'subsample': 0.6957344287941865, 'alpha': 0.04638980161071099, 'lambda': 2.448401071376108e-05, 'gamma': 0.000138721977293535, 'min_child_weight': 0.8256942720182535}. Best is trial 21 with value: 0.954840709128878.\u001b[0m\n\u001b[32m[I 2022-06-05 20:39:49,654]\u001b[0m Trial 25 finished with value: 0.9546532602267958 and parameters: {'max_depth': 6, 'learning_rate': 0.25903346519055803, 'colsample_bytree': 0.6623475974337655, 'subsample': 0.9219387479413029, 'alpha': 0.003626047666015344, 'lambda': 3.5183146788067095e-06, 'gamma': 0.0013433341057679786, 'min_child_weight': 0.17994043041838437}. Best is trial 21 with value: 0.954840709128878.\u001b[0m\n\u001b[32m[I 2022-06-05 20:40:02,979]\u001b[0m Trial 26 finished with value: 0.9535897433576875 and parameters: {'max_depth': 3, 'learning_rate': 0.24638805274686332, 'colsample_bytree': 0.8223430455173163, 'subsample': 0.7460579184013759, 'alpha': 0.1664396919023643, 'lambda': 0.0001417391608795231, 'gamma': 0.1214660122709712, 'min_child_weight': 0.5894729445745299}. Best is trial 21 with value: 0.954840709128878.\u001b[0m\n\u001b[32m[I 2022-06-05 20:40:14,264]\u001b[0m Trial 27 finished with value: 0.9545439179485978 and parameters: {'max_depth': 5, 'learning_rate': 0.27829805251627765, 'colsample_bytree': 0.9343361335924065, 'subsample': 0.8331986333331385, 'alpha': 0.02417580206704454, 'lambda': 5.421662671070274e-07, 'gamma': 4.900358887508686e-07, 'min_child_weight': 5.649874524145854}. Best is trial 21 with value: 0.954840709128878.\u001b[0m\n\u001b[32m[I 2022-06-05 20:40:29,634]\u001b[0m Trial 28 finished with value: 0.9519663705046275 and parameters: {'max_depth': 8, 'learning_rate': 0.21902915378629767, 'colsample_bytree': 0.6903911042466851, 'subsample': 0.4263155696270463, 'alpha': 0.06883351997694864, 'lambda': 0.0006173993968350982, 'gamma': 0.0001471193292729743, 'min_child_weight': 0.18825923359023128}. Best is trial 21 with value: 0.954840709128878.\u001b[0m\n\u001b[32m[I 2022-06-05 20:40:47,516]\u001b[0m Trial 29 finished with value: 0.9539357571635274 and parameters: {'max_depth': 7, 'learning_rate': 0.19570271611431717, 'colsample_bytree': 0.4998496695995199, 'subsample': 0.8918807685759229, 'alpha': 0.002383693421509988, 'lambda': 4.2742107780474566e-07, 'gamma': 1.1534299851511943e-07, 'min_child_weight': 1.293397028505336}. Best is trial 21 with value: 0.954840709128878.\u001b[0m\n\u001b[32m[I 2022-06-05 20:41:03,341]\u001b[0m Trial 30 finished with value: 0.9290250115242902 and parameters: {'max_depth': 6, 'learning_rate': 0.24830202310795232, 'colsample_bytree': 0.7802917786639704, 'subsample': 0.638214010881292, 'alpha': 0.00941578355921774, 'lambda': 3.79939581603934e-05, 'gamma': 7.022095556799313e-06, 'min_child_weight': 136.6155663381669}. Best is trial 21 with value: 0.954840709128878.\u001b[0m\n\u001b[32m[I 2022-06-05 20:41:18,091]\u001b[0m Trial 31 finished with value: 0.9545547982463315 and parameters: {'max_depth': 4, 'learning_rate': 0.2304437561501, 'colsample_bytree': 0.7386274481175191, 'subsample': 0.8139114223171113, 'alpha': 0.030180800384991113, 'lambda': 0.01649603872237935, 'gamma': 5.993874458888195e-05, 'min_child_weight': 1.3831340284124616}. Best is trial 21 with value: 0.954840709128878.\u001b[0m\n\u001b[32m[I 2022-06-05 20:41:34,199]\u001b[0m Trial 32 finished with value: 0.955104364823943 and parameters: {'max_depth': 4, 'learning_rate': 0.21436891120441207, 'colsample_bytree': 0.8372452898819402, 'subsample': 0.922811391863261, 'alpha': 0.07016537785122692, 'lambda': 0.9004248318373541, 'gamma': 0.0002491867647143335, 'min_child_weight': 3.6492189570198517}. Best is trial 32 with value: 0.955104364823943.\u001b[0m\n\u001b[32m[I 2022-06-05 20:41:50,684]\u001b[0m Trial 33 finished with value: 0.9552847403759469 and parameters: {'max_depth': 5, 'learning_rate': 0.20346585707435932, 'colsample_bytree': 0.8329198208930636, 'subsample': 0.9294125465901408, 'alpha': 0.09316233522489825, 'lambda': 1.2028182990743631e-08, 'gamma': 0.00039686315852934033, 'min_child_weight': 3.79832958178436}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:42:03,617]\u001b[0m Trial 34 finished with value: 0.9528187538865027 and parameters: {'max_depth': 3, 'learning_rate': 0.1734192416680317, 'colsample_bytree': 0.9290410819446286, 'subsample': 0.9468476940561987, 'alpha': 0.7401073334178393, 'lambda': 1.9270634058767841e-07, 'gamma': 0.0005056093573244626, 'min_child_weight': 3.5373985619167523}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:42:18,149]\u001b[0m Trial 35 finished with value: 0.9544103736064623 and parameters: {'max_depth': 6, 'learning_rate': 0.20445740606407553, 'colsample_bytree': 0.8586319804998492, 'subsample': 0.9115310768928764, 'alpha': 0.0010425797493955904, 'lambda': 1.621158499527395e-08, 'gamma': 0.003122981273331981, 'min_child_weight': 15.869617567645411}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:42:37,552]\u001b[0m Trial 36 finished with value: 0.9447766421455119 and parameters: {'max_depth': 7, 'learning_rate': 0.17311369750942626, 'colsample_bytree': 0.8940007105320658, 'subsample': 0.9684439526492715, 'alpha': 0.18158187089073655, 'lambda': 1.237821474609348, 'gamma': 9.506226359589245e-06, 'min_child_weight': 80.25901882605511}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:42:53,787]\u001b[0m Trial 37 finished with value: 0.9548199442762261 and parameters: {'max_depth': 4, 'learning_rate': 0.21342191736907654, 'colsample_bytree': 0.7826227485107349, 'subsample': 0.881537213397436, 'alpha': 0.08264102160124445, 'lambda': 8.622943421122571e-08, 'gamma': 0.07160168429917299, 'min_child_weight': 2.5353156354799045}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:43:06,019]\u001b[0m Trial 38 finished with value: 0.9501872395461802 and parameters: {'max_depth': 3, 'learning_rate': 0.1419859465243477, 'colsample_bytree': 0.6129048487354908, 'subsample': 0.8843109016525488, 'alpha': 0.08204666207973496, 'lambda': 6.112135468746129e-08, 'gamma': 0.1268716111842782, 'min_child_weight': 12.482226586101397}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:43:13,706]\u001b[0m Trial 39 finished with value: 0.9436599049254014 and parameters: {'max_depth': 4, 'learning_rate': 0.18564311863851057, 'colsample_bytree': 0.777778104538332, 'subsample': 0.9979046481607486, 'alpha': 0.12023838017296463, 'lambda': 2.272308700310823e-08, 'gamma': 4.8366561350611175, 'min_child_weight': 31.574109744089114}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:43:24,306]\u001b[0m Trial 40 finished with value: 0.9474465783643505 and parameters: {'max_depth': 2, 'learning_rate': 0.21162449302688713, 'colsample_bytree': 0.8574841510973162, 'subsample': 0.9352097256582208, 'alpha': 0.4188015960084796, 'lambda': 1.1132712031174424e-07, 'gamma': 0.07611751192947998, 'min_child_weight': 2.5957545083045344}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:43:39,175]\u001b[0m Trial 41 finished with value: 0.9517447954670782 and parameters: {'max_depth': 4, 'learning_rate': 0.22235359147804004, 'colsample_bytree': 0.6978855902629562, 'subsample': 0.8837911414503232, 'alpha': 9.500705200796093, 'lambda': 7.975651958506135e-06, 'gamma': 0.006129036732257609, 'min_child_weight': 3.694815172546556}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:43:55,507]\u001b[0m Trial 42 finished with value: 0.953647480921813 and parameters: {'max_depth': 10, 'learning_rate': 0.2527912324362901, 'colsample_bytree': 0.7704735117682308, 'subsample': 0.742925857099481, 'alpha': 0.2008517411931306, 'lambda': 2.222562818171473e-07, 'gamma': 0.021802881496182053, 'min_child_weight': 2.1278490365414533}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:44:11,602]\u001b[0m Trial 43 finished with value: 0.9547522371746285 and parameters: {'max_depth': 5, 'learning_rate': 0.19318558854770057, 'colsample_bytree': 0.8189873913204516, 'subsample': 0.8531947548135378, 'alpha': 0.01868638187877559, 'lambda': 1.0373396403789778e-06, 'gamma': 1.35930244850687e-08, 'min_child_weight': 5.1574856104447795}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:44:26,949]\u001b[0m Trial 44 finished with value: 0.9548599814487462 and parameters: {'max_depth': 5, 'learning_rate': 0.2099632948080045, 'colsample_bytree': 0.9053686254546679, 'subsample': 0.9117988565820639, 'alpha': 0.30075515903965466, 'lambda': 5.8949715759477024e-08, 'gamma': 0.44600726353088604, 'min_child_weight': 1.5603835702774507}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:44:43,282]\u001b[0m Trial 45 finished with value: 0.9436774053953003 and parameters: {'max_depth': 4, 'learning_rate': 0.032870234220916394, 'colsample_bytree': 0.9579815687974927, 'subsample': 0.9583208199114827, 'alpha': 0.32053071821318635, 'lambda': 4.28973722225469e-08, 'gamma': 0.3499734747866912, 'min_child_weight': 1.673282899991003}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:45:01,680]\u001b[0m Trial 46 finished with value: 0.9548792322911998 and parameters: {'max_depth': 5, 'learning_rate': 0.13391762161795923, 'colsample_bytree': 0.8556323121310855, 'subsample': 0.9139932417300238, 'alpha': 0.04906512236611517, 'lambda': 2.3849260437086187e-07, 'gamma': 0.346986504004563, 'min_child_weight': 11.793722705212007}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:45:20,061]\u001b[0m Trial 47 finished with value: 0.9544973888792203 and parameters: {'max_depth': 5, 'learning_rate': 0.09574494380382327, 'colsample_bytree': 0.895910040785814, 'subsample': 0.9200148174561744, 'alpha': 0.054964170899985496, 'lambda': 1.0200715336186943e-08, 'gamma': 0.5011076063981652, 'min_child_weight': 10.457522263535866}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:45:30,424]\u001b[0m Trial 48 finished with value: 0.9445753812946126 and parameters: {'max_depth': 5, 'learning_rate': 0.1201388664556419, 'colsample_bytree': 0.9662890513969065, 'subsample': 0.48328079655436607, 'alpha': 1.5002698855482677, 'lambda': 3.5536111053478716e-08, 'gamma': 2.9548542476013915, 'min_child_weight': 26.319196167524048}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n\u001b[32m[I 2022-06-05 20:45:47,032]\u001b[0m Trial 49 finished with value: 0.9488795122825132 and parameters: {'max_depth': 5, 'learning_rate': 0.07257284280815696, 'colsample_bytree': 0.8635976154838474, 'subsample': 0.9742339055769365, 'alpha': 0.5368766125844943, 'lambda': 0.5997349260358208, 'gamma': 0.6822450546486621, 'min_child_weight': 37.40136524546751}. Best is trial 33 with value: 0.9552847403759469.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time  739.828848361969\n           max_depth : 5\n       learning_rate : 0.20346585707435932\n    colsample_bytree : 0.8329198208930636\n           subsample : 0.9294125465901408\n               alpha : 0.09316233522489825\n              lambda : 1.2028182990743631e-08\n               gamma : 0.00039686315852934033\n    min_child_weight : 3.79832958178436\nbest objective value : 0.9552847403759469\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(alpha=0.09316233522489825, base_score=0.5, booster='gbtree',\n              callbacks=None, colsample_bylevel=1, colsample_bynode=1,\n              colsample_bytree=0.8329198208930636, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None,\n              gamma=0.00039686315852934033, gpu_id=0, grow_policy='depthwise',\n              importance_type=None, interaction_constraints='',\n              lambda=1.2028182990743631e-08, learning_rate=0.20346585707435932,\n              max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=5,\n              max_leaves=0, min_child_weight=3.79832958178436, missing=nan,\n              monotone_constraints='()', n_estimators=300, n_jobs=0,\n              num_parallel_tree=1, objective='multi:softprob', predictor='auto', ...)"},"metadata":{}}]},{"cell_type":"code","source":"#xgb = XGBClassifier(tree_method = 'gpu_hist', gpu_id = 0)\n#param_grid = {'eta':[0.1, 0.2, 0.3], 'max_depth':[4,6,8], 'n_estimators':[300]}\n#xgbm = GridSearchCV(xgb, param_grid, cv=2, scoring=f1w, verbose=1)\n\n\n#xgbm.fit(X_train, y_train)\n#print('XGB', xgbm.best_params_, xgbm.best_score_, time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T01:38:34.100285Z","iopub.execute_input":"2022-06-05T01:38:34.100639Z","iopub.status.idle":"2022-06-05T01:39:54.018072Z","shell.execute_reply.started":"2022-06-05T01:38:34.100608Z","shell.execute_reply":"2022-06-05T01:39:54.017103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize parameter importances.\noptuna.visualization.plot_param_importances(study)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T01:34:41.163815Z","iopub.execute_input":"2022-06-05T01:34:41.164197Z","iopub.status.idle":"2022-06-05T01:34:42.475186Z","shell.execute_reply.started":"2022-06-05T01:34:41.164166Z","shell.execute_reply":"2022-06-05T01:34:42.474314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_slice(study)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T01:35:18.793448Z","iopub.execute_input":"2022-06-05T01:35:18.793935Z","iopub.status.idle":"2022-06-05T01:35:19.124632Z","shell.execute_reply.started":"2022-06-05T01:35:18.793896Z","shell.execute_reply":"2022-06-05T01:35:19.1239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"# 7. Model evaluation #\n\nprint('Logistic IS', f1_score(y_train, lrm.predict(X_train), average='weighted'), \n      f1_score(y_test, lrm.predict(X_test), average='weighted'))\n\n#print('XGB_gs IS', f1_score(y_train, xgbm.predict(X_train), average='weighted'), \n#      f1_score(y_test, xgbm.predict(X_test), average='weighted'))\n\nprint('XGB_Optuna IS', f1_score(y_train, optuna_xgb.predict(X_train), average='weighted'), \n      f1_score(y_test, optuna_xgb.predict(X_test), average='weighted'))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:46:02.137181Z","iopub.execute_input":"2022-06-05T20:46:02.137892Z","iopub.status.idle":"2022-06-05T20:46:07.935302Z","shell.execute_reply.started":"2022-06-05T20:46:02.137855Z","shell.execute_reply":"2022-06-05T20:46:07.934495Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Logistic IS 0.9142852115986049 0.9135316469635705\nXGB_Optuna IS 0.9768323995480069 0.9576501379878262\n","output_type":"stream"}]},{"cell_type":"code","source":"pred","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:46:28.822920Z","iopub.execute_input":"2022-06-05T20:46:28.823291Z","iopub.status.idle":"2022-06-05T20:46:28.981601Z","shell.execute_reply.started":"2022-06-05T20:46:28.823244Z","shell.execute_reply":"2022-06-05T20:46:28.980699Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"             Id  Elevation    Aspect     Slope  Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type31  Soil_Type32  Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40\n0       4000000  -0.757296 -0.669686  0.569859                          0.467441                        0.526933                         1.012499       0.199197       -0.358207       1.243558  ...    -0.169528     -0.19819    -0.197285     -0.11282    -0.126101    -0.104283    -0.112389     -0.20703    -0.203746    -0.178611\n1       4000001  -0.539119  0.012576 -0.481125                         -0.031308                       -0.186873                        -1.119912       0.231767        0.762779       0.169396  ...    -0.169528     -0.19819    -0.197285     -0.11282    -0.126101    -0.104283    -0.112389     -0.20703    -0.203746    -0.178611\n2       4000002  -0.116617 -0.860719  0.453083                         -0.949360                       -0.114036                        -0.697074      -0.321920       -0.178850       0.512214  ...    -0.169528     -0.19819     5.068816     -0.11282    -0.126101    -0.104283    -0.112389     -0.20703    -0.203746    -0.178611\n3       4000003  -0.192806 -0.296716 -1.065006                         -0.499161                        1.197037                         0.277656       0.720314        0.852458       0.032269  ...    -0.169528     -0.19819    -0.197285     -0.11282    -0.126101    -0.104283    -0.112389     -0.20703    -0.203746    -0.178611\n4       4000004  -1.010104 -1.288270 -1.298558                         -1.028807                        0.818283                         1.380679       0.036348        0.000508       2.020611  ...    -0.169528     -0.19819    -0.197285     -0.11282    -0.126101    -0.104283    -0.112389     -0.20703    -0.203746    -0.178611\n...         ...        ...       ...       ...                               ...                             ...                              ...            ...             ...            ...  ...          ...          ...          ...          ...          ...          ...          ...          ...          ...          ...\n999995  4999995  -0.026576  0.931356 -0.014021                         -0.552126                        0.701743                        -0.870915       0.329476        1.076656      -0.539094  ...    -0.169528     -0.19819    -0.197285     -0.11282    -0.126101    -0.104283    -0.112389     -0.20703    -0.203746    -0.178611\n999996  4999996   0.686828 -0.542330  0.102755                         -0.786053                       -0.070333                         1.495309      -0.093932       -0.896281       0.032269  ...    -0.169528     -0.19819    -0.197285     -0.11282    -0.126101    -0.104283    -0.112389     -0.20703     4.908068    -0.178611\n999997  4999997  -1.030883 -0.915300  0.569859                         -1.046461                        1.036795                        -0.613569      -0.419630        0.179866       0.100832  ...    -0.169528     -0.19819    -0.197285     -0.11282     7.930134    -0.104283    -0.112389     -0.20703    -0.203746    -0.178611\n999998  4999998   1.133571 -0.797041 -0.364349                         -0.331441                        0.599770                         0.570682       0.459756       -1.254997      -1.521838  ...    -0.169528     -0.19819    -0.197285     -0.11282    -0.126101    -0.104283    -0.112389     -0.20703    -0.203746    -0.178611\n999999  4999999  -1.519183  1.549940 -0.948230                         -0.481507                        1.386414                         0.662538       0.362046        0.045348      -1.339002  ...    -0.169528     -0.19819    -0.197285     -0.11282    -0.126101    -0.104283    -0.112389     -0.20703    -0.203746    -0.178611\n\n[1000000 rows x 55 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Elevation</th>\n      <th>Aspect</th>\n      <th>Slope</th>\n      <th>Horizontal_Distance_To_Hydrology</th>\n      <th>Vertical_Distance_To_Hydrology</th>\n      <th>Horizontal_Distance_To_Roadways</th>\n      <th>Hillshade_9am</th>\n      <th>Hillshade_Noon</th>\n      <th>Hillshade_3pm</th>\n      <th>...</th>\n      <th>Soil_Type31</th>\n      <th>Soil_Type32</th>\n      <th>Soil_Type33</th>\n      <th>Soil_Type34</th>\n      <th>Soil_Type35</th>\n      <th>Soil_Type36</th>\n      <th>Soil_Type37</th>\n      <th>Soil_Type38</th>\n      <th>Soil_Type39</th>\n      <th>Soil_Type40</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4000000</td>\n      <td>-0.757296</td>\n      <td>-0.669686</td>\n      <td>0.569859</td>\n      <td>0.467441</td>\n      <td>0.526933</td>\n      <td>1.012499</td>\n      <td>0.199197</td>\n      <td>-0.358207</td>\n      <td>1.243558</td>\n      <td>...</td>\n      <td>-0.169528</td>\n      <td>-0.19819</td>\n      <td>-0.197285</td>\n      <td>-0.11282</td>\n      <td>-0.126101</td>\n      <td>-0.104283</td>\n      <td>-0.112389</td>\n      <td>-0.20703</td>\n      <td>-0.203746</td>\n      <td>-0.178611</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4000001</td>\n      <td>-0.539119</td>\n      <td>0.012576</td>\n      <td>-0.481125</td>\n      <td>-0.031308</td>\n      <td>-0.186873</td>\n      <td>-1.119912</td>\n      <td>0.231767</td>\n      <td>0.762779</td>\n      <td>0.169396</td>\n      <td>...</td>\n      <td>-0.169528</td>\n      <td>-0.19819</td>\n      <td>-0.197285</td>\n      <td>-0.11282</td>\n      <td>-0.126101</td>\n      <td>-0.104283</td>\n      <td>-0.112389</td>\n      <td>-0.20703</td>\n      <td>-0.203746</td>\n      <td>-0.178611</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4000002</td>\n      <td>-0.116617</td>\n      <td>-0.860719</td>\n      <td>0.453083</td>\n      <td>-0.949360</td>\n      <td>-0.114036</td>\n      <td>-0.697074</td>\n      <td>-0.321920</td>\n      <td>-0.178850</td>\n      <td>0.512214</td>\n      <td>...</td>\n      <td>-0.169528</td>\n      <td>-0.19819</td>\n      <td>5.068816</td>\n      <td>-0.11282</td>\n      <td>-0.126101</td>\n      <td>-0.104283</td>\n      <td>-0.112389</td>\n      <td>-0.20703</td>\n      <td>-0.203746</td>\n      <td>-0.178611</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4000003</td>\n      <td>-0.192806</td>\n      <td>-0.296716</td>\n      <td>-1.065006</td>\n      <td>-0.499161</td>\n      <td>1.197037</td>\n      <td>0.277656</td>\n      <td>0.720314</td>\n      <td>0.852458</td>\n      <td>0.032269</td>\n      <td>...</td>\n      <td>-0.169528</td>\n      <td>-0.19819</td>\n      <td>-0.197285</td>\n      <td>-0.11282</td>\n      <td>-0.126101</td>\n      <td>-0.104283</td>\n      <td>-0.112389</td>\n      <td>-0.20703</td>\n      <td>-0.203746</td>\n      <td>-0.178611</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4000004</td>\n      <td>-1.010104</td>\n      <td>-1.288270</td>\n      <td>-1.298558</td>\n      <td>-1.028807</td>\n      <td>0.818283</td>\n      <td>1.380679</td>\n      <td>0.036348</td>\n      <td>0.000508</td>\n      <td>2.020611</td>\n      <td>...</td>\n      <td>-0.169528</td>\n      <td>-0.19819</td>\n      <td>-0.197285</td>\n      <td>-0.11282</td>\n      <td>-0.126101</td>\n      <td>-0.104283</td>\n      <td>-0.112389</td>\n      <td>-0.20703</td>\n      <td>-0.203746</td>\n      <td>-0.178611</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>999995</th>\n      <td>4999995</td>\n      <td>-0.026576</td>\n      <td>0.931356</td>\n      <td>-0.014021</td>\n      <td>-0.552126</td>\n      <td>0.701743</td>\n      <td>-0.870915</td>\n      <td>0.329476</td>\n      <td>1.076656</td>\n      <td>-0.539094</td>\n      <td>...</td>\n      <td>-0.169528</td>\n      <td>-0.19819</td>\n      <td>-0.197285</td>\n      <td>-0.11282</td>\n      <td>-0.126101</td>\n      <td>-0.104283</td>\n      <td>-0.112389</td>\n      <td>-0.20703</td>\n      <td>-0.203746</td>\n      <td>-0.178611</td>\n    </tr>\n    <tr>\n      <th>999996</th>\n      <td>4999996</td>\n      <td>0.686828</td>\n      <td>-0.542330</td>\n      <td>0.102755</td>\n      <td>-0.786053</td>\n      <td>-0.070333</td>\n      <td>1.495309</td>\n      <td>-0.093932</td>\n      <td>-0.896281</td>\n      <td>0.032269</td>\n      <td>...</td>\n      <td>-0.169528</td>\n      <td>-0.19819</td>\n      <td>-0.197285</td>\n      <td>-0.11282</td>\n      <td>-0.126101</td>\n      <td>-0.104283</td>\n      <td>-0.112389</td>\n      <td>-0.20703</td>\n      <td>4.908068</td>\n      <td>-0.178611</td>\n    </tr>\n    <tr>\n      <th>999997</th>\n      <td>4999997</td>\n      <td>-1.030883</td>\n      <td>-0.915300</td>\n      <td>0.569859</td>\n      <td>-1.046461</td>\n      <td>1.036795</td>\n      <td>-0.613569</td>\n      <td>-0.419630</td>\n      <td>0.179866</td>\n      <td>0.100832</td>\n      <td>...</td>\n      <td>-0.169528</td>\n      <td>-0.19819</td>\n      <td>-0.197285</td>\n      <td>-0.11282</td>\n      <td>7.930134</td>\n      <td>-0.104283</td>\n      <td>-0.112389</td>\n      <td>-0.20703</td>\n      <td>-0.203746</td>\n      <td>-0.178611</td>\n    </tr>\n    <tr>\n      <th>999998</th>\n      <td>4999998</td>\n      <td>1.133571</td>\n      <td>-0.797041</td>\n      <td>-0.364349</td>\n      <td>-0.331441</td>\n      <td>0.599770</td>\n      <td>0.570682</td>\n      <td>0.459756</td>\n      <td>-1.254997</td>\n      <td>-1.521838</td>\n      <td>...</td>\n      <td>-0.169528</td>\n      <td>-0.19819</td>\n      <td>-0.197285</td>\n      <td>-0.11282</td>\n      <td>-0.126101</td>\n      <td>-0.104283</td>\n      <td>-0.112389</td>\n      <td>-0.20703</td>\n      <td>-0.203746</td>\n      <td>-0.178611</td>\n    </tr>\n    <tr>\n      <th>999999</th>\n      <td>4999999</td>\n      <td>-1.519183</td>\n      <td>1.549940</td>\n      <td>-0.948230</td>\n      <td>-0.481507</td>\n      <td>1.386414</td>\n      <td>0.662538</td>\n      <td>0.362046</td>\n      <td>0.045348</td>\n      <td>-1.339002</td>\n      <td>...</td>\n      <td>-0.169528</td>\n      <td>-0.19819</td>\n      <td>-0.197285</td>\n      <td>-0.11282</td>\n      <td>-0.126101</td>\n      <td>-0.104283</td>\n      <td>-0.112389</td>\n      <td>-0.20703</td>\n      <td>-0.203746</td>\n      <td>-0.178611</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000000 rows × 55 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"temp = optuna_xgb.predict(pred)\ntemp = pd.DataFrame(temp, columns = ['Cover_Type'])\nprint(temp.head())\ntemp.replace([0,1,2,3,4,5], [1, 2, 3, 4, 6, 7], inplace = True)\nprint(temp.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:57:08.429715Z","iopub.execute_input":"2022-06-05T20:57:08.430082Z","iopub.status.idle":"2022-06-05T20:57:33.073914Z","shell.execute_reply.started":"2022-06-05T20:57:08.430050Z","shell.execute_reply":"2022-06-05T20:57:33.073115Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"   Cover_Type\n0           1\n1           1\n2           1\n3           1\n4           1\n   Cover_Type\n0           2\n1           2\n2           2\n3           2\n4           2\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#yhat = optuna_xgb.predict(pred)\n\nsubmission_df_xgb = pd.DataFrame({'Id': id.Id, 'Cover_Type': temp['Cover_Type']}, columns=['Id', 'Cover_Type'])\n#submission_df_bt.Transported = np.array([bool(x) for x in submission_df_bt.Transported])\nsubmission_df_xgb.to_csv('KP14_xgb.csv',index=False)\n\nos.chdir(r'/kaggle/working')\n\nfrom IPython.display import FileLink\nFileLink(r'KP14_xgb.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:58:00.533531Z","iopub.execute_input":"2022-06-05T20:58:00.534219Z","iopub.status.idle":"2022-06-05T20:58:02.010941Z","shell.execute_reply.started":"2022-06-05T20:58:00.534181Z","shell.execute_reply":"2022-06-05T20:58:02.010115Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/KP14_xgb.csv","text/html":"<a href='KP14_xgb.csv' target='_blank'>KP14_xgb.csv</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
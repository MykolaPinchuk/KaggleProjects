{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pmykola/kp10-titanic?scriptVersionId=102633874\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"### This is a notebook, which generates predictions for Titanic passenger survival competition.\nIt's accuracy is up to 0.79425, a top 5\\% result.","metadata":{}},{"cell_type":"markdown","source":"### Outline:\n0. Load libraries and custom functions.\n1. Load data.\n2. Preliminary data analysis: explore features and a target, delete unneeded features, create new features.\n3. Train-test split.\n4. Missing values. In some cases it may be useful to explore skew and perform log-transform before imputing missing values.\n5. Feature engineering. Transform skewed variables, do OHC and scaling.\n6. Fit models.\n7. Evaluate models.\n8. Feature importance, error analysis. Based on the results, go to 2. and iterate.\n9. Make predictions.\n\n### To do:\n- Add EDA visualization.\n- Add SHAP feature importances.\n- Add Optuna XGBoost hyperparameter tuning.\n- Add PR curve analysis.","metadata":{}},{"cell_type":"code","source":"# 0. Load libraries #\n\nimport numpy as np\nimport pandas as pd\nimport os, time, warnings, shap, optuna\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, train_test_split, KFold\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, precision_recall_curve, auc\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score\nfrom sklearn.inspection import permutation_importance\nfrom xgboost import XGBClassifier\n\npd.set_option('display.max_columns', 20)\npd.set_option('mode.chained_assignment', None)\npd.set_option('display.expand_frame_repr', False)\nwarnings.filterwarnings('ignore')\n\n# Load custom pre-processing functions:\n\ndef draw_histograms(df, variables, n_rows, n_cols):\n    # stolen from https://stackoverflow.com/questions/29530355/plotting-multiple-histograms-in-grid\n    fig=plt.figure()\n    for i, var_name in enumerate(variables):\n        ax=fig.add_subplot(n_rows,n_cols,i+1)\n        df[var_name].hist(bins=10,ax=ax)\n        ax.set_title(var_name+\" Distribution\")\n    fig.tight_layout()  \n    plt.show()\n\n\ndef fillna_mp_i1(df_train, df_test, df_pred, num_features, cat_features, num_fill='median', cat_fill='mode'):\n    \"\"\"This function speeds up filling missing values for 3 main datasets using different imputation methods.\n    Later may replace it with some subclass.\n    Example: fillna_mp_i1(X_train, X_test, X_pred, num_cols, cat_cols)\"\"\"\n    # set df_pred to None if it does not exist\n    if not ((cat_fill=='mode') and (num_fill=='median')):\n        print ('Imputation method not Implemented yet!')\n        return None\n    \n    df_train[num_features] = df_train[num_features].fillna(value=df_train[num_features].median())\n    df_test[num_features] = df_test[num_features].fillna(value=df_train[num_features].median())\n    df_train[cat_features] = df_train[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n    df_test[cat_features] = df_test[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n    if (df_pred is not None):\n        df_pred[num_features] = df_pred[num_features].fillna(value=df_train[num_features].median())\n        df_pred[cat_features] = df_pred[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n    df_train[num_features+cat_features].count\n    \n    all_good = (\n    (np.prod(df_train[num_features+cat_features].shape)==df_train[num_features+cat_features].count().sum()) and \n    (np.prod(df_test[num_features+cat_features].shape) == df_test[num_features+cat_features].count().sum()) and \n    (np.prod(df_pred[num_features+cat_features].shape) == df_pred[num_features+cat_features].count().sum()))\n    if (all_good):\n        print('Missing values imputed successfully')\n    else:\n        print('There are still some missing values...')\n    \ndef add_misDummy_mp_i1(df_train, df_test, df_pred, features):\n    \"\"\"This function creates new dummy columns for missing features.\n    Example: add_misDummy_mp_i1(X_train, X_test, X_pred, ['Age'])\"\"\"\n    # set df_pred to None if it does not exist\n    for feature_name in features:\n        misColName = 'mis'+feature_name\n        df_train.loc[df_train[feature_name].isnull(), misColName]=1\n        df_train.loc[df_train[feature_name].notnull(), misColName]=0\n        df_test.loc[df_test[feature_name].isnull(), misColName]=1\n        df_test.loc[df_test[feature_name].notnull(), misColName]=0\n        if (df_pred is not None):\n            df_pred.loc[df_pred[feature_name].isnull(), misColName]=1\n            df_pred.loc[df_pred[feature_name].notnull(), misColName]=0\n   \n\ndef discretize_mp_i1(df_train, df_test, df_pred, feature, ntiles, delete_feature=False):\n    \"\"\"This function divides a continuous feature into quantile groups.\n    Example: discretize_mp_i1(X_train, X_test, X_pred, 'Age', 15)\"\"\"\n    # set df_pred to None if it does not exist\n    _,bin = pd.qcut(df_train[feature], ntiles, retbins = True, labels = False, duplicates = 'drop')\n    df_train[feature+'Ntile'] = pd.cut(df_train[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    df_test[feature+'Ntile'] = pd.cut(df_test[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    if (df_pred is not None):\n        df_pred[feature+'Ntile'] = pd.cut(df_pred[feature], labels=False, duplicates = 'drop', bins = bin ,include_lowest = True)\n    if (delete_feature==True):\n        df_train.drop(columns=[feature], inplace=True)\n        df_test.drop(columns=[feature], inplace=True)\n        df_pred.drop(columns=[feature], inplace=True)\n    print('Discretized ',feature, ' into ', len(bin)-1, ' bins')\n\n\ndef log_transformer_mp_i1(df_train, df_test, df_pred, feature_subset=False, min_skew=3):\n    \"\"\"This function divides a continuous feature into quantile groups.\n    Example: log_transformer_mp_i1(X_train, X_test, X_pred, feature_subset=num_cols)\"\"\"\n    # set df_pred to None if it does not exist\n    if (feature_subset==False):\n        features_totransform = df_train.columns\n    else:\n        features_totransform = feature_subset.copy()\n    skewed_vars = list(df_train.skew()[abs(df_train.skew())>min_skew].index)\n    for col in list(set(skewed_vars)&set(features_totransform)):\n        df_train[col] = np.log1p(df_train[col])\n        df_test[col] = np.log1p(df_test[col])\n        if (df_pred is not None):\n            df_pred[col] = np.log1p(df_pred[col])\n    print('Skewed columns log-transformed: ', list(set(skewed_vars)&set(features_totransform)))\n    \n    \n# 1. Load data #\n\ntime0 = time.time()\n\npath = '../input/titanic/train.csv'\ndf = pd.read_csv(path) \n\ndf.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'],inplace=True)\npred=pd.read_csv('../input/titanic/test.csv')\npred0 = pred.copy()\npred.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'],inplace=True)\n\nprint(df.shape, pred.shape)\n#df.head()\n\n# 2. EDA, adding features #\n\n#df.Survived.value_counts()\ndf['Age2'] = df['Age']**2\npred['Age2'] = pred['Age']**2\n\n# 3. Train-test split #\n\ntrain_y = df[['Survived']]\ntrain_x = df.drop(columns = ['Survived'])\nX_pred = pred.copy()\n\n#bin_cols = [col for col in train_x.columns if train_x[col].nunique()==2]\ncat_cols = [col for col in train_x.columns if train_x[col].nunique() in range(2,10)]\nnum_cols = list(set(train_x.columns)-set(cat_cols))\n\nprint('categorical features: ', cat_cols, 'numerical features: ', num_cols)\n\nX_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.1, random_state=101)\nprint(X_train.shape, X_test.shape, y_train.shape, X_pred.shape)\n\nX_train.info()\n\n# 4. Misisng values #\n\nadd_misDummy_mp_i1(X_train, X_test, X_pred, ['Age'])\n\nfillna_mp_i1(X_train, X_test, X_pred, num_cols, cat_cols)\n#[X_train.count(), X_test.count(), X_pred.count()]\n\n# extra feature engineering (manual)\n\ndiscretize_mp_i1(X_train, X_test, X_pred, 'Age', 15)\ndiscretize_mp_i1(X_train, X_test, X_pred, 'SibSp', 30)\ndiscretize_mp_i1(X_train, X_test, X_pred, 'Parch', 60)\n\ncat_cols.extend(['misAge', 'AgeNtile', 'SibSpNtile', 'ParchNtile'])\ncat_cols = list(set(cat_cols)-set(['SibSp', 'Parch']))\n\n\n# 5.Feature engineering #\n\nlog_transformer_mp_i1(X_train, X_test, X_pred, feature_subset=num_cols)\n\n# in general, if I plan using raw ols, I should drop one group. o/w, it is beteer to leabe all ohc groups.\n\nfeature_transformer = ColumnTransformer([\n    (\"num\", StandardScaler(), num_cols),\n    (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\"), cat_cols),\n    ])\n\nX_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\nX_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\nX_pred = pd.DataFrame(feature_transformer.transform(X_pred), columns=feature_transformer.get_feature_names_out())\n\nfewfeatures = ['num__Age', 'num__Age2', 'num__Fare', 'cat__Sex_male', 'cat__Pclass_2', 'cat__Pclass_3']\n\nX_train\n\n# 6. Fit models #\n\nlr = LogisticRegression()\nparam_grid = {'C':[0.3, 1, 3, 10, 30]}\nlrm = GridSearchCV(lr, param_grid, cv=8)\nlrm.fit(X_train, y_train)\nprint('Logistic ', lrm.best_params_, accuracy_score(y_train, lrm.predict(X_train)), roc_auc_score(y_train, lrm.predict(X_train)))\n\nsvm = SVC()\nparam_grid = {'C':[0.3, 1, 2, 3, 10]}\nsvmm = GridSearchCV(svm, param_grid, cv=8)\nsvmm.fit(X_train, y_train)\nprint('SVM ', svmm.best_params_, accuracy_score(y_train, svmm.predict(X_train)), roc_auc_score(y_train, svmm.predict(X_train)))\n\nknn = KNeighborsClassifier()\nparam_grid = dict(n_neighbors=range(2,20))\nknnm = GridSearchCV(knn, param_grid, cv=8)\nknnm.fit(X_train[fewfeatures], y_train)\nprint('KNN ', knnm.best_params_, accuracy_score(y_train, knnm.predict(X_train[fewfeatures])), roc_auc_score(y_train, knnm.predict(X_train[fewfeatures])))\n\ntime1 = time.time()\nrf = RandomForestClassifier()\nparam_grid = {'n_estimators':[100,200], 'max_depth':[2,4,6,8], 'max_features':[4,5,6]}\nrfm = GridSearchCV(rf, param_grid, cv=4)\nrfm.fit(X_train, y_train)\nprint('RF ', rfm.best_params_, accuracy_score(y_train, rfm.predict(X_train)), roc_auc_score(y_train, rfm.predict(X_train)), time.time()-time1)\n\ntime1 = time.time()\nxgb = XGBClassifier()\n# use 'gpu_hist' for more than 10,000 examples.\nparam_grid = {'n_estimators':[200], 'max_depth':[3,4], 'eta':[0.03, 0.04, 0.05], 'subsample':[0.6, 0.8],\n             'colsample_bytree':[0.4, 0.6]}\nxgbm = GridSearchCV(xgb, param_grid, cv=2)\nxgbm.fit(X_train, y_train)\nprint('XGB ', xgbm.best_params_, accuracy_score(y_train, xgbm.predict(X_train)), roc_auc_score(y_train, xgbm.predict(X_train)), time.time()-time1)\nprint('XGB', f1_score(y_train,xgbm.predict(X_train)), recall_score(y_train,xgbm.predict(X_train)), precision_score(y_train,xgbm.predict(X_train)))\n\n# 7. accuracy #\n\nprint('Out of Sample:')\nprint('Logistic ', accuracy_score(y_test, lrm.predict(X_test)), roc_auc_score(y_test, lrm.predict(X_test)))\nprint('SVM ', accuracy_score(y_test, svmm.predict(X_test)), roc_auc_score(y_test, svmm.predict(X_test)))\nprint('KNN ', accuracy_score(y_test, knnm.predict(X_test[fewfeatures])), roc_auc_score(y_test, knnm.predict(X_test[fewfeatures])))\nprint('RF ', accuracy_score(y_test, rfm.predict(X_test)), roc_auc_score(y_test, rfm.predict(X_test)))\nprint('XGB ', accuracy_score(y_test, xgbm.predict(X_test)), roc_auc_score(y_test, xgbm.predict(X_test)))\nprint('Total time ', time.time()-time0)\n\n# VotingClassifier:\n\nestimator = []\n#estimator.append(('LR', LogisticRegression(C=1)))\nestimator.append(('SVM', SVC(C=1, probability = True)))\n#estimator.append(('KNN', KNeighborsClassifier(n_neighbors=5)))\nestimator.append(('RF', RandomForestClassifier(max_depth=5, max_features=4, n_estimators=200)))\nestimator.append(('XGB', XGBClassifier(eta=0.04, max_depth=3, n_estimators=200, \n                                       subsample=0.6, colsample_bytree=0.6)))\nvot_soft = VotingClassifier(estimators = estimator, voting ='soft')\nvot_soft.fit(X_train, y_train)\nprint('VotingClassifier5 ', accuracy_score(y_train, vot_soft.predict(X_train)), roc_auc_score(y_train, vot_soft.predict(X_train)))\nprint('VotingClassifier5 ', accuracy_score(y_test, vot_soft.predict(X_test)), roc_auc_score(y_test, vot_soft.predict(X_test)))\n# to add KNN with different feature sets, \n# see https://stackoverflow.com/questions/45074579/votingclassifier-different-feature-sets","metadata":{"execution":{"iopub.status.busy":"2022-08-06T03:27:47.786017Z","iopub.execute_input":"2022-08-06T03:27:47.786477Z","iopub.status.idle":"2022-08-06T03:28:58.19908Z","shell.execute_reply.started":"2022-08-06T03:27:47.786408Z","shell.execute_reply":"2022-08-06T03:28:58.198081Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"(891, 8) (418, 7)\ncategorical features:  ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked'] numerical features:  ['Age', 'Fare', 'Age2']\n(801, 8) (90, 8) (801, 1) (418, 8)\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 801 entries, 825 to 863\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   Pclass    801 non-null    int64  \n 1   Sex       801 non-null    object \n 2   Age       646 non-null    float64\n 3   SibSp     801 non-null    int64  \n 4   Parch     801 non-null    int64  \n 5   Fare      801 non-null    float64\n 6   Embarked  799 non-null    object \n 7   Age2      646 non-null    float64\ndtypes: float64(3), int64(3), object(2)\nmemory usage: 56.3+ KB\nMissing values imputed successfully\nDiscretized  Age  into  12  bins\nDiscretized  SibSp  into  4  bins\nDiscretized  Parch  into  4  bins\nSkewed columns log-transformed:  ['Fare']\nLogistic  {'C': 30} 0.815230961298377 0.7958368125969224\nSVM  {'C': 1} 0.8414481897627965 0.8207980436597877\nKNN  {'n_neighbors': 6} 0.8539325842696629 0.8250228637321563\nRF  {'max_depth': 8, 'max_features': 5, 'n_estimators': 200} 0.8963795255930087 0.8746669847707662 26.023651599884033\nXGB  {'colsample_bytree': 0.8, 'eta': 0.03, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.4} 0.8651685393258427 0.8431050936418942 37.257102251052856\nXGB 0.8085106382978724 0.7524752475247525 0.8735632183908046\nOut of Sample:\nLogistic  0.8111111111111111 0.7971342383107088\nSVM  0.8111111111111111 0.7911010558069381\nKNN  0.7888888888888889 0.7594268476621416\nRF  0.8222222222222222 0.8009049773755655\nXGB  0.8 0.7812971342383107\nTotal time  68.9041976928711\nVotingClassifier5  0.8451935081148564 0.8231639429003141\nVotingClassifier5  0.8111111111111111 0.7911010558069381\n","output_type":"stream"}]},{"cell_type":"code","source":"# Optuna XGB hyperparameter optimization\n\ntime1=time.time()\n\n### Fit XGBoost using Optuna hyperparameter optimization ###\n\ndef objective(trial, cv_runs=1, n_splits=2, n_jobs=-1, scale_pos_weight=1, early_stopping_rounds=50):\n\n    cv_regularizer=0.05\n    # Usually values between 0.1 and 0.2 work fine.\n\n    params = {\n        #\"tree_method\": 'gpu_hist',\n        \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n        #\"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 1000),\n        \"n_estimators\": 500,\n        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.01, 0.2),\n        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.1, 0.95),\n        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 0.95),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 0.1, 10.0),\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 0.1, 150.0),\n        \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-10, 10.0),\n        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 0.1, 10),\n        \"n_jobs\": n_jobs,\n    }\n    # usually it makes sense to resrtict hyperparameter space from some solutions which Optuna will find\n    # e.g., for tmx-joined data only (downsampled tmx), optuna keeps selecting depths of 2 and 3.\n    # for my purposes (smooth left side of prc, close to 1), those solutions are no good.\n\n    temp_out = []\n\n    for i in range(cv_runs):\n\n        X = X_train\n        y = y_train.Survived\n\n        model = XGBClassifier(**params)\n        rkf = KFold(n_splits=n_splits, shuffle=True)\n        X_values = X.values\n        y_values = y.values\n        y_pred = np.zeros_like(y_values)\n        y_pred_train = np.zeros_like(y_values)\n        for train_index, test_index in rkf.split(X_values):\n            X_A, X_B = X_values[train_index, :], X_values[test_index, :]\n            y_A, y_B = y_values[train_index], y_values[test_index]\n            model.fit(X_A, y_A, eval_set=[(X_B, y_B)],\n                      early_stopping_rounds=early_stopping_rounds, verbose = False)\n            y_pred[test_index] += model.predict(X_B)\n            y_pred_train[train_index] += model.predict(X_A)\n        score_train = roc_auc_score(y_train, y_pred_train)\n        score_test = roc_auc_score(y_train, y_pred) \n        overfit = score_train-score_test\n        #return (score_test)\n        #return (score_test-cv_regularizer*overfit)\n        temp_out.append(score_test-cv_regularizer*overfit)\n\n    return (np.mean(temp_out))\n\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=40)\nprint('Total time for hypermarameter optimization ', time.time()-time1)\nhp = study.best_params\nfor key, value in hp.items():\n    print(f\"{key:>20s} : {value}\")\nprint(f\"{'best objective value':>20s} : {study.best_value}\")\n\noptuna_hyperpars = study.best_params\n#optuna_hyperpars['tree_method']='gpu_hist'\noptuna_hyperpars['scale_pos_weight']=1\n#optuna_hyperpars['early_stopping_rounds']=50\n\noptuna_xgb = XGBClassifier(**optuna_hyperpars)\noptuna_xgb.fit(X_train, y_train)\n\ndisplay('Accuracy: ', accuracy_score(y_train,optuna_xgb.predict(X_train)))\ndisplay('F1 score: ', f1_score(y_train,optuna_xgb.predict(X_train)))\ndisplay('Recall score: ', recall_score(y_train,optuna_xgb.predict(X_train)))\ndisplay('Precision score: ', precision_score(y_train,optuna_xgb.predict(X_train)))\ndisplay('ROCAUC: ', roc_auc_score(y_train,optuna_xgb.predict(X_train)))\n#display('Precision at 20% recall: ', r20prec_train)\n#display('Precision at 50% recall: ', r50prec_train)\n# Performance evaluation:\ndisplay('Accuracy: ', accuracy_score(y_test,optuna_xgb.predict(X_test)))\ndisplay('F1 score: ', f1_score(y_test,optuna_xgb.predict(X_test)))\ndisplay('Recall score: ', recall_score(y_test,optuna_xgb.predict(X_test)))\ndisplay('Precision score: ', precision_score(y_test,optuna_xgb.predict(X_test)))\ndisplay('ROCAUC: ', roc_auc_score(y_test,optuna_xgb.predict(X_test)))\n#display('Precision at 20% recall: ', r20prec_test)\n#display('Precision at 50% recall: ', r50prec_test)\ndisplay(time.time()-time0)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-06T03:28:58.201089Z","iopub.execute_input":"2022-08-06T03:28:58.201349Z","iopub.status.idle":"2022-08-06T03:31:41.08239Z","shell.execute_reply.started":"2022-08-06T03:28:58.201317Z","shell.execute_reply":"2022-08-06T03:31:41.081506Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-08-06 03:28:58,218]\u001b[0m A new study created in memory with name: no-name-ca7b7172-7174-4c47-abe5-c2071be521a5\u001b[0m\n\u001b[32m[I 2022-08-06 03:29:01,734]\u001b[0m Trial 0 finished with value: 0.7778788421010775 and parameters: {'max_depth': 5, 'learning_rate': 0.0815425429614267, 'colsample_bytree': 0.8926308445210102, 'subsample': 0.5410456033654187, 'alpha': 0.5311995662872802, 'lambda': 15.531742063636118, 'gamma': 0.8980013097204437, 'min_child_weight': 0.776081586530493}. Best is trial 0 with value: 0.7778788421010775.\u001b[0m\n\u001b[32m[I 2022-08-06 03:29:09,562]\u001b[0m Trial 1 finished with value: 0.7549440335599826 and parameters: {'max_depth': 3, 'learning_rate': 0.16624798136154964, 'colsample_bytree': 0.6310383969296037, 'subsample': 0.6563948628868858, 'alpha': 8.38577585992445, 'lambda': 136.01313493450127, 'gamma': 7.733704092623301e-06, 'min_child_weight': 8.251884651429103}. Best is trial 0 with value: 0.7778788421010775.\u001b[0m\n\u001b[32m[I 2022-08-06 03:29:11,803]\u001b[0m Trial 2 finished with value: 0.7488438904131377 and parameters: {'max_depth': 6, 'learning_rate': 0.16937763727835412, 'colsample_bytree': 0.36211290425133713, 'subsample': 0.8636517913350961, 'alpha': 2.7150328544300186, 'lambda': 0.25530182063488543, 'gamma': 5.578994048963103, 'min_child_weight': 0.3618780158436915}. Best is trial 0 with value: 0.7778788421010775.\u001b[0m\n\u001b[32m[I 2022-08-06 03:29:13,871]\u001b[0m Trial 3 finished with value: 0.7692781025090462 and parameters: {'max_depth': 2, 'learning_rate': 0.17101333925547438, 'colsample_bytree': 0.5641571228429659, 'subsample': 0.5367309439032453, 'alpha': 0.5484807116373998, 'lambda': 0.4017648213956542, 'gamma': 0.01704948846088985, 'min_child_weight': 6.934350036699449}. Best is trial 0 with value: 0.7778788421010775.\u001b[0m\n\u001b[32m[I 2022-08-06 03:29:20,107]\u001b[0m Trial 4 finished with value: 0.7630989303749653 and parameters: {'max_depth': 10, 'learning_rate': 0.09597379882991659, 'colsample_bytree': 0.4109760439515029, 'subsample': 0.5493619154525593, 'alpha': 7.490845590722637, 'lambda': 0.8265759579255876, 'gamma': 2.750128773139666e-08, 'min_child_weight': 0.22649014226582573}. Best is trial 0 with value: 0.7778788421010775.\u001b[0m\n\u001b[32m[I 2022-08-06 03:29:28,729]\u001b[0m Trial 5 finished with value: 0.7517366495685713 and parameters: {'max_depth': 10, 'learning_rate': 0.05022480127021312, 'colsample_bytree': 0.2676188309219364, 'subsample': 0.5174564283014915, 'alpha': 6.411848041019524, 'lambda': 79.32849933722828, 'gamma': 0.002279358658927404, 'min_child_weight': 0.5364343876850004}. Best is trial 0 with value: 0.7778788421010775.\u001b[0m\n\u001b[32m[I 2022-08-06 03:29:30,768]\u001b[0m Trial 6 finished with value: 0.7640338582050977 and parameters: {'max_depth': 9, 'learning_rate': 0.19293548282639683, 'colsample_bytree': 0.17773814561564438, 'subsample': 0.8883998642975789, 'alpha': 0.10225336585437966, 'lambda': 0.6021811960483926, 'gamma': 1.156404058468381e-07, 'min_child_weight': 2.2006505964946608}. Best is trial 0 with value: 0.7778788421010775.\u001b[0m\n\u001b[32m[I 2022-08-06 03:29:34,474]\u001b[0m Trial 7 finished with value: 0.7546304027993163 and parameters: {'max_depth': 10, 'learning_rate': 0.13974108664341314, 'colsample_bytree': 0.6640170332271172, 'subsample': 0.8308533654618973, 'alpha': 5.972506743370787, 'lambda': 7.387591373519345, 'gamma': 0.583716083210669, 'min_child_weight': 9.261781288835518}. Best is trial 0 with value: 0.7778788421010775.\u001b[0m\n\u001b[32m[I 2022-08-06 03:29:36,391]\u001b[0m Trial 8 finished with value: 0.7909618672710644 and parameters: {'max_depth': 6, 'learning_rate': 0.1459298511219891, 'colsample_bytree': 0.794522099150979, 'subsample': 0.5778633503488835, 'alpha': 0.42427033093214617, 'lambda': 2.4570045244260768, 'gamma': 5.091224559263251e-08, 'min_child_weight': 1.5755435730069012}. Best is trial 8 with value: 0.7909618672710644.\u001b[0m\n\u001b[32m[I 2022-08-06 03:29:39,073]\u001b[0m Trial 9 finished with value: 0.776983677283391 and parameters: {'max_depth': 2, 'learning_rate': 0.1627580769128128, 'colsample_bytree': 0.39534449373721425, 'subsample': 0.5032282085921346, 'alpha': 0.3680803232056414, 'lambda': 8.545631590639719, 'gamma': 0.0030801016844456256, 'min_child_weight': 0.14687727151275276}. Best is trial 8 with value: 0.7909618672710644.\u001b[0m\n\u001b[32m[I 2022-08-06 03:29:48,150]\u001b[0m Trial 10 finished with value: 0.7946976022903495 and parameters: {'max_depth': 8, 'learning_rate': 0.012189807030599548, 'colsample_bytree': 0.941960640420379, 'subsample': 0.6776630881566895, 'alpha': 0.1400727744293112, 'lambda': 1.80367394512704, 'gamma': 1.1973706872672933e-10, 'min_child_weight': 1.916096320397804}. Best is trial 10 with value: 0.7946976022903495.\u001b[0m\n\u001b[32m[I 2022-08-06 03:29:57,396]\u001b[0m Trial 11 finished with value: 0.8036363274881704 and parameters: {'max_depth': 8, 'learning_rate': 0.01436924083385748, 'colsample_bytree': 0.9405449323519067, 'subsample': 0.6777184524149369, 'alpha': 0.144409124988649, 'lambda': 2.714871460484515, 'gamma': 1.233635346511967e-10, 'min_child_weight': 1.8930694016562515}. Best is trial 11 with value: 0.8036363274881704.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:03,523]\u001b[0m Trial 12 finished with value: 0.7728612469680703 and parameters: {'max_depth': 8, 'learning_rate': 0.016868774507149964, 'colsample_bytree': 0.8750482306570819, 'subsample': 0.7355292251744746, 'alpha': 0.16042220287966513, 'lambda': 1.9277347680275743, 'gamma': 1.190822403183431e-09, 'min_child_weight': 2.995039597124694}. Best is trial 11 with value: 0.8036363274881704.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:11,730]\u001b[0m Trial 13 finished with value: 0.7747420374567577 and parameters: {'max_depth': 8, 'learning_rate': 0.019073708496879168, 'colsample_bytree': 0.7568174532045221, 'subsample': 0.70241980789267, 'alpha': 0.1901906767005481, 'lambda': 27.11569914889978, 'gamma': 1.6100354653926678e-10, 'min_child_weight': 3.6326352949001275}. Best is trial 11 with value: 0.8036363274881704.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:14,126]\u001b[0m Trial 14 finished with value: 0.7982017177621377 and parameters: {'max_depth': 8, 'learning_rate': 0.05493370615361444, 'colsample_bytree': 0.947968495703162, 'subsample': 0.7726613608459806, 'alpha': 0.9825928643690439, 'lambda': 0.13066749958972276, 'gamma': 1.6844924344268006e-10, 'min_child_weight': 1.246767797242845}. Best is trial 11 with value: 0.8036363274881704.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:16,444]\u001b[0m Trial 15 finished with value: 0.7838895184699192 and parameters: {'max_depth': 7, 'learning_rate': 0.0539463290391899, 'colsample_bytree': 0.7625565928173645, 'subsample': 0.7966205127757375, 'alpha': 1.5735521714310061, 'lambda': 0.139097506629658, 'gamma': 2.242510589417504e-06, 'min_child_weight': 1.0819046387869047}. Best is trial 11 with value: 0.8036363274881704.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:18,697]\u001b[0m Trial 16 finished with value: 0.7613742097101276 and parameters: {'max_depth': 4, 'learning_rate': 0.04960667139846894, 'colsample_bytree': 0.9431173215292116, 'subsample': 0.9394096539751009, 'alpha': 1.0439313392564171, 'lambda': 0.12380711774516635, 'gamma': 3.907100821529556e-09, 'min_child_weight': 0.9818712207738722}. Best is trial 11 with value: 0.8036363274881704.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:23,362]\u001b[0m Trial 17 finished with value: 0.785116207403873 and parameters: {'max_depth': 7, 'learning_rate': 0.07155405183848822, 'colsample_bytree': 0.7964738425427254, 'subsample': 0.7608215639650523, 'alpha': 2.8171763852280236, 'lambda': 1.2629611394861875, 'gamma': 1.199159688451732e-06, 'min_child_weight': 4.413307826671932}. Best is trial 11 with value: 0.8036363274881704.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:26,888]\u001b[0m Trial 18 finished with value: 0.7601326096465069 and parameters: {'max_depth': 9, 'learning_rate': 0.033349372075360005, 'colsample_bytree': 0.6649099960693057, 'subsample': 0.6236085192549051, 'alpha': 0.31244939201116007, 'lambda': 4.970798173459976, 'gamma': 6.856653495557836e-05, 'min_child_weight': 0.5312253023942052}. Best is trial 11 with value: 0.8036363274881704.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:35,020]\u001b[0m Trial 19 finished with value: 0.7865407173247446 and parameters: {'max_depth': 7, 'learning_rate': 0.03568387252575424, 'colsample_bytree': 0.48076996013656614, 'subsample': 0.6156562008229385, 'alpha': 1.004551983484689, 'lambda': 31.00744029995359, 'gamma': 2.130194590383763e-09, 'min_child_weight': 1.3131314520811597}. Best is trial 11 with value: 0.8036363274881704.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:40,431]\u001b[0m Trial 20 finished with value: 0.8034151457314407 and parameters: {'max_depth': 5, 'learning_rate': 0.11101813330731317, 'colsample_bytree': 0.8581334859372169, 'subsample': 0.7760861217128513, 'alpha': 2.397652674357796, 'lambda': 0.38791307283119103, 'gamma': 7.625355971407725e-05, 'min_child_weight': 4.904348566324909}. Best is trial 11 with value: 0.8036363274881704.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:42,264]\u001b[0m Trial 21 finished with value: 0.7653654220843772 and parameters: {'max_depth': 5, 'learning_rate': 0.11342972433761135, 'colsample_bytree': 0.861246291741515, 'subsample': 0.7781880410389397, 'alpha': 3.251913409553767, 'lambda': 0.25759370777491747, 'gamma': 0.0004359892198522195, 'min_child_weight': 5.152638010536066}. Best is trial 11 with value: 0.8036363274881704.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:44,198]\u001b[0m Trial 22 finished with value: 0.8015224263390194 and parameters: {'max_depth': 5, 'learning_rate': 0.11467549852967379, 'colsample_bytree': 0.8397003635539791, 'subsample': 0.7253217939943137, 'alpha': 1.8413699842603628, 'lambda': 0.27607388706623953, 'gamma': 5.362728577739612e-05, 'min_child_weight': 2.5613769771601516}. Best is trial 11 with value: 0.8036363274881704.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:48,224]\u001b[0m Trial 23 finished with value: 0.8070967036462683 and parameters: {'max_depth': 4, 'learning_rate': 0.11978623204969595, 'colsample_bytree': 0.7059600042134269, 'subsample': 0.7215799482865997, 'alpha': 1.85115171801713, 'lambda': 0.6497329601003864, 'gamma': 6.18695454002552e-05, 'min_child_weight': 3.1622273726565684}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:53,689]\u001b[0m Trial 24 finished with value: 0.7711946797089347 and parameters: {'max_depth': 4, 'learning_rate': 0.13158352248544813, 'colsample_bytree': 0.7010615209241599, 'subsample': 0.6760728421698582, 'alpha': 4.22872274883402, 'lambda': 0.7559741241717923, 'gamma': 7.318179182792974e-07, 'min_child_weight': 5.688369391216199}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:56,724]\u001b[0m Trial 25 finished with value: 0.7935414927034872 and parameters: {'max_depth': 4, 'learning_rate': 0.09667151568673883, 'colsample_bytree': 0.5802280138369025, 'subsample': 0.8105131765916035, 'alpha': 1.9952744225129373, 'lambda': 3.2434200723668223, 'gamma': 0.025079429144200825, 'min_child_weight': 3.4009345970635816}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:30:59,045]\u001b[0m Trial 26 finished with value: 0.8028743687621774 and parameters: {'max_depth': 3, 'learning_rate': 0.1248992893198367, 'colsample_bytree': 0.7176004911092227, 'subsample': 0.7459736267970635, 'alpha': 1.4170518240773455, 'lambda': 1.2720747969018489, 'gamma': 0.0002953747246369565, 'min_child_weight': 2.1430271557556537}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:31:03,560]\u001b[0m Trial 27 finished with value: 0.784812517396318 and parameters: {'max_depth': 3, 'learning_rate': 0.08298270612684944, 'colsample_bytree': 0.8283526138725255, 'subsample': 0.7096303300878968, 'alpha': 4.214823892829876, 'lambda': 0.5321945129061187, 'gamma': 9.503297892847632e-06, 'min_child_weight': 4.529991310068769}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:31:07,233]\u001b[0m Trial 28 finished with value: 0.7784007316394289 and parameters: {'max_depth': 5, 'learning_rate': 0.10468119042595606, 'colsample_bytree': 0.7372618387701444, 'subsample': 0.6377882438576161, 'alpha': 0.7357932749347329, 'lambda': 1.1178069337434855, 'gamma': 0.0003733515020826901, 'min_child_weight': 6.745316632364668}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:31:10,369]\u001b[0m Trial 29 finished with value: 0.7684331384945724 and parameters: {'max_depth': 6, 'learning_rate': 0.06923551888030685, 'colsample_bytree': 0.8697787977803291, 'subsample': 0.8387023311703173, 'alpha': 0.20942804331735235, 'lambda': 12.845315558057495, 'gamma': 0.21242102254675416, 'min_child_weight': 0.6724817986316897}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:31:14,995]\u001b[0m Trial 30 finished with value: 0.7880517117976857 and parameters: {'max_depth': 4, 'learning_rate': 0.08674460605508261, 'colsample_bytree': 0.9101607172240493, 'subsample': 0.597215116774618, 'alpha': 0.6911573801036284, 'lambda': 4.2787499425655, 'gamma': 1.9272565611159474e-07, 'min_child_weight': 1.7613665713906033}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:31:16,794]\u001b[0m Trial 31 finished with value: 0.765925086484552 and parameters: {'max_depth': 4, 'learning_rate': 0.1228816158342353, 'colsample_bytree': 0.7066092147023172, 'subsample': 0.7483746517724061, 'alpha': 1.5121278106902862, 'lambda': 1.105394803952486, 'gamma': 0.0005066790558276668, 'min_child_weight': 2.19903475975053}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:31:18,541]\u001b[0m Trial 32 finished with value: 0.7707741858523202 and parameters: {'max_depth': 3, 'learning_rate': 0.14778593929203165, 'colsample_bytree': 0.6278001350196115, 'subsample': 0.6863420051344369, 'alpha': 1.2112571508897192, 'lambda': 0.3974385617571313, 'gamma': 2.2140441469905396e-05, 'min_child_weight': 3.432034512916553}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:31:21,116]\u001b[0m Trial 33 finished with value: 0.7802243627977256 and parameters: {'max_depth': 2, 'learning_rate': 0.1240119014287708, 'colsample_bytree': 0.7925230988691842, 'subsample': 0.6620640606991751, 'alpha': 2.1932692668422162, 'lambda': 1.6121251899276572, 'gamma': 3.6772764961917964e-06, 'min_child_weight': 2.51581481970327}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:31:27,083]\u001b[0m Trial 34 finished with value: 0.7886869259215078 and parameters: {'max_depth': 3, 'learning_rate': 0.1089701462136464, 'colsample_bytree': 0.5099725107251745, 'subsample': 0.7186016379316078, 'alpha': 3.854318013757644, 'lambda': 2.896565350020729, 'gamma': 0.0036644244691340913, 'min_child_weight': 1.6611931594417775}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:31:30,047]\u001b[0m Trial 35 finished with value: 0.7819490834625632 and parameters: {'max_depth': 5, 'learning_rate': 0.15562350019617122, 'colsample_bytree': 0.6009809519013323, 'subsample': 0.8028354318365262, 'alpha': 1.3260732850293733, 'lambda': 0.39719431885813933, 'gamma': 0.0001263016750085637, 'min_child_weight': 7.564062908174157}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:31:31,377]\u001b[0m Trial 36 finished with value: 0.7865024454252655 and parameters: {'max_depth': 6, 'learning_rate': 0.18252133215188626, 'colsample_bytree': 0.8990256487032567, 'subsample': 0.7450458172867466, 'alpha': 2.351676121853963, 'lambda': 0.8655780500293941, 'gamma': 0.02362541935681604, 'min_child_weight': 0.8015189121881875}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:31:33,199]\u001b[0m Trial 37 finished with value: 0.7921706628494175 and parameters: {'max_depth': 3, 'learning_rate': 0.13275909315901108, 'colsample_bytree': 0.8136495014522417, 'subsample': 0.875420725549323, 'alpha': 0.6961216807343675, 'lambda': 0.24507179631917558, 'gamma': 1.5317698205363377e-05, 'min_child_weight': 4.07378329348089}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:31:36,373]\u001b[0m Trial 38 finished with value: 0.7781353135313531 and parameters: {'max_depth': 2, 'learning_rate': 0.09417980408134163, 'colsample_bytree': 0.6729405682782774, 'subsample': 0.7013952632208706, 'alpha': 0.26330465374238965, 'lambda': 0.1949162797722535, 'gamma': 0.0012900909244848778, 'min_child_weight': 5.927018210196176}. Best is trial 23 with value: 0.8070967036462683.\u001b[0m\n\u001b[32m[I 2022-08-06 03:31:40,545]\u001b[0m Trial 39 finished with value: 0.8135457672273252 and parameters: {'max_depth': 4, 'learning_rate': 0.0740337209996972, 'colsample_bytree': 0.30513373313592596, 'subsample': 0.6468124143278509, 'alpha': 0.502111981980168, 'lambda': 0.5400207533972782, 'gamma': 4.485062247802197e-07, 'min_child_weight': 2.8647627976570815}. Best is trial 39 with value: 0.8135457672273252.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Total time for hypermarameter optimization  162.32875061035156\n           max_depth : 4\n       learning_rate : 0.0740337209996972\n    colsample_bytree : 0.30513373313592596\n           subsample : 0.6468124143278509\n               alpha : 0.502111981980168\n              lambda : 0.5400207533972782\n               gamma : 4.485062247802197e-07\n    min_child_weight : 2.8647627976570815\nbest objective value : 0.8135457672273252\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"'Accuracy: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.8651685393258427"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'F1 score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.8091872791519436"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Recall score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.7557755775577558"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Precision score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.870722433460076"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'ROCAUC: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.8437512425941389"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Accuracy: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.8222222222222222"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'F1 score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.7714285714285716"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Recall score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.6923076923076923"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'Precision score: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.8709677419354839"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"'ROCAUC: '"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0.8069381598793364"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"233.22073364257812"},"metadata":{}}]},{"cell_type":"code","source":"# 8. feature importance #\n\nresults = permutation_importance(xgbm, X_test, y_test, scoring='accuracy', n_jobs=-1)\nfi_lr = pd.DataFrame({'col':X_test.columns, 'FI':results.importances_mean})\n#fi_lr.sort_values('FI', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2022-08-06T03:31:41.083704Z","iopub.execute_input":"2022-08-06T03:31:41.083935Z","iopub.status.idle":"2022-08-06T03:31:44.069976Z","shell.execute_reply.started":"2022-08-06T03:31:41.083908Z","shell.execute_reply":"2022-08-06T03:31:44.068888Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# 9. predictions #\n\nsubmission_df_vc = pd.DataFrame({'PassengerId': pred0.PassengerId, 'Survived': vot_soft.predict(X_pred)}, columns=['PassengerId', 'Survived'])\nsubmission_df_svm = pd.DataFrame({'PassengerId': pred0.PassengerId, 'Survived': svmm.predict(X_pred)}, columns=['PassengerId', 'Survived'])\nsubmission_df_rf = pd.DataFrame({'PassengerId': pred0.PassengerId, 'Survived': rfm.predict(X_pred)}, columns=['PassengerId', 'Survived'])\nsubmission_df_bt = pd.DataFrame({'PassengerId': pred0.PassengerId, 'Survived': xgbm.predict(X_pred)}, columns=['PassengerId', 'Survived'])\nsubmission_df_oxgb = pd.DataFrame({'PassengerId': pred0.PassengerId, 'Survived': optuna_xgb.predict(X_pred)}, columns=['PassengerId', 'Survived'])\n\nsubmission_df_vc.to_csv('KP10_v2_vc.csv',index=False)\nsubmission_df_svm.to_csv('KP10_v2_svm.csv',index=False)\nsubmission_df_rf.to_csv('KP10_v2_rf.csv',index=False)\nsubmission_df_bt.to_csv('KP10_v2_bt.csv',index=False)\nsubmission_df_oxgb.to_csv('KP10_oxgb.csv',index=False)\n\nos.chdir(r'/kaggle/working')\n\nfrom IPython.display import FileLink\nFileLink(r'KP10_oxgb.csv')\n\n#display(time.time()-time0)","metadata":{"execution":{"iopub.status.busy":"2022-08-06T03:32:53.647325Z","iopub.execute_input":"2022-08-06T03:32:53.64773Z","iopub.status.idle":"2022-08-06T03:32:53.795134Z","shell.execute_reply.started":"2022-08-06T03:32:53.647692Z","shell.execute_reply":"2022-08-06T03:32:53.79404Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/KP10_oxgb.csv","text/html":"<a href='KP10_oxgb.csv' target='_blank'>KP10_oxgb.csv</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Appendix:\n#### Exploring XGBoost predictions with PR curve","metadata":{}},{"cell_type":"code","source":"# Precision-Recall curve in train set\nprecision_t, recall_t, threshold = precision_recall_curve(y_train, xgbm.predict_proba(X_train)[:, 1])\nauc_precision_recall_train = auc(recall_t, precision_t)\ntemp = recall_t[(recall_t>0.195)&(recall_t<0.205)]\ntemp = temp[int(len(temp)/2)]\nindexx = ((np.where(recall_t==temp)))[0][0]\nr20prec_train = precision_t[indexx]\n\nfig, ax = plt.subplots()\nax.plot(recall_t, precision_t, color='purple')\nax.set_title('Precision-Recall Curve, train set')\nax.set_ylabel('Precision')\nax.set_xlabel('Recall')\nax.set_ylim(bottom=0, top=1.02)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-06T03:31:44.230537Z","iopub.execute_input":"2022-08-06T03:31:44.231342Z","iopub.status.idle":"2022-08-06T03:31:44.446989Z","shell.execute_reply.started":"2022-08-06T03:31:44.2313Z","shell.execute_reply":"2022-08-06T03:31:44.446095Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"display(xgbm.predict_proba(X_train)[:, 1])\ndisplay(precision_t, recall_t, threshold)","metadata":{"execution":{"iopub.status.busy":"2022-08-06T03:31:44.448443Z","iopub.execute_input":"2022-08-06T03:31:44.448926Z","iopub.status.idle":"2022-08-06T03:31:44.495171Z","shell.execute_reply.started":"2022-08-06T03:31:44.448888Z","shell.execute_reply":"2022-08-06T03:31:44.494251Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"array([0.05759007, 0.4886744 , 0.90027773, 0.93964666, 0.6307373 ,\n       0.9382993 , 0.7329252 , 0.10249637, 0.08693015, 0.7655485 ,\n       0.16671105, 0.9346553 , 0.17283529, 0.30109835, 0.41348416,\n       0.5972108 , 0.88914716, 0.89516747, 0.7759168 , 0.26943156,\n       0.47939023, 0.503356  , 0.42110527, 0.07647451, 0.55135924,\n       0.24154738, 0.9249877 , 0.1233901 , 0.2154063 , 0.64315015,\n       0.3691497 , 0.08579125, 0.9049402 , 0.08543334, 0.22322124,\n       0.13166068, 0.23616433, 0.11983263, 0.91860366, 0.25944772,\n       0.9318084 , 0.62029004, 0.93532413, 0.0575145 , 0.1648358 ,\n       0.07745197, 0.08448762, 0.04875061, 0.06085105, 0.8902183 ,\n       0.12690584, 0.62490684, 0.14663342, 0.12256721, 0.46221793,\n       0.09173054, 0.9606406 , 0.53678215, 0.07972509, 0.08552834,\n       0.8007337 , 0.47672427, 0.4270591 , 0.06085105, 0.13214801,\n       0.47273177, 0.59702176, 0.36317974, 0.89336455, 0.9736647 ,\n       0.13044435, 0.06423449, 0.28757027, 0.07805303, 0.3489416 ,\n       0.74899095, 0.08213837, 0.93030536, 0.12340131, 0.15382479,\n       0.9664305 , 0.11419851, 0.31180912, 0.9602815 , 0.04773891,\n       0.08213837, 0.9299845 , 0.07953631, 0.05080844, 0.09153768,\n       0.30750707, 0.14448275, 0.9508999 , 0.93362826, 0.5319692 ,\n       0.08773568, 0.06085105, 0.4305631 , 0.05244381, 0.11769941,\n       0.13681556, 0.08013944, 0.23710929, 0.8331138 , 0.39745143,\n       0.08552697, 0.04773891, 0.47057366, 0.29231358, 0.06032796,\n       0.27830672, 0.3767669 , 0.12942603, 0.9079247 , 0.12112405,\n       0.37173304, 0.09661717, 0.4053186 , 0.5290843 , 0.04986644,\n       0.24607944, 0.12080536, 0.12683496, 0.12734665, 0.18211022,\n       0.15405722, 0.20325755, 0.94282687, 0.08213837, 0.6134195 ,\n       0.698676  , 0.6472579 , 0.24242032, 0.14932384, 0.06423449,\n       0.27302554, 0.08213837, 0.08213837, 0.19698721, 0.15499194,\n       0.81797534, 0.3592309 , 0.435051  , 0.7654312 , 0.77649015,\n       0.12755145, 0.38183814, 0.64315015, 0.88469356, 0.10815894,\n       0.36582223, 0.9031079 , 0.10383927, 0.06933969, 0.95039624,\n       0.7390833 , 0.11983263, 0.1859863 , 0.8534546 , 0.31199753,\n       0.12205884, 0.8169367 , 0.06423449, 0.20216285, 0.1589235 ,\n       0.09406153, 0.12140556, 0.10204781, 0.9675744 , 0.06423449,\n       0.31421435, 0.9610851 , 0.49728894, 0.05535855, 0.93661755,\n       0.8739735 , 0.09526298, 0.9064075 , 0.95524323, 0.12456103,\n       0.8859873 , 0.62454385, 0.8117891 , 0.9033157 , 0.06423449,\n       0.95524323, 0.6643075 , 0.09956645, 0.07078345, 0.7773277 ,\n       0.12753229, 0.8696927 , 0.13011628, 0.06001712, 0.3622116 ,\n       0.30405024, 0.113466  , 0.9223306 , 0.10256679, 0.06085105,\n       0.36291102, 0.14062822, 0.11805464, 0.75365794, 0.05965459,\n       0.07649846, 0.5463509 , 0.08135831, 0.87933373, 0.55616385,\n       0.13403077, 0.1119016 , 0.45803326, 0.11872825, 0.20638575,\n       0.11771764, 0.06876154, 0.9356673 , 0.5925484 , 0.15687153,\n       0.16290773, 0.94302136, 0.1668034 , 0.8322063 , 0.30601645,\n       0.93725306, 0.14127772, 0.4493448 , 0.9710878 , 0.1481614 ,\n       0.22347501, 0.94084936, 0.9190628 , 0.08511243, 0.2327809 ,\n       0.06824177, 0.37508836, 0.50473225, 0.28031257, 0.8999453 ,\n       0.36566874, 0.14933775, 0.54945934, 0.8701113 , 0.11914778,\n       0.34703416, 0.20117658, 0.15200804, 0.11635166, 0.65886855,\n       0.38747022, 0.1786401 , 0.30405024, 0.7984669 , 0.13492502,\n       0.64315015, 0.04940382, 0.15059769, 0.07474084, 0.05535855,\n       0.27819872, 0.08371118, 0.898935  , 0.1626182 , 0.27578562,\n       0.259405  , 0.53802973, 0.28342992, 0.2033465 , 0.70167726,\n       0.83881104, 0.07717169, 0.39861357, 0.06423449, 0.12753229,\n       0.88023454, 0.17157066, 0.12811124, 0.06085105, 0.10926919,\n       0.44246197, 0.8702168 , 0.3916156 , 0.3622116 , 0.10133231,\n       0.10864446, 0.2524597 , 0.1841665 , 0.94544446, 0.17775424,\n       0.40455678, 0.11447731, 0.9524145 , 0.09911945, 0.16735733,\n       0.44206268, 0.1312398 , 0.2872251 , 0.89513326, 0.1066405 ,\n       0.27436852, 0.06876154, 0.40474316, 0.42628637, 0.14589743,\n       0.06085105, 0.18254277, 0.8879779 , 0.07474084, 0.13214801,\n       0.06423449, 0.1467367 , 0.40445966, 0.12185761, 0.9497722 ,\n       0.12894185, 0.34828597, 0.19076565, 0.14933775, 0.06085105,\n       0.5417539 , 0.10593569, 0.09938587, 0.86998683, 0.06085105,\n       0.08693015, 0.91754115, 0.11499077, 0.13492443, 0.09919723,\n       0.06730136, 0.09153768, 0.3945252 , 0.4996437 , 0.6681573 ,\n       0.07078345, 0.07971726, 0.16833559, 0.06876154, 0.09200528,\n       0.06837812, 0.07616375, 0.48923036, 0.4625247 , 0.6492898 ,\n       0.9374595 , 0.79308164, 0.8171703 , 0.5058938 , 0.06423449,\n       0.06730136, 0.08213837, 0.57440686, 0.70956504, 0.1649649 ,\n       0.6060062 , 0.13968953, 0.11805464, 0.07078345, 0.12491884,\n       0.5109356 , 0.8525183 , 0.52442366, 0.26943156, 0.9279359 ,\n       0.84228534, 0.73785025, 0.14932384, 0.855109  , 0.07078345,\n       0.05983861, 0.8038605 , 0.06085105, 0.16734678, 0.51664335,\n       0.14419885, 0.13892479, 0.06876154, 0.81998587, 0.14167641,\n       0.09012196, 0.10598893, 0.13957576, 0.06915187, 0.10655218,\n       0.11263213, 0.28420958, 0.08533001, 0.43873343, 0.90982574,\n       0.27795243, 0.14856961, 0.85816854, 0.22615846, 0.89521694,\n       0.15562762, 0.09978406, 0.9512016 , 0.9201382 , 0.17069057,\n       0.06730136, 0.15562762, 0.566605  , 0.11263213, 0.13412187,\n       0.5161693 , 0.79087853, 0.5354899 , 0.1960029 , 0.27946305,\n       0.13569477, 0.85751367, 0.87369263, 0.09536333, 0.9652094 ,\n       0.823784  , 0.8900148 , 0.08213837, 0.6717613 , 0.07322094,\n       0.06085105, 0.08213837, 0.9494891 , 0.55061257, 0.09629875,\n       0.17788321, 0.13945381, 0.14062822, 0.85530907, 0.198919  ,\n       0.21461906, 0.2718213 , 0.10598893, 0.7720262 , 0.19785792,\n       0.9403761 , 0.152084  , 0.8038605 , 0.4850809 , 0.8611108 ,\n       0.12561873, 0.11322047, 0.9518653 , 0.898935  , 0.93077195,\n       0.14892223, 0.09661717, 0.7494308 , 0.05920195, 0.1575421 ,\n       0.69575197, 0.07250199, 0.5077443 , 0.05585353, 0.17067587,\n       0.08572456, 0.9307747 , 0.8498113 , 0.09555266, 0.09909042,\n       0.16956623, 0.11462992, 0.11448696, 0.46221793, 0.18254277,\n       0.12630528, 0.91197175, 0.09798431, 0.07370864, 0.66467685,\n       0.18280928, 0.11621287, 0.35508057, 0.81998587, 0.44329706,\n       0.16862524, 0.16958646, 0.51386565, 0.13983703, 0.35883948,\n       0.13044435, 0.12131299, 0.9637353 , 0.07805303, 0.71833473,\n       0.8622817 , 0.11060616, 0.09798604, 0.46822497, 0.08213837,\n       0.89309126, 0.08720335, 0.3232396 , 0.11352687, 0.07078345,\n       0.08511243, 0.11218188, 0.25724632, 0.41341615, 0.16442956,\n       0.08213837, 0.23616433, 0.13783942, 0.08320058, 0.08719107,\n       0.05080844, 0.93069124, 0.07409893, 0.9306884 , 0.8555652 ,\n       0.54493535, 0.22322124, 0.6189597 , 0.9437444 , 0.52522385,\n       0.15079309, 0.20325755, 0.31989434, 0.9264185 , 0.15987995,\n       0.3692546 , 0.85515463, 0.5541904 , 0.3798342 , 0.07318102,\n       0.19312167, 0.70178854, 0.31091306, 0.49319744, 0.05678717,\n       0.58870536, 0.10015991, 0.60609174, 0.2193759 , 0.7675327 ,\n       0.4911815 , 0.25163496, 0.12327909, 0.08320058, 0.55229664,\n       0.27946305, 0.1544527 , 0.08071651, 0.911416  , 0.15024069,\n       0.09153106, 0.37438375, 0.19736797, 0.06824177, 0.45953453,\n       0.04890848, 0.12643914, 0.16753706, 0.8814726 , 0.27819872,\n       0.50161296, 0.16862524, 0.8764087 , 0.07297506, 0.14652883,\n       0.10926919, 0.33461148, 0.12416454, 0.5053786 , 0.8900148 ,\n       0.9587997 , 0.16894493, 0.12112915, 0.8785249 , 0.9004583 ,\n       0.06085105, 0.94302136, 0.78517455, 0.86150306, 0.17756897,\n       0.11015971, 0.06085105, 0.9622124 , 0.11621287, 0.16504864,\n       0.1617125 , 0.13835637, 0.44143876, 0.6717613 , 0.16671105,\n       0.87246627, 0.6994869 , 0.75283617, 0.5502307 , 0.05983861,\n       0.7700531 , 0.41778132, 0.1312398 , 0.45234364, 0.70323795,\n       0.61377364, 0.85448235, 0.91281927, 0.10769131, 0.9390163 ,\n       0.7996876 , 0.15375865, 0.04530733, 0.65883714, 0.12753229,\n       0.08346233, 0.47672427, 0.6109438 , 0.06876154, 0.77899295,\n       0.28674582, 0.07609387, 0.62562364, 0.20254698, 0.20362893,\n       0.27680686, 0.18539765, 0.89994454, 0.53007644, 0.86793065,\n       0.18013379, 0.13530637, 0.14602879, 0.13968953, 0.08213837,\n       0.9661077 , 0.26218203, 0.09153768, 0.95601106, 0.51458603,\n       0.8941137 , 0.8817227 , 0.5829718 , 0.04779771, 0.12616669,\n       0.41341615, 0.41392964, 0.6007725 , 0.21143186, 0.9198637 ,\n       0.14025167, 0.2297212 , 0.0944736 , 0.97206694, 0.17049728,\n       0.57310146, 0.20362893, 0.48194632, 0.05244381, 0.10045106,\n       0.18608414, 0.94640315, 0.06279442, 0.16819084, 0.6401778 ,\n       0.08579125, 0.18769354, 0.6717613 , 0.08213837, 0.7021249 ,\n       0.14444081, 0.1339061 , 0.7461849 , 0.8999248 , 0.92186165,\n       0.28370216, 0.9434279 , 0.04775624, 0.9625751 , 0.27444875,\n       0.481974  , 0.89580935, 0.0582961 , 0.16862524, 0.10290988,\n       0.09219795, 0.04773891, 0.13734442, 0.9422871 , 0.20362893,\n       0.13214801, 0.16819084, 0.12112915, 0.15987995, 0.28869468,\n       0.09664394, 0.12392453, 0.8159018 , 0.15027408, 0.9205111 ,\n       0.23616433, 0.1417913 , 0.3710808 , 0.5446018 , 0.07169779,\n       0.4319033 , 0.16734678, 0.04773891, 0.7654312 , 0.81729656,\n       0.8431872 , 0.97162354, 0.943962  , 0.04717859, 0.07611407,\n       0.17788321, 0.4462713 , 0.28370216, 0.34858733, 0.12643914,\n       0.08713038, 0.06983604, 0.34516713, 0.22415617, 0.50473225,\n       0.06423449, 0.52229595, 0.64315015, 0.06287126, 0.09909042,\n       0.11906359, 0.16633506, 0.06423449, 0.42224187, 0.0947094 ,\n       0.10225426, 0.7329407 , 0.14560877, 0.30592874, 0.8610515 ,\n       0.07430743, 0.11996082, 0.1723603 , 0.18257019, 0.10524745,\n       0.06184012, 0.09012196, 0.4271834 , 0.50697017, 0.34248382,\n       0.12643914, 0.5109356 , 0.64315015, 0.17404729, 0.8622817 ,\n       0.9218265 , 0.38395694, 0.10338216, 0.9610463 , 0.9460186 ,\n       0.08685369, 0.84939635, 0.81482995, 0.24289455, 0.17801552,\n       0.8682498 , 0.240233  , 0.2026147 , 0.11439114, 0.16956623,\n       0.64315015, 0.17433336, 0.8886895 , 0.40452757, 0.09173054,\n       0.13044435, 0.14035162, 0.1803477 , 0.06085105, 0.23785847,\n       0.89688814, 0.09911945, 0.18257019, 0.93364346, 0.14933775,\n       0.08101279, 0.08425833, 0.91730654, 0.8942667 , 0.09685775,\n       0.05342279, 0.4349761 , 0.33711472, 0.10287374, 0.08271927,\n       0.27477962, 0.1480703 , 0.05080844, 0.8610809 , 0.13530637,\n       0.16753706, 0.77899295, 0.09160311, 0.94858557, 0.1112029 ,\n       0.5185037 , 0.12596436, 0.4196583 , 0.94895816, 0.94851136,\n       0.14932384], dtype=float32)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([0.43162393, 0.43081312, 0.43142857, 0.43204578, 0.43959243,\n       0.44023324, 0.44152047, 0.44216691, 0.44281525, 0.44346549,\n       0.44411765, 0.44542773, 0.44608567, 0.44674556, 0.44592593,\n       0.44658754, 0.44725111, 0.4485842 , 0.44925373, 0.4505988 ,\n       0.44977511, 0.45045045, 0.45112782, 0.45180723, 0.45317221,\n       0.45385779, 0.45592705, 0.456621  , 0.45801527, 0.4587156 ,\n       0.45941807, 0.4601227 , 0.46082949, 0.46153846, 0.46224961,\n       0.46296296, 0.46367852, 0.46439628, 0.46428571, 0.46500778,\n       0.46573209, 0.4648986 , 0.465625  , 0.46708464, 0.46855346,\n       0.46929134, 0.47003155, 0.47077409, 0.46993671, 0.47068146,\n       0.47142857, 0.47217806, 0.47292994, 0.47368421, 0.47444089,\n       0.4752    , 0.47596154, 0.47672552, 0.47749196, 0.47826087,\n       0.47903226, 0.47980614, 0.48136143, 0.48214286, 0.48292683,\n       0.48371336, 0.48450245, 0.48529412, 0.48688525, 0.48768473,\n       0.48848684, 0.4892916 , 0.49009901, 0.49090909, 0.49087894,\n       0.49169435, 0.49251248, 0.49333333, 0.49415693, 0.49498328,\n       0.4958124 , 0.4966443 , 0.49579832, 0.496633  , 0.49831081,\n       0.49915398, 0.5       , 0.5008489 , 0.50255537, 0.50341297,\n       0.5042735 , 0.50513699, 0.50515464, 0.5060241 , 0.50689655,\n       0.50777202, 0.50953206, 0.51041667, 0.51130435, 0.51219512,\n       0.5113438 , 0.51223776, 0.51313485, 0.51403509, 0.51493849,\n       0.51584507, 0.51675485, 0.51590106, 0.51681416, 0.5177305 ,\n       0.51865009, 0.51957295, 0.52049911, 0.52329749, 0.52423698,\n       0.52517986, 0.52612613, 0.52898551, 0.52813067, 0.52909091,\n       0.53005464, 0.5310219 , 0.53199269, 0.53492647, 0.53690037,\n       0.53604436, 0.53903346, 0.54003724, 0.54104478, 0.54205607,\n       0.54307116, 0.54409006, 0.54613936, 0.54716981, 0.54820416,\n       0.54924242, 0.55028463, 0.5513308 , 0.55047619, 0.55152672,\n       0.55258126, 0.5547025 , 0.55576923, 0.55684008, 0.55791506,\n       0.56007752, 0.56116505, 0.56031128, 0.56140351, 0.5625    ,\n       0.56164384, 0.56078431, 0.56188605, 0.56299213, 0.56410256,\n       0.56521739, 0.56633663, 0.56746032, 0.56858847, 0.56972112,\n       0.57085828, 0.572     , 0.57545272, 0.57894737, 0.5801217 ,\n       0.58130081, 0.58248473, 0.58367347, 0.58486708, 0.58606557,\n       0.58726899, 0.58847737, 0.58969072, 0.59090909, 0.59213251,\n       0.59251559, 0.59375   , 0.59498956, 0.59623431, 0.59663866,\n       0.59578947, 0.59704641, 0.59830867, 0.59957627, 0.60084926,\n       0.60212766, 0.60341151, 0.60470085, 0.60729614, 0.60645161,\n       0.60475162, 0.6038961 , 0.60652174, 0.60917031, 0.61050328,\n       0.6123348 , 0.61368653, 0.61419069, 0.61555556, 0.6169265 ,\n       0.61830357, 0.6196868 , 0.62107623, 0.62247191, 0.62387387,\n       0.62528217, 0.62669683, 0.62811791, 0.62954545, 0.63242009,\n       0.63386728, 0.6353211 , 0.63448276, 0.6359447 , 0.63741339,\n       0.64037123, 0.64102564, 0.64252336, 0.6440281 , 0.64553991,\n       0.64705882, 0.64858491, 0.6501182 , 0.65165877, 0.65320665,\n       0.6547619 , 0.65632458, 0.65789474, 0.65947242, 0.66105769,\n       0.6626506 , 0.66425121, 0.66585956, 0.66747573, 0.67073171,\n       0.67237164, 0.67241379, 0.67160494, 0.67326733, 0.67493797,\n       0.67661692, 0.67581047, 0.67919799, 0.68090452, 0.68261965,\n       0.68434343, 0.68607595, 0.68527919, 0.69053708, 0.68974359,\n       0.69151671, 0.69329897, 0.69509044, 0.69689119, 0.6987013 ,\n       0.69791667, 0.6997389 , 0.70157068, 0.70341207, 0.70526316,\n       0.70448549, 0.70634921, 0.70744681, 0.70933333, 0.71122995,\n       0.71313673, 0.71505376, 0.71698113, 0.71891892, 0.72086721,\n       0.72282609, 0.72677596, 0.72876712, 0.73002755, 0.72928177,\n       0.73130194, 0.73259053, 0.73463687, 0.73669468, 0.73595506,\n       0.73802817, 0.73728814, 0.73654391, 0.73579545, 0.74      ,\n       0.74212034, 0.74425287, 0.74351585, 0.74277457, 0.74492754,\n       0.74709302, 0.74927114, 0.75146199, 0.75073314, 0.75294118,\n       0.75516224, 0.75739645, 0.75964392, 0.76190476, 0.7641791 ,\n       0.76646707, 0.76876877, 0.76807229, 0.7673716 , 0.76969697,\n       0.77439024, 0.77675841, 0.77607362, 0.77846154, 0.7808642 ,\n       0.78328173, 0.7826087 , 0.78504673, 0.784375  , 0.78683386,\n       0.78616352, 0.78548896, 0.78481013, 0.78730159, 0.78980892,\n       0.79233227, 0.79487179, 0.79742765, 0.8       , 0.802589  ,\n       0.80519481, 0.80781759, 0.81045752, 0.81311475, 0.81578947,\n       0.82119205, 0.82392027, 0.82333333, 0.82274247, 0.82214765,\n       0.82491582, 0.8277027 , 0.82711864, 0.82993197, 0.83276451,\n       0.83561644, 0.83848797, 0.84137931, 0.84429066, 0.84375   ,\n       0.84320557, 0.84265734, 0.84561404, 0.84507042, 0.84452297,\n       0.84397163, 0.84697509, 0.85      , 0.85304659, 0.85198556,\n       0.85507246, 0.85454545, 0.85766423, 0.85714286, 0.86346863,\n       0.86296296, 0.866171  , 0.86940299, 0.87265918, 0.87218045,\n       0.87169811, 0.87121212, 0.87072243, 0.87022901, 0.87356322,\n       0.87307692, 0.87258687, 0.87548638, 0.875     , 0.8745098 ,\n       0.87795276, 0.87747036, 0.87649402, 0.88      , 0.87951807,\n       0.87903226, 0.87854251, 0.87804878, 0.88163265, 0.8852459 ,\n       0.88477366, 0.88842975, 0.89211618, 0.89583333, 0.89539749,\n       0.89495798, 0.89451477, 0.8940678 , 0.89361702, 0.89316239,\n       0.89270386, 0.89655172, 0.8961039 , 0.89565217, 0.89956332,\n       0.90350877, 0.9030837 , 0.90707965, 0.90666667, 0.90625   ,\n       0.9103139 , 0.90990991, 0.90950226, 0.90909091, 0.9086758 ,\n       0.90825688, 0.9078341 , 0.90740741, 0.91162791, 0.91121495,\n       0.91079812, 0.91037736, 0.91469194, 0.91428571, 0.9138756 ,\n       0.91346154, 0.91304348, 0.91747573, 0.92195122, 0.92462312,\n       0.92424242, 0.92385787, 0.92857143, 0.92820513, 0.92783505,\n       0.93264249, 0.9375    , 0.93650794, 0.93617021, 0.94117647,\n       0.94086022, 0.94054054, 0.94021739, 0.93989071, 0.93956044,\n       0.94475138, 0.95      , 0.94972067, 0.9494382 , 0.94915254,\n       0.94886364, 0.94857143, 0.94827586, 0.94797688, 0.94767442,\n       0.94736842, 0.94674556, 0.94642857, 0.94610778, 0.94578313,\n       0.95151515, 0.95121951, 0.95092025, 0.95061728, 0.95      ,\n       0.94968553, 0.94936709, 0.95541401, 0.95512821, 0.95483871,\n       0.95454545, 0.96052632, 0.9602649 , 0.96      , 0.96644295,\n       0.96621622, 0.96598639, 0.96575342, 0.96551724, 0.96503497,\n       0.96478873, 0.96453901, 0.96428571, 0.96402878, 0.96376812,\n       0.96350365, 0.96323529, 0.96296296, 0.96268657, 0.96240602,\n       0.96212121, 0.96183206, 0.96153846, 0.96124031, 0.9609375 ,\n       0.96062992, 0.96825397, 0.976     , 0.97580645, 0.97560976,\n       0.97540984, 0.975     , 0.97478992, 0.97457627, 0.97435897,\n       0.97413793, 0.97391304, 0.98245614, 0.98230088, 0.98214286,\n       0.98198198, 0.99090909, 0.99082569, 0.99074074, 0.99065421,\n       0.99056604, 0.99047619, 0.99038462, 0.99029126, 0.99019608,\n       0.99009901, 0.99      , 0.98979592, 0.98969072, 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        ])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([1.        , 0.99669967, 0.99669967, 0.99669967, 0.99669967,\n       0.99669967, 0.99669967, 0.99669967, 0.99669967, 0.99669967,\n       0.99669967, 0.99669967, 0.99669967, 0.99669967, 0.99339934,\n       0.99339934, 0.99339934, 0.99339934, 0.99339934, 0.99339934,\n       0.99009901, 0.99009901, 0.99009901, 0.99009901, 0.99009901,\n       0.99009901, 0.99009901, 0.99009901, 0.99009901, 0.99009901,\n       0.99009901, 0.99009901, 0.99009901, 0.99009901, 0.99009901,\n       0.99009901, 0.99009901, 0.99009901, 0.98679868, 0.98679868,\n       0.98679868, 0.98349835, 0.98349835, 0.98349835, 0.98349835,\n       0.98349835, 0.98349835, 0.98349835, 0.98019802, 0.98019802,\n       0.98019802, 0.98019802, 0.98019802, 0.98019802, 0.98019802,\n       0.98019802, 0.98019802, 0.98019802, 0.98019802, 0.98019802,\n       0.98019802, 0.98019802, 0.98019802, 0.98019802, 0.98019802,\n       0.98019802, 0.98019802, 0.98019802, 0.98019802, 0.98019802,\n       0.98019802, 0.98019802, 0.98019802, 0.98019802, 0.97689769,\n       0.97689769, 0.97689769, 0.97689769, 0.97689769, 0.97689769,\n       0.97689769, 0.97689769, 0.97359736, 0.97359736, 0.97359736,\n       0.97359736, 0.97359736, 0.97359736, 0.97359736, 0.97359736,\n       0.97359736, 0.97359736, 0.97029703, 0.97029703, 0.97029703,\n       0.97029703, 0.97029703, 0.97029703, 0.97029703, 0.97029703,\n       0.9669967 , 0.9669967 , 0.9669967 , 0.9669967 , 0.9669967 ,\n       0.9669967 , 0.9669967 , 0.96369637, 0.96369637, 0.96369637,\n       0.96369637, 0.96369637, 0.96369637, 0.96369637, 0.96369637,\n       0.96369637, 0.96369637, 0.96369637, 0.96039604, 0.96039604,\n       0.96039604, 0.96039604, 0.96039604, 0.96039604, 0.96039604,\n       0.95709571, 0.95709571, 0.95709571, 0.95709571, 0.95709571,\n       0.95709571, 0.95709571, 0.95709571, 0.95709571, 0.95709571,\n       0.95709571, 0.95709571, 0.95709571, 0.95379538, 0.95379538,\n       0.95379538, 0.95379538, 0.95379538, 0.95379538, 0.95379538,\n       0.95379538, 0.95379538, 0.95049505, 0.95049505, 0.95049505,\n       0.94719472, 0.94389439, 0.94389439, 0.94389439, 0.94389439,\n       0.94389439, 0.94389439, 0.94389439, 0.94389439, 0.94389439,\n       0.94389439, 0.94389439, 0.94389439, 0.94389439, 0.94389439,\n       0.94389439, 0.94389439, 0.94389439, 0.94389439, 0.94389439,\n       0.94389439, 0.94389439, 0.94389439, 0.94389439, 0.94389439,\n       0.94059406, 0.94059406, 0.94059406, 0.94059406, 0.93729373,\n       0.9339934 , 0.9339934 , 0.9339934 , 0.9339934 , 0.9339934 ,\n       0.9339934 , 0.9339934 , 0.9339934 , 0.9339934 , 0.93069307,\n       0.92409241, 0.92079208, 0.92079208, 0.92079208, 0.92079208,\n       0.91749175, 0.91749175, 0.91419142, 0.91419142, 0.91419142,\n       0.91419142, 0.91419142, 0.91419142, 0.91419142, 0.91419142,\n       0.91419142, 0.91419142, 0.91419142, 0.91419142, 0.91419142,\n       0.91419142, 0.91419142, 0.91089109, 0.91089109, 0.91089109,\n       0.91089109, 0.90759076, 0.90759076, 0.90759076, 0.90759076,\n       0.90759076, 0.90759076, 0.90759076, 0.90759076, 0.90759076,\n       0.90759076, 0.90759076, 0.90759076, 0.90759076, 0.90759076,\n       0.90759076, 0.90759076, 0.90759076, 0.90759076, 0.90759076,\n       0.90759076, 0.9009901 , 0.89768977, 0.89768977, 0.89768977,\n       0.89768977, 0.89438944, 0.89438944, 0.89438944, 0.89438944,\n       0.89438944, 0.89438944, 0.89108911, 0.89108911, 0.88778878,\n       0.88778878, 0.88778878, 0.88778878, 0.88778878, 0.88778878,\n       0.88448845, 0.88448845, 0.88448845, 0.88448845, 0.88448845,\n       0.88118812, 0.88118812, 0.87788779, 0.87788779, 0.87788779,\n       0.87788779, 0.87788779, 0.87788779, 0.87788779, 0.87788779,\n       0.87788779, 0.87788779, 0.87788779, 0.87458746, 0.87128713,\n       0.87128713, 0.8679868 , 0.8679868 , 0.8679868 , 0.86468647,\n       0.86468647, 0.86138614, 0.85808581, 0.85478548, 0.85478548,\n       0.85478548, 0.85478548, 0.85148515, 0.84818482, 0.84818482,\n       0.84818482, 0.84818482, 0.84818482, 0.84488449, 0.84488449,\n       0.84488449, 0.84488449, 0.84488449, 0.84488449, 0.84488449,\n       0.84488449, 0.84488449, 0.84158416, 0.83828383, 0.83828383,\n       0.83828383, 0.83828383, 0.8349835 , 0.8349835 , 0.8349835 ,\n       0.8349835 , 0.83168317, 0.83168317, 0.82838284, 0.82838284,\n       0.82508251, 0.82178218, 0.81848185, 0.81848185, 0.81848185,\n       0.81848185, 0.81848185, 0.81848185, 0.81848185, 0.81848185,\n       0.81848185, 0.81848185, 0.81848185, 0.81848185, 0.81848185,\n       0.81848185, 0.81848185, 0.81518152, 0.81188119, 0.80858086,\n       0.80858086, 0.80858086, 0.80528053, 0.80528053, 0.80528053,\n       0.80528053, 0.80528053, 0.80528053, 0.80528053, 0.8019802 ,\n       0.79867987, 0.79537954, 0.79537954, 0.79207921, 0.78877888,\n       0.78547855, 0.78547855, 0.78547855, 0.78547855, 0.77887789,\n       0.77887789, 0.77557756, 0.77557756, 0.77227723, 0.77227723,\n       0.7689769 , 0.7689769 , 0.7689769 , 0.7689769 , 0.76567657,\n       0.76237624, 0.75907591, 0.75577558, 0.75247525, 0.75247525,\n       0.74917492, 0.74587459, 0.74257426, 0.73927393, 0.7359736 ,\n       0.7359736 , 0.73267327, 0.72607261, 0.72607261, 0.72277228,\n       0.71947195, 0.71617162, 0.71287129, 0.71287129, 0.71287129,\n       0.70957096, 0.70957096, 0.70957096, 0.70957096, 0.70627063,\n       0.7029703 , 0.69966997, 0.69636964, 0.69306931, 0.68976898,\n       0.68646865, 0.68646865, 0.68316832, 0.67986799, 0.67986799,\n       0.67986799, 0.67656766, 0.67656766, 0.67326733, 0.669967  ,\n       0.669967  , 0.66666667, 0.66336634, 0.66006601, 0.65676568,\n       0.65346535, 0.65016502, 0.64686469, 0.64686469, 0.64356436,\n       0.64026403, 0.6369637 , 0.6369637 , 0.63366337, 0.63036304,\n       0.62706271, 0.62376238, 0.62376238, 0.62376238, 0.60726073,\n       0.6039604 , 0.60066007, 0.60066007, 0.59735974, 0.59405941,\n       0.59405941, 0.59405941, 0.58415842, 0.58085809, 0.58085809,\n       0.57755776, 0.57425743, 0.5709571 , 0.56765677, 0.56435644,\n       0.56435644, 0.56435644, 0.56105611, 0.55775578, 0.55445545,\n       0.55115512, 0.54785479, 0.54455446, 0.54125413, 0.5379538 ,\n       0.53465347, 0.52805281, 0.52475248, 0.52145215, 0.51815182,\n       0.51815182, 0.51485149, 0.51155116, 0.50825083, 0.50165017,\n       0.49834983, 0.4950495 , 0.4950495 , 0.49174917, 0.48844884,\n       0.48514851, 0.48184818, 0.47854785, 0.47524752, 0.47524752,\n       0.47194719, 0.46864686, 0.46534653, 0.4620462 , 0.45544554,\n       0.45214521, 0.44884488, 0.44554455, 0.44224422, 0.43894389,\n       0.43564356, 0.43234323, 0.4290429 , 0.42574257, 0.42244224,\n       0.41914191, 0.41584158, 0.41254125, 0.40924092, 0.40594059,\n       0.40264026, 0.40264026, 0.40264026, 0.39933993, 0.3960396 ,\n       0.39273927, 0.38613861, 0.38283828, 0.37953795, 0.37623762,\n       0.37293729, 0.36963696, 0.36963696, 0.36633663, 0.3630363 ,\n       0.35973597, 0.35973597, 0.35643564, 0.35313531, 0.34983498,\n       0.34653465, 0.34323432, 0.33993399, 0.33663366, 0.33333333,\n       0.330033  , 0.32673267, 0.32013201, 0.31683168, 0.31683168,\n       0.31353135, 0.31023102, 0.30693069, 0.30363036, 0.30033003,\n       0.2970297 , 0.29372937, 0.29042904, 0.28382838, 0.28052805,\n       0.27722772, 0.27392739, 0.27062706, 0.26732673, 0.2640264 ,\n       0.26072607, 0.25742574, 0.25412541, 0.25082508, 0.24752475,\n       0.24422442, 0.24092409, 0.23762376, 0.23432343, 0.2310231 ,\n       0.22772277, 0.22442244, 0.22112211, 0.21782178, 0.21452145,\n       0.21122112, 0.20792079, 0.20462046, 0.20132013, 0.1980198 ,\n       0.19471947, 0.19141914, 0.18811881, 0.18481848, 0.18151815,\n       0.17821782, 0.17491749, 0.17161716, 0.16831683, 0.1650165 ,\n       0.16171617, 0.15841584, 0.15511551, 0.15181518, 0.14851485,\n       0.14521452, 0.14191419, 0.13861386, 0.13531353, 0.1320132 ,\n       0.12871287, 0.12541254, 0.12211221, 0.11551155, 0.11221122,\n       0.10891089, 0.10561056, 0.10231023, 0.0990099 , 0.09570957,\n       0.09240924, 0.08910891, 0.08580858, 0.08250825, 0.07920792,\n       0.07590759, 0.07260726, 0.06930693, 0.0660066 , 0.06270627,\n       0.05610561, 0.05280528, 0.04950495, 0.04620462, 0.04290429,\n       0.03960396, 0.03630363, 0.0330033 , 0.02970297, 0.02640264,\n       0.02310231, 0.01980198, 0.01650165, 0.01320132, 0.00990099,\n       0.00660066, 0.00330033, 0.        ])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([0.08071651, 0.08101279, 0.08135831, 0.08213837, 0.08271927,\n       0.08320058, 0.08346233, 0.08371118, 0.08425833, 0.08448762,\n       0.08511243, 0.08533001, 0.08543334, 0.08552697, 0.08552834,\n       0.08572456, 0.08579125, 0.08685369, 0.08693015, 0.08713038,\n       0.08719107, 0.08720335, 0.08773568, 0.09012196, 0.09153106,\n       0.09153768, 0.09160311, 0.09173054, 0.09200528, 0.09219795,\n       0.09406153, 0.0944736 , 0.0947094 , 0.09526298, 0.09536333,\n       0.09555266, 0.09629875, 0.09661717, 0.09664394, 0.09685775,\n       0.09798431, 0.09798604, 0.09909042, 0.09911945, 0.09919723,\n       0.09938587, 0.09956645, 0.09978406, 0.10015991, 0.10045106,\n       0.10133231, 0.10204781, 0.10225426, 0.10249637, 0.10256679,\n       0.10287374, 0.10290988, 0.10338216, 0.10383927, 0.10524745,\n       0.10593569, 0.10598893, 0.10655218, 0.1066405 , 0.10769131,\n       0.10815894, 0.10864446, 0.10926919, 0.11015971, 0.11060616,\n       0.1112029 , 0.1119016 , 0.11218188, 0.11263213, 0.11322047,\n       0.113466  , 0.11352687, 0.11419851, 0.11439114, 0.11447731,\n       0.11448696, 0.11462992, 0.11499077, 0.11621287, 0.11635166,\n       0.11769941, 0.11771764, 0.11805464, 0.11872825, 0.11906359,\n       0.11914778, 0.11983263, 0.11996082, 0.12080536, 0.12112405,\n       0.12112915, 0.12131299, 0.12140556, 0.12185761, 0.12205884,\n       0.12256721, 0.12327909, 0.1233901 , 0.12340131, 0.12392453,\n       0.12416454, 0.12456103, 0.12491884, 0.12561873, 0.12596436,\n       0.12616669, 0.12630528, 0.12643914, 0.12683496, 0.12690584,\n       0.12734665, 0.12753229, 0.12755145, 0.12811124, 0.12894185,\n       0.12942603, 0.13011628, 0.13044435, 0.1312398 , 0.13166068,\n       0.13214801, 0.1339061 , 0.13403077, 0.13412187, 0.13492443,\n       0.13492502, 0.13530637, 0.13569477, 0.13681556, 0.13734442,\n       0.13783942, 0.13835637, 0.13892479, 0.13945381, 0.13957576,\n       0.13968953, 0.13983703, 0.14025167, 0.14035162, 0.14062822,\n       0.14127772, 0.14167641, 0.1417913 , 0.14419885, 0.14444081,\n       0.14448275, 0.14560877, 0.14589743, 0.14602879, 0.14652883,\n       0.14663342, 0.1467367 , 0.1480703 , 0.1481614 , 0.14856961,\n       0.14892223, 0.14932384, 0.14933775, 0.15024069, 0.15027408,\n       0.15059769, 0.15079309, 0.15200804, 0.152084  , 0.15375865,\n       0.15382479, 0.15405722, 0.1544527 , 0.15499194, 0.15562762,\n       0.15687153, 0.1575421 , 0.1589235 , 0.15987995, 0.1617125 ,\n       0.1626182 , 0.16290773, 0.16442956, 0.1648358 , 0.1649649 ,\n       0.16504864, 0.16633506, 0.16671105, 0.1668034 , 0.16734678,\n       0.16735733, 0.16753706, 0.16819084, 0.16833559, 0.16862524,\n       0.16894493, 0.16956623, 0.16958646, 0.17049728, 0.17067587,\n       0.17069057, 0.17157066, 0.1723603 , 0.17283529, 0.17404729,\n       0.17433336, 0.17756897, 0.17775424, 0.17788321, 0.17801552,\n       0.1786401 , 0.18013379, 0.1803477 , 0.18211022, 0.18254277,\n       0.18257019, 0.18280928, 0.1841665 , 0.18539765, 0.1859863 ,\n       0.18608414, 0.18769354, 0.19076565, 0.19312167, 0.1960029 ,\n       0.19698721, 0.19736797, 0.19785792, 0.198919  , 0.20117658,\n       0.20216285, 0.20254698, 0.2026147 , 0.20325755, 0.2033465 ,\n       0.20362893, 0.20638575, 0.21143186, 0.21461906, 0.2154063 ,\n       0.2193759 , 0.22322124, 0.22347501, 0.22415617, 0.22615846,\n       0.2297212 , 0.2327809 , 0.23616433, 0.23710929, 0.23785847,\n       0.240233  , 0.24154738, 0.24242032, 0.24289455, 0.24607944,\n       0.25163496, 0.2524597 , 0.25724632, 0.259405  , 0.25944772,\n       0.26218203, 0.26943156, 0.2718213 , 0.27302554, 0.27436852,\n       0.27444875, 0.27477962, 0.27578562, 0.27680686, 0.27795243,\n       0.27819872, 0.27830672, 0.27946305, 0.28031257, 0.28342992,\n       0.28370216, 0.28420958, 0.28674582, 0.2872251 , 0.28757027,\n       0.28869468, 0.29231358, 0.30109835, 0.30405024, 0.30592874,\n       0.30601645, 0.30750707, 0.31091306, 0.31180912, 0.31199753,\n       0.31421435, 0.31989434, 0.3232396 , 0.33461148, 0.33711472,\n       0.34248382, 0.34516713, 0.34703416, 0.34828597, 0.34858733,\n       0.3489416 , 0.35508057, 0.35883948, 0.3592309 , 0.3622116 ,\n       0.36291102, 0.36317974, 0.36566874, 0.36582223, 0.3691497 ,\n       0.3692546 , 0.3710808 , 0.37173304, 0.37438375, 0.37508836,\n       0.3767669 , 0.3798342 , 0.38183814, 0.38395694, 0.38747022,\n       0.3916156 , 0.3945252 , 0.39745143, 0.39861357, 0.40445966,\n       0.40452757, 0.40455678, 0.40474316, 0.4053186 , 0.41341615,\n       0.41348416, 0.41392964, 0.41778132, 0.4196583 , 0.42110527,\n       0.42224187, 0.42628637, 0.4270591 , 0.4271834 , 0.4305631 ,\n       0.4319033 , 0.4349761 , 0.435051  , 0.43873343, 0.44143876,\n       0.44206268, 0.44246197, 0.44329706, 0.4462713 , 0.4493448 ,\n       0.45234364, 0.45803326, 0.45953453, 0.46221793, 0.4625247 ,\n       0.46822497, 0.47057366, 0.47273177, 0.47672427, 0.47939023,\n       0.48194632, 0.481974  , 0.4850809 , 0.4886744 , 0.48923036,\n       0.4911815 , 0.49319744, 0.49728894, 0.4996437 , 0.50161296,\n       0.503356  , 0.50473225, 0.5053786 , 0.5058938 , 0.50697017,\n       0.5077443 , 0.5109356 , 0.51386565, 0.51458603, 0.5161693 ,\n       0.51664335, 0.5185037 , 0.52229595, 0.52442366, 0.52522385,\n       0.5290843 , 0.53007644, 0.5319692 , 0.5354899 , 0.53678215,\n       0.53802973, 0.5417539 , 0.5446018 , 0.54493535, 0.5463509 ,\n       0.54945934, 0.5502307 , 0.55061257, 0.55135924, 0.55229664,\n       0.5541904 , 0.55616385, 0.566605  , 0.57310146, 0.57440686,\n       0.5829718 , 0.58870536, 0.5925484 , 0.59702176, 0.5972108 ,\n       0.6007725 , 0.6060062 , 0.60609174, 0.6109438 , 0.6134195 ,\n       0.61377364, 0.6189597 , 0.62029004, 0.62454385, 0.62490684,\n       0.62562364, 0.6307373 , 0.6401778 , 0.64315015, 0.6472579 ,\n       0.6492898 , 0.65883714, 0.65886855, 0.6643075 , 0.66467685,\n       0.6681573 , 0.6717613 , 0.69575197, 0.698676  , 0.6994869 ,\n       0.70167726, 0.70178854, 0.7021249 , 0.70323795, 0.70956504,\n       0.71833473, 0.7329252 , 0.7329407 , 0.73785025, 0.7390833 ,\n       0.7461849 , 0.74899095, 0.7494308 , 0.75283617, 0.75365794,\n       0.7654312 , 0.7655485 , 0.7675327 , 0.7700531 , 0.7720262 ,\n       0.7759168 , 0.77649015, 0.7773277 , 0.77899295, 0.78517455,\n       0.79087853, 0.79308164, 0.7984669 , 0.7996876 , 0.8007337 ,\n       0.8038605 , 0.8117891 , 0.81482995, 0.8159018 , 0.8169367 ,\n       0.8171703 , 0.81729656, 0.81797534, 0.81998587, 0.823784  ,\n       0.8322063 , 0.8331138 , 0.83881104, 0.84228534, 0.8431872 ,\n       0.84939635, 0.8498113 , 0.8525183 , 0.8534546 , 0.85448235,\n       0.855109  , 0.85515463, 0.85530907, 0.8555652 , 0.85751367,\n       0.85816854, 0.8610515 , 0.8610809 , 0.8611108 , 0.86150306,\n       0.8622817 , 0.86793065, 0.8682498 , 0.8696927 , 0.86998683,\n       0.8701113 , 0.8702168 , 0.87246627, 0.87369263, 0.8739735 ,\n       0.8764087 , 0.8785249 , 0.87933373, 0.88023454, 0.8814726 ,\n       0.8817227 , 0.88469356, 0.8859873 , 0.8879779 , 0.8886895 ,\n       0.88914716, 0.8900148 , 0.8902183 , 0.89309126, 0.89336455,\n       0.8941137 , 0.8942667 , 0.89513326, 0.89516747, 0.89521694,\n       0.89580935, 0.89688814, 0.898935  , 0.8999248 , 0.89994454,\n       0.8999453 , 0.90027773, 0.9004583 , 0.9031079 , 0.9033157 ,\n       0.9049402 , 0.9064075 , 0.9079247 , 0.90982574, 0.911416  ,\n       0.91197175, 0.91281927, 0.91730654, 0.91754115, 0.91860366,\n       0.9190628 , 0.9198637 , 0.9201382 , 0.9205111 , 0.9218265 ,\n       0.92186165, 0.9223306 , 0.9249877 , 0.9264185 , 0.9279359 ,\n       0.9299845 , 0.93030536, 0.9306884 , 0.93069124, 0.93077195,\n       0.9307747 , 0.9318084 , 0.93362826, 0.93364346, 0.9346553 ,\n       0.93532413, 0.9356673 , 0.93661755, 0.93725306, 0.9374595 ,\n       0.9382993 , 0.9390163 , 0.93964666, 0.9403761 , 0.94084936,\n       0.9422871 , 0.94282687, 0.94302136, 0.9434279 , 0.9437444 ,\n       0.943962  , 0.94544446, 0.9460186 , 0.94640315, 0.94851136,\n       0.94858557, 0.94895816, 0.9494891 , 0.9497722 , 0.95039624,\n       0.9508999 , 0.9512016 , 0.9518653 , 0.9524145 , 0.95524323,\n       0.95601106, 0.9587997 , 0.9602815 , 0.9606406 , 0.9610463 ,\n       0.9610851 , 0.9622124 , 0.9625751 , 0.9637353 , 0.9652094 ,\n       0.9661077 , 0.9664305 , 0.9675744 , 0.9710878 , 0.97162354,\n       0.97206694, 0.9736647 ], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"# Precision-Recall curve in test set\nprecision_t, recall_t, threshold = precision_recall_curve(y_test, xgbm.predict_proba(X_test)[:, 1])\nauc_precision_recall_train = auc(recall_t, precision_t)\ntemp = recall_t[(recall_t>0.18)&(recall_t<0.22)]\ntemp = temp[int(len(temp)/2)]\nindexx = ((np.where(recall_t==temp)))[0][0]\nr20prec_train = precision_t[indexx]\n\nfig, ax = plt.subplots()\nax.plot(recall_t, precision_t, color='purple')\nax.set_title('Precision-Recall Curve, test set')\nax.set_ylabel('Precision')\nax.set_xlabel('Recall')\nax.set_ylim(bottom=0, top=1.02)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-06T03:31:44.496531Z","iopub.execute_input":"2022-08-06T03:31:44.496793Z","iopub.status.idle":"2022-08-06T03:31:44.707358Z","shell.execute_reply.started":"2022-08-06T03:31:44.496759Z","shell.execute_reply":"2022-08-06T03:31:44.706484Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"# for those examples, which the model is confident about, it could make sense to set predicted probability as 1.","metadata":{"execution":{"iopub.status.busy":"2022-08-06T03:31:44.708969Z","iopub.execute_input":"2022-08-06T03:31:44.710619Z","iopub.status.idle":"2022-08-06T03:31:44.717433Z","shell.execute_reply.started":"2022-08-06T03:31:44.71051Z","shell.execute_reply":"2022-08-06T03:31:44.715207Z"},"trusted":true},"execution_count":41,"outputs":[]}]}